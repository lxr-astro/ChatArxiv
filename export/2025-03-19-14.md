# machine learning
## An Effective Theory of Bias Amplification
- **Url**: http://arxiv.org/abs/2410.17263v4
- **Authors**: ['Arjun Subramonian', 'Samuel J. Bell', 'Levent Sagun', 'Elvis Dohmatob']
- **Abstrat**: Machine learning models can capture and amplify biases present in data, leading to disparate test performance across social groups. To better understand, evaluate, and mitigate these biases, a deeper theoretical understanding of how model design choices and data distribution properties contribute to bias is needed. In this work, we contribute a precise analytical theory in the context of ridge regression, both with and without random projections, where the former models feedforward neural networks in a simplified regime. Our theory offers a unified and rigorous explanation of machine learning bias, providing insights into phenomena such as bias amplification and minority-group bias in various feature and parameter regimes. For example, we observe that there may be an optimal regularization penalty or training time to avoid bias amplification, and there can be differences in test error between groups that are not alleviated with increased parameterization. Importantly, our theoretical predictions align with empirical observations reported in the literature on machine learning bias. We extensively empirically validate our theory on synthetic and semi-synthetic datasets.


**Summary**: 

- (1): 这篇文章的研究背景是机器学习模型可能会捕捉和放大数据中存在的偏见，导致社会群体之间的测试表现不平等。
 
- (2): 以往的方法已经显示出偏见放大的问题，但机制尚不清晰。作者提出了一个全面且严格的理论框架，具有针对性地解释了偏见的产生。作者的方法不仅有严谨的理论支持，还通过综合验证与之前的研究成果相吻合。
 
- (3): 本文的贡献在于提出了一种有效的理论框架，解释了模型设计选择和数据分布特性如何影响偏见的放大现象，进一步提供了对机器学习偏见的深入理解。
 
- (4): 文中提出的研究方法主要涉及在岭回归框架下进行精确的分析理论，以及在随机投影的情况下分析前馈神经网络的模型。
 
- (5): 本文在综合验证中采用了合成和半合成数据集，实现了对理论的广泛实证验证，展示了该方法的有效性。


## La Méthode du Gradient Proximé
- **Url**: http://arxiv.org/abs/2503.14479v1
- **Authors**: ['Patrick L. Combettes']
- **Abstrat**: English version of abstract for "The Proximal Gradient Method": The proximal gradient method is a splitting algorithm for the minimization of the sum of two convex functions, one of which is smooth. It has applications in areas such as mechanics, inverse problems, machine learning, image reconstruction, variational inequalities, statistics, operations research, and optimal transportation. Its formalism encompasses a wide variety of numerical methods in optimization such as gradient descent, projected gradient, iterative thresholding, alternating projections, the constrained Landweber method, as well as various algorithms in statistics and sparse data analysis. This paper aims at providing an account of the main properties of the proximal gradient method and to discuss some of its applications. -- -- -- -- -- -  R\'esum\'e : La m\'ethode du gradient proxim\'e est un algorithme d'\'eclatement pour la minimisation de la somme de deux fonctions convexes, dont l'une est lisse. Elle trouve des applications dans des domaines tels que la m\'ecanique, le traitement du signal, les probl\`emes inverses, l'apprentissage automatique, la reconstruction d'images, les in\'equations variationnelles, les statistiques, la recherche op\'erationnelle et le transport optimal. Son formalisme englobe une grande vari\'et\'e de m\'ethodes num\'eriques en optimisation, telles que la descente de gradient, le gradient projet\'e, la m\'ethode de seuillage it\'eratif, la m\'ethode des projections altern\'ees, la m\'ethode de Landweber contrainte, ainsi que divers algorithmes en statistique et en analyse parcimonieuse de donn\'ees. Cet article vise \`a donner un aper\c{c}u des principales propri\'et\'es de la m\'ethode du gradient proxim\'e et d'aborder certaines de ses applications.


**Summary**: 

- (1):本文研究的背景是探讨出一个用于两个凸函数求最小值的拆分算法；
 
- (2):过去的方法包括梯度下降等，面临的问题是运算复杂度高、收敛速度慢。提出的方法不同在于融合了梯度下降和投影梯度等多种方法，在解决问题上更灵活有效，动机充分；
 
- (3):本文的贡献在于提供了对拆分梯度法的主要特性和一些应用的概述；
 
- (4):本文提出的研究方法是使用一种称为拆分梯度法的算法来求解两个凸函数的最小值问题；
  
- (5):在此文中，提出的方法在机械、逆问题、机器学习、图像重建等领域具有较高性能，支持了其研究目标。


## EnQode: Fast Amplitude Embedding for Quantum Machine Learning Using Classical Data
- **Url**: http://arxiv.org/abs/2503.14473v1
- **Authors**: ['Jason Han', 'Nicholas S. DiBrita', 'Younghyun Cho', 'Hengrui Luo', 'Tirthak Patel']
- **Abstrat**: Amplitude embedding (AE) is essential in quantum machine learning (QML) for encoding classical data onto quantum circuits. However, conventional AE methods suffer from deep, variable-length circuits that introduce high output error due to extensive gate usage and variable error rates across samples, resulting in noise-driven inconsistencies that degrade model accuracy. We introduce EnQode, a fast AE technique based on symbolic representation that addresses these limitations by clustering dataset samples and solving for cluster mean states through a low-depth, machine-specific ansatz. Optimized to reduce physical gates and SWAP operations, EnQode ensures all samples face consistent, low noise levels by standardizing circuit depth and composition. With over 90% fidelity in data mapping, EnQode enables robust, high-performance QML on noisy intermediate-scale quantum (NISQ) devices. Our open-source solution provides a scalable and efficient alternative for integrating classical data with quantum models.


**Summary**: 

- (1):该论文研究背景为量子机器学习（Quantum Machine Learning，QML）中的传统挑战和问题；

- (2):过去的方法存在深层、长度可变的量子电路，导致输出误差高，提出的EnQode方法通过集群数据样本、低深度机器定制方案解决这些问题，其动机充分；

- (3):本文的贡献在于引入EnQode技术，实现数据到量子模型的高效嵌入；

- (4):本文提出的研究方法是通过符号表示进行快速幅度嵌入，通过聚类数据样本和优化量子电路构成实现；

- (5):EnQode技术在嘈杂的中等规模量子设备上取得了90%以上的数据映射保真度，支持高性能的量子机器学习任务。


## Information Fusion in Smart Agriculture: Machine Learning Applications and Future Research Directions
- **Url**: http://arxiv.org/abs/2405.17465v2
- **Authors**: ['Aashu Katharria', 'Kanchan Rajwar', 'Millie Pant', 'Juan D. Velásquez', 'Václav Snášel', 'Kusum Deep']
- **Abstrat**: Machine learning (ML) is a rapidly evolving technology with expanding applications across various fields. This paper presents a comprehensive survey of recent ML applications in agriculture for sustainability and efficiency. Existing reviews mainly focus on narrow subdomains or lack a fusion-driven perspectives. This study provides a combined analysis of ML applications in agriculture, structured around five key objectives: (i) Analyzing ML techniques across pre-harvesting, harvesting, and post-harvesting phases. (ii) Demonstrating how ML can be used with agricultural data and data fusion. (iii) Conducting a bibliometric and statistical analysis to reveal research trends and activity. (iv) Investigating real-world case studies of leading artificial intelligence (AI)-driven agricultural companies that use different types of multisensors and multisource data. (v) Compiling publicly available datasets to support ML model training. Going beyond existing previous reviews, this review focuses on how machine learning (ML) techniques, combined with multi-source data fusion (integrating remote sensing, IoT, and climate analytics), enhance precision agriculture by improving predictive accuracy and decision-making. Case studies and statistical insights illustrate the evolving landscape of AI driven smart farming, while future research directions also discusses challenges associated with data fusion for heterogeneous datasets. This review bridges the gap between AI research and agricultural applications, offering a roadmap for researchers, industry professionals, and policymakers to harness information fusion and ML for advancing precision agriculture.


**Summary**: 

- (1):这篇文章的研究背景是人工智能（Artificial Intelligence）在农业领域的应用和发展；
 
- (2):过去的方法包括专家系统和传统方法，在应对气候变化、资源有限性等问题上存在不足。文章提出了结合信息融合的机器学习（Machine Learning）方法，以提高精度农业的预测准确性和决策制定。该方法的动机合理，能够有效解决现有方法面临的问题；
 
- (3):本文的贡献在于提供了对农业领域中机器学习应用的全面综述，重点关注信息融合对精度农业的改进，并提供了未来研究方向；
 
- (4):本文的研究方法包括分析机器学习在农业预收获、收获和售后阶段的应用，以及实地案例研究和统计数据分析；
  
- (5):本文的方法在预收获、收获和售后阶段应用机器学习技术，取得了较高的准确度和效率，支持了文章的研究目标。


## FNDaaS: Content-agnostic Detection of Fake News sites
- **Url**: http://arxiv.org/abs/2212.06492v2
- **Authors**: ['Panagiotis Papadopoulos', 'Dimitris Spithouris', 'Evangelos P. Markatos', 'Nicolas Kourtellis']
- **Abstrat**: Automatic fake news detection is a challenging problem in misinformation spreading, and it has tremendous real-world political and social impacts. Past studies have proposed machine learning-based methods for detecting such fake news, focusing on different properties of the published news articles, such as linguistic characteristics of the actual content, which however have limitations due to the apparent language barriers. Departing from such efforts, we propose Fake News Detection-as-a Service (FNDaaS), the first automatic, content-agnostic fake news detection method, that considers new and unstudied features such as network and structural characteristics per news website. This method can be enforced as-a-Service, either at the ISP-side for easier scalability and maintenance, or user-side for better end-user privacy. We demonstrate the efficacy of our method using more than 340K datapoints crawled from existing lists of 637 fake and 1183 real news websites, and by building and testing a proof of concept system that materializes our proposal. Our analysis of data collected from these websites shows that the vast majority of fake news domains are very young and appear to have lower time periods of an IP associated with their domain than real news ones. By conducting various experiments with machine learning classifiers, we demonstrate that FNDaaS can achieve an AUC score of up to 0.967 on past sites, and up to 77-92% accuracy on newly-flagged ones.


**Summary**: 

- (1):该论文研究的背景是自动检测虚假新闻在信息传播中的重要性;

- (2):过去的方法基于文章内容的语言特征进行虚假新闻检测，存在语言屏障和无法覆盖多语言网站等问题。提出的方法是内容无关的虚假新闻检测方法，主要关注新闻网站的网络和结构特征。该方法能够有效解决现有方法的局限性，并具有很强的动机性;

- (3):本文的贡献在于设计了一种全新的虚假新闻检测方法FNDaaS;

- (4):本文提出的研究方法是基于网站的网络和结构特征检测虚假新闻;

- (5):该方法在过去网站实验中取得了高达0.967的AUC分数，在新标记的网站上获得了77-92%的准确性，说明方法能够支持其目标。

# blackhole
# galaxy
## Low-Metallicity Star Formation Survey in Sh2-284 (LZ-STAR). I. Ordered massive star formation in the outer Galaxy
- **Url**: http://arxiv.org/abs/2503.14460v1
- **Authors**: ['Yu Cheng', 'Jonathan C. Tan', 'Morten Andersen', 'Rubén Fedriani', 'Yichen Zhang', 'Massimo Robberto', 'Zhi-Yun Li', 'Kei E. I. Tanaka']
- **Abstrat**: Star formation is a fundamental, yet poorly understood, process of the Universe. It is important to study how star formation occurs in different galactic environments. Thus, here, in the first of a series of papers, we introduce the Low-Metallicity Star Formation (LZ-STAR) survey of the Sh2-284 (hereafter S284) region, which, at $Z\sim 0.3-0.5Z_\odot$, is one of the lowest-metallicity star-forming regions of our Galaxy. LZ-STAR is a multi-facility survey, including observations with {\it JWST}, {\it ALMA}, {\it HST}, {\it Chandra} and {\it Gemini}. As a starting point, we report {\it JWST} and {\it ALMA} observations of one of the most massive protostars in the region, S284p1. The observations of shock-excited molecular hydrogen reveal a symmetric, bipolar outflow originating from the protostar, spanning several parsecs, and fully covered by the {\it JWST} field of view and the {\it ALMA} observations of CO(2-1) emission. This allows us to infer that the protostar has maintained a relatively stable orientation of disk accretion over its formation history. The {\it JWST} near-IR continuum observations detect a centrally illuminated bipolar outflow cavity around the protostar, as well as a surrounding cluster of low-mass young stars. We develop new radiative transfer models of massive protostars designed for the low metallicity of S284. Fitting these models to the protostar's spectral energy distribution implies a current protostellar mass of $\sim11\:M_\odot$ has formed from an initially $\sim100\:M_\odot$ core over the last $\sim3\times10^5$ years. Overall, these results indicate that massive stars can form in an ordered manner in low-metallicity, protocluster environments.


**Summary**: 

- (1):本文研究背景为在Sharpoless 2-284区域进行低金属丰度星际物质的星团形成调查。
 
- (2):过去方法主要集中于较近目标，如大和小麦哲伦云等，新方法利用现代观测设备开展系统调查，解决了低金属度星际环境下恒星形成的机制问题。提出方法具有充分的动机，能够精确解决前人方法的局限性。
 
- (3):本文展示了在Sharpoless 2-284区域进行Low-Metallicity Star Formation Survey的实证研究结果，揭示了低金属环境下大质量恒星的有序形成方式。
 
- (4):研究方法包括使用多个观测设备（如JWST，ALMA等）进行对Sharpoless 2-284区域内一个大质量原恒星的观测，并基于这些数据开展新的放射传递模型研究。
 
- (5):本文首次展示了在低金属丰度环境中恒星的有序形成，并通过方法的性能展示，支持了研究目的。


## Constraints on the early Universe star formation efficiency from galaxy clustering and halo modeling of H$α$ and [O III] emitters
- **Url**: http://arxiv.org/abs/2503.14280v1
- **Authors**: ['Marko Shuntov', 'Pascal A. Oesch', 'Sune Toft', 'Romain A. Meyer', 'Alba Covelo-Paz', 'Louise Paquereau', 'Rychard Bouwens', 'Gabriel Brammer', 'Viola Gelli', 'Emma Giovinazzo', 'Thomas Herard-Demanche', 'Garth D. Illingworth', 'Charlotte Mason', 'Rohan P. Naidu', 'Andrea Weibel', 'Mengyuan Xiao']
- **Abstrat**: We develop a theoretical framework to provide observational constraints on the early Universe galaxy-halo connection by combining measurements of the UV luminosity function (UVLF) and galaxy clustering via the 2-point correlation function (2PCF). We implemented this framework in the FRESCO and CONGRESS JWST NIRCam/grism surveys by measuring the 2PCF of spectroscopically selected samples of H$\alpha$ and [OIII] emitters at $3.8<z<9$ in 124 arcmin$^2$ in GOODS-N and GOODS-S. By fitting the 2PCF and UVLF at $3.8<z<9$ we inferred that the H$\alpha$ and [OIII] samples at $\langle z \rangle \sim4.3, 5.4$ and $7.3$ reside in halos of masses of log$(M_{\rm h}/$M$_{\odot}) = 11.5$, $11.2$, $11.0$ respectively, while their galaxy bias increases with redshift with values of $b_{\rm g} = 4.0$, $5.0$, $7.6$. These halos do not represent extreme overdense environments at these epochs. We constrain the instantaneous star formation efficiency (SFE), defined as the ratio of the star formation rate over the baryonic accretion rate as a function of halo mass. The SFE rises with halo mass, peaks at $\sim20\%$ at $M_{\rm h} \sim 3 \times 10^{11}\, M_{\odot}$, and declines at higher halo masses. The SFE-$M_{\rm h}$ shows only a mild evolution with redshift with tentative indications that low mass halos decrease but the high mass halos increase in efficiency with redshift. The scatter in the $M_{\rm UV}-M_{\rm h}$ relation, quantified by $\sigma_{\rm UV}$, implies stochasticity in the UV luminosities of $\sim 0.7$ mag, relatively constant with z. Extrapolating our model to $z>9$ shows that a constant SFE-$M_{\rm h}$ fixed at $z=8$ cannot reproduce the observed UVLF and neither high maximum SFE nor high stochasticity alone can explain the high abundances of luminous galaxies seen by JWST. Extending the analysis of the UVLF and 2PCF to $z>9$ measured from wider surveys will be crucial in breaking degeneracies.


**Summary**: 

- (1):本文研究背景是解释由詹姆斯·韦伯空间望远镜（JWST）揭示的早期宇宙中明亮和庞大星系的高丰度现象；

- (2):过去的方法包括提高早期宇宙中星形成效率的机制和增加UV光度的随机性的机制。但这些方法存在的问题是无法解释JWST数据中观察到的高星系丰度。而作者提出的方法通过结合UV光度函数（UVLF）和星系聚集度，提供了观测量数据和理论框架，以解决这些问题，并具有较强动机；

- (3):本文的贡献在于提供了关于早期宇宙星系-暗物质晕关联关系的理论框架，揭示了星系形成效率随暗物质晕质量变化的趋势；

- (4):本文采用在 FRESCO 和 CONGRESS JWST NIRCam/grism 调查中测量Hα和[O III]辐射体的二点相关函数（2PCF），从而确定了星系位于不同质量暗物质晕内的情况，进而推断星系的星形成效率；

- (5):本文的方法成功地解释了星系形成效率随暗物质晕质量变化的趋势，以及在不同红移下的演化趋势，为解释JWST观察到的明亮星系高丰度提供了关键信息。


## Populating Large N-body Simulations with LRGs Using Neural Networks
- **Url**: http://arxiv.org/abs/2503.14193v1
- **Authors**: ['M. Icaza-Lizaola', 'E. L. Sirks', 'Yong-Seon Song', 'Peder Norberg', 'Feng Shi']
- **Abstrat**: The analysis of state-of-the-art cosmological surveys like the Dark Energy Spectroscopic Instrument (DESI) survey requires high-resolution, large-volume simulations. However, the computational cost of hydrodynamical simulations at these scales is prohibitive. Instead, dark matter (DM)-only simulations are used, with galaxies populated a posteriori, typically via halo occupation distribution (HOD) models. While effective, HOD models are statistical in nature and lack full physical motivation.   In this work, we explore using neural networks (NNs) to learn the complex, physically motivated relationships between DM haloes and galaxy properties. Trained on small-volume, high-resolution hydrodynamical simulations, our NN predicts galaxy properties in a larger DM-only simulation and determines which galaxies should be classified as luminous red galaxies (LRGs).   Comparing the original LRG sample to the one generated by our NN, we find that, while the subhalo mass distributions are similar, our NN selects fewer low-mass subhaloes as LRG hosts, possibly due to the absence of baryonic feedback effects in DM-only simulations. This feedback could brighten or redden galaxies, altering their classification.   Finally, we generate a new LRG sample by fitting an HOD model to the NN-generated LRG sample. We verify that both the HOD- and NN-generated samples preserve a set of bias parameter relations, which assume that the higher-order parameters, $b_{s2}$ and $b_{3\rm{nl}}$, are determined by the linear bias parameter $b_{1}$. These relations are commonly used to simplify clustering analyses.


**Summary**: 

- (1):该文章的研究背景是针对如Dark Energy Spectroscopic Instrument (DESI) survey这样的宇宙学调查需要高分辨率、大体积模拟的需求。

- (2):过去的方法使用Halo Occupation Distribution (HOD) 模型来将星系添加到暗物质模拟中，缺乏完整的物理动机。而提出的方法使用神经网络(NN)来学习暗物质晕和星系性质之间的关系，并解决了HOD模型中的统计性质和缺乏物理动机的问题。新方法通过神经网络准确预测星系的性质、解决联合星系宿主的问题，耦合了暗物质和星系性质，提供了有力的动机。

- (3):本文的贡献是提出了使用神经网络在大N-body模拟中生成Luminous Red Galaxies（LRGs），并证实了生成的样本保留偏差参数关系。

- (4):本文的研究方法是在小体积、高分辨率的水动力学模拟上训练神经网络，预测大DM-only模拟中的星系属性，并确定应将哪些星系归类为LRGs。然后通过将HOD模型拟合到NN生成的LRG样本，生成新的LRG样本。

- (5):该方法的任务是在大N-body模拟中使用神经网络生成LRGs，并在选择LRGs方面取得了良好的性能，支持了他们的目标。

