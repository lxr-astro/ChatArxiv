# blackhole
# M87
## Traversable Wormholes Sourced by Dark Matter in Loop Quantum Cosmology
- **Url**: http://arxiv.org/abs/2411.12063v3
- **Authors**: ['Marcos V. de S. Silva', 'G. Alencar', 'R. N. Costa Filho', 'R. M. P. Neves', 'Celio R. Muniz']
- **Abstrat**: In this work, we investigate the existence of wormholes within the framework of Loop Quantum Cosmology, using isotropic dark matter as the source. We analyze three distinct density profiles and solve the modified gravity field equations alongside the stress-energy tensor conservation, applying appropriate boundary conditions to obtain traversable wormhole solutions. Each solution is shown to satisfy the geometric criteria for wormholes, and their regularity is verified by computing the Kretschmann scalar to ensure the absence of singularities under determined conditions. Additionally, we examine the stress-energy tensor to identify scenarios in which energy conditions are violated within this model. The wormhole geometry is further explored through embedding diagrams, and the amount of exotic matter required to sustain these structures is computed using the Volume Integral Quantifier. Finally, we study the shadow produced by our wormhole solution, considering one of the dark matter density profiles, and compare it with observations of the M87 galaxy.


**Translated Abstract**: 

在本工作中，我们在Loop Quantum Cosmology的框架内研究了穿越虫洞的存在，使用各向同性的暗物质作为源。我们分析了三种不同的密度分布，解算了修改过的引力场方程以及应力-能量张量守恒，应用适当的边界条件以获得可穿越的虫洞解。每个解都被证明满足虫洞的几何标准，并通过计算Kretschmann标量验证其规律性，以确保在确定条件下不存在奇点。此外，我们考察了应力-能量张量，以识别在该模型中违反能量条件的情景。通过嵌入图进一步探索了虫洞几何，并使用体积积分量化器计算维持这些结构所需的奇异物质的量。最后，我们研究了根据一个暗物质密度分布产生的虫洞解决方案所形成的阴影，并将其与M87星系的观测结果进行比较。

**Summary**:

- (1): 本文的研究背景是爱因斯坦广义相对论（General Relativity）成功地描述了重力现象，也引入了可穿越虫洞的概念。而在Loop Quantum Cosmology (LQC)框架下，量子引力效应可能使虫洞不再需要特殊的“奇异物质”。

- (2): 过去的方法主要集中在广义相对论框架中构造虫洞，通常需要违反能量条件的奇异物质，这带来了稳定性问题。本文提出的方案不同于传统方法，探讨了利用各向同性暗物质作为虫洞的源，并证明该暗物质在某些条件下能够支持虫洞的结构。

- (3): 本文的贡献在于通过LQC框架下探讨了由暗物质支撑的可穿越虫洞的解决方案，包括多种密度分布模型的分析，并提供了关於虫洞几何和奇异物质需求的量化结果。

- (4): 本文的研究方法包括分析三种冷暗物质模型，利用LQC修改的爱因斯坦方程及守恒方程，推导出相应的虫洞形状和红移函数，以评估几何条件和规律性。

- (5): 研究表明，所提出的方法成功获得了穿越虫洞的解，特别是针对NFW暗物质密度分布，形成的阴影也与M87星系的观测结果相一致，从而支持了其目标。


# galaxy
## An overview of what current data can (and cannot yet) say about evolving dark energy
- **Url**: http://arxiv.org/abs/2502.10264v2
- **Authors**: ['William Giarè', 'Tariq Mahassen', 'Eleonora Di Valentino', 'Supriya Pan']
- **Abstrat**: Recent measurements of Baryon Acoustic Oscillations (BAO) and distance moduli from Type Ia supernovae suggest a preference for Dynamical Dark Energy (DDE) scenarios characterized by a time-varying equation of state (EoS). This focused review assesses its robustness across independent measurements and surveys. Using the Chevallier-Polarski-Linder (CPL) parametrization to describe the evolution of the DE EoS, we analyze over 35 dataset combinations, incorporating Planck Cosmic Microwave Background (CMB) anisotropies, three independent Type Ia supernova (SN) catalogs (PantheonPlus, Union3, DESY5), BAO measurements from DESI and SDSS, and expansion rate measurements $H(z)$ inferred from the relative ages of massive, passively evolving galaxies at early cosmic times known as Cosmic Chronometers (CC). This review has two main objectives: first, to evaluate the statistical significance of the DDE preference across different dataset combinations, which incorporate varying sources of information. Specifically, we consider cases where only low-redshift probes are used in different combinations, others where individual low-redshift probes are analyzed together with CMB data, and finally, scenarios where high- and low-redshift probes are included in all possible independent combinations. Second, we provide a reader-friendly synthesis of what the latest cosmological and astrophysical probes can (and cannot yet) reveal about DDE. Overall, our findings highlight that combinations that \textit{simultaneously} include PantheonPlus SN and SDSS BAO significantly weaken the preference for DDE. However, intriguing hints supporting DDE emerge in combinations that do not include DESI-BAO measurements: SDSS-BAO combined with SN from Union3 and DESY5 (with and without CMB) support the preference for DDE.


**Translated Abstract**: 

最近的巴里子声学波动（BAO）和来自Ia型超新星的距离模量的测量表明对动态暗能量（DDE）场景的偏好，这些场景以随时间变化的状态方程（EoS）为特征。这篇集中审查评估了其在独立测量和调查中的稳健性。使用Chevallier-Polarski-Linder（CPL）参数化来描述DE EoS的演化，我们分析了超过35个数据集组合，包括Planck宇宙微波背景（CMB）各向异性、三个独立的Ia型超新星（SN）目录（PantheonPlus、Union3、DESY5）、来自DESI和SDSS的BAO测量，以及通过被动演化星系在早期宇宙时相对年龄推导的扩张率H(z)测量。此审查有两个主要目标：第一，评估不同数据集组合中DDE偏好的统计显著性；第二，为读者友好地总结最新的宇宙学和天体物理探针能够（以及尚未能）揭示关于DDE的内容。总体上，我们的发现表明，同时包含PantheonPlus SN和SDSS BAO的组合显著削弱了对DDE的偏好。然而，在不包含DESI-BAO测量的组合中，SDSS-BAO结合Union3和DESY5的SN（无论是否包含CMB）支持对DDE的偏好。

**Summary**:

- (1): 本文的研究背景是发现宇宙正经历加速扩张，这对物理学的基本理论提出了挑战，特别是在解释暗能量（DE）的性质方面。

- (2): 过去的方法主要假设暗能量的状态方程是常数，而本文提出的动态暗能量（DDE）方法允许状态方程随宇宙的扩张而变化。该方法通过考虑多种数据集组合来解决不足，从而更全面地评估暗能量的行为。

- (3): 这篇论文的贡献在于评估了DDE偏好的统计显著性，并总结了当前观测数据能揭示的有关DDE的知识。

- (4): 本文的研究方法包括分析超过35个数据集组合，使用CPL参数化，同时结合了CMB、超新星和BAO等多种数据源。

- (5): 本文的方法经过分析发现，在不包括DESI-BAO测量的组合中，DDE的偏好得到了支持，而包含PantheonPlus SN和SDSS BAO的组合则减弱了这种偏好。这表明当前数据在评估DDE方面存在一定的潜力，但仍需进一步研究。


## Ultraviolet Compactness of High-Redshift Galaxies as a Tracer of Early-Stage Gas Infall, Bursty Star Formation, and Offset from the Fundamental Metallicity Relation
- **Url**: http://arxiv.org/abs/2307.06336v2
- **Authors**: ['Danial Langeroodi', 'Jens Hjorth']
- **Abstrat**: The empirical anti-correlation between gas-phase metallicity and star formation rate (SFR), known as the fundamental metallicity relation (FMR), is generally understood as an equilibrium state in the interplay between gas infall, enrichment, and gas removal in galaxies. NIRSpec spectroscopy has shown a $z>3$ deviation from the local-universe calibration of the FMR, suggesting that these galaxies are potentially caught out of equilibrium. To investigate this, we measured the stellar population, nebular, and morphological properties of 427 galaxies at $3<z<10$ based on their uniformly reduced NIRSpec prism spectroscopy and NIRCam photometry. We find that a mass-size relation is already established at $4<z<10$, with a normalization anti-correlated with redshift. The size-redshift anti-correlation depends on stellar mass: while the size of $M_*<10^8M_{\odot}$ galaxies strongly declines with redshift, $M_*>10^9M_{\odot}$ galaxies exhibit negligible redshift evolution. Furthermore, we confirm the redshift evolution of the FMR: $z>3$ galaxies appear metal deficient compared to what is expected for their stellar mass and SFR based on the local-universe FMR. This offset grows with redshift. We find that metal deficiency is correlated with compactness: the most compact galaxies (those most offset from the average mass-size relation) are the most unexpectedly-metal-poor by being the most offset from the local-universe FMR. We interpret this as a consequence of bursty star formation: compact galaxies exhibit elevated SFR surface densities, indicating that they are observed during burst episodes induced by fresh gas infall. While the accretion of metal-poor gas has reduced their gas-phase metallicity by diluting the ISM, they are observed prior to chemical yield release by newly formed massive stars. Simply, they are chemically out of equilibrium compared to the equilibrium state known as the FMR.


**Translated Abstract**: 

气相金属丰度与恒星形成率（SFR）之间的经验反相关关系被称为基本金属丰度关系（FMR），一般被理解为气体流入、富集和气体去除之间的平衡状态的体现。NIRSpec光谱观测显示，z > 3的星系在FMR的局部宇宙校准中存在偏差，这表明这些星系可能处于非平衡状态。为了研究这一现象，我们基于均一化的NIRSpec棱镜光谱和NIRCam光度测量，分析了427个在3 < z < 10的星系的恒星种群、气体和形态特征。我们发现，在4 < z < 10的星系中已经建立了质量-尺寸关系，其归一化与红移反相关。这个尺寸-红移反相关关系依赖于恒星质量：当M_* < 10^8M⊙时，星系的尺寸随红移显著下降，而M_* > 10^9M⊙的星系则几乎没有红移演化。此外，我们确认FMR的红移演化：z > 3的星系相比于其恒星质量和SFR所期望的金属丰度显得缺乏金属，这种偏差随红移加大。我们发现金属缺乏与紧凑度相关：最紧凑的星系（与平均质量-尺寸关系偏离最大的）金属丰度最意外地低，因为它们与局部宇宙FMR的偏差也最大。我们认为这是由间歇性星形成的结果：紧凑星系表现出升高的SFR表面密度，表明它们在新气体流入引发的突发星形成期间被观察到。由于金属贫乏的气体的积累使得它们的气相金属丰度被稀释，它们在新形成的巨星释放化学产物之前被观测到。简单来说，相比于被称为FMR的平衡状态，它们在化学上处于非平衡状态。

**Summary**:

- (1): 本文研究了气相金属丰度与恒星形成率（SFR）之间的基本金属丰度关系（FMR），探讨了z > 3星系在其金属丰度表现方面的偏离，揭示了宇宙早期星系的非平衡状态。

- (2): 过去通过地基光谱仪研究质量-金属丰度关系，发现大约z ≈ 3.5的星系在金属丰度上显著低于局部宇宙，难以探测更高红移的星系，因光谱线受到红移影响。本文采用JWST NIRSpec提供的光谱观测，自z ≈ 3到z ≈ 10，克服了之前的观测限度，更全面地分析了高红移星系的金属丰度。

- (3): 本文的贡献在于首次基于NIRSpec观测对427个高红移星系的金属丰度和恒星形成特性进行了系统分析，揭示了金属贫乏与紧凑度的相关性，指出紧凑星系在气体流入期间的间歇性星形成引起了其金属丰度偏低。

- (4): 研究方法包括使用JWST NIRSpec和NIRCam对高红移（3 < z < 10）星系进行统一的数据收集，分析其恒星种群、气体和形态特征，并确认质量-尺寸关系及FMR演化。

- (5): 该研究在解析z > 3星系的金属丰度与其恒星形成率方面取得了显著成果，确认了金属贫乏与紧凑度的关系，这一发现支持了物理模型的目标，即理解宇宙早期星系的形成和演化过程。


## Using simulation based inference on tidally perturbed dwarf galaxies: the dynamics of NGC205
- **Url**: http://arxiv.org/abs/2501.13148v2
- **Authors**: ['Axel Widmark', 'Kathryn V. Johnston']
- **Abstrat**: We develop a novel approach to performing precision inference on tidally perturbed dwarf galaxies. We use a Bayesian inference framework of implicit likelihood inference, previously applied mainly in the field of cosmology, based on forward simulation, data compression, and likelihood emulation with neural density estimators. We consider the case of NGC205, a satellite of M31. NGC205 exhibits an S-shape in the mean line-of-sight velocity along its semi-major spatial axis, suggestive of tidal perturbation. We demonstrate that this velocity profile can be qualitatively reproduced even if NGC205 was in a spherically symmetric and isotropic state before its most recent pericenter passage. We apply our inference method to mock data and show that the precise shape of a perturbed satellite's sky-projected internal velocity field can be highly informative of both its orbit and total mass density profile, even in the absence of proper motion information. For the actual NGC205, our method is hampered because the available data only covers a line along its semi-major axis, rather than the full sky-projected field. This shortcoming could be addressed with another round of observations.


**Translated Abstract**: 

我们开发了一种新颖的方法来对潮汐干扰的矮星系进行精确推断。我们使用一种基于前向模拟、数据压缩和利用神经密度估计的隐式似然推断的贝叶斯推断框架，该框架以前主要应用于宇宙学领域。我们考虑了M31的卫星NGC205的案例。NGC205在其半主轴的平均视线速度上表现出S形特征，暗示其受到潮汐扰动。我们证明，即使在最近一次近心点通过之前，NGC205处于球形对称和各向同性状态的情况下，其速度轮廓也可以定性地再现。我们将推断方法应用于模拟数据，表明即使在缺乏适当运动信息的情况下，被扰动卫星的天空投影内部速度场的精确形状也可以提供有关其轨道和总质量密度分布的重要信息。对于实际的NGC205来说，我们的方法受到限制，因为现有数据仅覆盖其半主轴上的一条线，而不是完整的天空投影场。这一缺陷可以通过进行另一轮观测来解决。

**Summary**:

- (1): 本文研究的背景是针对潮汐干扰的矮星系进行精确的动力学推断，特别关注NGC205这一M31的卫星星系的运动特征。

- (2): 过去的方法通常基于稳态假设，直接计算数据似然性，然而对于时间变化的系统，这些方法难以处理。提出的方法通过隐式似然推断，解决了无法直接计算似然性的问题，使用前向模拟来学习输入参数与可观测量之间的映射，并利用神经密度估计进行似然仿真，其动机合理。

- (3): 本文的贡献在于提出了一种新的分析方法，能够获取被潮汐扰动的卫星星系的轨道和质量分布信息，尽管缺乏适当运动数据。

- (4): 研究方法包括使用隐式似然推断，通过前向模拟和数据压缩来处理高维度和高度简并的模型空间，以便提取天体的动力学信息。

- (5): 本文的方法应用于NGC205的内部速度场的推断，尽管用于实际数据时受限于观测范围，但能在模拟数据中展现出良好的表现，支持作者提取轨道和质量密度分布的目标。


## Quantum Rods and Clock in a Gravitational Universe
- **Url**: http://arxiv.org/abs/2412.03636v3
- **Authors**: ['Hao Geng']
- **Abstrat**: Local operators are the basic observables in quantum field theory which encode the physics observed by a local experimentalist. However, when gravity is dynamical, diffeomorphism symmetries are gauged which apparently obstructs a sensible definition of local operators, as different locations in spacetime are connected by these gauged symmetries. This consideration brings in the puzzle of reconciling our empirical world with quantum gravity. Intuitively, this puzzle can be avoided using relatively defined observables when there exists a natural reference system such as a distribution of galaxies in our universe. Nevertheless, this intuition is classical as the rods and clock defined in this way may also have quantum fluctuations so it is not a priori clear if it can be realized in the quantum regime. In this letter, we provide an affirmative answer to this question. Interestingly, we notice that the quantum fluctuations of the reference system are in fact essential for the realization of the above intuition in the quantum regime.


**Translated Abstract**: 

局部算符是量子场论中的基本可观测量，编码了局部实验者所观察的物理现象。然而，当引力是动态时，微分同胚对称性被规范，似乎妨碍了局部算符的合理定义，因为时空中的不同位置通过这些规范对称性连接在一起。这一考虑引入了将我们的经验世界与量子引力调和的难题。直观上，当存在自然参考系统（如我们宇宙中的星系分布）时，可以避免这一难题。然而，这种直觉是经典的，因为以这种方式定义的杆和钟表也可能具有量子波动，因此在量子状态下是否能够实现并不明确。在这封信中，我们对这个问题给出了肯定的回答。有趣的是，我们注意到参考系统的量子波动实际上对于在量子状态下实现上述直观是至关重要的。

**Summary**:

- (1): 文章的研究背景是动态引力下局部算符的定义问题，以及如何在量子引力理论中理解观察的局域性。

- (2): 过去的方法主要依赖于经典参考框架（如引力的Wison线方法），但存在无法构造真正局部算符的问题。该文提出的方法使用量子波动作为参考系统，克服了传统方法的局限，具备良好的动机来探讨量子状态下的局部性质。

- (3): 本文的贡献在于确认了在量子引力背景下，量子波动是实现局部算符定义的重要因素，提供了新的理解框架。

- (4): 文章提出的研究方法是利用相对定义的可观测量，即在引力波动存在情况下，实现量子状态下的自然参考系统。

- (5): 文章在量子引力理论中的局部算符构造任务上取得了积极成果，从理论上支持了该方法的设想，表明量子波动在局域性质的实现中起关键作用。


## Magnetic Fields of Satellite Galaxies Stronger Than Comparable Centrals in TNG100
- **Url**: http://arxiv.org/abs/2504.07895v1
- **Authors**: ['Bryanne McDonough', 'Alexander Poulin']
- **Abstrat**: Magnetic fields exist in and around galaxies, but the properties of these fields have not been fully explored due to the challenges inherent in observing and modeling them. In this Note, we explore the differences in magnetic field strength of central and satellite galaxies from the magnetohydrodynamic TNG100 simulation. We find that on average, magnetic fields in satellite galaxies are roughly an order of magnitude stronger than those of central galaxies with comparable masses. The difference is greater for satellites that have already approached within $1 R_{200}$ of their host galaxies. These results indicate that magnetic fields in satellite galaxies are amplified by environmental processes as they fall into a host halo.


**Translated Abstract**: 

磁场存在于星系内部和周围，但由于观察和建模中的固有挑战，其属性尚未得到充分探讨。在本研究中，我们探索了来自磁流体动力学TNG100模拟的中心星系和卫星星系的磁场强度差异。我们发现，平均而言，卫星星系的磁场强度大约是同等质量中央星系的一个数量级更强。对于已经接近其宿主星系1 R_{200}内的卫星星系，这一差异更大。这些结果表明，卫星星系中的磁场在其落入宿主光环时受到环境过程的增强。

**Summary**:

- (1): 本文研究背景在于磁场是星系演化的重要组成部分，但对磁场的理解不足，主要由于观察和模拟的挑战。

- (2): 过去的方法主要是通过独立的MHD模拟研究卫星星系的磁场，存在对环境影响的考量不足。本研究利用TNG100全尺度模拟，探讨了磁场强度差异，并强调了环境对卫星星系磁场的增强作用，克服了现有方法中对于背景影响的忽视。

- (3): 本文的贡献在于首次系统性地展示了卫星星系的磁场强度显著高于同质量中央星系，扩展了对卫星星系演化和环境影响的理解。

- (4): 本文采用了TNG100模拟中的数据，特别关注具有超过109 M⊙的卫星星系，比较了其与中央星系的磁场强度。

- (5): 在比较中央和卫星星系的磁场强度任务中，发现卫星星系的磁场强度更强。此结果支持了其研究目标，强调了环境过程对卫星星系磁场的放大作用。


## Simulating Solar Neighborhood Brown Dwarfs I: The Luminosity Function Above and Below the Galactic Plane
- **Url**: http://arxiv.org/abs/2411.06330v2
- **Authors**: ['Easton J. Honaker', 'John E. Gizis']
- **Abstrat**: Brown dwarfs form the key, yet poorly understood, link between stellar and planetary astrophysics. These objects offer unique tests of Galactic structure, but observational limitations have inhibited their large-scale analysis to date. Major upcoming sky surveys will reveal unprecedented numbers of brown dwarfs, among even greater numbers of stellar objects, greatly enhancing the statistical study of brown dwarfs. To extract the comparatively rare brown dwarfs from these massive datasets, we must understand the parameter space they will occupy. In this work, we construct synthetic populations of brown dwarfs in the Solar Neighborhood to explore their evolutionary properties using Gaia-derived star formation histories alongside observational mass, metallicity, and age relationships. We apply the Sonora Bobcat, SM08, and Sonora Diamondback evolutionary models. From the populations, we explore the space densities and median ages by spectral type. We present the simulated luminosity function and its evolution with distance from the Galactic Plane. Our simulation shows that brown dwarf population statistics are a function of height above/below the Galactic Plane and sample different age distributions. Interpreting the local sample requires combining evolutionary models, the initial mass function, the star formation history, and kinematic heating. Our models are a guide to how well height-dependent samples can test these scenarios. Sub-populations of brown dwarfs farther from the Plane are older and occupy a different region of parameter space than younger sub-populations closer to the Galactic Plane. Therefore, fully exploring population statistics both near and far from the Plane is critical to prepare for upcoming surveys.


**Translated Abstract**: 

棕色矮星在恒星和行星天体物理学之间形成了关键但尚不充分理解的联系。这些物体提供了对银河结构的独特测试，但观察限制使其大规模分析受阻。即将到来的主要天空 survey 将揭示前所未有数量的棕色矮星，伴随更多的恒星对象，从而大大增强对棕色矮星的统计研究。为了从这些海量数据集中提取相对少见的棕色矮星，我们必须理解它们所占据的参数空间。本研究构建了太阳邻域中棕色矮星的合成种群，以利用 Gaia 导出的恒星形成历史以及观察到的质量、金属丰度和年龄关系来探索其演化特性。我们应用了 Sonora Bobcat、SM08 和 Sonora Diamondback 演化模型。通过这些种群，我们探讨了按光谱类型划分的空间密度和中位年龄。我们展示了光度函数的模拟及其随距离银河平面的变化。本模拟显示，棕色矮星的种群统计取决于其高度（距离银河平面上下），并展现出不同的年龄分布。解释局部样本需要结合演化模型、初始质量函数、恒星形成历史和运动加热。我们的模型为高度依赖的样本测试这些情景提供了指导。远离银河平面的棕色矮星亚群更老，并占据不同的参数空间与较年轻的靠近银河平面的亚群。因此，全面探索接近和远离银河平面的种群统计在为即将到来的 survey 做准备时至关重要。

**Summary**:

- (1): 本文研究背景为棕色矮星的形成及其在银河结构中的重要性，但由于观察限制，导致过去对其大规模分析较为困难。

- (2): 过去的方法依赖于假设恒星形成率、初始质量函数等，存在无法准确描述棕色矮星种群的不足。本文提出的新方法基于最新的 Gaia 数据，结合观察关系来构建合成种群，解决了前述的观察和分析不足的问题，动机明确。

- (3): 本文的贡献在于通过新的模拟方法探讨太阳邻域棕色矮星的演化特性，提供了不同高度下棕色矮星种群统计的见解。

- (4): 本文提出的研究方法通过使用 Gaia 导出的恒星形成历史及多种演化模型，模拟了太阳邻域的棕色矮星种群并探讨参数变化。

- (5): 本文在监测棕色矮星种群统计及其光度函数方面取得了成果，能够支持即将到来的 survey 进行更全面的研究。


## oMEGACat. VI. Analysis of the overall kinematics of Omega Centauri in 3D: velocity dispersion, kinematic distance, anisotropy, and energy equipartition
- **Url**: http://arxiv.org/abs/2503.04903v2
- **Authors**: ['Maximilian Häberle', 'Nadine Neumayer', 'Callie Clontz', 'Anil Seth', 'Peter Smith', 'Sebastian Kamann', 'Renuka Pechetti', 'Maria Selina Nitschai', 'Mayte Alfaro-Cuello', 'Holger Baumgardt', 'Andrea Bellini', 'Anja Feldmeier-Krause', 'Nikolay Kacharov', 'Mattia Libralato', 'Antonino P. Milone', 'Stefano Souza', 'Glenn van de Ven', 'Zixian Wang']
- **Abstrat**: Omega Centauri ($\omega$ Cen) is the Milky Way's most massive globular cluster and is likely the stripped nucleus of an accreted dwarf galaxy. In this paper, we analyze $\omega$ Cen's kinematics using data from oMEGACat, a comprehensive catalog of $\omega$ Cen's central regions, including 1.4 million proper motion measurements and 300,000 spectroscopic radial velocities. Our velocity dispersion profiles and kinematic maps are consistent with previous work but improve on their resolution, precision, and spatial coverage. The cluster's 3D dispersion is isotropic in the core, with increasing radial anisotropy at larger radii. The 2D kinematic maps show an elongation of the velocity dispersion field comparable to the flattening observed photometrically. We find good agreement between proper motions and line-of-sight velocity dispersion and measure a kinematic distance of 5494$\pm$61 pc, the most precise kinematic distance to $\omega$ Cen available. The subset of data with precise metallicity measurements shows no correlation between metallicity and kinematics, supporting the picture of well-mixed stellar populations within the half-light radius of $\omega$ Cen. Finally, we study the degree of energy equipartition using a large range of stellar masses. We find partial energy equipartition in the center that decreases towards large radii. The spatial dependence of the radial energy equipartition is stronger than the tangential energy equipartition. Our kinematic observations can serve as a new reference for future dynamical modeling efforts that will help to further disentangle the complex mass distribution within $\omega$ Cen.


**Translated Abstract**:

Omega Centauri (ω Cen) 是银河系中质量最大的球状星团，很可能是被吞并的矮星系的剥离核。在本文中，我们利用来自oMEGACat的数据显示ω Cen的运动学，包括140万条适当运动测量和30万条光谱径向速度记录。我们的速度色散剖面和运动学图是与以前的工作一致，但在分辨率、精度和空间覆盖方面有所改善。该星团在核心区域的三维色散是各向同性的，而在更大半径处则呈现出逐渐增加的径向各向异性。二维运动学图显示出速度色散场的拉伸，与光度观察到的扁平化现象相似。我们发现适当运动和视线速度色散之间具有良好的一致性，并测量到ω Cen的运动学距离为5494±61 pc，这是迄今为止对ω Cen可用的最精确的运动学距离。具有精确金属丰度测量的数据子集显示金属丰度与运动学之间没有相关性，这支持了ω Cen半光径内星系群体的良好混合场景。最后，我们研究了使用大范围恒星质量的能量均分程度。我们发现中心区域存在部分能量均分，且在大半径处逐渐减小。径向能量均分的空间依赖性强于切向能量均分。我们的运动学观测可以作为未来动态建模工作的新参考，以帮助进一步解开ω Cen内复杂的质量分布。

**Summary**:

- (1): 本文的研究背景是ω Cen作为银河系中最重的球状星团，其内部复杂的运动学吸引了天文学家的关注，以更好地理解其质量分布及形成历史。

- (2): 过去的研究方法主要基于视线速度和早期的适当运动测量，受限于样本数量较少且多集中在亮星上。这些方法的问题在于无法充分涵盖星团的整体运动学特征。本文提出的方法利用了oMEGACat数据库，极大地增强了运动学数据的数量和覆盖范围，从而更全面地解决了之前方法的局限性，具有良好的动机。

- (3): 本文的贡献在于提供了ω Cen运动学的高分辨率和高精度分析，包括更详细的速度色散分布、运动学距离测量及能量均分状态的研究，为未来的动力学模型提供了新的参考。

- (4): 本文所采用的研究方法包括利用oMEGACat数据集，结合1.4百万的适当运动测量和30万的光谱径向速度记录，分析速度色散、运动学距离、各向异性和能量均分等多个方面。

- (5): 本文的方法达成了5500±61 pc的精确运动学距离测量，表明星团内部的运动状态已得到更准确的描述。这一性能充分支持了作者关于探索ω Cen内部复杂质量分布的研究目标。


## Improving Photometric Redshift Estimation for CSST Mock Catalog Using SED Templates Calibrated with Perturbation Algorithm
- **Url**: http://arxiv.org/abs/2504.07684v1
- **Authors**: ['Yicheng Li', 'Liping Fu', 'Zhu Chen', 'Zhijian Luo', 'Wei Du', 'Yan Gong', 'Xianmin Meng', 'Junhao Lu', 'Zhirui Tang', 'Pengfei Chen', 'Shaohua Zhang', 'Chenggang Shu', 'Xingchen Zhou', 'Zuhui Fan']
- **Abstrat**: Photometric redshifts of galaxies obtained by multi-wavelength data are widely used in photometric surveys because of its high efficiency. Although various methods have been developed, template fitting is still adopted as one of the most popular approaches. Its accuracy strongly depends on the quality of the Spectral Energy Distribution (SED) templates, which can be calibrated using broadband photometric data from galaxies with known spectroscopic redshifts. Such calibration is expected to improve photometric redshift accuracy, as the calibrated templates will align with observed photometric data more closely. The upcoming China Space Station Survey Telescope (CSST) is one of the Stage IV surveys, which aiming for high precision cosmological studies. To improve the accuracy of photometric redshift estimation for CSST, we calibrated the CWW+KIN templates using a perturbation algorithm with broadband photometric data from the CSST mock catalog. This calibration used a training set consisting of approximately 4,500 galaxies, which is 10% of the total galaxy sample. The outlier fraction and scatter of the photometric redshifts derived from the calibrated templates are 2.55% and 0.036, respectively. Compared to the CWW+KIN templates, these values are reduced by 34% and 23%, respectively. This demonstrates that SED templates calibrated with a small training set can effectively optimize photometric redshift accuracy for future large-scale surveys like CSST, especially with limited spectral training data.


**Translated Abstract**: 

通过多波长数据获得的星系光度红移在光度调查中广泛使用，因为其高效性。虽然已经开发了各种方法，但模板拟合仍然被采用为最流行的方法之一。其准确性很大程度上取决于光谱能量分布（SED）模板的质量，这些模板可以通过从已知光谱红移的星系获得的宽波段光度数据进行校准。这种校准预计能提高光度红移的准确性，因为校准后的模板将更紧密地与观测到的光度数据对齐。即将到来的中国空间站巡天望远镜（CSST）是一个第四阶段的调查，旨在进行高精度的宇宙学研究。为了提高CSST的光度红移估计精度，我们利用一种扰动算法对CWW+KIN模板进行了校准，使用了来自CSST模拟目录的宽波段光度数据。该校准使用了一个由约4500个星系组成的训练集，占总星系样本的10%。由校准模板推导的光度红移的异常值比例和散射分别为2.55%和0.036。与CWW+KIN模板相比，这些值分别降低了34%和23%。这表明，使用小型训练集校准的SED模板可以有效优化未来大型调查（如CSST）的光度红移准确性，特别是在有限的光谱训练数据情况下。

**Summary**:

- (1): 本文的研究背景是光度红移在宇宙学研究中的重要性，以及即将部署的中国空间站巡天望远镜（CSST）的需求，以提供高精度的光度红移估计。

- (2): 过去的方法是通过光谱和光度观测获得红移的方法，尤其是模板拟合。然而，这些方法的准确性依赖于模板的质量，且现有模板可能无法全面覆盖不同红移星系的特性。本文提出的使用扰动算法校准SED模板的方法能有效提高光度红移的准确性，尤其在训练数据有限的情况下，具有良好的动机。

- (3): 论文的贡献在于证明了通过少量训练集校准SED模板，能够显著改善使用CSST光度红移估计的方法，展示出即使在有限的观测条件下也能优化结果。

- (4): 本文提出的研究方法是利用一种扰动算法，对使用CWW+KIN模板的光度红移进行校准，通过来自CSST的模拟光度数据进行训练。

- (5): 本文的方法在CSST模拟目录中实现了2.55%的异常值比例和0.036的散射，这表明方法在提升光度红移估计的准确性上显著改善，支持其研究目标。


## Non-linear magnetic buoyancy instability and galactic dynamos
- **Url**: http://arxiv.org/abs/2412.05086v3
- **Authors**: ['Yasin Qazi', 'Anvar. Shukurov', 'Frederick. A. Gent', 'Devika. Tharakkal', 'Abhijit. B. Bendre']
- **Abstrat**: Magnetic buoyancy (MBI) and Parker instabilities are strong, generic instabilities expected to occur in most astrophysical systems with sufficiently strong magnetic fields. In galactic and accretion discs, large-scale magnetic fields are thought to arise from mean-field dynamo action, particularly the $\alpha^2\Omega$-dynamo. Using non-ideal MHD equations, we model a section of the galactic disc where the large-scale magnetic field is generated by an imposed $\alpha$-effect and differential rotation. We extend our previous study of the interplay between magnetic buoyancy and the mean-field dynamo by incorporating differential rotation, which enhances the dynamo, and cosmic rays, which amplify magnetic buoyancy.We construct a simple 1D model which replicates all significant features of the 3D simulations. Simulations confirm that magnetic buoyancy can lead to oscillatory magnetic fields and reveal that it can change the magnetic field parity between quadrupolar and dipolar states. Differential rotation facilitates this switch in parity, suggesting that the large-scale magnetic field can adopt a dipolar parity within a few kiloparsecs of the galactic centre. In contrast, quadrupolar parity may remain predominant in the outer parts of a galactic disc. Cosmic rays accelerate both the dynamo and the MBI, supporting oscillatory non-linear states and a spatial magnetic field structure similar to the alternating magnetic field directions observed in {the haloes of} some edge-on galaxies.


**Translated Abstract**: 

磁浮力不稳定性（MBI）和帕克不稳定性是普遍存在的强烈不稳定性，预期会在大多数具有足够强磁场的天体物理系统中发生。在星系和吸积盘中，大规模磁场被认为是由平均场动力学作用产生的，特别是𝛼²Ω动力学。采用非理想磁流体动力学方程，我们模拟了一个星系盘的一部分，其中大规模磁场由施加的𝛼效应和差异旋转生成。我们通过引入差异旋转（增强动力学）和宇宙射线（增强磁浮力）来扩展我们之前对磁浮力与平均场动力学相互作用的研究。我们构建了一个简单的一维模型，复制了三维模拟的所有重要特征。模拟确认磁浮力可以导致振荡磁场，并揭示其可以在四极和偶极态之间改变磁场奇偶性。差异旋转促进这种奇偶性的切换，表明大规模磁场可以在星系中心几千秒差距内采用偶极奇偶性。相比之下，四极奇偶性可能在星系盘的外部区域仍然占主导地位。宇宙射线同时加速动力学和MBI，支持振荡非线性状态及其与一些边缘星系的光环中观察到的交替磁场方向相似的空间磁场结构。

**Summary**:

- (1): 本文研究背景为在具有强磁场的天体物理系统中，磁浮力不稳定性和帕克不稳定性是普遍存在的重要现象，尤其是在星系和吸积盘中。

- (2): 过去的研究主要使用线性模型，处理磁浮力和平均场动力学的相互作用存在局限性，无法准确描述非线性状态。本文提出的是一种结合差异旋转和宇宙射线影响的非理想MHD模型，能有效模拟这些不稳定性和变化，从而克服了先前模型在理解非线性行为方面的不足，并具有充分的理论动机。

- (3): 论文的贡献在于阐明了磁浮力如何导致磁场奇偶性转换，并展示了差异旋转和宇宙射线在星系中大规模磁场演化中的重要作用。

- (4): 本文提出的研究方法基于非理想MHD方程，通过构建简单的一维模型来描述星系盘中大规模磁场的生成及其动态演化过程。

- (5): 方法在数值模拟中证明了能够生成振荡磁场并改变磁场奇偶性，表明其在数个千秒差距内的动力学行为能够支持其科学目标。


## Gas excitation in galaxies and active galactic nuclei with He IIλ4686 and X-ray emission
- **Url**: http://arxiv.org/abs/2503.03496v3
- **Authors**: ['K. Kouroumpatzakis', 'J. Svoboda']
- **Abstrat**: The origin of He II emission in galaxies remains a debated topic, requiring ionizing photons with energies exceeding 54 eV. While massive stars, such as Wolf-Rayet stars, have been considered potential sources, their UV flux often fails to fully explain the observed He II emission. Recent studies suggest that X-ray binaries (XRBs) might contribute significantly to this ionization. We explore the relationship between X-ray and $\rm He~II \lambda4686$ emission in a statistically significant sample of galaxies, investigating whether X-ray sources, including active galactic nuclei (AGNs) and XRBs, serve as the primary mechanism for He II ionization across different galactic environments. We cross-matched a sample of known well-detected He II galaxies with the Chandra Source Catalog, yielding 165 galaxies with X-ray and $\rm He~II \lambda4686$ detections. The sources were classified into star-forming galaxies (SFGs) and AGNs based on the BPT diagram and a classification scheme defined for He II galaxies. We find a strong, linear correlation between X-ray and He II luminosity across AGNs and SFGs spanning over seven orders of magnitude. AGNs generally exhibit higher He II/H$\beta$ flux ratios, stronger extinction, and harder X-ray spectra. The O32 ratio of SFGs is tightly correlated with the H$\beta$ equivalent width ($\rm EW_{H\beta}$) but not with the He II/H$\beta$ ratio, suggesting a different excitation mechanism. We derive an O32--$\rm EW_{H\beta}$ line above which only AGNs of our sample reside. The tight correlation between X-ray and He II luminosity supports X-rays as the primary driver of He II excitation. While AGNs have one common ionization source, the central black hole, in SFGs low-energy species are mainly excited by UV emission related to star-forming activity, however, high-energy species like He II require the presence of XRBs.


**Translated Abstract**:

气体在星系中的He II发射源仍然是一个有争议的话题，这需要超过54 eV的离子光子。尽管大质量恒星（如Wolf-Rayet恒星）被认为是潜在来源，它们的紫外光通量往往无法完全解释观察到的He II发射。最近的研究表明，X射线双星（XRBs）可能显著贡献于这种电离。我们探讨了在一个具有统计意义的星系样本中，X射线与He IIλ4686发射之间的关系，调查了包括活跃星系核（AGNs）和XRB在内的X射线源是否在不同的星系环境中作为He II电离的主要机制。我们将已知的好探测到He II星系的样本与Chandra源目录交叉匹配，获得165个具有X射线和He II λ4686探测的星系。根据BPT图和为He II星系定义的分类方案，我们将这些源分类为恒星形成星系（SFGs）和AGNs。我们发现AGNs和SFGs之间X射线与He II光度之间存在强而线性的相关性，涵盖了七个数量级。AGNs通常表现出更高的He II/Hβ通量比、更强的消光和更硬的X射线光谱。SFGs的O32比与Hβ等效宽度（EW_{Hβ}）密切相关，但与He II/Hβ比无关，表明不同的激发机制。我们推导出一个O32–EW_{Hβ}线，仅在样本中包含AGNs。X射线与He II光度之间的紧密相关性支持X射线作为He II激发的主要驱动因素的观点。虽然AGNs的电离源是中心黑洞，但在SFGs中，低能量粒子主要通过与恒星形成活动相关的紫外发射被激发，然而高能粒子如He II则需要XRB的存在。

**Summary**:

- (1): 本文探讨了星系中的He II发射源，这一领域对需超过54 eV离子光子的来源仍有争议，传统认知认为大质量恒星（如Wolf-Rayet恒星）为潜在来源。

- (2): 过去的研究主要依赖于大质量恒星的紫外发射进行解释，但发现其能量不足以激发He II。与现有方法的不同之处在于，本文提出了X射线源（包括AGNs和XRBs）可能是另一重要电离来源，解决了传统方法未能充分解释的He II发射问题。

- (3): 本文的贡献在于确定X射线与He II发射之间的强线性相关性，支持了XRB作为He II主要激发机制的观点，并揭示了AGNs与SFGs在激发机制上的差异。

- (4): 本文的方法包括将具有He II探测的星系样本与Chandra源目录交叉匹配，分析X射线与He II光度的相关性，并进行分类，以探讨不同类型星系中的He II电离机制。

- (5): 本文任务围绕分析165个具X射线和He II探测的星系，验证了X射线与He II光度之间的相关性，性能支持了XRB作为He II电离主要驱动因素的研究目标。


## A new quasar strongly-lensed candidate by the galaxy cluster WHJ0400-27 with a $18''$ image-separation
- **Url**: http://arxiv.org/abs/2504.07622v1
- **Authors**: ['L. Bazzanini', 'G. Angora', 'M. Scialpi', 'G. Di Rosa', 'P. Bergamini', 'P. Rosati', 'M. Lombardi', 'D. Abriola', 'A. Acebron', "M. D'Addona", 'G. Granata', 'C. Grillo', 'F. Mannucci', 'M. Maturi', 'M. Meneghetti', 'A. Mercurio', 'M. Radovich']
- **Abstrat**: Time-delay cosmography (TDC) using multiply-lensed quasars (QSOs) by galaxies has recently emerged as an independent and competitive tool to measure the value of the Hubble constant. Lens galaxy clusters hosting multiply-imaged QSOs, when coupled with an accurate and precise knowledge of their total mass distribution, are equally powerful cosmological probes. However, less than ten such systems have been identified to date. Our study aims to expand the limited sample of cluster-lensed QSO systems by identifying new candidates within rich galaxy clusters. Starting from a sample of ~$10^5$ galaxy cluster candidates (Wen & Han, 2022), built from Dark Energy Survey and Wide-field Infrared Survey Explorer imaging data, and a highly-pure catalogue of over one million QSOs, based on Gaia DR3 data, we cross-correlate them to identify candidate lensed QSOs near the core of massive galaxy clusters. Our search yielded 3 lensed double candidates over an area of ~$5000$ sq. degree. In this work, we focus on the best candidate consisting of a double QSO with Gaia-based redshift of 1.35, projected behind a moderately rich cluster (WHJ0400-27) at $z_{phot}=0.65$. Based on a first spectroscopic follow-up study, we confirm the two QSOs at $z=1.345$, with indistinguishable spectra, and a brightest cluster galaxy at $z=0.626$. These observations seem to support the strong lensing nature of this system, although some tension emerges when the cluster mass from a preliminary lens model is compared with that from other mass proxies. We also discuss the possibility that such system is a rare physical association of two distinct QSOs with a projected physical distance of ~$150$ kpc. If further spectroscopic observations confirm its lensing nature, such a rare lens system would exhibit one of the largest image separations observed to date ($\Delta\vartheta=17.8''$), opening interesting TDC applications.


**Translated Abstract**:  

时间延迟宇宙学（TDC）利用由星系产生的多重成像类星体（QSOs）最近已成为测量哈勃常数的独立且竞争性工具。宿主多个成像QSOs的透镜星系团在与其总质量分布的准确了解结合时，同样是强有力的宇宙学探针。然而，迄今为止，仅识别出不到十个此类系统。我们的研究旨在通过在丰富的星系团中识别新候选者来扩展集群透镜QSO系统的有限样本。我们从大约10^5个星系团候选者样本开始，利用暗能量 survey 和广域红外 survey 数据，以及基于Gaia DR3数据的超过一百万个QSO的高纯度目录，进行交叉关联以识别靠近重要星系团核心的候选透镜QSOs。我们的搜索共发现3个成像双重候选，在约5000平方度的区域内。在这项工作中，我们专注于一个最佳候选，包含一个基于Gaia的红shift为1.35的双QSO，投影在一个中等富集的星系团 (WHJ0400-27)后，其 $z_{phot}=0.65$。根据首次光谱跟进研究，我们确认了两个红shift为 $z=1.345$ 的QSOs，具有无法区分的光谱，以及一个亮的星系团明星体，红shift为 $z=0.626$。这些观察结果似乎支持该系统的强透镜特性，尽管当初步透镜模型的星系团质量与其他质量代理进行比较时，出现了一些紧张情况。我们还讨论了该系统可能是两个不同QSOs稀有物理关联的可能性，投影的物理距离约为150 kpc。如果进一步的光谱观察确认其透镜特性，这样的稀有透镜系统将展现迄今为止观察到的最大成像分离之一（$\Delta\vartheta=17.8''$），为TDC应用打开有趣的可能性。

**Summary**:

- (1): 本文的研究背景是当前对哈勃常数（H0）值测量的精确性不足，导致不同宇宙学测量之间存在显著差异，且仅识别到少数多重成像类星体（QSOs）系统。

- (2): 过去的方法主要使用时间延迟宇宙学（TDC）技术，尽管取得了一定的成果，但已识别的透镜系统数量有限。该研究提出了一种新方法，通过交叉关联大量星系团候选者与类星体目录来识别新候选，以扩展样本数量，以应对过去样本稀缺的问题。

- (3): 本文的贡献在于识别了一个新的强透镜候选者WHJ0400-27，包含一个双QSO，极大地扩展了星系团透镜QSO系统的样本和后续研究的潜力。

- (4): 研究方法是基于Gaia DR3数据的光谱跟进、交叉关联大规模数据集，以识别投影在星系团后面的类星体并确认其红shift。

- (5): 本文在识别到的双QSO系统方面取得了成功，确认了两个QSOs的红shift为 $z=1.345$，并为未来星系团透镜的研究和TDC应用奠定了良好的基础，显示出较高的研究价值。


## Unveiling two deeply embedded young protostars in the S68N Class 0 protostellar core with JWST/NIRSpec
- **Url**: http://arxiv.org/abs/2410.11095v3
- **Authors**: ['Valentin J. M. Le Gouellec', 'Ben W. P. Lew', 'Thomas P. Greene', 'Doug Johnstone', 'Antoine Gusdorf', 'Logan Francis', 'Curtis DeWitt', 'Michael Meyer', 'Łukasz Tychoniec', 'Ewine F. van Dishoeck', 'Mary Barsony', 'Klaus W. Hodapp', 'Peter G. Martin', 'Massimo Robberto']
- **Abstrat**: The near-infrared (NIR) emission of the youngest protostars still needs to be characterized to better understand the evolution of their accretion and ejection activity. We analyze James Webb Space Telescope NIRSpec 1.7 -- 5.3 $\mu$m observations of two deeply embedded sources in the S68N protostellar core in Serpens. The North Central (NC) source exhibits a highly obscured spectrum (A_K ~ 4.8 mag) that is modeled with a pre-main-sequence photosphere and a hot disk component. The photospheric parameters are consistent with a young, low-mass photosphere, as suggested by the low surface gravity, log g of 1.95 $\pm$ 0.15 cm s$^{-2}$. The hot disk suggests that accretion onto the central protostellar embryo is ongoing, although prototypical accretion-tracing emission lines HI are not detected. The South Central (SC) source, which is even more embedded (A_K ~ 8 mag; no continuum is detected shortward of 3.6 $\mu$m) appears to be driving the large-scale S68N protostellar outflow, and launches a collimated hot molecular jet detected in \Ht and CO ro-vibrational lines. Shock modeling of the \Ht (ro)vibrational lines establishes that fast $C$-type shocks ($\geq$ 30 km s$^{-1}$), with high pre-shock density ($\geq$ $10^7$ cm$^{-3}$), and strong magnetic field (b ~ 3--10, where $B = b\,\times\,\sqrt{\textrm{n}_{\textrm{H}} (\textrm{cm}^{-3})}\,\mu\textrm{G}$) best match the data. The bright CO fundamental line forest suggests energetic excitation, with the contribution of non-LTE effects, ie irradiation pumping. Detected OH and CH$^{+}$ ro-vibrational lines support this hypothesis. These two Class 0 protostars seem to be in very young evolutionary stages and still have to acquire the bulk of their final stellar masses. These results demonstrate that JWST enables unprecedented diagnostics of these first stages of the protostellar evolutionary phase.


**Translated Abstract**: 

年轻原恒星的近红外（NIR）辐射尚需被表征，以更好地理解它们的吸积和喷射活动的演化。我们分析了詹姆斯·韦布太空望远镜（James Webb Space Telescope）NIRSpec在1.7到5.3微米范围的观测数据，研究了在Serpens的S68N原恒星核心中两个深度嵌入的源。北中（North Central, NC）源展现出高度被遮蔽的光谱（A_K ~ 4.8 mag），其光谱可用预主序光球和热盘部分模型化。光球参数与年轻的低质量光球一致，表明其低表面重力（log g 为1.95 ± 0.15 cm s⁻²）。热盘表明向中央原恒星胚胎的吸积仍在进行，尽管未检测到典型的吸积迹象的发射线H I。南中（South Central, SC）源则被更深地嵌入（A_K ~ 8 mag；在3.6微米以下未检测到连续谱），似乎在驱动大规模的S68N原恒星喷流，并推出了在H₂和CO的转动振动线中检测到的定向热分子喷射。对H₂（转动）振动线的冲击建模显示，快速的C型冲击（≥ 30 km s⁻¹），具有高的前冲密度（≥ 10⁷ cm⁻³）和强大的磁场（b ~ 3–10，B = b × \sqrt{n_H（cm⁻³）} μG）与数据最好匹配。明亮的CO基态线森林表明能量激发，同时也涉及非LTE效应，即辐照泵浦。检测到的OH和CH⁺转动振动线支持了这一假设。这两个Class 0原恒星似乎处于非常年轻的演化阶段，尚未获得大部分最终恒星质量。这些结果表明，JWST能够对这些原恒星演化阶段的第一阶段进行前所未有的诊断。

**Summary**:

- (1): 本文研究了Class 0原恒星阶段的NIR辐射，以理解它们的吸积和喷射活动的演化。

- (2): 过去的方法主要依赖于ALMA和NOEMA对原恒星周围系统的毫米波观测，存在对年轻光球和吸积活动的识别不足的问题。本文通过使用JWST进行NIR观测，提供了一种新的观察手段，能更好地分析深度嵌入源的光谱特征和吸积状态。

- (3): 本文的贡献在于揭示了两颗深度嵌入的Class 0原恒星的光谱特征，以及提供了关于它们的吸积和喷流活动的细节，展示了JWST在原恒星演化初期阶段的应用潜力。

- (4): 本文提出了基于JWST NIRSpec观测数据的研究方法，通过分析1.7到5.3微米的NIR光谱，结合冲击建模，深入探讨了年轻原恒星的热盘和出流。

- (5): 本文的研究聚焦于S68N原恒星核心中原恒星的吸积和喷流特性，方法在揭示源的热盘和冲击特征上表现出显著的效果，支持了对原恒星演化阶段的研究目标。


## Power spectrum of the CODEX clusters
- **Url**: http://arxiv.org/abs/2504.07613v1
- **Authors**: ['Valtteri Lindholm', 'Alexis Finoguenov', 'Andrés Balaguera-Antolínez', 'Tiago Castro']
- **Abstrat**: Aims. We analyze the clustering of galaxy clusters in a large contiguous sample, the Constrain Dark Energy with X-ray (CODEX) sample. We construct a likelihood for cosmological parameters by comparing the measured clustering signal and a theoretical prediction, and use this to obtain parameter constraints. Methods. We measured the three multipole moments (monopole, quadrupole, and hexadecapole, $\ell = 0, 2, 4$) of the power spectrum of a subset of the CODEX clusters. To fully model cluster clustering, we also determined the expected clustering bias of the sample using estimates for the cluster masses and a mass-to-bias model calibrated using N-body simulations. We estimated the covariance matrix of the measured power spectrum multipoles using a set of simulated dark-matter halo catalogs. Combining all these ingredients, we performed a Markov chain Monte Carlo sampling of cosmological parameters $\Omega_m$ and $\sigma_8$ to obtain their posterior. Results. We found the CODEX clustering signal to be consistent with an earlier X-ray selected cluster sample, the REFLEX II sample. We also found that the measured power spectrum multipoles are compatible with the predicted, bias-scaled linear matter power spectrum when the cosmological parameters determined by the Planck satellite are assumed. Furthermore, we found the marginalized parameter constraints of $\Omega_m = 0.24^{+0.06}_{-0.04}$ and $\sigma_8 = 1.13^{+0.43}_{-0.24}$. The full 2D posterior is consistent, for example, with the Planck cosmology within the 68% confidence region.


**Translated Abstract**: 

本文旨在分析一个较大连贯样本的星系团聚集性，即利用X射线的约束暗能量（CODEX）样本。我们通过比较测量到的聚集信号和理论预测，构建了一个针对宇宙学参数的似然函数，并用其获得参数约束。我们测量了CODEX星系团的功率谱的三个多极矩（零级、二级和四级）。为了全面建模星系团的聚集性，我们还根据星系团的质量估计值和一个通过N体模拟校准的质量-偏差模型，确定了样本的预期聚集偏差。利用一组模拟的暗物质晕目录，我们估计了测量功率谱多极矩的协方差矩阵。结合所有这些要素，我们进行了宇宙学参数\(\Omega_m\)和\(\sigma_8\)的Markov链Monte Carlo抽样，以获得它们的后验分布。结果表明，CODEX聚集信号与早期的X射线选定星系团样本（REFLEX II样本）一致。测得的功率谱多极矩也与假定Planck卫星确定的宇宙学参数时的预测线性物质功率谱兼容。此外，我们找到的边际参数约束为\(\Omega_m = 0.24^{+0.06}_{-0.04}\)和\(\sigma_8 = 1.13^{+0.43}_{-0.24}\)。完整的二维后验分布在68%置信区间内与Planck宇宙学一致。

**Summary**:

- (1): 本文研究星系团的聚集性，这与宇宙的几何和结构增长密切相关，尤其利用X射线选定的样本（CODEX）作为宇宙学探针。

- (2): 过去的方法包括使用两点关联函数来调查星系团聚集性，但这些方法在估计协方差矩阵和处理聚集偏差方面存在问题。本文提出的新方法在于使用功率谱多极矩和更准确的协方差矩阵，解决了前述问题，方法论动机充足。

- (3): 本文的贡献在于测量CODEX样本的功率谱，提供了新的宇宙学参数约束，并验证了与此前样本（REFLEX II）的兼容性。

- (4): 本文的方法论包括测量CODEX星系团的功率谱多极矩，建立预期聚集偏差模型，根据N体模拟估计协方差矩阵，并利用Markov链Monte Carlo进行参数抽样。

- (5): 本文的任务是测量功率谱并获得宇宙学参数的约束，结果表明CIODEX聚集信号与先前结果一致，且所取得的性能能够支持其宇宙学目标。


## DUCA: Dynamic Universe Cosmological Analysis. I. The halo mass function in dynamical dark energy cosmologies
- **Url**: http://arxiv.org/abs/2504.07608v1
- **Authors**: ['Tiago Castro', 'Stefano Borgani', 'Jeppe Dakin']
- **Abstrat**: The halo mass function (HMF) is fundamental for interpreting the number counts of galaxy clusters, serving as a pivotal theoretical tool in cosmology. With the advent of high-precision surveys such as LSST, eROSITA, DESI, and Euclid, accurate HMF modeling becomes indispensable to avoid systematic biases in cosmological parameter estimation from cluster cosmology. Moreover, these surveys aim to shed light on the dark sector and uncover dark energy's puzzling nature, necessitating models that faithfully capture its features to ensure robust parameter inference. We aim to construct a model for the HMF in dynamical dark energy cosmologies that preserves the accuracy achieved for the standard $\Lambda (\nu)$CDM model of cosmology, while meeting the precision requirements necessary for future cosmological surveys. Our approach models the HMF parameters as functions of the deceleration parameter at the turnaround, a quantity shown to encapsulate essential information regarding the impact of dynamical dark energy on structure formation. We calibrate the model using results from a comprehensive suite of $N$-body simulations spanning various cosmological scenarios, ensuring sub-percent systematic accuracy. We present an HMF model tailored for dynamical dark energy cosmologies. The model is calibrated following a Bayesian approach, and its uncertainty is characterized by a single parameter controlling its systematic error, which remains at the sub-percent level. This ensures that theoretical uncertainties from our model are subdominant relative to other error sources in future cluster number counts analyses.


**Translated Abstract**: 

晕质量函数（HMF）对于解释星系团的数量计数至关重要，是宇宙学中一个重要的理论工具。随着高精度观测的出现，如 LSST、eROSITA、DESI 和 Euclid，准确的 HMF 建模变得不可或缺，以避免从星系团宇宙学中估计宇宙学参数时出现系统偏差。此外，这些观测还旨在揭示暗能量的神秘特性，需要准确捕捉其特征的模型以确保稳健的参数推断。我们旨在构建一个适用于动态暗能量宇宙学的 HMF 模型，该模型保持与标准的 Λ(ν)CDM 宇宙学所获得的准确性，同时满足未来宇宙学调查所需的精度要求。我们的方法将 HMF 参数建模为回转时减速参数的函数，这一量被证明能够很好地概括动态暗能量对结构形成的影响。我们使用涵盖各种宇宙学场景的全面 N 体模拟结果对模型进行校准，从而确保亚百分点的系统精度。我们提出了一个为动态暗能量宇宙学量身定制的 HMF 模型。该模型采用贝叶斯方法进行校准，其不确定性由单一参数控制其系统误差，且保持在亚百分点水平。这确保了我们模型的理论不确定性在未来的星系团数量计数分析中远低于其他误差来源。

**Summary**:

- (1): 本文的研究背景是晕质量函数（HMF）在星系团数量计数中的重要性，以及随着 LSST、eROSITA、DESI 和 Euclid 等高精度观测的出现，对 HMF 模型的准确需求，以避免宇宙学参数估计中的系统偏差。

- (2): 过去的方法主要依赖于 N 体模拟，在这些模拟中，重力主导结构形成。然而，它们通常忽略了光学物质的影响，这在不同的研究中显示出对结构形成有显著影响。本文提出的方法通过将 HMF 参数建模为回转时减速参数的函数，更好地捕捉动态暗能量对结构形成的影响，解决了现有方法中对动态暗能量理解不足的问题，具有良好的动机。

- (3): 本文的贡献在于提出了一个适用于动态暗能量宇宙学的 HMF 模型，该模型具有亚百分点的系统精度，以适应未来的宇宙学调查需求。

- (4): 本文提出的方法论是通过贝叶斯方法对 HMF 模型进行校准，同时利用多种宇宙学场景的 N 体模拟结果，确保模型的系统准确性。

- (5): 本文的方法在动态暗能量宇宙学的 HMF 模型上实现了高精度的结果，其性能在亚百分点的系统误差范围内，能够支持未来星系团观测所需的精度目标。


## Wide Binaries from GAIA DR3 : testing GR vs MOND with realistic triple modelling
- **Url**: http://arxiv.org/abs/2504.07569v1
- **Authors**: ['Charalambos Pittordis', 'Will Sutherland', 'Paul Shepherd']
- **Abstrat**: We provide an updated test for modifications of gravity from a sample of wide-binary stars from GAIA DR3, and their sky-projected relative velocities. Here we extend on our earlier 2023 study, using several updated selection cuts aimed at reducing contamination from triple systems with an undetected third star. We also use improved mass estimates from FLAMES, and we add refinements to previous modelling of the triple and other populations and the model-fitting. We fit histograms of observed vs Newtonian velocity differences to a flexible mixture of binary + triple populations with realistic eccentricity distributions, plus unbound flyby and random-chance populations. We find as before that Newtonian models provide a significantly better fit than MOND, though improved understanding of the triple population is necessary to make this fully decisive.


**Translated Abstract**: 
我们提供了对来自GAIA DR3的宽二元星样本的重测试，以检测引力的修正及其天空投影的相对速度。在这项研究中，我们在2023年的早期研究基础上进行了扩展，采用了多项更新的选择标准，以减少未检测到的第三颗星的三重系统的污染。我们还使用了来自FLAMES的改进质量估计，并在三重和其他种群的建模及模型拟合方面进行了细化。我们对观察到的与牛顿模型的速度差异的直方图进行了拟合，使用了现实的离心率分布的二元加三重种群的灵活混合模型，以及不稳定的飞越和随机机会种群。我们发现，牛顿模型提供了显著优于MOND的拟合，但对三重种群的更好理解是做出最终决定的必要条件。

**Summary**:

- (1): 本文研究的背景为分析GAIA DR3中的宽二元星的相对速度，以区分引力相对论（GR）和修正引力的MOND模型。

- (2): 过去的方法主要是基于GAIA数据进行的宽二元测试，但受到早期研究中数据精度有限的影响，未能充分考虑三重系统的影响。本文的方法通过使用更新的选择标准和改进的建模方法，有效减少三重系统的干扰，从而提供更清晰的结果。

- (3): 本文的贡献在于更新了对GAIA DR3宽二元星样本的分析，使用更真实的三重种群建模，并展示出牛顿模型比MOND模型更具优势。

- (4): 本文提出的研究方法包括使用改进的选择标准来减少三重系统的污染、使用FLAMES数据进行质量估计，以及对多种群体的混合模型进行拟合。

- (5): 本文集中在宽二元星的相对速度测量任务，结果表明牛顿模型的拟合优于MOND模型，支持了其研究目标。


## The emergence of galactic thin and thick discs across cosmic history
- **Url**: http://arxiv.org/abs/2409.15909v2
- **Authors**: ['Takafumi Tsukui', 'Emily Wisnioski', 'Joss Bland-Hawthorn', 'Ken Freeman']
- **Abstrat**: Present-day disc galaxies often exhibit distinct thin and thick discs. The formation mechanisms of the two discs and the timing of their onset remain open questions. To address these questions, we select edge-on galaxies from flagship JWST programs and investigate their disc structures in rest-frame, near-infrared bands. For the first time, we identify thick and thin discs at cosmological distances, dating back over 10 Gyr, and investigate their decomposed structural properties. We classify galaxies into those that require two (i.e. thin and thick) discs and those well fitted by a single disc. Disc radial sizes and vertical heights correlate strongly with the total galaxy mass and/or disc mass, independent of cosmic time. The structure of the thick disc resembles discs found in single-disc galaxies, suggesting that galaxies form a thick disc first, followed by the subsequent formation of an embedded thin disc. The transition from single to double discs occurred around 8 Gyr ago in high-mass galaxies ($10^{9.75} - 10^{11}M_\odot$), earlier than the transition which occurred 4 Gyr ago in low-mass galaxies ($10^{9.0} - 10^{9.75}M_\odot$), indicating sequential formation proceeds in a "downsizing" manner. Toomre $Q$-regulated disc formation explains the delayed thin disc formation in low-mass galaxies, leading to the observed anti-correlation between the thick-to-thin disc mass ratio and the total galaxy mass. Despite the dominant sequential formation, observations suggest that thick discs may continue to build up mass alongside their thin-disc counterparts.


**Translated Abstract**: 

目前的盘面星系通常展现出明显的薄盘和厚盘。两种盘面的形成机制和起始时间仍然是未解的问题。为了解决这些问题，我们从JWST旗舰项目中选择了边缘视角的星系，研究其在静止红外带中的盘面结构。首次，我们识别出具有厚盘和薄盘的星系，追溯到超过10亿年的宇宙距离，并探讨它们的分解结构特性。我们将星系分类为需要两个（即薄盘和厚盘）盘面的星系和被单一盘面良好拟合的星系。盘的径向大小和垂直高度与总星系质量和/或盘质量强相关，独立于宇宙时间。厚盘的结构与单个盘星系中发现的盘相似，表明星系首先形成厚盘，随后形成嵌入的薄盘。高质量星系（$10^{9.75} - 10^{11}M_\odot$）的单盘向双盘的转变发生在大约80亿年前，而低质量星系的转变（$10^{9.0} - 10^{9.75}M_\odot$）则发生在40亿年前，表明顺序形成以“去下行”的方式进行。Toomre $Q$-调节的盘形成解释了低质量星系中薄盘形成的延迟，导致厚盘与薄盘质量比率与总星系质量的负相关关系。尽管以顺序形成为主，观测结果表明厚盘可能与薄盘同时继续增质量。

**Summary**:

- (1): 本文的研究背景是当前盘面星系中常见的薄盘和厚盘现象，以及其形成机制和起始时间仍然悬而未决。

- (2): 以往方法主要通过观测现有星系结构来进行研究，存在无法直接定义厚盘和薄盘的界限等问题。本文采用JWST的边缘视角星系数据，首次在宇宙尺度上直接识别这两种盘面，并分析其结构特性。

- (3): 本文的贡献在于首次识别出具有厚盘和薄盘的边缘视角星系，并明确了两种盘面在宇宙演化中的形成顺序，提供了新的关于星系演化的见解。

- (4): 本文的研究方法通过JWST程序观察太空中的边缘视角星系，分析其在近红外波段的盘面结构，分类虚拟星系以获得其几何和物理特征。

- (5): 通过对具有历史的星系的观察，本文实现了对厚盘和薄盘的分类与结构特性分析，所达成的结论支持了研究目标，即理解星系演化中的厚盘与薄盘的形成历程。


## Gravitational wave signals from primordial black holes orbiting solar-type stars
- **Url**: http://arxiv.org/abs/2504.07517v1
- **Authors**: ['Vitorio A. De Lorenci', 'David I. Kaiser', 'Patrick Peter', 'Lucas S. Ruiz', 'Noah E. Wolfe']
- **Abstrat**: Primordial black holes (PBHs) with masses between $10^{14}$ and $10^{20}$ kg are candidates to contribute a substantial fraction of the total dark matter abundance. When in orbit around the center of a star, which can possibly be a completely interior orbit, such objects would emit gravitational waves, as predicted by general relativity. In this work, we examine the gravitational wave signals emitted by such objects when they orbit typical stars, such as the Sun. We show that the magnitude of the waves that could eventually be detected on Earth from a possible PBH orbiting the Sun or a neighboring Sun-like star within our galaxy can be significantly stronger than those originating from a PBH orbiting a denser but more distant neutron star (NS). Such signals may be detectable by the LISA gravitational-wave detector. In addition, we estimate the contribution that a large collection of such PBH-star systems would make to the stochastic gravitational-wave background (SGWB) within a range of frequencies to which pulsar timing arrays are sensitive.


**Translated Abstract**: 

原始黑洞（PBHs）质量在 $10^{14}$ 到 $10^{20}$ kg 之间，可能在整体暗物质丰度中占据了相当大的份额。当这些物体围绕恒星（例如太阳）中心运行时，它们会发出引力波，这是广义相对论的预测。在本研究中，我们检查了当这种物体围绕典型恒星（例如太阳）运行时发出的引力波信号。我们表明，从一个可能围绕太阳或我们星系内邻近的类似太阳的恒星运行的PBH发出的波的强度，可能显著强于来自围绕较密集但更远的中子星（NS）的PBH所发出的波。这些信号可能通过LISA引力波探测器进行检测。此外，我们估算了一大群这样的PBH-恒星系统在旋转频率范围内对随机引力波背景（SGWB）的贡献，这个范围是脉冲星时序阵列敏感的。

**Summary**:

- (1): 本文的研究背景是原始黑洞（PBHs）可能构成整体暗物质丰度的一个重要组成部分，并且它们在围绕恒星（如太阳）运行时会发出引力波信号。

- (2): 过去的研究通常关注于考虑由大振幅标量曲率扰动引起的引力波信号，主要集中在PBHs通过引力塌缩形成的机制上。这些方法的局限在于主要针对源自较大质量天体的信号，而本研究提出的方法则考察小质量PBHs绕太阳或类似恒星运动时的引力波信号，从而弥补了对小质量PBHs的关注。

- (3): 本文的贡献在于提出了研究PBHs与太阳类恒星系统的引力波信号，并且计算了它们对随机引力波背景（SGWB）的潜在贡献，揭示了PBH在小质量范围内可能探测的引力波信号。

- (4): 本文的研究方法包括对PBHs在典型恒星（如太阳）附近的轨道运动进行建模，计算它们发出的引力波特征，特别是量化PBHs对SGWB的贡献。

- (5): 本文的方法在估计PBH-恒星系统对SGWB的贡献方面取得了进展，并预测LISA等未来引力波探测器可能探测到的峰值频率和波幅。这些性能表明该方法确实能够支持其研究目标。


## Infrared Spectroscopy of Pentagon-Containing PAHs: Indenyl and Fluorenyl Anions and Indenyl Cation
- **Url**: http://arxiv.org/abs/2504.07512v1
- **Authors**: ['Gabi Wenzel', 'Miguel Jiménez-Redondo', 'Milan Ončák', 'Brett A. McGuire', 'Sandra Brünken', 'Paola Caselli', 'Pavol Jusko']
- **Abstrat**: Polycyclic aromatic hydrocarbon (PAH) ions are crucial intermediates in interstellar chemistry and may play a key role in the infrared emission features observed in space. Here, we investigate the infrared spectra of the indenyl (C$_9$H$_7^-$) and fluorenyl (C$_{13}$H$_9^-$) anions and the indenyl cation (C$_9$H$_7^+$) using infrared pre-dissociation (IRPD) spectroscopy. The experiments were performed in a cryogenic 22 pole ion trap at the FELion beamline of the tunable free-electron laser FELIX. Spectral analysis of the two anionic PAHs, in combination with density functional theory (DFT) computations, revealed key vibrational modes near 1300 cm$^{-1}$, making these ions potential carriers of the 7.7 {\mu}m PAH emission band seen in many astronomical objects. The feature-rich spectrum of cationic indenyl could not be entirely explained by modeling through time-independent anharmonic DFT calculations. Although a better match has been achieved through molecular dynamics simulations, we cannot completely rule out the presence of multiple cationic isomers of the H-loss fragments of indene in the experiments.


**Translated Abstract**: 

多环芳香烃（PAH）离子是星际化学中的关键中间体，可能在空间中观察到的红外发射特征中发挥重要作用。在这里，我们使用红外前解离（IRPD）光谱学研究了 indenyl (C$_9$H$_7^-$) 和 fluorenyl (C$_{13}$H$_9^-$) 离子以及 indenyl (C$_9$H$_7^+$) 阳离子的红外光谱。实验在可调自由电子激光 FELIX 的低温 22 极离子阱中进行。对这两种阴离子的光谱分析结合密度泛函理论（DFT）计算，揭示了近 1300 cm$^{-1}$ 的关键振动模式，使这些离子成为潜在的 7.7 μm PAH 发射带的载体，该发射带在许多天体中均可见。尽管通过无时间依赖的非谐 DFT 计算对阳离子 indenyl 的特征丰富的光谱进行了建模，但我们尚未完全解释该光谱。通过分子动力学模拟取得了更好的匹配，但我们无法完全排除实验中 indene 的多个 H 损失片段阳离子异构体的存在。

**Summary**:

- (1): 本文研究的背景是多环芳香烃（PAH）离子在星际化学中的重要性，以及它们可能与观察到的红外发射特征的关系。

- (2): 过去的方法主要依赖密度泛函理论（DFT）进行光谱建模，但常常无法完全解释阳离子的光谱特征。本文提出结合红外前解离（IRPD）光谱学与分子动力学模拟的新方法，解决了光谱匹配不佳的问题，并提供了更多的动态信息。

- (3): 本文的贡献在于通过实验和计算相结合的方法，揭示了 indenyl 和 fluorenyl 阴离子及 indenyl 阳离子的红外光谱特征，为理解星际化学提供了新的视角。

- (4): 本文提出的研究方法包括在低温 22 极离子阱中进行红外前解离光谱测量，并使用密度泛函理论和分子动力学进行光谱分析。

- (5): 本文的任务是在星际化学背景下研究 PAH 离子的红外光谱，取得了新增的关键振动模式，能支持它们与 7.7 μm 发射带的关联。


## Are Models of Strong Gravitational Lensing by Clusters Converging or Diverging?
- **Url**: http://arxiv.org/abs/2411.05083v2
- **Authors**: ['Derek Perera', 'John H Miller Jr', 'Liliya L. R. Williams', 'Jori Liesenborgs', 'Allison Keen', 'Sung Kei Li', 'Marceau Limousin']
- **Abstrat**: The increasingly large numbers of multiple images in cluster-scale gravitational lenses have allowed for tighter constraints on the mass distributions of these systems. Most lens models have progressed alongside this increase in image number. The general assumption is that these improvements would result in lens models converging to a common solution, suggesting that models are approaching the true mass distribution. To test whether or not this is occurring, we examine a sample of lens models of MACS J0416.1$-$2403 containing varying number of images as input. Splitting the sample into two bins (those including $<150$ and $>150$ images), we quantify the similarity of models in each bin using three comparison metrics, two of which are novel: Median Percent Difference, Frechet Distance, and Wasserstein Distance. In addition to quantifying similarity, the Frechet distance metric seems to also be an indicator of the mass sheet degeneracy. Each metric indicates that models with a greater number of input images are no more similar between one another than models with fewer input images. This suggests that lens models are neither converging nor diverging to a common solution for this system, regardless of method. With this result, we suggest that future models more carefully investigate lensing degeneracies and anomalous mass clumps (mass features significantly displaced from baryonic counterparts) to rigorously evaluate their model's validity. We also recommend further study into alternative, underutilized lens model priors (e.g. flux ratios) as an additional input constraint to image positions in hopes of breaking existing degeneracies.


**Translated Abstract**: 

随着集群尺度引力透镜中多重图像数量的不断增加，这些系统的质量分布约束也更加紧密。大多数透镜模型都随着图像数量的增加而进步。一般假设这些改进将导致透镜模型收敛到一个共同的解决方案，这表明模型正在接近真实的质量分布。为了测试这种情况，我们检查了一组包含不同数量图像输入的 MACS J0416.1−2403 的透镜模型。将样本分为两个组（包含 <150 和 >150 图像的组），我们使用三个比较指标（其中两个是新颖的：中位数百分比差异、Frechet 距离和 Wasserstein 距离）量化每个组模型的相似性。除了量化相似性，Frechet 距离指标似乎也是质量平面退化的一个指示。每个指标都表明，输入图像数量较多的模型之间并不比图像数量较少的模型更为相似。这表明，无论方法如何，这些透镜模型都没有收敛或发散到一个共同的解决方案。基于此结果，我们建议未来的模型更仔细地调查透镜退化和异常质量团簇（与其物质对应体显著错位的质量特征），以严格评估模型的有效性。我们还推荐进一步研究替代的、未充分利用的透镜模型先验（例如，光通量比），作为图像位置的附加输入约束，希望能够打破现有的退化。

**Summary**:

- (1): 本文的研究背景是随着观测技术的进步，尤其是 **James Webb Space Telescope (JWST)** 的发展，集群尺度引力透镜中的多重图像数量显著增加，从而为更加准确的质量分布模型提供了契机。

- (2): 尽管过去的研究依赖于不同的透镜建模方法进行比较，但问题在于这些模型之间的相似性并没有随着图像数量的增加而增强。文中提出的研究方法通过使用 **Median Percent Difference**、**Frechet Distance** 和 **Wasserstein Distance** 等新颖指标，系统地评估这些模型的相似性，以应对传统方法的不足。提出的方法通过量化模型之间的差异来识别模型的收敛性或发散性，具有较强的动机。

- (3): 本文的贡献在于通过对 **MACS J0416.1−2403** 的透镜模型进行系统评估，表明这些模型的相似性并没有随着输入图像数量的增加而增强，从而挑战了假设模型收敛于真实质量分布的常规观点。

- (4): 本文的研究方法包括将透镜模型分为两组（少于或多于150个图像），并使用多个指标（中位数百分比差异、Frechet 距离和 Wasserstein 距离）量化每组模型的相似性，进而分析模型之间的收敛程度。

- (5): 本文在 **MACS J0416.1−2403** 这一透镜模型上进行的任务表明，模型的相似性并没有提升，无法支持假设的收敛性目标。研究成果提示要更深入地考虑透镜退化和不同质量特征的影响。


## Ultraluminous X-ray sources in Globular Clusters
- **Url**: http://arxiv.org/abs/2501.06037v3
- **Authors**: ['Grzegorz Wiktorowicz', 'Mirek Giersz', 'Abbas Askar', 'Arkadiusz Hypki', 'Lucas Helstrom']
- **Abstrat**: This paper investigates the formation, populations, and evolutionary paths of UltraLuminous X-ray Sources (ULXs) within Globular Clusters (GCs). ULXs, characterised by their extreme X-ray luminosities, present a challenge to our understanding of accretion physics and compact object formation. While previous studies have largely focused on field populations, this research examines the unique environment of GCs, where dynamical interactions play a significant role. Using the MOCCA Monte Carlo code, we explore how dynamics influences ULX populations within these dense stellar clusters.   Our findings reveal that dynamical processes, such as binary hardening and exchanges, can both facilitate and impede ULX formation in GCs. The study explores the impact of parameters including the initial binary fraction, tidal filling, and multiple stellar populations on the evolution of ULXs. We find that non-tidally filling clusters exhibit significantly larger ULX populations compared to tidally filling ones.   The results indicate that the apparent scarcity of ULXs in GCs may be related to the older stellar populations of GCs relative to the field. Furthermore, the study identifies a population of "escaper" ULXs, which originate in GCs but are ejected and emit X-rays outside the cluster. These escapers may significantly contribute to the observed field ULX population.


**Translated Abstract**: 

本文研究了球状星团（Globular Clusters，GCs）内超光亮X射线源（Ultraluminous X-ray Sources，ULXs）的形成、种群和演化路径。超光亮X射线源以其极端的X射线亮度为特征，使得我们对吸积物理和致密天体形成的理解面临挑战。尽管以往的研究主要集中在星系外环境中，本文考察了球状星团这一独特环境，其中动力学相互作用起着重要作用。我们利用MOCCA Monte Carlo代码，探索这些密集恒星团内动力学如何影响ULX种群。我们的研究结果表明，动力学过程（如双星硬化和交换）既能促进也能妨碍GCs内ULX的形成。研究还探讨了初始双星比例、潮汐填充和多重恒星种群等参数对ULX演化的影响。我们发现非潮汐填充的星团较潮汐填充的星团展现出显著更大的ULX种群。此外，结果表明GCs中ULXs的明显稀缺性可能与GCs相对较老的恒星种群有关。此外，研究确认了一种“逃逸”ULXs的种群，这些ULXs起源于GCs，但被弹出并在星团外发射X射线。这些逃逸者可能显著增加观察到的星系外ULX的种群。

**Summary**:

- (1): 本文的研究背景是探索超光亮X射线源（ULXs）在球状星团（GCs）中的形成和演化，旨在解决吸积物理和密集天体形成的理解挑战。

- (2): 以往的方法主要集中于场星球的种群，而本文提出的方法考察球状星团独特的动态环境。该方法通过MOCCA Monte Carlo代码考虑了动力学相互作用对ULXs形成的影响，从而弥补了过去研究未能深入探讨这一问题的不足，具有良好的动机。

- (3): 本文的贡献在于揭示了GCs中ULXs形成的动力学过程，包括双星硬化、潮汐填充和多重恒星种群的影响，并确认了“逃逸”ULXs的存在，这一发现可能显著影响对星系外ULX整体数量的理解。

- (4): 本文采用的研究方法是使用MOCCA Monte Carlo代码，模拟和分析GCs内的动态过程对ULXs种群的影响。

- (5): 本文的方法在揭示GCs内部和外部ULXs的种群特征方面表现出色，找到的结果支持了研究目标，即深入理解ULXs的形成机制及其在宇宙中的分布。


## Measuring Cosmic Growth Rate with CSST Spectroscopic Survey and Fast Radio Burst
- **Url**: http://arxiv.org/abs/2504.07460v1
- **Authors**: ['Shi-Yuan Wang', 'Jun-Qing Xia']
- **Abstrat**: The cosmic growth rate, which is related to peculiar velocity and is a primary scientific objective of galaxy spectroscopic surveys, can be inferred from the Redshift Space Distortion effect and the kinetic Sunyaev-Zel'dovich effect. However, the reconstruction noise power spectrum of the radial velocity field in kSZ is significantly dependent on the measurement of the small-scale galaxy-electron power spectrum $P_{ge}$. In this study, we thoroughly discuss the enhancement of cosmic growth rate measurements facilitated by Fast Radio Bursts, which probe the electron density of the universe along their propagation paths to provide crucial additional information on $P_{ge}$. Subsequently, we utilize future spectroscopic surveys from the Chinese Space Station Telescope and the CMB-S4 experiment, combined with FRB dispersion measures, to achieve precise measurements of the cosmic growth rate at redshifts $z_g = 0.15,0.45,0.75$. Employing Fisher matrix forecasting analysis, we anticipate that constraints on $f\sigma_8$ will reach a precision of 0.001 with a sample size of $10^6$ FRBs. Furthermore, we perform a global analysis using Markov Chain Monte Carlo methods to constrain key parameters of three distinct dark energy models and a modified gravity model based on cosmic growth rate measurements. The results demonstrate that these refined $f\sigma_8$ measurements considerably enhance the constraints on relevant cosmological parameters compared to those obtained from Planck. As the number of observed FRBs increases, alongside more precise galaxy surveys and next-generation CMB observations, new opportunities will arise for constraining cosmological models using the kSZ effect and for developing novel cosmological applications of FRBs.


**Translated Abstract**: 

宇宙增长率与特殊速度有关，是银河光谱测量的重要科学目标。宇宙增长率可以通过红移空间畸变效应和动量Sunyaev-Zel'dovich效应推断。然而，kSZ中径向速度场的重建噪声功率谱显著依赖于小尺度银河-电子功率谱 $P_{ge}$ 的测量。本研究详细讨论了快速射电暴（FRB）促进宇宙增长率测量的增强，FRB探测沿其传播路径的宇宙电子密度，为 $P_{ge}$ 提供了关键额外信息。随后，我们利用来自中国空间站望远镜和CMB-S4实验的未来光谱调查，结合FRB色散测量，以实现对红移 $z_g = 0.15, 0.45, 0.75$ 的宇宙增长率的精确测量。使用Fisher矩阵预测分析，我们预计 $f\sigma_8$ 的约束将达到0.1%的精度，样本量为 $10^6$ FRBs。此外，我们利用Markov链蒙特卡罗方法进行全局分析，以基于宇宙增长率测量约束三个不同的暗能量模型及一个修正引力模型的关键参数。结果表明，这些精确的 $f\sigma_8$ 测量显著增强了对相关宇宙参数的约束，相比于Planck所获得的数据。随着观察到的FRB数量的增加，以及更精确的银河调查和下一代CMB观察的进行，利用kSZ效应来约束宇宙模型的新机会将会出现，同时也会为FRB的新的宇宙学应用提供发展可能。

**Summary**:

- (1): 本文研究背景是宇宙增长率作为测量银河结构的关键指标，以及如何通过快速射电暴（FRB）与动量Sunyaev-Zel'dovich（kSZ）效应来增强增长率的测量精度。

- (2): 过去的方法主要通过kSZ效应和红移空间畸变测量增长率，存在依赖于小尺度银河-电子功率谱 $P_{ge}$ 测量的局限性。提出的方法利用FRB探测的电子密度提供额外信息，通过高信噪比的交叉相关函数解决了 $P_{ge}$ 测量的偏差问题，逻辑合理且具有创新性。

- (3): 本文的贡献在于整合FRB和未来的光谱调查数据，实现对宇宙增长率的高精度测量，并显著增强对宇宙学参数的约束。

- (4): 本文提出了使用Markov链蒙特卡罗方法进行全球分析，以约束不同暗能量模型的参数，并结合来自CMB-S4和中国空间站望远镜的数据。

- (5): 本文的方法在红移 $z_g = 0.15, 0.45, 0.75$ 上实现了对宇宙增长率的精确测量，期望在 $f\sigma_8$ 的约束精度达到0.1%，这种性能足以支持其目标。


## Traversable Wormholes Sourced by Dark Matter in Loop Quantum Cosmology
- **Url**: http://arxiv.org/abs/2411.12063v3
- **Authors**: ['Marcos V. de S. Silva', 'G. Alencar', 'R. N. Costa Filho', 'R. M. P. Neves', 'Celio R. Muniz']
- **Abstrat**: In this work, we investigate the existence of wormholes within the framework of Loop Quantum Cosmology, using isotropic dark matter as the source. We analyze three distinct density profiles and solve the modified gravity field equations alongside the stress-energy tensor conservation, applying appropriate boundary conditions to obtain traversable wormhole solutions. Each solution is shown to satisfy the geometric criteria for wormholes, and their regularity is verified by computing the Kretschmann scalar to ensure the absence of singularities under determined conditions. Additionally, we examine the stress-energy tensor to identify scenarios in which energy conditions are violated within this model. The wormhole geometry is further explored through embedding diagrams, and the amount of exotic matter required to sustain these structures is computed using the Volume Integral Quantifier. Finally, we study the shadow produced by our wormhole solution, considering one of the dark matter density profiles, and compare it with observations of the M87 galaxy.


**Translated Abstract**: 

在这项工作中，我们研究了在Loop Quantum Cosmology框架内存在的虫洞，使用各向同性的暗物质作为源。我们分析了三种不同的密度分布，并解决了修改后的引力场方程以及能量动量张量的守恒，应用适当的边界条件以获取可遍历的虫洞解。每个解都符合虫洞的几何标准，并通过计算Kretschmann标量来验证其规则性，以确保在一定条件下没有奇点。此外，我们检查了能量动量张量，以识别在该模型中能量条件被违反的情景。通过嵌入图进一步探索了虫洞几何，并使用体积分量化器计算了维持这些结构所需的奇异物质数量。最后，我们研究了虫洞解产生的阴影，考虑了其中一个暗物质密度分布，并将其与M87星系的观测结果进行了比较。

**Summary**:

- (1): 本文的研究背景是探讨在引力理论中虫洞的存在，特别是在Loop Quantum Cosmology框架下，考虑利用暗物质作为支持虫洞结构的物质来源。

- (2): 过去的方法主要集中在使用爱因斯坦引力理论构造虫洞，通常需要奇异物质，限制了虫洞的稳定性。本文提出的方法不同于现有方法，通过Loop Quantum Gravity框架引入量子效应，可以在一定条件下使用暗物质作为替代品，从而可能减少或消除对奇异物质的需求，因此具有合理的动机。

- (3): 本文的贡献在于发现了在Loop Quantum Cosmology下，通过暗物质支持的可遍历虫洞解，并对其几何性质及必要的奇异物质量进行了系统分析。

- (4): 本文提出的研究方法包括解析三种冷暗物质模型的密度分布，结合LQC修改的爱因斯坦方程，推导出虫洞解，并通过验证几何特性和能量条件来确保这些解的合理性。

- (5): 本文的方法关注于虫洞解的结构与阴影形成，并与M87星系的观测结果进行了对比，表明所获得的虫洞解可以在量子引力框架下支持所提出的目标。


## Galaxy and halo properties around cosmic filaments from Sloan Digital Sky Survey Data Release 7 and the ELUCID simulation
- **Url**: http://arxiv.org/abs/2504.07367v1
- **Authors**: ['Youcai Zhang', 'Xiaohu Yang', 'Hong Guo', 'Peng Wang', 'Feng Shi']
- **Abstrat**: Using galaxies from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7) along with haloes from the dark matter only constrained ELUCID (Exploring the Local Universe with the reConstructed Initial Density field) simulation, we examine the properties of galaxies and haloes with respect to their distance to cosmic filaments, determined by the medial-axis thinning technique of the COsmic Web Skeleton (COWS) method. Our findings suggest that galaxies or subhaloes grow in mass as they approach these filaments. Galaxies exhibit a redder colour and diminished specific star formation rates as they approach these filaments. Additionally, older subhaloes tend to be more common near the central regions of these filaments. Elliptical galaxies are more frequently found than spiral galaxies in the central regions of the filaments. Lower-mass galaxies typically display reduced sizes in proximity to filaments, whereas higher-mass galaxies tend to exhibit increased sizes when close to filaments. Moreover, the concentration and spin of the haloes grow as they approach the filaments. These findings support the notion that the large-scale structure of the universe, characterized by cosmic web structures, plays a vital role in shaping galaxy and halo properties.


**Translated Abstract**: 

利用来自斯隆数字天空调查数据发布7（SDSS DR7）的星系和仅受暗物质约束的ELUCID（探索局部宇宙与重建初始密度场）模拟中的晕，我们研究了星系和晕与宇宙细丝距离相关的性质。我们的发现表明，星系或亚晕在接近这些细丝时质量增加。星系显示出更红的颜色和较低的特定星形成速率。此外，较老的亚晕往往更常见于这些细丝的中心区域。在细丝中心区域，椭圆星系比螺旋星系更为常见。较低质量的星系通常在靠近细丝时显示出减小的尺寸，而较高质量的星系在接近细丝时则表现出增大的尺寸。此外，接近细丝时，晕的浓度和自旋会增强。这些发现支持了宇宙的大尺度结构，即宇宙网络结构在塑造星系和晕的性质中起着至关重要的作用。

**Summary**:

- (1): 本文的研究背景是星系和晕在宇宙网络中形成与演化的过程，特别是如何受到宇宙细丝环境的影响。

- (2): 过去的方法主要集中在直接观测星系及其周围环境，存在忽视宇宙细丝重要性的缺陷。本文提出的COsmic Web Skeleton (COWS)方法通过细化宇宙细丝的识别，解决了现有方法的局限性，能更好地分析星系与细丝之间的关系。

- (3): 本文的贡献在于确认了星系和晕的性质在靠近宇宙细丝的情况下发生显著变化，提供了新的视角来理解宇宙大尺度结构对星系演化的影响。

- (4): 研究方法包括使用SDSS DR7中的星系数据和ELUCID模拟中的晕数据，结合COWS方法识别宇宙细丝，分析星系和晕环境的相互作用。

- (5): 本文在研究星系和晕的质量、颜色、尺寸和星形成速率等方面取得了显著结果，这些结果表明了宇宙细丝对这些特性的影响，支持了研究目标。


## Resolved ALMA [CII] 158 micron Observations at Cosmic Noon: ISM Structure and Dynamics of Starbursting QSO SDSSJ1000
- **Url**: http://arxiv.org/abs/2504.07325v1
- **Authors**: ['Christopher Rooney', 'Bo Peng', 'Amit Vishwas', 'Gordon Stacey', 'Thomas Nikola', 'Cody Lamarche', 'Catie Ball', 'Carl Ferkinhoff', 'Drew Brisbin', 'Steven Hailey-Dunsheath']
- **Abstrat**: We present spatially resolved Alma Band-9 observations of the [CII] 158 $\mu$m fine structure line from an optically selected quasar, SDSS J100038.01+020822.4 (J1000), at z=1.8275. By utilizing [OI] 63 $\mu$m line observations from Herschel/PACS and constructing a detailed dust SED using Herschel and Spitzer archival imaging data, we show that the [CII] line emission is well explained by a photodissociation region (PDR) model, in which the emission arises from the surfaces of molecular clouds exposed to far-UV radiation fields $\sim 5\cdot10^3$ times the local interstellar radiation field (G$_0$). We find a factor of 30 variation in spatially resolved [CII]/Far-IR continuum across the source which is explained by the reduced fraction of cooling via [CII] line emission at such high far-UV field strengths. By matching derived PDR parameters to the observed far-IR line and continuum intensities we derive cloud size-scales and find that typical cloud radii in J1000 are $\sim$3.5 pc perhaps indicating an ISM that is highly fractured due to intense star formation activity. We model the galaxy dynamically and find that the [CII] emission is contained within a compact, dynamically cold disk with v/$\sigma$=6.2, consistent with cosmological simulations. We also report the discovery of a companion galaxy to j1000 confirmed by the detection of [CII] and use recently obtained JWST/NirCAM imaging of the system to argue for J1000 being an interacting system. With total stellar mass $\sim 1.5 \times 10^{10}$ M$_\odot$ and main-component dynamical mass $\gtrsim 10^{11}$ M$_\odot$, the J1000 system is a progenitor to the most massive galaxies seen in the local Universe.


**Translated Abstract**: 

我们展示了对光学选择类星体SDSS J100038.01+020822.4 (J1000) 在z=1.8275时的[CII] 158 μm细结构线的空间分辨Alma第9波段观测。通过利用Herschel/PACS的[OI] 63 μm线观测，并利用Herschel和Spitzer档案成像数据构建详细的尘埃SED，我们表明[CII]线发射可以通过光解离区(PDR)模型很好地解释，其中发射来自暴露于约5·10^3倍于局部星际辐射场(G₀)的分子云表面。我们发现源区的[CII]/远红外连续光谱比率在空间上具有30倍的变化，这可以通过在如此高的远紫外场强度下，[CII]线发射冷却比例的降低来解释。通过将所推导的PDR参数与观测到的远红外线和连续光谱强度相匹配，我们推导出云的大小尺度，发现J1000中典型的云半径约为3.5 pc，这可能表明因强烈的星形成活动而导致的星际介质高度破碎。我们动态建模该星系，发现[CII]发射被包含在一个紧凑、动态冷却的盘中，v/σ=6.2，与宇宙学模拟一致。我们还报告了J1000的伴星系的发现，确认了[CII]的检测，并利用最近获得的JWST/NirCAM成像数据，论证了J1000是一个相互作用的系统。J1000系统的总星体质量约为1.5 × 10¹⁰ M⊙，主要成分动力学质量大于等于10¹¹ M⊙，是目前观察到的最大星系的前体。

**Summary**:

- (1): 本文的研究背景为“宇宙中午”（z ∼ 1-3）时期星形成速率密度达到峰值，这一时期形成了大多数现在宇宙中的星体。

- (2): 过去的方法主要依赖于光学波段观测，不易于探测被尘埃遮蔽的星形成区域，导致在紫外线强场下的物理条件难以准确获取。本文提出的方法结合了[CII]和[OI]线的观测，基于PDR模型提供了更好的物理描述，克服了传统方法的阻碍。

- (3): 本文的贡献在于利用Alma的高分辨率成像技术，探测到重要的细结构线[CII]，并获得了关于星系的 ISM 结构和动力学的新信息，揭示了星形成的复杂条件。

- (4): 本文采用的研究方法包括空间分辨的Alma观测与Herschel/PACS的数据结合，通过分析[CII]线发射来构建PDR模型，从而推导出星际介质的属性。

- (5): 本文的方法在探测并分析星系SDSS J1000的[CII]发射和整体动态质量方面取得了有效结果，支持了星系演化的理论框架，表现出该星系作为最巨大星系前体的重要性。


## ASKAP Discoveries of Giant Radio Galaxies in the Sculptor field
- **Url**: http://arxiv.org/abs/2504.07314v1
- **Authors**: ['B. S. Koribalski']
- **Abstrat**: We present the discovery of 15 well-resolved giant radio galaxies (GRGs) with angular sizes >5 arcmin and physical sizes >1 Mpc in wide-field Phased Array Feed 944 MHz observations on the Australian Square Kilometre Array Pathfinder (ASKAP). We identify their host galaxies, examine their radio properties as well as their environment, and classify their morphologies as FR I (4), FR II (8), intermediate FR I/II (2), and hybrid (1). The combined ~40 deg^2 ASKAP image of the Sculptor field, which is centred near the starburst galaxy NGC 253, has a resolution of 13" and an rms sensitivity of >10 microJy/beam. The largest GRGs in our sample are ASKAP J0057-2428 (zphot = 0.238), ASKAP J0059-2352 (zphot = 0.735) and ASKAP J0107-2347 (zphot = 0.312), for which we estimate linear projected sizes of 2.7, 3.5 and 3.8 Mpc, respectively. In total we catalog 232 extended radio galaxies of which 77 (33%) are larger than 0.7 Mpc and 35 (15%) are larger than 1 Mpc. The radio galaxy densities are 5.8 deg^-2 (total) and 0.9 (1.9) deg^-2 for those larger than 1 (0.7) Mpc, similar to previous results. Furthermore, we present the ASKAP discovery of a head-tail radio galaxy, a double-lobe radio galaxy with a spiral host, and radio emission from several galaxy clusters. As the ASKAP observations were originally conducted to search for a radio counterpart to the gravitational wave detection GW190814 (z ~ 0.05), we highlight possible host galaxies in our sample.


**Translated Abstract**: 

我们在澳大利亚平方千米阵列探测器（ASKAP）进行的宽场相位阵列馈电944 MHz观测中，发现了15个分辨良好的巨型射电星系（GRGs），其角度尺寸≥5弧分，物理尺寸>1 Mpc。我们识别了它们的宿主星系，检查了它们的射电性质及其环境，并将其形态分类为FR I（4个）、FR II（8个）、中间FR I/II（2个）和混合型（1个）。组合的约40平方度ASKAP图像以星暴星系NGC 253为中心，分辨率为13''，rms灵敏度>10微Jy/beam。我们样本中最大的GRG是ASKAP J0057-2428（zphot = 0.238）、ASKAP J0059-2352（zphot = 0.735）和ASKAP J0107-2347（zphot = 0.312），我们估计它们的线性投影尺寸分别为2.7、3.5和3.8 Mpc。我们总共目录了232个扩展射电星系，其中77（33%）的尺寸超过0.7 Mpc，35（15%）的尺寸超过1 Mpc。射电星系的密度分别为5.8 deg^-2（总数）和0.9（1.9）deg^-2，类似于之前的结果。此外，我们报道了ASKAP发现了一种头尾射电星系、一种具有螺旋宿主的双耳射电星系，以及来自多个星系团的射电辐射。由于ASKAP观测最初是为了寻找引力波探测GW190814（z ~ 0.05）的射电对应体，我们突显了样本中的可能宿主星系。

**Summary**:

- (1): 本文的研究背景是巨型射电星系（GRGs）在宇宙中是最大的单一物体之一，它们的物理尺寸通常超过0.7 Mpc或1 Mpc，能够反映其宿主星系内的能量过程及与周围星际介质的相互作用。

- (2): 过去的方法主要依赖于较小规模的射电调查，其存在的问题如样本量有限和探测灵敏度差。与现有方法不同，本文利用ASKAP的宽场高灵敏度观测，能够识别更大、数量更多的GRGs，解决了之前研究中的样本不足和分辨率低的问题。

- (3): 本文的主要贡献在于发现了15个巨型射电星系，并对其宿主星系及环境进行了详细的分类和分析，扩展了GRG的已知样本及其性质。

- (4): 本文提出的研究方法是通过ASKAP进行宽场944 MHz观测，结合了高分辨率和高灵敏度，使得对GRG的观察与分析更加细致全面。

- (5): 本文的研究在识别与分类巨型射电星系和其射电性质的任务上取得了显著表现，发现了232个扩展射电星系，支持了研究者对GRGs特性以及与星际介质相互作用的目标。


# galaxies
## An overview of what current data can (and cannot yet) say about evolving dark energy
- **Url**: http://arxiv.org/abs/2502.10264v2
- **Authors**: ['William Giarè', 'Tariq Mahassen', 'Eleonora Di Valentino', 'Supriya Pan']
- **Abstrat**: Recent measurements of Baryon Acoustic Oscillations (BAO) and distance moduli from Type Ia supernovae suggest a preference for Dynamical Dark Energy (DDE) scenarios characterized by a time-varying equation of state (EoS). This focused review assesses its robustness across independent measurements and surveys. Using the Chevallier-Polarski-Linder (CPL) parametrization to describe the evolution of the DE EoS, we analyze over 35 dataset combinations, incorporating Planck Cosmic Microwave Background (CMB) anisotropies, three independent Type Ia supernova (SN) catalogs (PantheonPlus, Union3, DESY5), BAO measurements from DESI and SDSS, and expansion rate measurements $H(z)$ inferred from the relative ages of massive, passively evolving galaxies at early cosmic times known as Cosmic Chronometers (CC). This review has two main objectives: first, to evaluate the statistical significance of the DDE preference across different dataset combinations, which incorporate varying sources of information. Specifically, we consider cases where only low-redshift probes are used in different combinations, others where individual low-redshift probes are analyzed together with CMB data, and finally, scenarios where high- and low-redshift probes are included in all possible independent combinations. Second, we provide a reader-friendly synthesis of what the latest cosmological and astrophysical probes can (and cannot yet) reveal about DDE. Overall, our findings highlight that combinations that \textit{simultaneously} include PantheonPlus SN and SDSS BAO significantly weaken the preference for DDE. However, intriguing hints supporting DDE emerge in combinations that do not include DESI-BAO measurements: SDSS-BAO combined with SN from Union3 and DESY5 (with and without CMB) support the preference for DDE.


**Translated Abstract**: 最近的对声波声学振荡（BAO）和来自Ia型超新星的距离模量的测量表明，倾向于动态暗能量（DDE）场景，其特征是时间变化的状态方程（EoS）。本次专注的综述评估了其在独立测量和调查中的可靠性。我们利用Chevallier-Polarski-Linder（CPL）参数化描述暗能量EoS的演变，分析了超过35个数据集组合，结合了Planck宇宙微波背景（CMB）各向异性、三个独立的Ia型超新星（SN）目录（PantheonPlus、Union3、DESY5）、来自DESI和SDSS的BAO测量，以及从早期宇宙时期被动演化的星系相对年龄推断的扩展率测量$H(z)$。本综述有两个主要目标：第一，评估不同数据集组合中DDE偏好的统计显著性；第二，提供关于最新宇宙学和天体物理探测器能够（或尚不能）揭示有关DDE的信息的易读综述。总体而言，我们的结果强调，结合PantheonPlus SN和SDSS BAO的数据组合显著削弱了对DDE的偏好。然而，支持DDE的有趣线索出现在不包括DESI-BAO测量的组合中：SDSS-BAO与没有CMB的Union3和DESY5 SN组合（与不包含CMB的组合）支持对DDE的偏好。

**Summary**:

- (1): 本文研究背景是1998年通过对远距离Ia型超新星的观测发现，宇宙正经历加速扩展，这对理解宇宙的最终命运产生了深远影响，但解释这一加速的物理机制仍然存在挑战。

- (2): 过去的方法主要基于常数状态方程的暗能量模型。然而，这些模型未能很好解释宇宙的加速扩展，因此考虑了动态暗能量（DDE）。与现有方法不同，本文采用Chevallier-Polarski-Linder（CPL）参数化来允许EoS随宇宙膨胀变化，从而更加灵活地描述暗能量。

- (3): 本文的贡献在于评估了不同数据集组合中DDE偏好的统计显著性，并且提供了对当前宇宙学和天体物理探测器揭示DDE的能力的易读综述，强调了一些组合支持DDE的潜在迹象。

- (4): 本文的研究方法主要包括分析超过35个数据集组合，结合Planck CMB、多个Ia型超新星数据库和BAO测量，采用Chevallier-Polarski-Linder（CPL）参数化来描述暗能量状态方程的演变。

- (5): 本文的任务是评估DDE的偏好统计显著性，结果表明，在不包括DESI-BAO的情况下，某些组合支持DDE的偏好。这些结果在一定程度上支持了作者的目标，揭示了当前数据对DDE的局限性和潜在支持。


## Ultraviolet Compactness of High-Redshift Galaxies as a Tracer of Early-Stage Gas Infall, Bursty Star Formation, and Offset from the Fundamental Metallicity Relation
- **Url**: http://arxiv.org/abs/2307.06336v2
- **Authors**: ['Danial Langeroodi', 'Jens Hjorth']
- **Abstrat**: The empirical anti-correlation between gas-phase metallicity and star formation rate (SFR), known as the fundamental metallicity relation (FMR), is generally understood as an equilibrium state in the interplay between gas infall, enrichment, and gas removal in galaxies. NIRSpec spectroscopy has shown a $z>3$ deviation from the local-universe calibration of the FMR, suggesting that these galaxies are potentially caught out of equilibrium. To investigate this, we measured the stellar population, nebular, and morphological properties of 427 galaxies at $3<z<10$ based on their uniformly reduced NIRSpec prism spectroscopy and NIRCam photometry. We find that a mass-size relation is already established at $4<z<10$, with a normalization anti-correlated with redshift. The size-redshift anti-correlation depends on stellar mass: while the size of $M_*<10^8M_{\odot}$ galaxies strongly declines with redshift, $M_*>10^9M_{\odot}$ galaxies exhibit negligible redshift evolution. Furthermore, we confirm the redshift evolution of the FMR: $z>3$ galaxies appear metal deficient compared to what is expected for their stellar mass and SFR based on the local-universe FMR. This offset grows with redshift. We find that metal deficiency is correlated with compactness: the most compact galaxies (those most offset from the average mass-size relation) are the most unexpectedly-metal-poor by being the most offset from the local-universe FMR. We interpret this as a consequence of bursty star formation: compact galaxies exhibit elevated SFR surface densities, indicating that they are observed during burst episodes induced by fresh gas infall. While the accretion of metal-poor gas has reduced their gas-phase metallicity by diluting the ISM, they are observed prior to chemical yield release by newly formed massive stars. Simply, they are chemically out of equilibrium compared to the equilibrium state known as the FMR.


**Translated Abstract**: 

气体相金属丰度与恒星形成率（SFR）之间的经验反相关，即基本金属丰度关系（FMR），通常被理解为气体流入、富集与气体移除在星系中的相互作用的平衡状态。NIRSpec光谱学显示出z>3与本地宇宙FMR的校准偏差，这表明这些星系可能处于非平衡状态。为此，我们基于均匀处理的NIRSpec棱镜光谱和NIRCam光度测量了427个红移为3<z<10的星系的恒星种群、气体和形态特征。我们发现，在4<z<10时，质量-尺度关系已经建立，并且其归一化与红移反相关。尺度-红移反相关依赖于恒星质量：对于质量小于10^8M⊙的星系，尺度随红移明显降低，而质量大于10^9M⊙的星系则表现出微弱的红移演化。此外，我们确认FMR的红移演化：z>3的星系与基于本地宇宙FMR的其恒星质量和SFR预期相比，表现出金属缺乏。随着红移的增长，这种偏移加大。我们发现金属缺乏与紧凑性相关：最紧凑的星系（那些与平均质量-尺度关系的偏移最大）是最意外的金属贫乏星系，它们相对于本地宇宙FMR的偏移也最大。我们将此解释为突发星形成的结果：紧凑星系展现出较高的SFR表面密度，表明它们在新气体流入引发的爆发期间被观察到。尽管金属贫乏的气体注入减少了它们的气相金属丰度，但它们是在新形成的大质量恒星释放化学产物之前被观察到的。简而言之，它们在化学上与被称为FMR的平衡状态不一致。

**Summary**:

- (1): 本文研究气体相金属丰度与恒星形成率（SFR）之间的基本金属丰度关系（FMR），特别是红移大于3的星系在此关系下的非平衡状态。

- (2): 过去的研究主要依赖地面光谱仪探测质量-金属丰度关系，发现z≈3.5的星系金属丰度明显低于本地宇宙。然而，对更高红移的探测由于光谱线被红移而变得困难。本文提出使用JWST NIRSpec提供的光谱，解决了高红移探测中的挑战，能够获取红移为3至10的星系数据。

- (3): 本文的贡献在于测量了427个高红移星系的恒星种群、气体属性及形态特征，确认并量化了FMR的红移演化，并发现金属贫乏与星系的紧凑性之间的关系。

- (4): 本文采用的研究方法是基于NIRSpec的光谱数据和NIRCam的光度数据，对468个赤方星系在气体相金属丰度和恒星形成活动的平衡状态进行分析。

- (5): 本文分析显示，z>3的星系表现出金属贫乏的特征，相较于当地FMR的预期，这种金属偏离随着红移增强，支持了星系演化模型中的突发星形成理论。


## Using simulation based inference on tidally perturbed dwarf galaxies: the dynamics of NGC205
- **Url**: http://arxiv.org/abs/2501.13148v2
- **Authors**: ['Axel Widmark', 'Kathryn V. Johnston']
- **Abstrat**: We develop a novel approach to performing precision inference on tidally perturbed dwarf galaxies. We use a Bayesian inference framework of implicit likelihood inference, previously applied mainly in the field of cosmology, based on forward simulation, data compression, and likelihood emulation with neural density estimators. We consider the case of NGC205, a satellite of M31. NGC205 exhibits an S-shape in the mean line-of-sight velocity along its semi-major spatial axis, suggestive of tidal perturbation. We demonstrate that this velocity profile can be qualitatively reproduced even if NGC205 was in a spherically symmetric and isotropic state before its most recent pericenter passage. We apply our inference method to mock data and show that the precise shape of a perturbed satellite's sky-projected internal velocity field can be highly informative of both its orbit and total mass density profile, even in the absence of proper motion information. For the actual NGC205, our method is hampered because the available data only covers a line along its semi-major axis, rather than the full sky-projected field. This shortcoming could be addressed with another round of observations.


**Translated Abstract**: 

我们开发了一种新的方法来对潮汐干扰的矮星系进行精确定量推断。我们采用基于前向模拟、数据压缩和使用神经密度估计器的似然仿真框架。我们考虑了M31的卫星NGC205的案例。NGC205的均值视线速度沿其半主轴表现出S形状，这表明它受到潮汐扰动。我们证明，即使在最近的近心点通路之前，NGC205处于球对称和各向同性状态，这种速度轮廓也能被定性再现。我们将推断方法应用于虚拟数据，表明扰动卫星的天空投影内部速度场的精确形状可以提供关于其轨道和总质量密度分布的关键信息，即使在缺乏实际运动信息的情况下。对于实际的NGC205而言，由于现有数据仅覆盖沿其半主轴的一条线，而不是完整的天空投影场，因此我们的办法受阻。这一缺陷可以通过另一轮观测来解决。

**Summary**:

- (1): 本文研究的背景是银河动力学，特别是时间变化系统的动力学质量测量方法。

- (2): 过去的方法通常基于稳态假设，但在处理时变系统时常常面临困难。本文提出的方法通过隐式似然推断，利用前向模拟和神经密度估计，可解决传统方法中的计算复杂性和高维模型的问题，具有良好的动机。

- (3): 本文的贡献在于首次将隐式似然推断方法应用于潮汐干扰的星系内部动力学分析，尤其是对NGC205的研究。

- (4): 本文提出了使用前向模拟学习输入参数与观测之间的映射，并通过神经网络模拟似然的研究方法。

- (5): 本文方法在重建NGC205的内部速度场和轨道信息任务中表现出较高的精确性，有助于识别其质量密度分布，支持其研究目标。


## Quantum Rods and Clock in a Gravitational Universe
- **Url**: http://arxiv.org/abs/2412.03636v3
- **Authors**: ['Hao Geng']
- **Abstrat**: Local operators are the basic observables in quantum field theory which encode the physics observed by a local experimentalist. However, when gravity is dynamical, diffeomorphism symmetries are gauged which apparently obstructs a sensible definition of local operators, as different locations in spacetime are connected by these gauged symmetries. This consideration brings in the puzzle of reconciling our empirical world with quantum gravity. Intuitively, this puzzle can be avoided using relatively defined observables when there exists a natural reference system such as a distribution of galaxies in our universe. Nevertheless, this intuition is classical as the rods and clock defined in this way may also have quantum fluctuations so it is not a priori clear if it can be realized in the quantum regime. In this letter, we provide an affirmative answer to this question. Interestingly, we notice that the quantum fluctuations of the reference system are in fact essential for the realization of the above intuition in the quantum regime.


**Translated Abstract**: 

局部算子是量子场论中的基本可观测量，编码了局部实验者所观察到的物理现象。然而，当引力是动态的时，流形对称性被规范化，这似乎妨碍了局部算子的合理定义，因为时空中的不同位置通过这些规范对称性相连。这一考虑引发了将我们经验世界与量子引力调和的难题。直观上，当存在自然参考系（如我们宇宙中的星系分布）时，可以使用相对定义的可观测量来避免这一难题。然而，这一直观是经典的，因为以这种方式定义的杆和钟也可能具有量子波动，因此尚不清楚它是否可以在量子范围内实现。在本文中，我们对此问题提供了肯定的回答。有趣的是，我们注意到参考系的量子波动事实上对于在量子范围内实现上述直观是必不可少的。

**Summary**:

- (1): 本文的研究背景是量子场论中局部算子的定义受到动态引力的流形对称性影响，从而导致实验者在量子引力下对可观测量的理解面临挑战。

- (2): 过去的方法主要依赖于将局部算子与背景物质分布相结合以尝试定义差异性不变的算子，但这些方法往往只能在简化的情境中适用且无法真正实现本质上的局部性。本文提出的方法通过引入相对性定义的可观测量，利用星系作为自然参考系，从而解决了局部算子在量子范围内的定义问题，且该方法具有良好的动机。

- (3): 本文的贡献在于确认了量子波动在量子引力背景下实现“参考系”直观的重要性，推进了对量子引力中局部算子合理定义的理解。

- (4): 本文提出的研究方法通过建立与参考系的量子波动的关系，探讨了如何在量子背景下定义和实现局部算子，提出了一种新的观察框架。

- (5): 本文的方法主要任务是建立在引力宇宙中可行的局部算子定义。虽然没有直接提供性能指标，但通过理论推导确认了量子波动在实现局部性方面的必要性，支持了对量子引力的理解目标。


## Magnetic Fields of Satellite Galaxies Stronger Than Comparable Centrals in TNG100
- **Url**: http://arxiv.org/abs/2504.07895v1
- **Authors**: ['Bryanne McDonough', 'Alexander Poulin']
- **Abstrat**: Magnetic fields exist in and around galaxies, but the properties of these fields have not been fully explored due to the challenges inherent in observing and modeling them. In this Note, we explore the differences in magnetic field strength of central and satellite galaxies from the magnetohydrodynamic TNG100 simulation. We find that on average, magnetic fields in satellite galaxies are roughly an order of magnitude stronger than those of central galaxies with comparable masses. The difference is greater for satellites that have already approached within $1 R_{200}$ of their host galaxies. These results indicate that magnetic fields in satellite galaxies are amplified by environmental processes as they fall into a host halo.


**Translated Abstract**: 
磁场存在于星系及其周围，但由于观察和建模的挑战，尚未充分探索这些场的性质。在这篇短文中，我们探讨了来自磁流体动力学 TNG100 模拟的中心星系和卫星星系的磁场强度差异。我们发现，平均而言，卫星星系的磁场强度大约比同等质量的中心星系强出一个数量级。对于已经接近主星系 $1 R_{200}$ 的卫星，差异更大。结果表明，卫星星系的磁场在它们进入宿主星系时由环境过程增强。

**Summary**:

- (1): 本文的研究背景是磁场在星系演化中的重要性，尤其是在环境中对卫星星系的影响，但目前对这一领域的了解有限。

- (2): 过去的方法主要基于观察和小规模模拟，存在难以量化磁场强度的问题。本文采用了 TNG100 全卷模拟，与既往研究相比，能够提供更全面的卫星星系的环境影响和磁场强度的定量分析，从而更有效地揭示磁场增强机制。

- (3): 本文的贡献在于发现卫星星系的磁场强度普遍大于同质量的中心星系，并且这种增强现象在接近主星系时更加明显，明确了环境对卫星星系磁场的影响。

- (4): 本文采用 TNG100 模拟数据，从中提取卫星和中心星系的磁场强度进行比较，使用了统计分析的方法来验证结果的可靠性。

- (5): 本文的方法在分析磁场强度时实现了更好的定量评估，表明卫星星系的磁场在其环境影响下显著增强，支持了研究目标。


## Simulating Solar Neighborhood Brown Dwarfs I: The Luminosity Function Above and Below the Galactic Plane
- **Url**: http://arxiv.org/abs/2411.06330v2
- **Authors**: ['Easton J. Honaker', 'John E. Gizis']
- **Abstrat**: Brown dwarfs form the key, yet poorly understood, link between stellar and planetary astrophysics. These objects offer unique tests of Galactic structure, but observational limitations have inhibited their large-scale analysis to date. Major upcoming sky surveys will reveal unprecedented numbers of brown dwarfs, among even greater numbers of stellar objects, greatly enhancing the statistical study of brown dwarfs. To extract the comparatively rare brown dwarfs from these massive datasets, we must understand the parameter space they will occupy. In this work, we construct synthetic populations of brown dwarfs in the Solar Neighborhood to explore their evolutionary properties using Gaia-derived star formation histories alongside observational mass, metallicity, and age relationships. We apply the Sonora Bobcat, SM08, and Sonora Diamondback evolutionary models. From the populations, we explore the space densities and median ages by spectral type. We present the simulated luminosity function and its evolution with distance from the Galactic Plane. Our simulation shows that brown dwarf population statistics are a function of height above/below the Galactic Plane and sample different age distributions. Interpreting the local sample requires combining evolutionary models, the initial mass function, the star formation history, and kinematic heating. Our models are a guide to how well height-dependent samples can test these scenarios. Sub-populations of brown dwarfs farther from the Plane are older and occupy a different region of parameter space than younger sub-populations closer to the Galactic Plane. Therefore, fully exploring population statistics both near and far from the Plane is critical to prepare for upcoming surveys.


**Translated Abstract**: 

褐矮星是介于恒星和行星之间的重要但理解不足的天体。这些物体为银河结构提供了独特的测试，但观察限制导致至今对其大规模分析受阻。即将进行的大型天空调查将揭示前所未有的褐矮星数量，同时也会增添更多恒星对象，从而极大提升对褐矮星的统计研究。为了从这些庞大的数据集中提取较为稀有的褐矮星，我们必须了解它们所占据的参数空间。在本研究中，我们建立了太阳邻域的合成褐矮星群体，利用基于Gaia的数据推导的恒星形成历史以及观察到的质量、金属丰度和年龄关系，探讨它们的演化特性。我们应用了Sonora Bobcat、SM08和Sonora Diamondback演化模型。从这些群体中，我们考察了不同光谱类型的空间密度和中位年龄。我们呈现了模拟的光度函数及其随离银河平面的距离演变的情况。我们的模拟表明，褐矮星群体统计是高度依赖于银河平面的上下位置，并展现出不同年龄分布。解析本地样本需要结合演化模型、初始质量函数、恒星形成历史和运动加热。我们的模型为如何测试这些情景的高度相关样本提供了指导。更远离平面的褐矮星亚群体更老，且占据与更靠近银河平面的年轻亚群体不同的参数空间。因此，全面探讨离平面近和远的群体统计对即将来临的调查至关重要。

**Summary**:

- (1): 本文研究的背景是对褐矮星这类介于恒星与行星之间的天体的理解仍然不足，同时观察限制影响了对其大规模分析，未来的天空调查将增加对这些对象的统计研究。

- (2): 过去的研究方法主要依赖于假设恒星形成率（SFR）和初始质量函数（IMF），并假设银河平面上下的指数分布。这些方法未能反映更复杂的形成机制和空间分布。本文通过结合Gaia数据与观察关系，建立合成褐矮星群体，解决了过去方法的不足，并且在研究设计中有充分的动机支持其新方法的实施。

- (3): 本文的贡献在于构建了太阳邻域的合成褐矮星群体模型，并探讨了它们的演化特性，揭示了光度函数及其与银河平面高度的关系，为未来大规模天空调查做好了准备。

- (4): 研究方法包括利用Gaia数据构建合成褐矮星群体，应用多种演化模型（如Sonora Bobcat、SM08、Sonora Diamondback），分析不同高度下的群体参数和光度函数。

- (5): 本文方法专注于模拟褐矮星的群体统计，并展示了其随距离银河平面的变化，评估了不同高度的亚群体对即将到来的调查的支持能力，从而为未来研究提供了重要的统计基础。


## oMEGACat. VI. Analysis of the overall kinematics of Omega Centauri in 3D: velocity dispersion, kinematic distance, anisotropy, and energy equipartition
- **Url**: http://arxiv.org/abs/2503.04903v2
- **Authors**: ['Maximilian Häberle', 'Nadine Neumayer', 'Callie Clontz', 'Anil Seth', 'Peter Smith', 'Sebastian Kamann', 'Renuka Pechetti', 'Maria Selina Nitschai', 'Mayte Alfaro-Cuello', 'Holger Baumgardt', 'Andrea Bellini', 'Anja Feldmeier-Krause', 'Nikolay Kacharov', 'Mattia Libralato', 'Antonino P. Milone', 'Stefano Souza', 'Glenn van de Ven', 'Zixian Wang']
- **Abstrat**: Omega Centauri ($\omega$ Cen) is the Milky Way's most massive globular cluster and is likely the stripped nucleus of an accreted dwarf galaxy. In this paper, we analyze $\omega$ Cen's kinematics using data from oMEGACat, a comprehensive catalog of $\omega$ Cen's central regions, including 1.4 million proper motion measurements and 300,000 spectroscopic radial velocities. Our velocity dispersion profiles and kinematic maps are consistent with previous work but improve on their resolution, precision, and spatial coverage. The cluster's 3D dispersion is isotropic in the core, with increasing radial anisotropy at larger radii. The 2D kinematic maps show an elongation of the velocity dispersion field comparable to the flattening observed photometrically. We find good agreement between proper motions and line-of-sight velocity dispersion and measure a kinematic distance of 5494$\pm$61 pc, the most precise kinematic distance to $\omega$ Cen available. The subset of data with precise metallicity measurements shows no correlation between metallicity and kinematics, supporting the picture of well-mixed stellar populations within the half-light radius of $\omega$ Cen. Finally, we study the degree of energy equipartition using a large range of stellar masses. We find partial energy equipartition in the center that decreases towards large radii. The spatial dependence of the radial energy equipartition is stronger than the tangential energy equipartition. Our kinematic observations can serve as a new reference for future dynamical modeling efforts that will help to further disentangle the complex mass distribution within $\omega$ Cen.


**Translated Abstract**: 
Ω Centauri（ω Cen）是银河系内最大、最重的球状星团，可能是一个被剥离的矮星系的核心。本文通过使用oMEGACat数据集，其中包含140万个运动测量和30万个光谱径向速度数据，分析了ω Cen的运动学。我们的速度色散分布和运动学图谱与先前的研究一致，但在分辨率、精确度及空间覆盖率上有所提高。核心区的三维运动色散是各向同性的，而在更大半径处呈现出逐渐增加的径向各向异性。二维运动学图谱显示出与光度测量中观察到的扁平化现象相当的速度色散场的拉伸。我们发现运动测量与视线速度色散之间有很好的一致性，并测得ω Cen的运动学距离为5494 ± 61 pc，这是目前对ω Cen可用的最精确的运动学距离。具有精确元素丰度测量的数据子集显示出金属丰度与运动学之间没有相关性，支持ω Cen半光半径内恒星种群的均匀混合图景。最后，我们研究了不同质量恒星范围内的能量均分程度，发现中心区域有部分能量均分，而在大半径下降低。径向能量均分的空间依赖性强于切向能量均分。我们的运动学观测可以作为未来动力学建模工作的新参考，帮助进一步解构ω Cen内部复杂的质量分布。

**Summary**:

- (1): 本文的研究背景是Ω Centauri（ω Cen）作为银河系最大球状星团的复杂星系结构和内部运动学特性，涉及其可能作为被剥离的矮星系的核。

- (2): 过去的研究方法主要依赖视线速度和早期的运动测量，样本规模较小，限制了对星团的更广泛分析。相比之下，提出的方法使用oMEGACat数据集，能够获得更高分辨率和覆盖率的运动学数据，解决了样本数量有限的问题，并且是充分激励的。

- (3): 本文的贡献在于提供了更高精度的运动学分析，具体包括运动色散分布、运动学距离的测量，以及能量均分情况的探讨，从而深化了对ω Cen内恒星种群及其运动学特性的理解。

- (4): 研究方法包括使用综合的光谱和运动学数据，详细分析星团的速度色散、各向异性、旋转特性，以及建立二维运动学图谱，综合评估恒星的运动学特征。

- (5): 本文方法在测量Ω Centauri的运动学距离方面取得了5494 ± 61 pc的性能表现，这不仅为后续模型建立提供了新参考，同时确认了恒星群体的均匀混合状态，有助于支撑未来研究的目标。


## Improving Photometric Redshift Estimation for CSST Mock Catalog Using SED Templates Calibrated with Perturbation Algorithm
- **Url**: http://arxiv.org/abs/2504.07684v1
- **Authors**: ['Yicheng Li', 'Liping Fu', 'Zhu Chen', 'Zhijian Luo', 'Wei Du', 'Yan Gong', 'Xianmin Meng', 'Junhao Lu', 'Zhirui Tang', 'Pengfei Chen', 'Shaohua Zhang', 'Chenggang Shu', 'Xingchen Zhou', 'Zuhui Fan']
- **Abstrat**: Photometric redshifts of galaxies obtained by multi-wavelength data are widely used in photometric surveys because of its high efficiency. Although various methods have been developed, template fitting is still adopted as one of the most popular approaches. Its accuracy strongly depends on the quality of the Spectral Energy Distribution (SED) templates, which can be calibrated using broadband photometric data from galaxies with known spectroscopic redshifts. Such calibration is expected to improve photometric redshift accuracy, as the calibrated templates will align with observed photometric data more closely. The upcoming China Space Station Survey Telescope (CSST) is one of the Stage IV surveys, which aiming for high precision cosmological studies. To improve the accuracy of photometric redshift estimation for CSST, we calibrated the CWW+KIN templates using a perturbation algorithm with broadband photometric data from the CSST mock catalog. This calibration used a training set consisting of approximately 4,500 galaxies, which is 10% of the total galaxy sample. The outlier fraction and scatter of the photometric redshifts derived from the calibrated templates are 2.55% and 0.036, respectively. Compared to the CWW+KIN templates, these values are reduced by 34% and 23%, respectively. This demonstrates that SED templates calibrated with a small training set can effectively optimize photometric redshift accuracy for future large-scale surveys like CSST, especially with limited spectral training data.


**Translated Abstract**: 

通过多波段数据获得的星系光度红移在光度调查中得到了广泛应用，因为它具有高效率。尽管已经开发了多种方法，模版拟合仍然被作为最受欢迎的选择之一。其准确性强烈依赖于光谱能量分布（SED）模版的质量，这些模版可以通过已知光谱红移的星系的宽波段光度数据进行校准。这种校准预计会提高光度红移的准确性，因为经过校准的模板将与观察到的光度数据更紧密地对齐。即将到来的中国空间站巡天望远镜（CSST）是一项阶段 IV 调查，旨在进行高精度的宇宙学研究。为了提高CSST光度红移估计的准确性，我们使用带扰动算法的CWW+KIN模版，通过CSST模拟目录中的宽波段光度数据进行了校准。该校准使用了大约4500个星系的训练集，占总星系样本的10%。从校准模版中获得的光度红移的异常值比例和散射值分别为2.55%和0.036。与CWW+KIN模版相比，这些值分别降低了34%和23%。这表明，使用小规模训练集校准的SED模版可以有效优化未来大规模调查（如CSST）的光度红移准确性，特别是在有限的光谱训练数据下。

**Summary**:

- (1): 本文研究背景主要是星系光度红移的估计在推进星系外天文学和宇宙学研究中至关重要，而传统的光谱红移获取方法难以应用于遥远而微弱的天体。

- (2): 过去主要采用机器学习和光谱能量分布（SED）拟合方法来估计光度红移，面临训练样本质量和规模限制的问题，导致对深远星系的光度红移估计不精确。本文提出的方法通过使用校准的SED模版和扰动算法，针对模版的准确性问题，表现出优越性，动机明确。

- (3): 本文的贡献在于有效地利用小样本训练集通过扰动算法校准SED模版，显著提高了光度红移的估计精度。

- (4): 本文的研究方法包括使用CSST模拟目录中的宽波段光度数据，对CWW+KIN模版进行校准，以提高光度红移估计的准确性。

- (5): 本文方法在光度红移估计任务中表现出异常值比例为2.55%和散射值为0.036，相较于未校准模版有显著提升，这样的性能支持了进行高精度宇宙学研究的目标。


## Non-linear magnetic buoyancy instability and galactic dynamos
- **Url**: http://arxiv.org/abs/2412.05086v3
- **Authors**: ['Yasin Qazi', 'Anvar. Shukurov', 'Frederick. A. Gent', 'Devika. Tharakkal', 'Abhijit. B. Bendre']
- **Abstrat**: Magnetic buoyancy (MBI) and Parker instabilities are strong, generic instabilities expected to occur in most astrophysical systems with sufficiently strong magnetic fields. In galactic and accretion discs, large-scale magnetic fields are thought to arise from mean-field dynamo action, particularly the $\alpha^2\Omega$-dynamo. Using non-ideal MHD equations, we model a section of the galactic disc where the large-scale magnetic field is generated by an imposed $\alpha$-effect and differential rotation. We extend our previous study of the interplay between magnetic buoyancy and the mean-field dynamo by incorporating differential rotation, which enhances the dynamo, and cosmic rays, which amplify magnetic buoyancy.We construct a simple 1D model which replicates all significant features of the 3D simulations. Simulations confirm that magnetic buoyancy can lead to oscillatory magnetic fields and reveal that it can change the magnetic field parity between quadrupolar and dipolar states. Differential rotation facilitates this switch in parity, suggesting that the large-scale magnetic field can adopt a dipolar parity within a few kiloparsecs of the galactic centre. In contrast, quadrupolar parity may remain predominant in the outer parts of a galactic disc. Cosmic rays accelerate both the dynamo and the MBI, supporting oscillatory non-linear states and a spatial magnetic field structure similar to the alternating magnetic field directions observed in {the haloes of} some edge-on galaxies.


**Translated Abstract**: 

磁浮力不稳定性（MBI）和帕克不稳定性是一些强大的、普遍存在的，预计在大多数具有足够强磁场的天体系统中会发生的不稳定性。在星系和吸积盘中，大规模磁场被认为是由均值场发电作用产生的，特别是𝛼²Ω-发电。利用非理想磁流体动力学（MHD）方程，我们对星系盘的一部分进行模型化，其中大规模磁场由施加的𝛼-效应和差分旋转产生。我们通过纳入增强发电的差分旋转和增强磁浮力的宇宙射线，扩展了之前对磁浮力和均值场发电相互作用的研究。我们构建了一个简单的1D模型，复制了3D模拟的所有显著特征。模拟确认磁浮力可以导致振荡磁场，并揭示其可以在四极态和偶极态之间改变磁场对称性。差分旋转促进了这种态的转变，表明大规模磁场在星系中心的几千秒差距内可以采取偶极态。相比之下，四极态可能在星系盘的外部始终占主导地位。宇宙射线加速了发电和MBI，支持振荡非线性状态和与一些边缘星系的光晕中观察到的交替磁场方向相似的空间磁场结构。

**Summary**:

- (1): 本文研究的背景是星系和吸积盘中的大规模磁场如何通过均值场发电产生，这些系统存在的强大的磁浮力不稳定性（MBI）和帕克不稳定性。

- (2): 过去的方法主要基于线性不稳定性理论，集中于磁场的线性阶段，而其非线性状态的理解较少，缺乏有效的数值模拟手段。本文提出的方法引入了差分旋转和宇宙射线，以增强对MBI的理解，并有效地模拟其非线性行为。

- (3): 本文的贡献在于展示了差分旋转和宇宙射线的作用使得磁场能够在四极态和偶极态之间切换，并揭示了星系中心和外部部分磁场对称性差异的重要性。

- (4): 本文的研究方法包括构建一个简单的一维模型，通过非理想MHD方程模拟星系盘的磁场形成及其动力学行为，验证了与三维模拟的一致性。

- (5): 本文的方法在模拟中实现了磁场的振荡状态及态的切换，性能表现支持其研究目标，揭示了星系中大规模磁场演化的复杂性。


## Gas excitation in galaxies and active galactic nuclei with He IIλ4686 and X-ray emission
- **Url**: http://arxiv.org/abs/2503.03496v3
- **Authors**: ['K. Kouroumpatzakis', 'J. Svoboda']
- **Abstrat**: The origin of He II emission in galaxies remains a debated topic, requiring ionizing photons with energies exceeding 54 eV. While massive stars, such as Wolf-Rayet stars, have been considered potential sources, their UV flux often fails to fully explain the observed He II emission. Recent studies suggest that X-ray binaries (XRBs) might contribute significantly to this ionization. We explore the relationship between X-ray and $\rm He~II \lambda4686$ emission in a statistically significant sample of galaxies, investigating whether X-ray sources, including active galactic nuclei (AGNs) and XRBs, serve as the primary mechanism for He II ionization across different galactic environments. We cross-matched a sample of known well-detected He II galaxies with the Chandra Source Catalog, yielding 165 galaxies with X-ray and $\rm He~II \lambda4686$ detections. The sources were classified into star-forming galaxies (SFGs) and AGNs based on the BPT diagram and a classification scheme defined for He II galaxies. We find a strong, linear correlation between X-ray and He II luminosity across AGNs and SFGs spanning over seven orders of magnitude. AGNs generally exhibit higher He II/H$\beta$ flux ratios, stronger extinction, and harder X-ray spectra. The O32 ratio of SFGs is tightly correlated with the H$\beta$ equivalent width ($\rm EW_{H\beta}$) but not with the He II/H$\beta$ ratio, suggesting a different excitation mechanism. We derive an O32--$\rm EW_{H\beta}$ line above which only AGNs of our sample reside. The tight correlation between X-ray and He II luminosity supports X-rays as the primary driver of He II excitation. While AGNs have one common ionization source, the central black hole, in SFGs low-energy species are mainly excited by UV emission related to star-forming activity, however, high-energy species like He II require the presence of XRBs.


**Translated Abstract**: 

氦 II 发射的起源在星系中仍然是一个有争议的话题，这需要超过 54 eV 的电离光子。尽管像Wolf-Rayet星这样的巨型恒星被认为是潜在源，但它们的紫外线通量往往无法完全解释所观察到的氦 II 发射。最近的研究表明，X射线双星（XRBs）可能在这种电离中贡献重大。我们探索了X射线与He II λ4686发射之间的关系，研究X射线源（包括活动星系核AGNs和XRBs）在不同星系环境中是否作为He II电离的主要机制。我们将已知的He II星系样本与Chandra源目录交叉匹配，获得165个具有X射线和He II λ4686探测的星系。这些源基于BPT图和为He II星系定义的分类方案被分类为星形成星系（SFGs）和AGNs。我们发现，AGNs和SFGs之间的X射线和He II 亮度之间存在强线性相关，跨越七个数量级。AGNs通常表现出更高的He II/Hβ通量比、更强的消光和更硬的X射线光谱。SFGs的O32比与Hβ等效宽度（EWHβ）紧密相关，但与He II/Hβ比无关，表明存在不同的激发机制。我们推导出的O32-EWHβ线仅包含我们的样本中的AGNs。X射线与He II 亮度之间的紧密相关性支持X射线作为He II 激发的主要驱动因素。

**Summary**:

- (1): 本文探讨了如何电离氦 II 发射的问题，现有的观点通常认为是巨型恒星或X射线双星（XRBs）在产生这种电离。

- (2): 过去的方法主要依赖于研究巨型恒星（例如，Wolf-Rayet星）及其紫外线辐射，但这些光源的辐射不足以完全解释氦 II 的观测数据。本文的方法通过对比X射线与氦 II 发射的关系，提供了一个新的视角，展示XRBs作为重要电离源的作用，从而解决了现有方法无法完全解释的不足之处。

- (3): 本文的贡献在于首次在一个统计显著的样本中明确了X射线与氦 II 发射之间的强线性相关性，进一步支持了X射线作为氦 II 激发主要驱动因素的观点。

- (4): 研究方法包括将已知的He II星系与Chandra源目录进行交叉匹配，获得165个样本，并通过BPT图将其分类为星形成星系和AGNs，分析X射线与He II 亮度之间的关系。

- (5): 方法在探测到的165个星系样本上取得了强线性相关性，这一表现表明X射线在He II 激发中的重要性，且能支持作者的研究目标。


## A new quasar strongly-lensed candidate by the galaxy cluster WHJ0400-27 with a $18''$ image-separation
- **Url**: http://arxiv.org/abs/2504.07622v1
- **Authors**: ['L. Bazzanini', 'G. Angora', 'M. Scialpi', 'G. Di Rosa', 'P. Bergamini', 'P. Rosati', 'M. Lombardi', 'D. Abriola', 'A. Acebron', "M. D'Addona", 'G. Granata', 'C. Grillo', 'F. Mannucci', 'M. Maturi', 'M. Meneghetti', 'A. Mercurio', 'M. Radovich']
- **Abstrat**: Time-delay cosmography (TDC) using multiply-lensed quasars (QSOs) by galaxies has recently emerged as an independent and competitive tool to measure the value of the Hubble constant. Lens galaxy clusters hosting multiply-imaged QSOs, when coupled with an accurate and precise knowledge of their total mass distribution, are equally powerful cosmological probes. However, less than ten such systems have been identified to date. Our study aims to expand the limited sample of cluster-lensed QSO systems by identifying new candidates within rich galaxy clusters. Starting from a sample of ~$10^5$ galaxy cluster candidates (Wen & Han, 2022), built from Dark Energy Survey and Wide-field Infrared Survey Explorer imaging data, and a highly-pure catalogue of over one million QSOs, based on Gaia DR3 data, we cross-correlate them to identify candidate lensed QSOs near the core of massive galaxy clusters. Our search yielded 3 lensed double candidates over an area of ~$5000$ sq. degree. In this work, we focus on the best candidate consisting of a double QSO with Gaia-based redshift of 1.35, projected behind a moderately rich cluster (WHJ0400-27) at $z_{phot}=0.65$. Based on a first spectroscopic follow-up study, we confirm the two QSOs at $z=1.345$, with indistinguishable spectra, and a brightest cluster galaxy at $z=0.626$. These observations seem to support the strong lensing nature of this system, although some tension emerges when the cluster mass from a preliminary lens model is compared with that from other mass proxies. We also discuss the possibility that such system is a rare physical association of two distinct QSOs with a projected physical distance of ~$150$ kpc. If further spectroscopic observations confirm its lensing nature, such a rare lens system would exhibit one of the largest image separations observed to date ($\Delta\vartheta=17.8''$), opening interesting TDC applications.


**Translated Abstract**: 本文旨在通过识别富含星系团的新候选者，扩大多重透镜类星体（QSOs）系统的有限样本。通过在大约5000平方度的区域中，对约10^5个银河星系团候选者（基于暗能量调查和广域红外调查者的成像数据）与超过一百万个QSOs的高纯度目录（基于Gaia DR3数据）进行交叉匹配，找到了3个有透镜特征的双重候选者。重点研究了一个最好的候选者，该候选者由一个Gaia基础红移为1.35的双QSO组成，投影在一个中等丰度的星系团（WHJ0400-27，红移z_phot=0.65）后。经过第一次光谱跟进研究，确认了两个具有近似光谱的QSO，红移z=1.345，以及红移为0.626的最亮星系团中心星系。这些观察结果似乎支持该系统的强透镜特性，尽管在与其他质量代理进行比较时，初步透镜模型的星系团质量存在一定紧张。如果进一步的光谱观察确认其透镜特性，这种稀有透镜系统将展示迄今所观察到的最大的图像分离之一（Δθ=17.8''），为时间延迟宇宙学（TDC）应用开辟了有趣的可能性。

**Summary**:

- (1): 本文的研究背景是时间延迟宇宙学（TDC）使用多重透镜QSO作为独立的工具来测量哈勃常数（H0），然而，目前已知的星系团透镜QSO系统少于十个。

- (2): 传统方法依赖于已识别的星系团和QSO的成对，并利用光学或红外数据进行观测，存在样本稀少和透镜特征确认困难的问题。本文提出的方法通过交叉匹配大规模的星系团候选者和QSO数据库，显著扩展了候选者样本，并通过初步光谱观察来确认透镜特性，从而解决了这些问题。

- (3): 本文的贡献在于发现了一个新的强透镜候选者（WHJ0400-27），并提供了基于大规模观测数据的分析，扩大了已识别星系团透镜QSO系统的数量，为未来的TDC研究奠定基础。

- (4): 本文采用的方法包括对10^5个星系团候选者与超过一百万个QSO进行交叉匹配，验证了候选者，并通过光谱跟进确认它们的红移和透镜特性，从而实现了新候选者的识别。

- (5): 该研究在星系团WHJ0400-27上获得了两个QSO的确认，图像分离达到18"，这种性能展示了显著的发现潜力，如果进一步工作确认其透镜特性，可以支持TDC应用的目标。


## Unveiling two deeply embedded young protostars in the S68N Class 0 protostellar core with JWST/NIRSpec
- **Url**: http://arxiv.org/abs/2410.11095v3
- **Authors**: ['Valentin J. M. Le Gouellec', 'Ben W. P. Lew', 'Thomas P. Greene', 'Doug Johnstone', 'Antoine Gusdorf', 'Logan Francis', 'Curtis DeWitt', 'Michael Meyer', 'Łukasz Tychoniec', 'Ewine F. van Dishoeck', 'Mary Barsony', 'Klaus W. Hodapp', 'Peter G. Martin', 'Massimo Robberto']
- **Abstrat**: The near-infrared (NIR) emission of the youngest protostars still needs to be characterized to better understand the evolution of their accretion and ejection activity. We analyze James Webb Space Telescope NIRSpec 1.7 -- 5.3 $\mu$m observations of two deeply embedded sources in the S68N protostellar core in Serpens. The North Central (NC) source exhibits a highly obscured spectrum (A_K ~ 4.8 mag) that is modeled with a pre-main-sequence photosphere and a hot disk component. The photospheric parameters are consistent with a young, low-mass photosphere, as suggested by the low surface gravity, log g of 1.95 $\pm$ 0.15 cm s$^{-2}$. The hot disk suggests that accretion onto the central protostellar embryo is ongoing, although prototypical accretion-tracing emission lines HI are not detected. The South Central (SC) source, which is even more embedded (A_K ~ 8 mag; no continuum is detected shortward of 3.6 $\mu$m) appears to be driving the large-scale S68N protostellar outflow, and launches a collimated hot molecular jet detected in \Ht and CO ro-vibrational lines. Shock modeling of the \Ht (ro)vibrational lines establishes that fast $C$-type shocks ($\geq$ 30 km s$^{-1}$), with high pre-shock density ($\geq$ $10^7$ cm$^{-3}$), and strong magnetic field (b ~ 3--10, where $B = b\,\times\,\sqrt{\textrm{n}_{\textrm{H}} (\textrm{cm}^{-3})}\,\mu\textrm{G}$) best match the data. The bright CO fundamental line forest suggests energetic excitation, with the contribution of non-LTE effects, ie irradiation pumping. Detected OH and CH$^{+}$ ro-vibrational lines support this hypothesis. These two Class 0 protostars seem to be in very young evolutionary stages and still have to acquire the bulk of their final stellar masses. These results demonstrate that JWST enables unprecedented diagnostics of these first stages of the protostellar evolutionary phase.


**Translated Abstract**: 

对于最年轻的原恒星近红外（NIR）发射的特征尚需进一步研究，以更好地理解它们的吸积和喷射活动的演化。我们分析了詹姆斯·韦布太空望远镜（JWST）NIRSpec 1.7—5.3 µm的观测数据，针对位于Serpens的S68N原恒星核心中的两个深度嵌入源进行研究。北中央源（NC）展现出高度遮蔽的光谱（A_K ~ 4.8 mag），其模型包括一个前主序光球和一个热盘成分。光球参数符合年轻低质量光球的特征，表明低表面重力log g为1.95 ± 0.15 cm s^−2。热盘表明中央原恒星胚胎正在进行吸积，尽管未检测到典型的吸积跟踪发射线HI。南中央源（SC）则更为嵌入（A_K ~ 8 mag；在3.6 µm短波长下未检测到连续光），被认为驱动S68N的大规模原恒星喷流，并发射出在H2和CO旋转振动线中检测到的定向热分子喷流。对H2（旋转）振动线的冲击建模表明，快速的C型冲击（≥ 30 km s^−1）与高前冲密度（≥ 10^7 cm^−3）以及强磁场（b ~ 3–10）最符合数据。明亮的CO基础线阵列暗示了能量激发，非LTE效应（即辐照泵浦）的贡献也支持这种假设。检测到的OH和CH^+旋转振动线进一步支持了这一假设。这两颗Class 0原恒星似乎处于非常年轻的演化阶段，尚需获取大部分最终星体质量。这些结果表明JWST能够提供无与伦比的原恒星演化早期阶段的诊断。

**Summary**:

- (1): 该文章的研究背景是需要更好地理解最年轻的原恒星在吸积和喷射活动中的演化，尤其是在深度嵌入的原恒星核心中。

- (2): 过去的方法主要依赖于ALMA和NOEMA等毫米波观测，难以直接检测嵌入性强的源。现有方法在捕捉早期原恒星的吸积能力表现不佳，而本研究利用JWST的新技术，提供了对这些早期阶段的独特诊断，解决了对深度嵌入源研究的局限。

- (3): 本文的贡献在于探测并分析了S68N原恒星核心中两颗深度嵌入的Class 0原恒星，揭示了它们的光谱特征、喷流活动及其动力学特征，为理解原恒星的形成与演化提供了新数据。

- (4): 本文提出的研究方法利用JWST/NIRSpec观察数据，分析了1.7—5.3 µm波段，结合光谱模型和冲击建模，以研究原恒星光球、热盘及喷流。

- (5): 该研究在揭示原恒星的光谱特征和喷流动力学方面取得了显著成果，这些表现支持了对早期原恒星演化阶段的深入理解及其目标。


## Power spectrum of the CODEX clusters
- **Url**: http://arxiv.org/abs/2504.07613v1
- **Authors**: ['Valtteri Lindholm', 'Alexis Finoguenov', 'Andrés Balaguera-Antolínez', 'Tiago Castro']
- **Abstrat**: Aims. We analyze the clustering of galaxy clusters in a large contiguous sample, the Constrain Dark Energy with X-ray (CODEX) sample. We construct a likelihood for cosmological parameters by comparing the measured clustering signal and a theoretical prediction, and use this to obtain parameter constraints. Methods. We measured the three multipole moments (monopole, quadrupole, and hexadecapole, $\ell = 0, 2, 4$) of the power spectrum of a subset of the CODEX clusters. To fully model cluster clustering, we also determined the expected clustering bias of the sample using estimates for the cluster masses and a mass-to-bias model calibrated using N-body simulations. We estimated the covariance matrix of the measured power spectrum multipoles using a set of simulated dark-matter halo catalogs. Combining all these ingredients, we performed a Markov chain Monte Carlo sampling of cosmological parameters $\Omega_m$ and $\sigma_8$ to obtain their posterior. Results. We found the CODEX clustering signal to be consistent with an earlier X-ray selected cluster sample, the REFLEX II sample. We also found that the measured power spectrum multipoles are compatible with the predicted, bias-scaled linear matter power spectrum when the cosmological parameters determined by the Planck satellite are assumed. Furthermore, we found the marginalized parameter constraints of $\Omega_m = 0.24^{+0.06}_{-0.04}$ and $\sigma_8 = 1.13^{+0.43}_{-0.24}$. The full 2D posterior is consistent, for example, with the Planck cosmology within the 68% confidence region.


**Translated Abstract**: 

本文旨在分析大型连通样本“约束暗能量与X射线”（CODEX）样本中的星系团的聚类。我们通过比较测量到的聚类信号和理论预测来构建宇宙学参数的似然函数，并利用此方法获得参数约束。

**Summary**:

- (1): 文章的研究背景是星系团的聚类对于宇宙的几何和结构增长具有敏感性，已被证明是有效的宇宙学探测工具。

- (2): 过去的方法主要是通过两点关联函数来研究星系团聚类，其问题在于对不同聚类统计量的处理不够全面。提出的方法通过多极矩（单极、四极和十六极）对CODEX样本的功率谱进行直接测量，改进了对聚类偏差的建模，并处理了集群质量的估计不确定性。

- (3): 本文的贡献在于提供了CODEX样本的功率谱测量结果，并通过更准确的协方差矩阵和质量估计的不确定性处理，为宇宙学参数的约束提供了新的视角。

- (4): 研究方法包括测量CODEX样本的功率谱多极矩，估计样本的聚类偏差，并使用Markov链Monte Carlo方法对宇宙学参数（Ω_m 和 σ_8）进行后验分析。

- (5): 方法在约束宇宙学参数方面取得了成果，得到了Ω_m = 0.24^{+0.06}_{-0.04}和σ_8 = 1.13^{+0.43}_{-0.24}的限制，且与Planck卫星的结果相一致，支持了其研究目标。


## DUCA: Dynamic Universe Cosmological Analysis. I. The halo mass function in dynamical dark energy cosmologies
- **Url**: http://arxiv.org/abs/2504.07608v1
- **Authors**: ['Tiago Castro', 'Stefano Borgani', 'Jeppe Dakin']
- **Abstrat**: The halo mass function (HMF) is fundamental for interpreting the number counts of galaxy clusters, serving as a pivotal theoretical tool in cosmology. With the advent of high-precision surveys such as LSST, eROSITA, DESI, and Euclid, accurate HMF modeling becomes indispensable to avoid systematic biases in cosmological parameter estimation from cluster cosmology. Moreover, these surveys aim to shed light on the dark sector and uncover dark energy's puzzling nature, necessitating models that faithfully capture its features to ensure robust parameter inference. We aim to construct a model for the HMF in dynamical dark energy cosmologies that preserves the accuracy achieved for the standard $\Lambda (\nu)$CDM model of cosmology, while meeting the precision requirements necessary for future cosmological surveys. Our approach models the HMF parameters as functions of the deceleration parameter at the turnaround, a quantity shown to encapsulate essential information regarding the impact of dynamical dark energy on structure formation. We calibrate the model using results from a comprehensive suite of $N$-body simulations spanning various cosmological scenarios, ensuring sub-percent systematic accuracy. We present an HMF model tailored for dynamical dark energy cosmologies. The model is calibrated following a Bayesian approach, and its uncertainty is characterized by a single parameter controlling its systematic error, which remains at the sub-percent level. This ensures that theoretical uncertainties from our model are subdominant relative to other error sources in future cluster number counts analyses.


**Translated Abstract**: 

暗晦质量函数（HMF）是解释星系团数量统计的基本工具，它在宇宙学中起着关键作用。随着高精度观测的到来，例如LSST、eROSITA、DESI和Euclid，准确的HMF建模变得不可或缺，以避免集群宇宙学中宇宙参数估计的系统偏差。此外，这些观测旨在揭示暗物质的性质并探索暗能量的神秘特征，这需要忠实捕捉其特征的模型，以确保稳健的参数推断。我们的目标是构建一个动态暗能量宇宙学中HMF的模型，该模型在满足未来宇宙学调查所需的精度要求的同时，保持与标准的Λ(ν)CDM模型相同的精确度。我们的方法将HMF参数建模为回升时的减速参数的函数，这个量能够封装动态暗能量对结构形成影响的重要信息。我们使用涵盖各种宇宙学场景的综合N体模拟结果来校准模型，确保亚百分比的系统准确性。我们提出了一个针对动态暗能量宇宙学的HMF模型，采用贝叶斯方法进行校准，并通过单个参数控制其系统误差，其误差保持在亚百分比水平。这确保了该模型的理论不确定性在未来的星系团数量统计分析中相对于其他误差来源是次要的。

**Summary**:

- (1): 本文研究的背景是暗晦质量函数（HMF）在宇宙学中解释星系团数量统计的重要性，以及高精度观测对HMF建模的需求。

- (2): 以往的方法主要是依赖于N体模拟，但缺乏对动态暗能量影响的精确建模，可能导致宇宙参数估计出现偏差。提出的方法通过将HMF参数与动态暗能量的减速参数相关联，能够更好地捕捉其对结构形成的影响。因此，该方法具有较强的理论基础。

- (3): 本文的贡献在于提出了一个新的动态暗能量宇宙学HMF模型，经过严谨的贝叶斯校准，能够保持亚百分比的系统性准确性。

- (4): 研究方法包括通过N体模拟获得的结果，利用减速参数作为HMF参数的函数进行模型化，同时采用贝叶斯方法进行模型校准。

- (5): 本文的方法在动态暗能量宇宙学HMF建模任务中实现了亚百分比的系统性准确性，这一性能能够支持论文的研究目标。


## Wide Binaries from GAIA DR3 : testing GR vs MOND with realistic triple modelling
- **Url**: http://arxiv.org/abs/2504.07569v1
- **Authors**: ['Charalambos Pittordis', 'Will Sutherland', 'Paul Shepherd']
- **Abstrat**: We provide an updated test for modifications of gravity from a sample of wide-binary stars from GAIA DR3, and their sky-projected relative velocities. Here we extend on our earlier 2023 study, using several updated selection cuts aimed at reducing contamination from triple systems with an undetected third star. We also use improved mass estimates from FLAMES, and we add refinements to previous modelling of the triple and other populations and the model-fitting. We fit histograms of observed vs Newtonian velocity differences to a flexible mixture of binary + triple populations with realistic eccentricity distributions, plus unbound flyby and random-chance populations. We find as before that Newtonian models provide a significantly better fit than MOND, though improved understanding of the triple population is necessary to make this fully decisive.


**Translated Abstract**: 

我们提供了一项基于GAIA DR3的宽双星样本的更新测试，用于探讨引力的修改及其天空投影相对速度。我们在早期的2023年研究基础上进行了扩展，使用了几项更新的选择标准，以减少未被发现的第三星的三重系统的污染。我们还使用了来自FLAMES的改进质量估计，并对三重系统和其他种群的先前建模及模型拟合进行了改进。我们将观测到的与牛顿速度差的直方图拟合为具有现实偏心率分布的二元+三重种群的灵活混合，以及不受约束的掠过和随机偶然种群。我们发现，牛顿模型比MOND的拟合更优，但对三重种群的理解需要进一步加强，以使这一结果更加决定性。

**Summary**:

- (1): 本文旨在利用GAIA DR3的宽双星样本测试引力的修改，探讨广义相对论（GR）和修改引力理论（MOND）之间的差异。

- (2): 过去的方法主要依赖于对宽双星的相对速度的分析，受到未识别的三重系统的污染影响，造成不准确的结果。相比之下，本文提出了更严格的数据选择标准和更为真实的三重系统建模，旨在减少这些干扰因素，进而改善拟合精度。

- (3): 本文的贡献在于通过细化选择标准和改进模型拟合方法，提供了对三重系统的更好理解，并再一次支持了牛顿模型优于MOND的结论。

- (4): 研究方法涉及对宽双星进行选择和分类，结合更精确的质量估计以及模型的多样性，以适应更广泛的距离和速度数据。

- (5): 这项研究通过比较观察到的相对速度直方图与模拟结果，在表明牛顿理论比MOND理论的拟合质量更高方面，取得了显著的成果，支持其研究目标。


## The emergence of galactic thin and thick discs across cosmic history
- **Url**: http://arxiv.org/abs/2409.15909v2
- **Authors**: ['Takafumi Tsukui', 'Emily Wisnioski', 'Joss Bland-Hawthorn', 'Ken Freeman']
- **Abstrat**: Present-day disc galaxies often exhibit distinct thin and thick discs. The formation mechanisms of the two discs and the timing of their onset remain open questions. To address these questions, we select edge-on galaxies from flagship JWST programs and investigate their disc structures in rest-frame, near-infrared bands. For the first time, we identify thick and thin discs at cosmological distances, dating back over 10 Gyr, and investigate their decomposed structural properties. We classify galaxies into those that require two (i.e. thin and thick) discs and those well fitted by a single disc. Disc radial sizes and vertical heights correlate strongly with the total galaxy mass and/or disc mass, independent of cosmic time. The structure of the thick disc resembles discs found in single-disc galaxies, suggesting that galaxies form a thick disc first, followed by the subsequent formation of an embedded thin disc. The transition from single to double discs occurred around 8 Gyr ago in high-mass galaxies ($10^{9.75} - 10^{11}M_\odot$), earlier than the transition which occurred 4 Gyr ago in low-mass galaxies ($10^{9.0} - 10^{9.75}M_\odot$), indicating sequential formation proceeds in a "downsizing" manner. Toomre $Q$-regulated disc formation explains the delayed thin disc formation in low-mass galaxies, leading to the observed anti-correlation between the thick-to-thin disc mass ratio and the total galaxy mass. Despite the dominant sequential formation, observations suggest that thick discs may continue to build up mass alongside their thin-disc counterparts.


**Translated Abstract**: 

现代盘面星系通常表现出不同的薄盘和厚盘。两者的形成机制和开始时机仍然是未解之谜。为了解决这些问题，我们选择了来自JWST重要项目的边缘星系，并研究其在静态红外波段的盘面结构。我们首次识别出距今超过10亿年的厚盘和薄盘，并研究其分解的结构特性。我们将星系分类为需要两个（即薄盘和厚盘）盘面以及那些可以很好地拟合为单个盘面的星系。盘面半径和垂直高度与总星系质量和/或盘面质量强相关，与宇宙时间无关。厚盘的结构与单盘星系中的盘面相似，表明星系首先形成厚盘，随后形成嵌入的薄盘。高质量星系（$10^{9.75} - 10^{11}M_\odot$）的单盘到双盘的过渡发生在约80亿年前，低质量星系（$10^{9.0} - 10^{9.75}M_\odot$）则在40亿年前过渡，表明顺序形成以“向下的方式”进行。图姆尔Q调节的盘面形成解释了低质量星系中薄盘形成的延迟，导致厚盘与薄盘质量比和总星系质量之间的反相关。尽管主要是顺序形成，但观察显示厚盘可能与薄盘同时继续积累质量。

**Summary**:

- (1): 本文的研究背景是现代盘面星系常常表现出薄盘和厚盘的二元结构，但两者的形成机制和时机尚不清楚。

- (2): 过去的研究主要依赖于通过较近的观测及简单的结构分析来探讨盘面结构，但这些方法对薄盘和厚盘的形成时序及机制解释不足。本文提出通过JWST的边缘星系观测，在静态红外波段研究盘面结构，填补了这些空白并提供了更深入的理解。

- (3): 本文的贡献在于首次在宇宙学距离内识别出厚盘和薄盘，揭示了厚盘和薄盘的形成顺序及其与星系质量的关系，同时提出了顺序形成的“向下的方式”理论。

- (4): 本文使用JWST的观测数据分析星系的盘面结构，分类成两个盘面或单个盘面，并研究其与总质量的相关性。

- (5): 本文的任务是探测厚盘和薄盘的形成及其结构特性，观察结果支持提出的顺序形成理念，并强调了高级别星系与低级别星系间在形成时间上存在差异。


## Gravitational wave signals from primordial black holes orbiting solar-type stars
- **Url**: http://arxiv.org/abs/2504.07517v1
- **Authors**: ['Vitorio A. De Lorenci', 'David I. Kaiser', 'Patrick Peter', 'Lucas S. Ruiz', 'Noah E. Wolfe']
- **Abstrat**: Primordial black holes (PBHs) with masses between $10^{14}$ and $10^{20}$ kg are candidates to contribute a substantial fraction of the total dark matter abundance. When in orbit around the center of a star, which can possibly be a completely interior orbit, such objects would emit gravitational waves, as predicted by general relativity. In this work, we examine the gravitational wave signals emitted by such objects when they orbit typical stars, such as the Sun. We show that the magnitude of the waves that could eventually be detected on Earth from a possible PBH orbiting the Sun or a neighboring Sun-like star within our galaxy can be significantly stronger than those originating from a PBH orbiting a denser but more distant neutron star (NS). Such signals may be detectable by the LISA gravitational-wave detector. In addition, we estimate the contribution that a large collection of such PBH-star systems would make to the stochastic gravitational-wave background (SGWB) within a range of frequencies to which pulsar timing arrays are sensitive.


**Translated Abstract**: 

原始黑洞（PBHs）质量在 $10^{14}$ 到 $10^{20}$ 千克之间，可能构成总暗物质丰度的显著部分。当这些物体围绕星体（如太阳）中心旋转时，会发出引力波，根据广义相对论的预测。本文研究了这些物体在围绕典型恒星（如太阳）轨道时发出的引力波信号。我们表明，从围绕太阳或邻近的太阳型恒星的PBH发出的波的强度，远超来自密度更大的远处中子星（NS）周围的PBH的波信号。这些信号可能被LISA引力波探测器探测到。此外，我们估计了一大批PBH-恒星系统对脉冲星定时阵列灵敏频率范围内的随机引力波背景（SGWB）的贡献。

**Summary**:

- (1): 该文章的研究背景是，原始黑洞（PBHs）可能是暗物质的一个重要组成部分，尤其是在早期宇宙中形成的PBHs尚未被确切探测到，存在一个质量范围（$10^{14}$ kg至$10^{20}$ kg），即“小行星质量范围”。

- (2): 过去的研究主要关注由大幅度的标量曲率扰动引发的PBHs的引力波信号，主要在于合并或碰撞过程。此方法存在对信号起源的局限性，而该文提出的方法是关注围绕普通恒星的PBHs的轨道运动产生的引力波信号。这种新方法解决了寻找PBHs信号的局限性，并提供了更直接的探测途径，具有充分的动机。

- (3): 本文的贡献在于展示了围绕太阳和相似恒星的PBHs能够产生强于远处中子星的引力波，这可能为未来的引力波探测器（如LISA）提供可检测的信号，并且还估计了这些PBH-恒星系统对随机引力波背景（SGWB）的贡献。

- (4): 本文提出的研究方法涉及对PBH与恒星的相互作用及其引力波信号的详细计算，特别是从PBH的轨道运动中提取信号特性，以及分析了大规模PBH-恒星系统对SGWB的影响。

- (5): 本文的方法实现了对PBH轨道引力波信号的预测，并建立了其对SGWB的影响模型。这些性能足以支持通过未来引力波探测器对该信号的探测，进而帮助解决暗物质成分的相关问题。


## Infrared Spectroscopy of Pentagon-Containing PAHs: Indenyl and Fluorenyl Anions and Indenyl Cation
- **Url**: http://arxiv.org/abs/2504.07512v1
- **Authors**: ['Gabi Wenzel', 'Miguel Jiménez-Redondo', 'Milan Ončák', 'Brett A. McGuire', 'Sandra Brünken', 'Paola Caselli', 'Pavol Jusko']
- **Abstrat**: Polycyclic aromatic hydrocarbon (PAH) ions are crucial intermediates in interstellar chemistry and may play a key role in the infrared emission features observed in space. Here, we investigate the infrared spectra of the indenyl (C$_9$H$_7^-$) and fluorenyl (C$_{13}$H$_9^-$) anions and the indenyl cation (C$_9$H$_7^+$) using infrared pre-dissociation (IRPD) spectroscopy. The experiments were performed in a cryogenic 22 pole ion trap at the FELion beamline of the tunable free-electron laser FELIX. Spectral analysis of the two anionic PAHs, in combination with density functional theory (DFT) computations, revealed key vibrational modes near 1300 cm$^{-1}$, making these ions potential carriers of the 7.7 {\mu}m PAH emission band seen in many astronomical objects. The feature-rich spectrum of cationic indenyl could not be entirely explained by modeling through time-independent anharmonic DFT calculations. Although a better match has been achieved through molecular dynamics simulations, we cannot completely rule out the presence of multiple cationic isomers of the H-loss fragments of indene in the experiments.


**Translated Abstract**: 

多环芳烃（PAH）离子是星际化学中的关键中间体，可能在空间中观察到的红外发射特征中发挥重要作用。在这里，我们使用红外前解离（IRPD）光谱技术研究了 indenyl (C$_9$H$_7^-$) 和 fluorenyl (C$_{13}$H$_9^-$) 负离子以及 indenyl (C$_9$H$_7^+$) 正离子的红外光谱。实验在可调谐自由电子激光器 FELIX 的低温 22 极离子阱中进行。对这两种阴离子 PAH 的光谱分析，以及与密度泛函理论 (DFT) 计算的结合，揭示了大约在 1300 cm$^{-1}$ 附近的关键振动模式，使这些离子成为许多天体中所见到的 7.7 μm PAH 发射带的潜在载体。阳离子 indenyl 的特征丰富的光谱无法完全通过时间独立的非谐 DFT 计算模型来解释。尽管通过分子动力学模拟取得了更好的匹配，但我们并不能完全排除实验中 indene 失氢片段的多样阳离子异构体的存在。

**Summary**:

- (1): 该文章的研究背景是多环芳烃（PAH）离子在星际化学中的重要性，以及它们在星际中红外发射特征中的潜在角色。

- (2): 过去的方法主要是使用密度泛函理论 (DFT) 和时间独立模型进行光谱计算，这些方法在解释阳离子 indenyl 的光谱时存在不足。提出的方法结合红外前解离（IRPD）光谱和分子动力学模拟，提供了更为精确的光谱特征，该方法通过模拟分子动态过程来克服传统方法中的局限性。

- (3): 本文的贡献在于揭示了 indenyl 和 fluorenyl 阴离子的关键振动模式，并指出这些离子可能是 7.7 μm PAH 发射带的主要载体。

- (4): 文章提出的研究方法包括使用红外前解离（IRPD）光谱技术，结合密度泛函理论 (DFT) 和分子动力学模拟，探讨了离子在低温条件下的振动特性。

- (5): 该方法在确定 indenyl 和 fluorenyl 阴离子的红外光谱特征及其潜在在星际化学中的角色上表现出色，支持其在理解星际环境中 PAH 的重要性目标。


## Are Models of Strong Gravitational Lensing by Clusters Converging or Diverging?
- **Url**: http://arxiv.org/abs/2411.05083v2
- **Authors**: ['Derek Perera', 'John H Miller Jr', 'Liliya L. R. Williams', 'Jori Liesenborgs', 'Allison Keen', 'Sung Kei Li', 'Marceau Limousin']
- **Abstrat**: The increasingly large numbers of multiple images in cluster-scale gravitational lenses have allowed for tighter constraints on the mass distributions of these systems. Most lens models have progressed alongside this increase in image number. The general assumption is that these improvements would result in lens models converging to a common solution, suggesting that models are approaching the true mass distribution. To test whether or not this is occurring, we examine a sample of lens models of MACS J0416.1$-$2403 containing varying number of images as input. Splitting the sample into two bins (those including $<150$ and $>150$ images), we quantify the similarity of models in each bin using three comparison metrics, two of which are novel: Median Percent Difference, Frechet Distance, and Wasserstein Distance. In addition to quantifying similarity, the Frechet distance metric seems to also be an indicator of the mass sheet degeneracy. Each metric indicates that models with a greater number of input images are no more similar between one another than models with fewer input images. This suggests that lens models are neither converging nor diverging to a common solution for this system, regardless of method. With this result, we suggest that future models more carefully investigate lensing degeneracies and anomalous mass clumps (mass features significantly displaced from baryonic counterparts) to rigorously evaluate their model's validity. We also recommend further study into alternative, underutilized lens model priors (e.g. flux ratios) as an additional input constraint to image positions in hopes of breaking existing degeneracies.


**Translated Abstract**: 

随着聚类尺度引力透镜中多重图像数量的不断增加，能够对这些系统的质量分布进行更严格的约束。大多数透镜模型的进展与图像数量的增加密切相关。一般假设是，这些改进将导致透镜模型收敛于一个共同的解决方案，暗示模型正在接近真实的质量分布。为了测试这一点，我们检查了包含不同数量图像输入的 MACS J0416.1−2403 的透镜模型样本。将样本分为两个类别（包括<150和>150个图像），我们使用三种比较指标量化每个类别中模型的相似性，其中两种是新颖的：中位百分比差异、Frechet距离和Wasserstein距离。除量化相似性外，Frechet距离指标似乎也反映了质量层退化现象。每种指标表明，输入图像较多的模型之间并没有比较少图像的模型更相似。这表明这些透镜模型无论采用何种方法都没有朝着一个共同的解决方案收敛或发散。基于这一结果，我们建议未来的模型更加谨慎地研究透镜退化和异常质量团块（与重子对应物明显偏离的质量特征），以严格评估其模型的有效性。我们还建议进一步研究其他未被充分利用的透镜模型先验（例如，通量比）作为图像位置的附加输入约束，以期打破现有的退化现象。

**Summary**:

- (1): 本文研究背景是引力透镜中多重图像数量的增加如何影响聚类尺度引力透镜的质量分布建模精度。

- (2): 过去的方法依赖于越来越多的图像数据来提高质量重构精度，但未能在输入图像数量增加时实现模型的一致性。提出的方法通过量化不同模型间的相似性，采用了新的比较指标（中位百分比差异、Frechet距离和Wasserstein距离）来解决这些问题，是合适且合理的。

- (3): 本文的贡献在于首次系统性地评估了大规模引力透镜模型的相似性，提出模型在即便图像数量增多的情况下并未收敛的发现。

- (4): 本文的研究方法包括对在不同输入图像数量下的透镜模型进行比较，并引入新的比较指标 quantification 相似性。

- (5): 本文的方法在评估 MACS J0416.1−2403 的透镜模型相似性及其质量分布的任务上表现出一致的结果，结果表明模型之间没有收敛现象，支持了研究目标的有效性。


## Ultraluminous X-ray sources in Globular Clusters
- **Url**: http://arxiv.org/abs/2501.06037v3
- **Authors**: ['Grzegorz Wiktorowicz', 'Mirek Giersz', 'Abbas Askar', 'Arkadiusz Hypki', 'Lucas Helstrom']
- **Abstrat**: This paper investigates the formation, populations, and evolutionary paths of UltraLuminous X-ray Sources (ULXs) within Globular Clusters (GCs). ULXs, characterised by their extreme X-ray luminosities, present a challenge to our understanding of accretion physics and compact object formation. While previous studies have largely focused on field populations, this research examines the unique environment of GCs, where dynamical interactions play a significant role. Using the MOCCA Monte Carlo code, we explore how dynamics influences ULX populations within these dense stellar clusters.   Our findings reveal that dynamical processes, such as binary hardening and exchanges, can both facilitate and impede ULX formation in GCs. The study explores the impact of parameters including the initial binary fraction, tidal filling, and multiple stellar populations on the evolution of ULXs. We find that non-tidally filling clusters exhibit significantly larger ULX populations compared to tidally filling ones.   The results indicate that the apparent scarcity of ULXs in GCs may be related to the older stellar populations of GCs relative to the field. Furthermore, the study identifies a population of "escaper" ULXs, which originate in GCs but are ejected and emit X-rays outside the cluster. These escapers may significantly contribute to the observed field ULX population.


**Translated Abstract**: 

本文研究了超光谱X射线源（ULXs）在球状星团（GCs）中的形成、种群和演化路径。超光谱X射线源以其极端的X射线亮度为特征，给我们对吸积物理学和紧凑天体形成的理解带来了挑战。之前的研究主要集中于场域种群，而本研究考察了GCs这一独特环境，其中动力学相互作用起着重要作用。利用MOCCA Monte Carlo代码，我们探索了动力学如何影响这些密集恒星集群中的ULX种群。我们的研究结果表明，动力学过程（如双星的硬化和交换）可以促进和阻碍GCs中ULX的形成。研究还探讨了初始双星比、潮汐充填和多重恒星种群等参数对ULX演化的影响。我们发现非潮汐充填集群的ULX种群明显大于潮汐充填集群。此外，结果表明GCs中ULXs的表观稀缺性可能与其相对于场域的老龄恒星种群有关。研究还识别出一类“逃逸”ULXs，源于GCs但被抛出并在集群外发射X射线。这些逃逸者可能显著贡献于观测到的场域ULX种群。

**Summary**:

- (1): 本文的研究背景是超光谱X射线源（ULXs）作为极端X射线发射体，其形成与演化的机制尚不明确，尤其是在球状星团（GCs）这样的特殊环境中。

- (2): 过去的研究主要针对场域种群，但忽视了GCs中的动力学相互作用带来的影响。本研究采用MOCCA Monte Carlo代码，考察了动力学如何具体影响ULX种群的形成，弥补了以往方法的不足，尤其在理解GCs环境中的ULX形成机理方面。

- (3): 本文的贡献在于揭示了球状星团中ULXs形成的动力学过程，说明了非潮汐充填集群中ULX数量的增加以及逃逸ULXs的存在对于观测到的场域ULX种群的潜在影响。

- (4): 研究方法包括使用MOCCA Monte Carlo代码来模拟GCs中的动力学过程，并分析不同物理参数对ULXs种群演化的影响。

- (5): 本研究的主要任务是理解GCs中ULXs的形成与演化过程，发现非潮汐充填集群中的ULX数量显著增加且逃逸者组成ULXs总数的约七分之一。这一性能支持了对GCs中ULX现象的深入理解。


## Measuring Cosmic Growth Rate with CSST Spectroscopic Survey and Fast Radio Burst
- **Url**: http://arxiv.org/abs/2504.07460v1
- **Authors**: ['Shi-Yuan Wang', 'Jun-Qing Xia']
- **Abstrat**: The cosmic growth rate, which is related to peculiar velocity and is a primary scientific objective of galaxy spectroscopic surveys, can be inferred from the Redshift Space Distortion effect and the kinetic Sunyaev-Zel'dovich effect. However, the reconstruction noise power spectrum of the radial velocity field in kSZ is significantly dependent on the measurement of the small-scale galaxy-electron power spectrum $P_{ge}$. In this study, we thoroughly discuss the enhancement of cosmic growth rate measurements facilitated by Fast Radio Bursts, which probe the electron density of the universe along their propagation paths to provide crucial additional information on $P_{ge}$. Subsequently, we utilize future spectroscopic surveys from the Chinese Space Station Telescope and the CMB-S4 experiment, combined with FRB dispersion measures, to achieve precise measurements of the cosmic growth rate at redshifts $z_g = 0.15,0.45,0.75$. Employing Fisher matrix forecasting analysis, we anticipate that constraints on $f\sigma_8$ will reach a precision of 0.001 with a sample size of $10^6$ FRBs. Furthermore, we perform a global analysis using Markov Chain Monte Carlo methods to constrain key parameters of three distinct dark energy models and a modified gravity model based on cosmic growth rate measurements. The results demonstrate that these refined $f\sigma_8$ measurements considerably enhance the constraints on relevant cosmological parameters compared to those obtained from Planck. As the number of observed FRBs increases, alongside more precise galaxy surveys and next-generation CMB observations, new opportunities will arise for constraining cosmological models using the kSZ effect and for developing novel cosmological applications of FRBs.


**Translated Abstract**: 

宇宙增长率与特殊速度相关，是星系光谱调查的主要科学目标，可以通过红移空间畸变效应和动能Sunyaev-Zel'dovich效应来推断。然而，动能Sunyaev-Zel'dovich中的径向速度场重建噪声功率谱显著依赖于小尺度星系-电子功率谱 $P_{ge}$ 的测量。在本研究中，我们详细讨论了快速射电暴（FRBs）如何增强宇宙增长率测量的能力，这些暴发通过传播路径探测宇宙中电子的密度，从而为 $P_{ge}$ 提供关键信息。随后，我们利用来自中国空间站望远镜（CSST）和CMB-S4实验的未来光谱调查，结合FRB色散测量，实现了在红移 $z_g = 0.15, 0.45, 0.75$ 处的宇宙增长率精确测量。采用Fisher矩阵预测分析，我们预计 $f\sigma_8$ 的约束精度将达到0.1%，样本规模为 $10^6$ FRBs。此外，我们使用马尔可夫链蒙特卡洛方法进行全局分析，以约束基于宇宙增长率测量的三种不同暗能量模型和修改重力模型的关键参数。结果表明，与Planck获得的结果相比，这些精细的 $f\sigma_8$ 测量显著增强了对相关宇宙学参数的约束。随着观察到的FRBs数量增加，以及更精确的星系调查和下一代CMB观测的开展，利用动能Sunyaev-Zel'dovich效应约束宇宙模型的新机会将出现，同时也为FRBs的创新宇宙学应用提供可能。

**Summary**:

- (1): 本文研究宇宙增长率的测量，强调其与星系光谱调查的科学重要性和对相关宇宙学模型的测试。

- (2): 过去的方法通过动能Sunyaev-Zel'dovich（kSZ）效应和红移空间畸变（RSD）来测量增长率，但小尺度的星系-电子功率谱 $P_{ge}$ 测量误差导致了重建误差。提出的方法基于快速射电暴（FRBs）的观测，利用其对电子密度的探测来补充 $P_{ge}$ 的信息，从而改善测量精度。

- (3): 本文的贡献在于结合FRBs和未来的光谱调查，显著提高了宇宙增长率测量的精度，并通过改进的 $f\sigma_8$ 测量约束了多个宇宙学参数。

- (4): 研究方法包括利用中国空间站望远镜（CSST）和CMB-S4实验的数据，并通过马尔可夫链蒙特卡洛（MCMC）方法进行全局分析，约束三种暗能量模型和修改重力模型的关键参数。

- (5): 本文的方法在红移 $z_g = 0.15, 0.45, 0.75$ 处实现了宇宙增长率的高精度测量，约束精度达到0.1%。该性能能够支持其对宇宙学模型的目标。


## Traversable Wormholes Sourced by Dark Matter in Loop Quantum Cosmology
- **Url**: http://arxiv.org/abs/2411.12063v3
- **Authors**: ['Marcos V. de S. Silva', 'G. Alencar', 'R. N. Costa Filho', 'R. M. P. Neves', 'Celio R. Muniz']
- **Abstrat**: In this work, we investigate the existence of wormholes within the framework of Loop Quantum Cosmology, using isotropic dark matter as the source. We analyze three distinct density profiles and solve the modified gravity field equations alongside the stress-energy tensor conservation, applying appropriate boundary conditions to obtain traversable wormhole solutions. Each solution is shown to satisfy the geometric criteria for wormholes, and their regularity is verified by computing the Kretschmann scalar to ensure the absence of singularities under determined conditions. Additionally, we examine the stress-energy tensor to identify scenarios in which energy conditions are violated within this model. The wormhole geometry is further explored through embedding diagrams, and the amount of exotic matter required to sustain these structures is computed using the Volume Integral Quantifier. Finally, we study the shadow produced by our wormhole solution, considering one of the dark matter density profiles, and compare it with observations of the M87 galaxy.


**Translated Abstract**: 

在本研究中，我们在Loop Quantum Cosmology的框架下，使用各向同性暗物质作为源，探讨了虫洞的存在。我们分析了三种不同的密度分布，并通过解决修改后的引力场方程和应力-能量张量守恒，应用适当的边界条件获得了可穿越虫洞解。每个解都证明满足虫洞的几何标准，并通过计算Kretschmann标量确保在特定条件下不存在奇点，从而验证其规则性。此外，我们检查了应力-能量张量以识别模型中能量条件违反的情景。通过嵌入图进一步探索虫洞几何，并使用体积分量化器计算维持这些结构所需的奇异物质的量。最后，我们研究了基于我们虫洞解产生的阴影，并考虑了某种暗物质密度分布，将其与M87星系的观测结果进行比较。

**Summary**:

- (1): 本文研究背景是广义相对论（GR）在描述引力现象方面的成功以及虫洞的可能性，特别是在考虑量子引力效应的情况下。

- (2): 以往的方法主要依赖于广义相对论，通常需要奇异物质来构造稳定的虫洞解。此方法的限制在于奇异物质的要求造成构造上的困难。与此相对，本文提出通过Loop Quantum Cosmology中的各向同性暗物质来支持虫洞，从而可能减少对奇异物质的依赖，此方法是有动机的，在量子效应下，暗物质可能展现出支持虫洞所需的特性。

- (3): 本文的贡献在于找到在Loop Quantum Cosmology框架下使用各向同性暗物质构造的可穿越虫洞解，探讨了其几何特性和规范条件，并计算了维持这些虫洞所需的奇异物质。

- (4): 本文的研究方法包括分析三种冷暗物质模型，计算其对应的修正引力场方程解与应力-能量守恒，使用Kretschmann标量验证虫洞的规则性，并通过嵌入图形象化虫洞结构。

- (5): 本文通过计算虫洞的阴影及与M87星系观测的比较，展示了所提出模型的可行性，香气在支持目标方面表现出积极的效果。


## Galaxy and halo properties around cosmic filaments from Sloan Digital Sky Survey Data Release 7 and the ELUCID simulation
- **Url**: http://arxiv.org/abs/2504.07367v1
- **Authors**: ['Youcai Zhang', 'Xiaohu Yang', 'Hong Guo', 'Peng Wang', 'Feng Shi']
- **Abstrat**: Using galaxies from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7) along with haloes from the dark matter only constrained ELUCID (Exploring the Local Universe with the reConstructed Initial Density field) simulation, we examine the properties of galaxies and haloes with respect to their distance to cosmic filaments, determined by the medial-axis thinning technique of the COsmic Web Skeleton (COWS) method. Our findings suggest that galaxies or subhaloes grow in mass as they approach these filaments. Galaxies exhibit a redder colour and diminished specific star formation rates as they approach these filaments. Additionally, older subhaloes tend to be more common near the central regions of these filaments. Elliptical galaxies are more frequently found than spiral galaxies in the central regions of the filaments. Lower-mass galaxies typically display reduced sizes in proximity to filaments, whereas higher-mass galaxies tend to exhibit increased sizes when close to filaments. Moreover, the concentration and spin of the haloes grow as they approach the filaments. These findings support the notion that the large-scale structure of the universe, characterized by cosmic web structures, plays a vital role in shaping galaxy and halo properties.


**Translated Abstract**: 

本文利用Sloan Digital Sky Survey 数据第七次发布 (SDSS DR7) 的星系及基于ELUCID (Exploring the Local Universe with the reConstructed Initial Density field) 模拟的暗物质晕，研究星系和暗晕相对于宇宙丝带的距离的性质。我们的研究结果表明，星系或亚晕在靠近这些丝带时质量会增长。星系在靠近这些丝带时表现出更红的颜色和下降的特定星形成率。此外，较老的亚晕更常见于丝带的中心区域。椭圆星系在丝带的中心区域的出现频率高于螺旋星系。小质量星系在靠近丝带时通常显示出较小的尺寸，而大质量星系在接近丝带时则往往展现出较大的尺寸。此外，晕的集中度和自旋在接近丝带时也会增加。这些发现支持了宇宙的大规模结构，特别是宇宙网络结构在塑造星系和晕的性质方面发挥了重要作用。

**Summary**:

- (1): 本文的研究背景是宇宙丝带的结构与星系和暗物质晕的性质之间的关系，强调宇宙网络对它们形成和演化的影响。

- (2): 过去的研究方法主要集中在星系周围的环境影响，但对大规模宇宙结构的深入分析不足。相较于之前的方法，本文采用了基于COSmic Web Skeleton (COWS) 方法的中轴稀疏技术，以更精准地分析星系在宇宙丝带附近的性质，解决了对环境影响理解不充分的问题。

- (3): 本文的贡献在于揭示了星系和暗物质晕与宇宙丝带之间的关系，尤其是在不同质量星系的生长、颜色变化、形态特征及集中度增加等方面的发现。

- (4): 研究方法包括对SDSS DR7数据和ELUCID模拟中的星系进行分析，利用COWS方法识别星系与丝带的空间关系及其性质变化。

- (5): 本文在研究星系的质量、颜色、形状以及晕的集中度等任务中获得了重要的性能指标，这些性能表明大规模环境对星系特性具有显著影响，进一步支持了研究目标的达成。


## Resolved ALMA [CII] 158 micron Observations at Cosmic Noon: ISM Structure and Dynamics of Starbursting QSO SDSSJ1000
- **Url**: http://arxiv.org/abs/2504.07325v1
- **Authors**: ['Christopher Rooney', 'Bo Peng', 'Amit Vishwas', 'Gordon Stacey', 'Thomas Nikola', 'Cody Lamarche', 'Catie Ball', 'Carl Ferkinhoff', 'Drew Brisbin', 'Steven Hailey-Dunsheath']
- **Abstrat**: We present spatially resolved Alma Band-9 observations of the [CII] 158 $\mu$m fine structure line from an optically selected quasar, SDSS J100038.01+020822.4 (J1000), at z=1.8275. By utilizing [OI] 63 $\mu$m line observations from Herschel/PACS and constructing a detailed dust SED using Herschel and Spitzer archival imaging data, we show that the [CII] line emission is well explained by a photodissociation region (PDR) model, in which the emission arises from the surfaces of molecular clouds exposed to far-UV radiation fields $\sim 5\cdot10^3$ times the local interstellar radiation field (G$_0$). We find a factor of 30 variation in spatially resolved [CII]/Far-IR continuum across the source which is explained by the reduced fraction of cooling via [CII] line emission at such high far-UV field strengths. By matching derived PDR parameters to the observed far-IR line and continuum intensities we derive cloud size-scales and find that typical cloud radii in J1000 are $\sim$3.5 pc perhaps indicating an ISM that is highly fractured due to intense star formation activity. We model the galaxy dynamically and find that the [CII] emission is contained within a compact, dynamically cold disk with v/$\sigma$=6.2, consistent with cosmological simulations. We also report the discovery of a companion galaxy to j1000 confirmed by the detection of [CII] and use recently obtained JWST/NirCAM imaging of the system to argue for J1000 being an interacting system. With total stellar mass $\sim 1.5 \times 10^{10}$ M$_\odot$ and main-component dynamical mass $\gtrsim 10^{11}$ M$_\odot$, the J1000 system is a progenitor to the most massive galaxies seen in the local Universe.


**Translated Abstract**: 

我们展示了对选定的光学类星体 SDSS J100038.01+020822.4 (J1000) 在 z=1.8275 处的 [CII] 158 μm 细结构线的空间分辨率 ALMA Band-9 观测。通过利用 Herschel/PACS 的 [OI] 63 μm 线观测并构建详细的尘埃 SED，利用 Herschel 和 Spitzer 的归档成像数据，我们表明 [CII] 线发射很好地被光解离区（PDR）模型解释，即发射来自暴露于约 5000 倍当地星际辐射场（G0）的分子云表面。我们发现 [CII] 与 Far-IR 连续场在源头的空间分辨率之间存在 30 倍的变化，这一变化由如此高的远紫外场强度下 [CII] 发射的冷却比例降低所解释。通过将得到的 PDR 参数与观察到的 Far-IR 线和连续场强度相匹配，我们推导出云的尺度，并发现 J1000 中典型的云半径约为 3.5 pc，可能表明由于强烈的恒星形成活动，ISM相当破碎。我们对银河系进行了动态建模，发现 [CII] 发射位于一个紧凑、动态冷却的盘内，v/σ=6.2，这与宇宙学模拟一致。我们还报告了与 J1000 的伴星系的发现，通过 [CII] 的检测确认，并利用最近获取的 JWST/NirCAM 成像数据论证 J1000 是一个相互作用的系统。J1000 系统的总恒星质量约为 1.5 × 10^{10} M⊙，主成分的动力学质量大于或约等于 10^{11} M⊙，是目前宇宙中已知最大银河系的前体。

**Summary**:

- (1): 本文研究的背景是宇宙中期 (Cosmic Noon)时期 (z∼1-3)，期间星形成速率密度达到最高水平，大部分今天宇宙中的星星是在这一时间段形成的。

- (2): 以往的方法主要依赖于光学波段的观测，难以有效研究尘埃星形成的重子物质；通量在多数源中被尘埃吸收，导致对光谱线的错估。本文利用 ALMA Band-9 观测[ CII] 158 μm 线发射，通过 PDR 模型解析低温高光照条件下的发射特征，并克服了以往方法中的劣势。

- (3): 本文的贡献在于通过 ALMA 对目标光学类星体的空间分辨率探测，揭示了星际介质 (ISM) 的结构和动力学特性，指出了因强烈的星形成活动导致的分子云的破碎情况，以及确认其关联的伴星系。

- (4): 本文提出的研究方法包括使用 ALMA 观测数据结合 Herschel 和 Spitzer 的尘埃 SED 构建，通过 PDR 模型分析 [CII] 发射与 Far-IR 连续场的关系。

- (5): 本文的方法聚焦于对 SDSS J1000 星系的动态建模和 PDR 特性探讨，已取得云半径、发射强度及动态冷却盘的探测结果，这些结果支持了其关于星系形成和演化的研究目标。


## ASKAP Discoveries of Giant Radio Galaxies in the Sculptor field
- **Url**: http://arxiv.org/abs/2504.07314v1
- **Authors**: ['B. S. Koribalski']
- **Abstrat**: We present the discovery of 15 well-resolved giant radio galaxies (GRGs) with angular sizes >5 arcmin and physical sizes >1 Mpc in wide-field Phased Array Feed 944 MHz observations on the Australian Square Kilometre Array Pathfinder (ASKAP). We identify their host galaxies, examine their radio properties as well as their environment, and classify their morphologies as FR I (4), FR II (8), intermediate FR I/II (2), and hybrid (1). The combined ~40 deg^2 ASKAP image of the Sculptor field, which is centred near the starburst galaxy NGC 253, has a resolution of 13" and an rms sensitivity of >10 microJy/beam. The largest GRGs in our sample are ASKAP J0057-2428 (zphot = 0.238), ASKAP J0059-2352 (zphot = 0.735) and ASKAP J0107-2347 (zphot = 0.312), for which we estimate linear projected sizes of 2.7, 3.5 and 3.8 Mpc, respectively. In total we catalog 232 extended radio galaxies of which 77 (33%) are larger than 0.7 Mpc and 35 (15%) are larger than 1 Mpc. The radio galaxy densities are 5.8 deg^-2 (total) and 0.9 (1.9) deg^-2 for those larger than 1 (0.7) Mpc, similar to previous results. Furthermore, we present the ASKAP discovery of a head-tail radio galaxy, a double-lobe radio galaxy with a spiral host, and radio emission from several galaxy clusters. As the ASKAP observations were originally conducted to search for a radio counterpart to the gravitational wave detection GW190814 (z ~ 0.05), we highlight possible host galaxies in our sample.


**Translated Abstract**:

我们呈现了在澳大利亚平方公里阵列探测器（ASKAP）上进行的944 MHz宽场相位阵列馈电观测中，发现了15个分辨良好的巨大射电星系（GRGs），其角度尺寸大于5弧分钟，物理尺寸大于1 Mpc。我们识别了它们的宿主星系，检查了它们的射电特性以及它们的环境，并将其形态分类为FR I（4个）、FR II（8个）、中间FR I/II（2个）和混合（1个）。结合约40 deg²的ASKAP图像，中心位于星爆星系NGC 253，分辨率为13"且rms灵敏度为>10微焦耳/波束。我们样本中最大的GRGs是ASKAP J0057-2428（zphot = 0.238）、ASKAP J0059-2352（zphot = 0.735）和ASKAP J0107-2347（zphot = 0.312），我们估计其线性投影尺寸分别为2.7、3.5和3.8 Mpc。总共 catalog 了232个扩展射电星系，其中77个（33%）大于0.7 Mpc，35个（15%）大于1 Mpc。射电星系的密度为5.8 deg⁻²（总计），对于那些大于1（0.7）Mpc的星系分别为0.9（1.9）deg⁻²，类似于先前结果。此外，我们介绍了ASKAP发现的一个首尾射电星系、一个具有螺旋宿主的双核射电星系以及从几个星系团中发现的射电辐射。由于ASKAP观察最初是为了寻找重力波探测GW190814（z ~ 0.05）的射电对应物，我们强调了样本中可能的宿主星系。

**Summary**:

- (1): 本文研究背景为巨型射电星系（GRGs）是宇宙中规模最大的天体之一，能够提供宿主椭圆星系内部能量过程的证据。

- (2): 过去的方法主要依赖于以前的射电调查，然而这些调查往往样本数量有限，分辨率和灵敏度不足。本文采用ASKAP的944 MHz宽场观测，较好解决了样本数量和精度等问题，提供了更为全面的GRG分类和特性分析。

- (3): 论文的贡献在于发现了15个新的GRGs，并在约40 deg²的范围内 catalog 了232个扩展射电星系，增强了对GRGs的了解，并探讨了其环境和宿主星系。

- (4): 本研究采用ASKAP的相位阵列馈电观测法，对GRGs进行全面分析，包括宿主星系识别及射电特性检查，并分类其形态学。

- (5): 方法在发现GRGs及描绘它们物理特性上表现卓越，所获得的结果支持了对巨型射电星系理解深化的目标。


# machine learning
## Cat, Rat, Meow: On the Alignment of Language Model and Human Term-Similarity Judgments
- **Url**: http://arxiv.org/abs/2504.07965v1
- **Authors**: ['Lorenz Linhardt', 'Tom Neuhäuser', 'Lenka Tětková', 'Oliver Eberle']
- **Abstrat**: Small and mid-sized generative language models have gained increasing attention. Their size and availability make them amenable to being analyzed at a behavioral as well as a representational level, allowing investigations of how these levels interact. We evaluate 32 publicly available language models for their representational and behavioral alignment with human similarity judgments on a word triplet task. This provides a novel evaluation setting to probe semantic associations in language beyond common pairwise comparisons. We find that (1) even the representations of small language models can achieve human-level alignment, (2) instruction-tuned model variants can exhibit substantially increased agreement, (3) the pattern of alignment across layers is highly model dependent, and (4) alignment based on models' behavioral responses is highly dependent on model size, matching their representational alignment only for the largest evaluated models.


**Translated Abstract**: 

小型和中型生成语言模型受到越来越多的关注。它们的规模和可获取性使得可以在行为和表征层面进行分析，从而能够研究这两个层面的相互作用。我们评估了32种公开可用的语言模型在与人类相似性判断的表征和行为对齐方面的表现，使用了一个单词三元组任务。这提供了一种新颖的评估设置，用于探测语言中的语义关联，超越常见的成对比较。我们的研究发现：(1) 即使是小型语言模型的表征也可以达到人类级别的对齐，(2) 指令调优的模型变体可以显著提高一致性，(3) 各层之间的对齐模式高度依赖于模型，(4) 基于模型行为响应的对齐高度依赖于模型大小，仅在评估的最大模型中匹配它们的表征对齐。

**Summary**:

- (1): 本文研究小型和中型生成语言模型的行为与表征层面之间的关系。

- (2): 过去的方法主要关注行为评估，使用了一些简单的成对比较，存在方法局限性和对齐问题。本文提出的三元组任务方法更全面地探测语义关联，解决了传统方法中对齐不充分的问题，具有良好的理论动机。

- (3): 本文的贡献在于评估32种公开语言模型在与人类相似性判断对齐方面的表现，并揭示了模型大小和调优方式对模型表现的影响。

- (4): 本文采用的研究方法为使用三元组任务来评估语言模型的表征和行为对齐。

- (5): 在该任务上，评估的语言模型表现出与人类相似性判断的对齐，尤其是较大的模型表现良好，支持了减少传统评估方法局限性的目标。


## C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization for Test-Time Expert Re-Mixing
- **Url**: http://arxiv.org/abs/2504.07964v1
- **Authors**: ['Zhongyang Li', 'Ziyue Li', 'Tianyi Zhou']
- **Abstrat**: Mixture-of-Experts (MoE) Large Language Models (LLMs) suffer from severely sub-optimal expert pathways-our study reveals that naive expert selection learned from pretraining leaves a surprising 10-20% accuracy gap for improvement. Motivated by this observation, we develop a novel class of test-time optimization methods to re-weight or "re-mixing" the experts in different layers jointly for each test sample. Since the test sample's ground truth is unknown, we propose to optimize a surrogate objective defined by the sample's "successful neighbors" from a reference set of samples. We introduce three surrogates and algorithms based on mode-finding, kernel regression, and the average loss of similar reference samples/tasks. To reduce the cost of optimizing whole pathways, we apply our algorithms merely to the core experts' mixing weights in critical layers, which enjoy similar performance but save significant computation. This leads to "Critical-Layer, Core-Expert, Collaborative Pathway Optimization (C3PO)". We apply C3PO to two recent MoE LLMs and examine it on six widely-used benchmarks. It consistently improves the base model by 7-15% in accuracy and outperforms widely used test-time learning baselines, e.g., in-context learning and prompt/prefix tuning, by a large margin. Moreover, C3PO enables MoE LLMs with 1-3B active parameters to outperform LLMs of 7-9B parameters, hence improving MoE's advantages on efficiency. Our thorough ablation study further sheds novel insights on achieving test-time improvement on MoE.


**Translated Abstract**: 

混合专家（Mixture-of-Experts，MoE）的大型语言模型（LLMs）存在严重的专家路径次优问题——我们的研究表明，从预训练中学习到的简单专家选择会导致意想不到的10-20%的准确率差距。受到这一观察的启发，我们开发了一种新颖的测试时优化方法，在每个测试样本上共同重新加权或“重新混合”不同层中的专家。由于测试样本的真实标签未知，我们提出了通过样本的“成功邻居”来优化替代目标，邻居是来自参考样本集的样本。我们引入了三种替代目标和基于模式寻找、核回归以及相似参考样本/任务平均损失的算法。为了减少优化整个路径的成本，我们的算法仅应用于关键层中核心专家的混合权重，这在性能上保持相似但节省了显著的计算资源。这导致了“关键层、核心专家、协作路径优化（C3PO）”。我们将C3PO应用于两个新的MoE LLM，并在六个广泛使用的基准测试上进行验证。它始终提高基础模型7-15%的准确率，并显著超越广泛使用的测试时学习基线，如上下文学习和提示/前缀调整。此外，C3PO使得激活参数在1-3B的MoE LLM超越7-9B参数的LLM，从而提升了MoE在效率方面的优势。我们的全面消融研究进一步提供了关于实现MoE测试时改进的新见解。

**Summary**:

- (1): 该文章的研究背景是混合专家（MoE）大型语言模型在推理时专家路径的选择存在显著的次优性，导致10-20%的准确率差距。

- (2): 过去的方法包括在上下文学习（ICL）和提示/前缀调整等测试时优化方法，但这些方法在MoE/路径LLM中的适用性尚不明确。提出的方法侧重于优化每个测试样本的专家路径，通过优化关键层中核心专家的混合权重来解决路径选择问题，且具有良好的动机。

- (3): 本文的贡献在于提出了一种新的测试时优化方法C3PO，能显著改善LLM的性能，同时节省计算资源，并通过对比证明了其效率和效果。

- (4): 本文提出的研究方法包括三种基于模式寻找、核回归及相似参考样本平均损失的优化算法，旨在重新加权每个测试样本的专家路径。

- (5): 本文在六个广泛使用的基准测试上评估了C3PO，取得了7-15%的准确率提升，表现支持其提高测试时适应性能的目标。


## Dynamic Cheatsheet: Test-Time Learning with Adaptive Memory
- **Url**: http://arxiv.org/abs/2504.07952v1
- **Authors**: ['Mirac Suzgun', 'Mert Yuksekgonul', 'Federico Bianchi', 'Dan Jurafsky', 'James Zou']
- **Abstrat**: Despite their impressive performance on complex tasks, current language models (LMs) typically operate in a vacuum: Each input query is processed separately, without retaining insights from previous attempts. Here, we present Dynamic Cheatsheet (DC), a lightweight framework that endows a black-box LM with a persistent, evolving memory. Rather than repeatedly re-discovering or re-committing the same solutions and mistakes, DC enables models to store and reuse accumulated strategies, code snippets, and general problem-solving insights at inference time. This test-time learning enhances performance substantially across a range of tasks without needing explicit ground-truth labels or human feedback. Leveraging DC, Claude 3.5 Sonnet's accuracy more than doubled on AIME math exams once it began retaining algebraic insights across questions. Similarly, GPT-4o's success rate on Game of 24 increased from 10% to 99% after the model discovered and reused a Python-based solution. In tasks prone to arithmetic mistakes, such as balancing equations, DC enabled GPT-4o and Claude to reach near-perfect accuracy by recalling previously validated code, whereas their baselines stagnated around 50%. Beyond arithmetic challenges, DC yields notable accuracy gains on knowledge-demanding tasks. Claude achieved a 9% improvement in GPQA-Diamond and an 8% boost on MMLU-Pro problems. Crucially, DC's memory is self-curated, focusing on concise, transferable snippets rather than entire transcript. Unlike finetuning or static retrieval methods, DC adapts LMs' problem-solving skills on the fly, without modifying their underlying parameters. Overall, our findings present DC as a promising approach for augmenting LMs with persistent memory, bridging the divide between isolated inference events and the cumulative, experience-driven learning characteristic of human cognition.


**Translated Abstract**: 

尽管当前语言模型（LM）在复杂任务中的表现令人印象深刻，但它们通常在“真空”中操作：每个输入查询都是单独处理的，没有保留先前尝试的见解。在此，我们提出了动态备忘单（Dynamic Cheatsheet，DC），这是一个轻量级框架，使黑箱LM具备持久、不断发展的内存。DC使模型能够在推理时存储和重用积累的策略、代码片段和一般的解决问题的见解，从而避免重复发现或犯同样的错误。这种测试时学习显著提高了多种任务的性能，而无需显式的真实标签或人工反馈。利用DC，Claude 3.5 Sonnet在AIME数学考试上的准确率翻了一番，而GPT-4o在Game of 24中的成功率则从10%提高到99%。在容易出错的任务中，比如平衡方程，DC使GPT-4o和Claude的准确率接近完美，而它们的基线则停留在约50%。此外，DC在知识需求较高的任务中也显著提高了准确率。Claude在GPQA-Diamond和MMLU-Pro问题上的表现分别提高了9%和8%。重要的是，DC的内存是自我策划的，专注于简洁、可转移的片段，而不是整个转录内容。与微调或静态检索方法不同，DC在不修改基础参数的情况下，实时调整LM的解决问题能力。总体来看，我们的发现表明DC是一种有前景的方法，可以通过持久性内存增强LM，弥合隔离推理事件与人类认知特征之间的差距。

**Summary**:

- (1): 本文的研究背景是当前语言模型（LM）在处理复杂任务时缺乏持久记忆，导致每个查询独立处理，无法利用以往的成功和错误经验。

- (2): 过去的方法主要依赖于微调模型参数或从大型静态语料库中检索信息，存在模型在推理时无法动态学习的问题。本文提出的动态备忘单（DC）通过构建可重用的策略和代码片段的持久性内存，解决了这一缺陷，提供了实时的学习能力，没有显式的真实标签或人工反馈的需求，因此具有较强的动机。

- (3): 本文的贡献在于提出了动态备忘单（DC）这一新框架，它在推理时允许语言模型在线学习和自我调整，从而显著提高了其解决问题的能力。

- (4): 本文的研究方法论包括在查询前或后动态策划一套可重用的、基于经验的策略和代码，使用自我更新的机制来有效管理内存，避免增加过多的上下文信息。

- (5): 在多个任务上取得显著性能提升，如Claude 3.5 Sonnet在AIME数学考试中的准确率从23%提升至50%，GPT-4o在Game of 24的成功率从10%提升至99%。这些结果表明，所提出的方法确实支持其研究目标。


## Pushing the Accuracy Limit of Foundation Neural Network Models with Quantum Monte Carlo Forces and Path Integrals
- **Url**: http://arxiv.org/abs/2504.07948v1
- **Authors**: ['Anouar Benali', 'Thomas Plé', 'Olivier Adjoua', 'Valay Agarawal', 'Thomas Applencourt', 'Marharyta Blazhynska', 'Raymond Clay III', 'Kevin Gasperich', 'Khalid Hossain', 'Jeongnim Kim', 'Christopher Knight', 'Jaron T. Krogel', 'Yvon Maday', 'Maxime Maria', 'Mathieu Montes', 'Ye Luo', 'Evgeny Posenitskiy', 'Corentin Villot', 'Venkat Vishwanath', 'Louis Lagardère', 'Jean-Philip Piquemal']
- **Abstrat**: We propose an end-to-end integrated strategy for the production of highly accurate quantum chemistry (QC) synthetic datasets aimed at deriving atomistic Foundation Machine Learning (ML) Models. We first present a GPU-accelerated QC database generation Exascale protocol able to produce the required energies and forces. A "Jacob's Ladder" approach leverages computationally-optimized layers of massively parallel high performance software with increasing accuracy to compute: i) Density Functional Theory (DFT); ii) Quantum Monte Carlo (QMC); iii) Selected Configuration Interaction (s-CI), within large volumes and optimized time-to-solution performances. Handling this ambitious computational pipeline would be impossible without exascale computing resources, particularly for the notoriously difficult and computationally intensive calculation of QMC forces and for the combination of multi-determinant QMC energies and forces using selected CI wavefunctions methodologies. To our knowledge, this is the first time that such quantities are computed at such scale. We combine these data with the FeNNix-Bio-1 foundation ML model to bridge the gap between highly accurate QC calculations and condensed-phase Molecular Dynamics (MD). We demonstrate stable multi-ns simulations using the resulting beyond DFT accuracy fully reactive model coupled to full path integrals adaptive sampling quantum dynamics. A complete 1 million-atom plant virus solvated structure, including its full genetic material, is simulated using Ring-Polymer MD quantum dynamics along as its response to acidification under physiological NaCl concentrations. These new capabilities open the door to the possibility to monitor bond breaking/creation and proton transfers chemical interactions taking place in biosystems allowing us to reach a deeper understanding of their complex internal machinery.


**Translated Abstract**: 

我们提出了一种端到端集成策略，用于生成高精度量子化学（QC）合成数据集，旨在推导出原子级基础机器学习（ML）模型。我们首先展示一个基于GPU加速的QC数据库生成的Exascale协议，能够产生所需的能量和力。采用“Jacob's Ladder”方法，利用计算优化的分层高性能软件，逐步计算：i) 密度泛函理论（DFT）；ii) 量子蒙特卡罗（QMC）；iii) 选定配置相互作用（s-CI），以优化解决方案性能。处理这一雄心勃勃的计算流水线在没有Exascale计算资源的情况下是不可想象的，特别是对于计算QMC力和结合多决定子QMC能量和力的复杂性。我们结合这些数据与FeNNix-Bio-1基础ML模型，弥合高精度QC计算与凝聚相分子动力学（MD）之间的差距。我们展示了使用该完全反应模型的稳定多纳秒模拟，并与全路径积分自适应采样量子动力学相耦合。在模拟中，一个包含其全部遗传物质的100万原子植物病毒溶剂化结构通过环聚合物MD量子动力学进行了研究，并分析了其在生理NaCl浓度下酸化的反应。这些新能力为监测生物系统中的化学反应（如键的断裂/形成和质子转移）打开了大门，使我们能够更深入地理解其复杂的内部机制。

**Summary**:

- (1): 本文的研究背景是量子化学数据集生成对原子级基础机器学习模型推导的重要性。

- (2): 过去的方法主要依赖于计算量大且复杂的量子化学计算，如质量很高的QMC。问题在于这些方法计算成本高，限制了其常规使用。该方法通过提出基于“Jacob's Ladder”的分层计算协议，以及利用GPU加速来提高效率，有效解决了这些问题。

- (3): 本文的贡献在于提出了一种新的GPU加速的量子化学数据库生成协议，能够生成大量高精度的量子化学数据，用于支持凝聚相的分子动力学模拟。

- (4): 本文采用的研究方法包括使用Exascale计算资源，通过分层的量子化学计算（DFT、QMC、s-CI）生成所需的能量和力数据，并结合FeNNix-Bio-1模型进行分子动力学仿真。

- (5): 方法在对100万原子植物病毒溶剂化结构的量子动力学模拟任务中表现出稳定的多纳秒模拟性能，成功支持了监测复杂化学反应的目标。


## The Performance Of The Unadjusted Langevin Algorithm Without Smoothness Assumptions
- **Url**: http://arxiv.org/abs/2502.03458v2
- **Authors**: ['Tim Johnston', 'Iosif Lytras', 'Nikolaos Makras', 'Sotirios Sabanis']
- **Abstrat**: In this article, we study the problem of sampling from distributions whose densities are not necessarily smooth nor log-concave. We propose a simple Langevin-based algorithm that does not rely on popular but computationally challenging techniques, such as the Moreau Yosida envelope or Gaussian smoothing. We derive non-asymptotic guarantees for the convergence of the algorithm to the target distribution in Wasserstein distances. Non asymptotic bounds are also provided for the performance of the algorithm as an optimizer, specifically for the solution of associated excess risk optimization problems.


**Translated Abstract**: 

在本文中，我们研究了从其密度不一定平滑或对数凹分布中采样的问题。我们提出了一种简单的基于Langevin的算法，它不依赖于流行但计算上具有挑战性的技术，如Moreau-Yosida包络或高斯平滑。我们推导了算法在Wasserstein距离下收敛到目标分布的非渐近保证。此外，还提供了该算法作为优化器的性能的非渐近界限，特别是对于相关的超额风险优化问题的解。

**Summary**:

- (1): 本文的研究背景是非平滑势能的采样在贝叶斯推断、非平滑优化问题和物理与计算统计中的约束采样等多个领域的应用。

- (2): 过去的方法主要是使用如Moreau-Yosida包络或高斯平滑的技术，它们在计算上具有挑战性。本文提出的方法与现有方法的不同之处在于其简单且计算高效，不需要平滑技术。提出的方法通过明晰的算法设计缓解了在非平滑设定中难以直接模拟Langevin动态的问题，并且动机明确。

- (3): 本文的贡献在于提供了一种简单、计算上高效的Langevin算法，扩展了对非平滑潜力的采样研究，同时在非渐近收敛保证方面取得了新进展。

- (4): 本文提出的研究方法是一种基于Langevin动态的采样算法，能够在非平滑非对数凹分布下有效地采样，并且提供了在Wasserstein距离下的收敛保证。

- (5): 本文的方法在解决相关的超额风险优化问题上展现了有效性，性能的非渐近界限表明算法在目标设定下能够实现预期的表现。


## Trading Graph Neural Network
- **Url**: http://arxiv.org/abs/2504.07923v1
- **Authors**: ['Xian Wu']
- **Abstrat**: This paper proposes a new algorithm -- Trading Graph Neural Network (TGNN) that can structurally estimate the impact of asset features, dealer features and relationship features on asset prices in trading networks. It combines the strength of the traditional simulated method of moments (SMM) and recent machine learning techniques -- Graph Neural Network (GNN). It outperforms existing reduced-form methods with network centrality measures in prediction accuracy. The method can be used on networks with any structure, allowing for heterogeneity among both traders and assets.


**Translated Abstract**: 

本论文提出了一种新的算法——交易图神经网络（TGNN），该算法能够对交易网络中资产特征、交易商特征和关系特征对资产价格的影响进行结构性估计。它结合了传统的模拟矩方法（SMM）和近期的机器学习技术——图神经网络（GNN）的优势。TGNN在预测准确性上优于现有的、基于网络中心性测量的简化模型方法。该方法可以应用于任何结构的网络，允许交易商和资产之间的异质性。

**Summary**:


  - (1): 本文的研究背景是金融市场通常以交易网络的形式组织，交易商在网络中的位置对资产价格有重要影响，但是在估计交易商和资产特征对资产价格的影响时，考虑网络结构存在挑战。

  - (2): 过去的方法主要是简化模型，利用网络中心性度量来捕捉交易商在网络中的位置，但在稀疏网络中可能导致偏倚估计。现有方法在估计的准确性和普适性上存在局限。本文提出的TGNN基于结构估计，通过结合机器学习技术提高估计效率，降低偏差，是有动机的。

  - (3): 本文的贡献在于提出了一种新的结构性估计方法TGNN，可以在任意结构的网络中量化资产特征、交易商特征及其关系对价格的影响。

  - (4): 本文的方法论是构建一个简约的交易网络模型，用交易商作为节点，通过反复迭代的方式估计交易商的价值，并使用回归技术最小化预测价格与观测价格之间的均方误差。

  - (5): 本文所提出的方法应用于交易网络的分析任务，尤其是在传统的场外交易市场和去中心化数字市场中进行结构估计。TGNN在多个测试案例中表现出高准确性，能有效捕捉关键参与者、估计议价能力和持有成本，其性能支持了研究的目标。


## Semantically Encoding Activity Labels for Context-Aware Human Activity Recognition
- **Url**: http://arxiv.org/abs/2504.07916v1
- **Authors**: ['Wen Ge', 'Guanyi Mou', 'Emmanuel O. Agu', 'Kyumin Lee']
- **Abstrat**: Prior work has primarily formulated CA-HAR as a multi-label classification problem, where model inputs are time-series sensor data and target labels are binary encodings representing whether a given activity or context occurs. These CA-HAR methods either predicted each label independently or manually imposed relationships using graphs. However, both strategies often neglect an essential aspect: activity labels have rich semantic relationships. For instance, walking, jogging, and running activities share similar movement patterns but differ in pace and intensity, indicating that they are semantically related. Consequently, prior CA-HAR methods often struggled to accurately capture these inherent and nuanced relationships, particularly on datasets with noisy labels typically used for CA-HAR or situations where the ideal sensor type is unavailable (e.g., recognizing speech without audio sensors). To address this limitation, we propose SEAL, which leverage LMs to encode CA-HAR activity labels to capture semantic relationships. LMs generate vector embeddings that preserve rich semantic information from natural language. Our SEAL approach encodes input-time series sensor data from smart devices and their associated activity and context labels (text) as vector embeddings. During training, SEAL aligns the sensor data representations with their corresponding activity/context label embeddings in a shared embedding space. At inference time, SEAL performs a similarity search, returning the CA-HAR label with the embedding representation closest to the input data. Although LMs have been widely explored in other domains, surprisingly, their potential in CA-HAR has been underexplored, making our approach a novel contribution to the field. Our research opens up new possibilities for integrating more advanced LMs into CA-HAR tasks.


**Translated Abstract**: 
过去的研究主要将上下文感知的人类活动识别（CA-HAR）视为一个多标签分类问题，其中模型输入为时间序列传感器数据，目标标签为二进制编码，表示特定活动或上下文是否发生。这些CA-HAR方法要么独立预测每个标签，要么手动通过图结构施加关系。然而，这两种策略通常忽视了活动标签具有丰富的语义关系这一重要方面。例如，走路、慢跑和跑步活动共享相似的运动模式，但在速度和强度上有所不同，表明它们在语义上是相关的。因此，以前的CA-HAR方法往往难以准确捕捉这些固有且微妙的关系，特别是在通常用于CA-HAR的带噪声标签的数据集或理想传感器类型不可用的情况下（例如，在没有音频传感器的情况下识别语音）。为了解决这一局限性，我们提出了SEAL，利用语言模型（LM）对CA-HAR活动标签进行编码，以捕捉语义关系。语言模型生成的向量嵌入保留了自然语言中的丰富语义信息。我们的SEAL方法将来自智能设备的输入时间序列传感器数据及其关联的活动和上下文标签（文本）编码为向量嵌入。在训练过程中，SEAL将传感器数据表示与其相应的活动/上下文标签嵌入对齐到共享嵌入空间。在推理时，SEAL执行相似性搜索，返回与输入数据的嵌入表示最接近的CA-HAR标签。尽管语言模型在其他领域广泛被探索，但它们在CA-HAR中的潜力却未受到充分重视，使我们的研究在该领域成为一种新颖的贡献。我们的SEAL方法在三组真实世界的数据集上经过严格评估，展示了其卓越表现。在MCC上，性能持续优于最先进的方法7.8%至22.6%；在宏观F1上，优于3.9%至8.4%。此外，SEAL的性能与所使用的数据编码框架无关，在不同的数据编码模型中，MCC的性能提升4.7%至73.3%，宏观F1提升2.6%至30.5%。这种强大的性能为在CA-HAR任务中整合更先进的语言模型打开了新的可能性。我们将代码共享在https://github.com/GMouYes/SEAL上。

**Summary**:

- (1): 本文的研究背景是上下文感知的人类活动识别（CA-HAR），利用传感器数据检测人类活动及其上下文。

- (2): 过去的方法主要是将CA-HAR视为多标签分类问题，存在独立预测标签或手动构建图形关系的局限性，这导致无法捕捉到活动标签间的微妙语义关系。提出的方法SEAL通过利用语言模型对标签进行语义编码，解决了传统方法的不足，并且充分考虑了活动标签之间的语义关系。

- (3): 本文的贡献在于提出了SEAL框架，该框架利用语言模型编码CA-HAR的活动标签，增强了模型对活动标签间丰富语义关系的捕捉能力。

- (4): 研究方法是通过语言模型生成时间序列传感器数据及其对应标签的向量嵌入，在训练阶段对齐这些嵌入，在推理阶段进行相似性搜索以返回最相近的活动标签。

- (5): 本文的方法在三组真实世界的数据集上进行了评估，性能在MCC上提升了7.8%至22.6%，在宏观F1上提升了3.9%至8.4%。这些性能支持了其在CA-HAR任务中的目标。


## Echo Chamber: RL Post-training Amplifies Behaviors Learned in Pretraining
- **Url**: http://arxiv.org/abs/2504.07912v1
- **Authors**: ['Rosie Zhao', 'Alexandru Meterez', 'Sham Kakade', 'Cengiz Pehlevan', 'Samy Jelassi', 'Eran Malach']
- **Abstrat**: Reinforcement learning (RL)-based fine-tuning has become a crucial step in post-training language models for advanced mathematical reasoning and coding. Following the success of frontier reasoning models, recent work has demonstrated that RL fine-tuning consistently improves performance, even in smaller-scale models; however, the underlying mechanisms driving these improvements are not well-understood. Understanding the effects of RL fine-tuning requires disentangling its interaction with pretraining data composition, hyperparameters, and model scale, but such problems are exacerbated by the lack of transparency regarding the training data used in many existing models. In this work, we present a systematic end-to-end study of RL fine-tuning for mathematical reasoning by training models entirely from scratch on different mixtures of fully open datasets. We investigate the effects of various RL fine-tuning algorithms (PPO, GRPO, and Expert Iteration) across models of different scales. Our study reveals that RL algorithms consistently converge towards a dominant output distribution, amplifying patterns in the pretraining data. We also find that models of different scales trained on the same data mixture will converge to distinct output distributions, suggesting that there are scale-dependent biases in model generalization. Moreover, we find that RL post-training on simpler questions can lead to performance gains on harder ones, indicating that certain reasoning capabilities generalize across tasks. Our findings show that small-scale proxies in controlled settings can elicit interesting insights regarding the role of RL in shaping language model behavior.


**Translated Abstract**:

基于强化学习（RL）的微调已成为后训练语言模型在高级数学推理和编程中的关键步骤。最近的研究表明，RL微调在各种规模的模型中持续提高性能；然而，推动这些改进的潜在机制尚不清楚。理解RL微调的影响需要解开其与预训练数据组成、超参数和模型规模之间的相互作用，但由于许多现有模型所使用的训练数据缺乏透明性，这些问题变得更加复杂。在这项工作中，我们通过在不同混合的完全开放数据集上从头开始训练模型，系统地研究了RL微调在数学推理中的作用。我们考察了不同RL微调算法（PPO、GRPO和专家迭代）在不同规模模型上的效果。我们的研究表明，RL算法始终收敛于主导输出分布，放大了预训练数据中的模式。我们还发现，在相同数据混合上训练的不同规模模型会收敛到不同的输出分布，这表明模型泛化存在规模相关的偏差。此外，我们发现对简单问题进行的RL后训练可以提高对困难问题的性能，表明某些推理能力可以跨任务泛化。我们的研究发现，在受控环境下的小规模代理能够对RL在塑造语言模型行为中的作用提供有趣的见解。

**Summary**:

- (1): 本文的研究背景是基于强化学习的微调在数学推理和编程中提升语言模型能力的重要性，以及现有方法在针对这些任务时的局限性。

- (2): 过去的方法主要是使用现有的、通常不透明的模型微调，但这些方法难以控制预训练数据的影响，导致了模型表现的不可预知性。该文提出的通过完全开放数据集进行系统性微调的方法则能更好地识别和分析RL微调所引发的效果，从而解决了数据透明性不足的问题。

- (3): 论文的贡献在于提供了一个系统的RL微调研究，揭示了不同规模模型对预训练数据的依赖以及相关的推理能力的泛化，并建立了对RL微调与预训练数据相互作用的清晰理解。

- (4): 本文采用的研究方法是在完全开放的数据集上从头开始训练语言模型，通过控制预训练数据的组成，随后使用不同的RL算法（比如PPO和GRPO）进行微调。

- (5): 本文的方法在数学问题回答任务上取得了显著的性能提升，支持了推理能力的跨任务泛化，表明了通过RL微调改善模型表现的可能性。


## Hodge Laplacians and Hodge Diffusion Maps
- **Url**: http://arxiv.org/abs/2504.07910v1
- **Authors**: ['Alvaro Almeida Gomez', 'Jorge Duque Franco']
- **Abstrat**: We introduce Hodge Diffusion Maps, a novel manifold learning algorithm designed to analyze and extract topological information from high-dimensional data-sets. This method approximates the exterior derivative acting on differential forms, thereby providing an approximation of the Hodge Laplacian operator. Hodge Diffusion Maps extend existing non-linear dimensionality reduction techniques, including vector diffusion maps, as well as the theories behind diffusion maps and Laplacian Eigenmaps. Our approach captures higher-order topological features of the data-set by projecting it into lower-dimensional Euclidean spaces using the Hodge Laplacian. We develop a theoretical framework to estimate the approximation error of the exterior derivative, based on sample points distributed over a real manifold. Numerical experiments support and validate the proposed methodology.


**Translated Abstract**: 

我们介绍了Hodge扩散映射（Hodge Diffusion Maps），这是一种新颖的流形学习算法，旨在分析和提取高维数据集中的拓扑信息。该方法近似于作用于微分形式的外导数，从而提供了Hodge Laplacian算子的近似。Hodge扩散映射扩展了现有的非线性降维技术，包括向量扩散映射（vector diffusion maps）以及扩散映射（diffusion maps）和拉普拉斯本明算子（Laplacian Eigenmaps）背后的理论。我们的方法通过使用Hodge Laplacian将数据集投影到低维欧几里得空间中，捕获数据集的高阶拓扑特征。我们开发了一个理论框架，以估计外导数的近似误差，基于分布在真实流形上的样本点。数值实验支持并验证了所提出的方法。

**Summary**:

- (1): 本文的研究背景是高维数据集的分析与降维，旨在揭示重要模式和结构，同时克服维度灾难问题。

- (2): 过去的方法包括扩散映射（Diffusion Maps）和向量扩散映射（Vector Diffusion Maps），它们主要专注于低阶几何特征，常常缺失重要的高阶结构。所提出的方法通过引入Hodge扩散映射（Hodge Diffusion Maps），利用k阶Hodge Laplacian克服了这些限制，能够捕捉高阶拓扑特征，并提供有效的流形学习。

- (3): 论文的贡献在于提出了一种外导数的近似方法，以及基于此构造的Hodge Laplacian的样本近似，进而开发了Hodge扩散映射算法，能够应用于高阶微分形式。

- (4): 本文提出的研究方法包括对未知流形上分布的样本点应用外导数的近似，构建Hodge Laplacian的样本近似，然后通过Hodge扩散映射算法将数据投影到Hodge Laplacian的特征形式的点积上。

- (5): 本文在合成数据上进行了数值实验，将Hodge扩散映射与扩散映射、PCA和t-SNE等算法进行比较，结果支持其目标，即在保留数据的内在几何特征的前提下，有效识别高阶拓扑结构。


## Porting an LLM based Application from ChatGPT to an On-Premise Environment
- **Url**: http://arxiv.org/abs/2504.07907v1
- **Authors**: ['Teemu Paloniemi', 'Manu Setälä', 'Tommi Mikkonen']
- **Abstrat**: Given the data-intensive nature of Machine Learning (ML) systems in general, and Large Language Models (LLM) in particular, using them in cloud based environments can become a challenge due to legislation related to privacy and security of data. Taking such aspects into consideration implies porting the LLMs to an on-premise environment, where privacy and security can be controlled. In this paper, we study this porting process of a real-life application using ChatGPT, which runs in a public cloud, to an on-premise environment. The application being ported is AIPA, a system that leverages Large Language Models (LLMs) and sophisticated data analytics to enhance the assessment of procurement call bids. The main considerations in the porting process include transparency of open source models and cost of hardware, which are central design choices of the on-premise environment. In addition to presenting the porting process, we evaluate downsides and benefits associated with porting.


**Translated Abstract**: 

鉴于机器学习（ML）系统和大型语言模型（LLM）数据密集型的特性，在基于云的环境中使用它们可能由于与数据隐私和安全相关的立法而变得具有挑战性。考虑到这些方面，将LLM移植到本地环境中，便可以控制隐私和安全。本文研究了将一个真实应用程序（使用ChatGPT并在公共云中运行）迁移到本地环境的过程。被迁移的应用是AIPA，一个利用大型语言模型（LLM）和复杂数据分析来增强采购呼叫投标评估的系统。移植过程中的主要考虑因素包括开源模型的透明性和硬件成本，这些都是本地环境的核心设计选择。除了呈现移植过程外，我们还评估了与移植相关的缺点和好处。

**Summary**:

- (1): 本文的研究背景是针对大型语言模型（LLM）在数据隐私和安全法律法规影响下，如何将其移植到本地环境以实现更好的数据控制和合规性。

- (2): 过去的方法主要是在云端使用LLM服务，这会受限于数据保护法律。现有方法的问题在于无法完全控制数据隐私和安全。本文提出的方法则是将LLM应用移植到本地环境，该方法能够解决数据合规性问题，并具有良好的动机。

- (3): 论文的贡献在于系统性地研究并展示了将使用ChatGPT的应用程序AIPA移植到本地环境的过程，并评估该过程中的优缺点。

- (4): 研究方法论包括对现有应用在公共云中运行时的限制进行分析，确定在本地环境中移植LLM所需的技术步骤，并考虑硬件成本和开源模型的透明性。

- (5): 本文以AIPA系统评估公共采购呼叫投标的任务为例，评估方法在移植后的实际应用中表现出一定的效率和可控性，这支持了数据隐私和合规性的目标。


## The Efficacy of Semantics-Preserving Transformations in Self-Supervised Learning for Medical Ultrasound
- **Url**: http://arxiv.org/abs/2504.07904v1
- **Authors**: ['Blake VanBerlo', 'Alexander Wong', 'Jesse Hoey', 'Robert Arntfield']
- **Abstrat**: Data augmentation is a central component of joint embedding self-supervised learning (SSL). Approaches that work for natural images may not always be effective in medical imaging tasks. This study systematically investigated the impact of data augmentation and preprocessing strategies in SSL for lung ultrasound. Three data augmentation pipelines were assessed: (1) a baseline pipeline commonly used across imaging domains, (2) a novel semantic-preserving pipeline designed for ultrasound, and (3) a distilled set of the most effective transformations from both pipelines. Pretrained models were evaluated on multiple classification tasks: B-line detection, pleural effusion detection, and COVID-19 classification. Experiments revealed that semantics-preserving data augmentation resulted in the greatest performance for COVID-19 classification - a diagnostic task requiring global image context. Cropping-based methods yielded the greatest performance on the B-line and pleural effusion object classification tasks, which require strong local pattern recognition. Lastly, semantics-preserving ultrasound image preprocessing resulted in increased downstream performance for multiple tasks. Guidance regarding data augmentation and preprocessing strategies was synthesized for practitioners working with SSL in ultrasound.


**Translated Abstract**: 数据增强是联合嵌入自监督学习（SSL）的一个重要组成部分。适用于自然图像的方法在医学影像任务中可能并不总是有效。本研究系统地调查了数据增强和预处理策略在肺部超声中的自监督学习中的影响。评估了三种数据增强管道：（1）一种在各成像领域常用的基线管道；（2）一种专为超声设计的新型语义保留管道；（3）来自两种管道中最有效转换的提炼集。对预训练模型进行多项分类任务评估，包括B线检测、胸腔积液检测和COVID-19分类。实验结果表明，语义保留数据增强在COVID-19分类任务中表现最佳，而裁剪基础方法在B线和胸腔积液物体分类任务中表现突出。最后，语义保留的超声图像预处理对多项任务的下游性能提升具有重要作用。本研究为从事超声中自监督学习的实践者提供了有关数据增强和预处理策略的指导。

**Summary**:

- (1): 本文研究背景是医疗超声（US）图像的自动解释逐渐使用深度学习，但面临数据集匮乏的问题，迫切需要有效的数据增强和预处理策略。

- (2): 过去的方法使用普适的数据增强技术，这些在自然图像中的成功不一定适用于超声图像。提出的语义保留方法专为超声设计，以解决数据增强对图像语义内容无效的问题。方法的动机在于提高医疗超声的分类性能。

- (3): 文章的贡献包括提供超声图像的语义保留预处理技术和数据增强方法，并比较了多种数据增强策略的效果，为超声领域的实践者提供指导。

- (4): 本文提出的研究方法包括评估三种数据增强管道，分别是基线管道、语义保留管道和提炼转换集，以改善超声图像的自监督学习效果。

- (5): 研究任务包括B线检测、胸腔积液检测和COVID-19分类，通过语义保留增强措施在COVID-19分类任务中实现了最佳性能，这些性能支持其提升超声学习结果的目标。


## MONA: Myopic Optimization with Non-myopic Approval Can Mitigate Multi-step Reward Hacking
- **Url**: http://arxiv.org/abs/2501.13011v2
- **Authors**: ['Sebastian Farquhar', 'Vikrant Varma', 'David Lindner', 'David Elson', 'Caleb Biddulph', 'Ian Goodfellow', 'Rohin Shah']
- **Abstrat**: Future advanced AI systems may learn sophisticated strategies through reinforcement learning (RL) that humans cannot understand well enough to safely evaluate. We propose a training method which avoids agents learning undesired multi-step plans that receive high reward (multi-step "reward hacks") even if humans are not able to detect that the behaviour is undesired. The method, Myopic Optimization with Non-myopic Approval (MONA), works by combining short-sighted optimization with far-sighted reward. We demonstrate that MONA can prevent multi-step reward hacking that ordinary RL causes, even without being able to detect the reward hacking and without any extra information that ordinary RL does not get access to. We study MONA empirically in three settings which model different misalignment failure modes including 2-step environments with LLMs representing delegated oversight and encoded reasoning and longer-horizon gridworld environments representing sensor tampering.


**Translated Abstract**: 

未来先进的 AI 系统可能通过强化学习（RL）学习出人类难以理解的复杂策略，从而无法安全评估。我们提议一种训练方法，避免智能体学习到高奖励的非期望多步骤计划（多步骤“奖励劫持”），即使人类无法检测到这些行为是不期望的。这种名为 Myopic Optimization with Non-myopic Approval（MONA）的方法通过结合短期优化和长期奖励来实现。我们证明了 MONA 能够防止普通 RL 导致的多步骤奖励劫持，即使在无法检测奖励劫持和没有普通 RL 访问的额外信息的情况下。我们在三种环境下对 MONA 进行了实证研究，模型不同的错配失败模式，包括代表委托监督和编码推理的2步环境，和代表传感器篡改的长时间地网环境。

**Summary**:

- (1): 本文的研究背景是，随着 AI 系统变得越来越强大，并在长期任务上进行训练，智能体可能会采用复杂的不当行为（奖励劫持），这对人类评估其表现造成挑战。

- (2): 过去的方法主要通过“修补”来解决奖励劫持问题，即在发现不当行为后调整奖励。然而，这些方法的有效性依赖于监督者能够识别不当行为。所提方法 MONA 则不同，它结合了短期优化与长期奖励，而不依赖于完全检测不当行为的能力，从而有效解决了多步骤奖励劫持的问题。该方法具有明确的动机，通过限制智能体的策略选择范围来降低监督的复杂性。

- (3): 本文的贡献在于提出了 MONA 方法，该方法可以有效防止多步骤奖励劫持，即使在监督者无法事前识别不当行为的情况下。

- (4): 本文提出的研究方法包括利用短期优化使智能体专注于近期奖励，并通过监督者对智能体行为的未来有用性进行非短期的评估来引导智能体行为。

- (5): 本文在三种模拟环境中对 MONA 进行了实证研究，显示出能有效避免多步骤奖励劫持的潜力，且实验结果支持其提出的目标。


## Minmax Trend Filtering: Generalizations of Total Variation Denoising via a Local Minmax/Maxmin Formula
- **Url**: http://arxiv.org/abs/2410.03041v3
- **Authors**: ['Sabyasachi Chatterjee']
- **Abstrat**: Total Variation Denoising (TVD) is a fundamental denoising and smoothing method. In this article, we identify a new local minmax/maxmin formula producing two estimators which sandwich the univariate TVD estimator at every point. Operationally, this formula gives a local definition of TVD as a minmax/maxmin of a simple function of local averages. Moreover we find that this minmax/maxmin formula is generalizeable and can be used to define other TVD like estimators. In this article we propose and study higher order polynomial versions of TVD which are defined pointwise lying between minmax and maxmin optimizations of penalized local polynomial regressions over intervals of different scales. These appear to be new nonparametric regression methods, different from usual Trend Filtering and any other existing method in the nonparametric regression toolbox. We call these estimators Minmax Trend Filtering (MTF). We show how the proposed local definition of TVD/MTF estimator makes it tractable to bound pointwise estimation errors in terms of a local bias variance like trade-off. This type of local analysis of TVD/MTF is new and arguably simpler than existing analyses of TVD/Trend Filtering. In particular, apart from minimax rate optimality over bounded variation and piecewise polynomial classes, our pointwise estimation error bounds also enable us to derive local rates of convergence for (locally) Holder Smooth signals. These local rates offer a new pointwise explanation of local adaptivity of TVD/MTF instead of global (MSE) based justifications.


**Translated Abstract**: 

总变差去噪（TVD）是一种基本的去噪和平滑方法。本文确定了一种新的局部最小化/最大化公式，生成两个在每个点上夹住一元TVD估计量的估计器。操作上，这个公式为TVD提供了一个局部定义，即局部平均值的简单函数的最小化/最大化。此外，我们发现这个最小化/最大化公式是可推广的，可以用于定义其他类似TVD的估计器。本文提出并研究了TVD的高阶多项式版本，这些版本在不同尺度的区间上定义，与惩罚局部多项式回归的最小化和最大化的优化值之间存在点对点的关系。这些似乎是新的非参数回归方法，与常规趋势过滤和非参数回归工具箱中的其他现有方法不同。我们称这些估计器为最小最大趋势过滤（MTF）。我们展示了所提出的TVD/MTF估计器的局部定义使得在局部偏差和方差的权衡方面变得可操作。这种对TVD/MTF的局部分析是新的，且可谓比现有的TVD/趋势过滤分析更简单。尤其是，除了对有界变差和分段多项式类的最小最大速率最优性，我们的点估计误差界限还使我们能够推导出（局部）Holder平滑信号的局部收敛速率。这些局部速率提供了对TVD/MTF局部自适应性的新点对点解释，而不是仅仅依赖于全局（均方误差）基准的辩护。

**Summary**:

- (1): 本文研究的背景是非参数回归，特别是针对具有不同局部平滑性特征的回归函数的适应性。

- (2): 过去的方法包括经典的非参数回归技术，如局部多项式回归和趋势过滤等，但这些方法无法适应回归函数在不同区域的平滑特征。所提出的最小最大趋势过滤（Minmax Trend Filtering, MTF）通过引入局部最小化/最大化公式解决了这一问题，提供了对TVD的新的局部定义，从而增强了模型的自适应性。

- (3): 本文的贡献在于提出了一种新的非参数回归估计方法——最小最大趋势过滤（MTF），并与现有的TVD方法进行对比，从而改善了在局部适应性方面的性能。

- (4): 本文采用了局部最小化/最大化的数学方法，定义了点wise的TVD/MTF估计器，并对其偏差和方差进行了局部分析。

- (5): 文中的方法在处理具有局部平滑特征的信号时表现出良好的性能，能够在局部层面上提供收敛速率，表明其目标达成情况令人满意。


## How do Large Language Models Understand Relevance? A Mechanistic Interpretability Perspective
- **Url**: http://arxiv.org/abs/2504.07898v1
- **Authors**: ['Qi Liu', 'Jiaxin Mao', 'Ji-Rong Wen']
- **Abstrat**: Recent studies have shown that large language models (LLMs) can assess relevance and support information retrieval (IR) tasks such as document ranking and relevance judgment generation. However, the internal mechanisms by which off-the-shelf LLMs understand and operationalize relevance remain largely unexplored. In this paper, we systematically investigate how different LLM modules contribute to relevance judgment through the lens of mechanistic interpretability. Using activation patching techniques, we analyze the roles of various model components and identify a multi-stage, progressive process in generating either pointwise or pairwise relevance judgment. Specifically, LLMs first extract query and document information in the early layers, then process relevance information according to instructions in the middle layers, and finally utilize specific attention heads in the later layers to generate relevance judgments in the required format. Our findings provide insights into the mechanisms underlying relevance assessment in LLMs, offering valuable implications for future research on leveraging LLMs for IR tasks.


**Translated Abstract**:   

最近的研究表明，大型语言模型（LLMs）能够评估相关性，并支持信息检索（IR）任务，如文档排名和相关性判断生成。然而，现成的LLMs理解和运用相关性的内部机制仍然很大程度上未被探索。本文通过机械解释的视角系统性地研究不同LLM模块如何在相关性判断中发挥作用。使用激活打补丁技术，我们分析了各种模型组件的角色，并识别出生成点对点或对比相关性判断的多阶段、渐进过程。具体而言，LLMs首先在早期层中提取查询和文档信息，然后在中间层中根据指令处理相关性信息，最后在后期层中利用特定的注意力头生成所需格式的相关性判断。我们的发现为LLMs背后的相关性评估机制提供了见解，为未来利用LLMs进行IR任务的研究提供了有价值的启示。

**Summary**:

- (1): 文章的研究背景是信息检索中的相关性概念，强调了传统方法与大型语言模型（LLMs）在评估相关性时的差异。

- (2): 过去的方法依赖于显式反馈机制和特征权重，而LLMs的机制则不透明。本文提出的方法通过机械解释分析LLMs内部模块，解决了其他方法无法明确理解其相关性信号的不足，具有良好的动机。

- (3): 本文的贡献在于揭示了LLMs在相关性判断过程中的多阶段流程，为理解LLMs如何通过内部交互评估相关性提供了新视角。

- (4): 研究方法包括使用激活打补丁技术，分析LLMs中各个组件的作用，识别出从查询和文档信息提取到生成相关性判断的多个过程。

- (5): 本文的方法在相关性判断和文档排名任务中展现了良好的性能，表现支持了其在IR任务中利用LLMs的研究目标。


## Fast Adaptation with Behavioral Foundation Models
- **Url**: http://arxiv.org/abs/2504.07896v1
- **Authors**: ['Harshit Sikchi', 'Andrea Tirinzoni', 'Ahmed Touati', 'Yingchen Xu', 'Anssi Kanervisto', 'Scott Niekum', 'Amy Zhang', 'Alessandro Lazaric', 'Matteo Pirotta']
- **Abstrat**: Unsupervised zero-shot reinforcement learning (RL) has emerged as a powerful paradigm for pretraining behavioral foundation models (BFMs), enabling agents to solve a wide range of downstream tasks specified via reward functions in a zero-shot fashion, i.e., without additional test-time learning or planning. This is achieved by learning self-supervised task embeddings alongside corresponding near-optimal behaviors and incorporating an inference procedure to directly retrieve the latent task embedding and associated policy for any given reward function. Despite promising results, zero-shot policies are often suboptimal due to errors induced by the unsupervised training process, the embedding, and the inference procedure. In this paper, we focus on devising fast adaptation strategies to improve the zero-shot performance of BFMs in a few steps of online interaction with the environment while avoiding any performance drop during the adaptation process. Notably, we demonstrate that existing BFMs learn a set of skills containing more performant policies than those identified by their inference procedure, making them well-suited for fast adaptation. Motivated by this observation, we propose both actor-critic and actor-only fast adaptation strategies that search in the low-dimensional task-embedding space of the pre-trained BFM to rapidly improve the performance of its zero-shot policies on any downstream task. Notably, our approach mitigates the initial "unlearning" phase commonly observed when fine-tuning pre-trained RL models. We evaluate our fast adaptation strategies on top of four state-of-the-art zero-shot RL methods in multiple navigation and locomotion domains. Our results show that they achieve 10-40% improvement over their zero-shot performance in a few tens of episodes, outperforming existing baselines.


**Translated Abstract**: 

无监督的零-shot 强化学习 (RL) 已成为预训练行为基础模型 (BFMs) 的一种有效范式，使得代理能够以零-shot 方式解决通过奖励函数指定的广泛下游任务，即无需在测试阶段进行额外的学习或计划。这是通过学习自监督任务嵌入及相应的近似最优行为并结合推理过程，直接检索潜在任务嵌入和与之相关的策略。尽管结果令人鼓舞，但零-shot 策略由于无监督训练过程、嵌入和推理过程所引发的错误，往往是次优的。本文集中于制定快速适应策略，以在与环境的几步在线交互中提高 BFMs 的零-shot 性能，同时避免适应过程中的任何性能下降。值得注意的是，我们证明现有的 BFM 学习了一组包含比推理过程所识别的策略更具表现力的技能，使其非常适合快速适应。基于这一观察，我们提出了基于演员-批评者和仅演员的快速适应策略，在预训练 BFM 的低维任务嵌入空间中搜索，以快速提高其在任何下游任务上的零-shot 策略性能。值得一提的是，我们的方法减轻了在微调预训练 RL 模型时常见的初始“遗忘”阶段。我们在多个导航和运动领域对四种最先进的零-shot RL 方法上的快速适应策略进行了评估。我们的结果表明，它们在数十个回合中实现了 10-40% 的零-shot 性能提升，超越了现有基线。

**Summary**:

- (1): 本文的研究背景是无监督（或自监督）预训练在计算机视觉和语言建模中的突破，尤其在强化学习 (RL) 中如何有效转变以解决序列决策问题。

- (2): 过去的方法主要依赖于无监督 RL，尽管取得了一定成果，但常常导致零-shot 策略变得次优。提出的方法与现有方法的不同之处在于，强调现有 BFM 学习的技能集合中包含更优的策略，从而更适合快速适应。通过提出演员-批评者和仅演员的快速适应策略，方法有效改善了零-shot 性能，并缓解了微调时的“遗忘”现象，动机充分。

- (3): 论文的贡献在于提出了快速适应策略，以提高行为基础模型在零-shot 情境下的性能，同时避免性能下降。

- (4): 本文的方法论涉及在预训练 BFM 的低维任务嵌入空间中进行快速搜索，以提升零-shot 策略的效果，采用演员-批评者和仅演员的策略。

- (5): 本文的方法在多个导航和运动任务上进行评估，表现出 10-40% 的零-shot 性能提升，支持了其研究目标。


## DiverseFlow: Sample-Efficient Diverse Mode Coverage in Flows
- **Url**: http://arxiv.org/abs/2504.07894v1
- **Authors**: ['Mashrur M. Morshed', 'Vishnu Boddeti']
- **Abstrat**: Many real-world applications of flow-based generative models desire a diverse set of samples that cover multiple modes of the target distribution. However, the predominant approach for obtaining diverse sets is not sample-efficient, as it involves independently obtaining many samples from the source distribution and mapping them through the flow until the desired mode coverage is achieved. As an alternative to repeated sampling, we introduce DiverseFlow: a training-free approach to improve the diversity of flow models. Our key idea is to employ a determinantal point process to induce a coupling between the samples that drives diversity under a fixed sampling budget. In essence, DiverseFlow allows exploration of more variations in a learned flow model with fewer samples. We demonstrate the efficacy of our method for tasks where sample-efficient diversity is desirable, such as text-guided image generation with polysemous words, inverse problems like large-hole inpainting, and class-conditional image synthesis.


**Translated Abstract**: 

许多基于流的生成模型在实际应用中希望获得涵盖目标分布多个模式的多样化样本。然而，获取多样化集合的主要方法并不高效，因为它涉及从源分布独立获取许多样本并通过流进行映射，直到实现所需的模式覆盖。作为重复采样的替代方案，我们引入了DiverseFlow：一种无需训练的提高流模型多样性的的方法。我们的关键思想是使用行列式点过程来引导样本之间的耦合，从而在固定的采样预算下驱动多样性。本质上，DiverseFlow允许在较少样本的情况下探索学习的流模型中的更多变体。我们展示了方法在样本效率多样性需求较高的任务中的有效性，例如基于文本的图像生成（带有多义词）、逆问题（如大孔填充）和类条件图像合成。

**Summary**:

- (1): 本文的研究背景是基于流的生成模型在真实-world应用中对多样化样本的需求，尤其是在覆盖目标分布多个模式时。

- (2): 过去的方法是通过依赖独立和同分布（IID）样本从源分布中反复采样并映射至目标分布以实现多样性，这一过程效率低下。提出的方法DiverseFlow与其不同之处在于它无需训练，并采用行列式点过程来促进样本之间的多样性，解决了样本效率不足的问题。该方法的动机在于寻找在固定预算下获得更多样本多样性的可能性。

- (3): 本文的贡献在于提出了一种高效的采样方法DiverseFlow，以在流模型中获得多样化样本，并在多个应用中进行了定性和定量的验证。

- (4): 本文提出的研究方法是使用基于行列式点过程的约束来提高在固定采样预算下样本的多样性，特别关注于基于确定性常微分方程（ODE）的采样。

- (5): 本文的方法在任务如基于文本的图像生成、大孔人脸填补和类条件图像合成中表现出卓越性能，其结果表明该方法有效支持实现其目标，即在样本效率和多样性之间找到平衡。


## SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning
- **Url**: http://arxiv.org/abs/2504.07891v1
- **Authors**: ['Rui Pan', 'Yinwei Dai', 'Zhihao Zhang', 'Gabriele Oliaro', 'Zhihao Jia', 'Ravi Netravali']
- **Abstrat**: Recent advances in inference-time compute have significantly improved performance on complex tasks by generating long chains of thought (CoTs) using Large Reasoning Models (LRMs). However, this improved accuracy comes at the cost of high inference latency due to the length of generated reasoning sequences and the autoregressive nature of decoding. Our key insight in tackling these overheads is that LRM inference, and the reasoning that it embeds, is highly tolerant of approximations: complex tasks are typically broken down into simpler steps, each of which brings utility based on the semantic insight it provides for downstream steps rather than the exact tokens it generates. Accordingly, we introduce SpecReason, a system that automatically accelerates LRM inference by using a lightweight model to (speculatively) carry out simpler intermediate reasoning steps and reserving the costly base model only to assess (and potentially correct) the speculated outputs. Importantly, SpecReason's focus on exploiting the semantic flexibility of thinking tokens in preserving final-answer accuracy is complementary to prior speculation techniques, most notably speculative decoding, which demands token-level equivalence at each step. Across a variety of reasoning benchmarks, SpecReason achieves 1.5-2.5$\times$ speedup over vanilla LRM inference while improving accuracy by 1.0-9.9\%. Compared to speculative decoding without SpecReason, their combination yields an additional 19.4-44.2\% latency reduction. We open-source SpecReason at https://github.com/ruipeterpan/specreason.


**Translated Abstract**: 

近年来，推理时计算的进展通过使用大型推理模型（Large Reasoning Models，LRMs）生成长时间链的思考（Chains of Thought，CoTs）显著提升了复杂任务的性能。然而，这种提高的准确性以推理延迟的增加为代价，原因在于生成推理序列的长度和自回归解码的性质。我们的关键见解是，LRM推理及其嵌入的推理对近似非常宽容：复杂任务通常分解为更简单的步骤，每个步骤为后续步骤提供语义见解，而非生成的确切令牌。因此，我们引入了SpecReason，一个系统，通过使用轻量级模型（speculatively）进行简单中间推理步骤，加速LRM推理，并仅保留成本较高的基本模型用于评估（并可能修正）推测的输出。值得注意的是，SpecReason专注于利用思维令牌的语义灵活性来保持最终答案的准确性，这与以往的推测技术（尤其是推测解码）是互补的，后者要求每一步都有令牌级的等价性。在各种推理基准上，SpecReason相较传统LRM推理实现了1.5-2.5倍的加速，同时准确性提高1.0-9.9%。与没有SpecReason的推测解码相比，两者组合则能进一步减少19.4-44.2%的延迟。我们将SpecReason开源，地址为https://github.com/ruipeterpan/specreason。

**Summary**:

- (1): 本文的研究背景是大型推理模型（LRMs）在复杂任务中取得的高准确性，但同时面临推理延迟高的问题。

- (2): 过去的方法主要依赖于自动回归的解码过程，导致推理延迟增加。现有方法如推测解码要求在每一步都有令牌级的等价性，而提出的方法SpecReason放宽了这一要求，通过利用轻量级模型进行简单推理，加速LRM推理并保持准确性。这种方法的动机得到了合理的支持。

- (3): 本文的贡献在于提出了SpecReason系统，通过合理结合轻量级模型和基本模型，实现了推理时计算的加速，并在保持高准确性的同时显著降低延迟。

- (4): 本文提出的研究方法是通过使用轻量级模型进行推测推理步骤，而保留基本模型仅用于评估推测输出。

- (5): 在多项推理基准任务上，本文方法实现了1.5-2.5倍的延迟降低和1.0-9.9%的准确性提升，表明其性能支持了加速推理的目标。


## An LLM-Driven Multi-Agent Debate System for Mendelian Diseases
- **Url**: http://arxiv.org/abs/2504.07881v1
- **Authors**: ['Xinyang Zhou', 'Yongyong Ren', 'Qianqian Zhao', 'Daoyi Huang', 'Xinbo Wang', 'Tingting Zhao', 'Zhixing Zhu', 'Wenyuan He', 'Shuyuan Li', 'Yan Xu', 'Yu Sun', 'Yongguo Yu', 'Shengnan Wu', 'Jian Wang', 'Guangjun Yu', 'Dake He', 'Bo Ban', 'Hui Lu']
- **Abstrat**: Accurate diagnosis of Mendelian diseases is crucial for precision therapy and assistance in preimplantation genetic diagnosis. However, existing methods often fall short of clinical standards or depend on extensive datasets to build pretrained machine learning models. To address this, we introduce an innovative LLM-Driven multi-agent debate system (MD2GPS) with natural language explanations of the diagnostic results. It utilizes a language model to transform results from data-driven and knowledge-driven agents into natural language, then fostering a debate between these two specialized agents. This system has been tested on 1,185 samples across four independent datasets, enhancing the TOP1 accuracy from 42.9% to 66% on average. Additionally, in a challenging cohort of 72 cases, MD2GPS identified potential pathogenic genes in 12 patients, reducing the diagnostic time by 90%. The methods within each module of this multi-agent debate system are also replaceable, facilitating its adaptation for diagnosing and researching other complex diseases.


**Translated Abstract**: 


准确诊断孟德尔疾病对精确治疗和辅助植入前基因诊断至关重要。然而，现有方法往往未能达到临床标准，或依赖于广泛的数据集来构建预训练的机器学习模型。为了解决这一问题，我们引入了一种创新的基于大语言模型的多智能体辩论系统（MD2GPS），该系统提供诊断结果的自然语言解释。它利用语言模型将数据驱动和知识驱动代理的结果转化为自然语言，然后促进这两个专业代理之间的辩论。该系统在四个独立数据集上对1,185个样本进行了测试，平均TOP1准确率从42.9%提高到66%。此外，在一个具有挑战性的72例病例的队列中，MD2GPS识别出12名患者的潜在致病基因，将诊断时间缩短了90%。该多智能体辩论系统中的每个模块的方法也可替换，便于其适应其他复杂疾病的诊断和研究。


**Summary**:


- (1): 本文的研究背景是孟德尔疾病的准确诊断对于精确治疗和植入前基因诊断的重要性。

- (2): 过去的方法往往未能达到临床标准，或依赖于庞大的数据集来训练机器学习模型。与现有方法不同，本文提出的MD2GPS系统通过多智能体辩论提供自然语言解释，解决了依赖数据集和缺乏解释性的问题，因此该方法有充分的动机。

- (3): 本文的贡献在于提出了一个创新的多智能体辩论系统（MD2GPS），显著提高了诊断准确性。

- (4): 本文提出的研究方法是利用大语言模型将不同来源的诊断信息转化为自然语言，并促进其之间的辩论，从而达成共识。

- (5): 本文在1,185个样本的诊断任务中实现了平均TOP1准确率从42.9%提高到66%，并在72个复杂病例中成功识别了12个潜在致病基因，该性能支持其诊断精度和效率的目标。


## A first principles approach to electromechanics in liquids
- **Url**: http://arxiv.org/abs/2503.09768v2
- **Authors**: ['Anna T. Bui', 'Stephen J. Cox']
- **Abstrat**: Electromechanics in fluids describes the response of the number density to electric fields, and thus provides a powerful means by which to control the behavior of liquids. While continuum approaches have proven successful in describing electromechanical phenomena in macroscopic bodies, their use is questionable when relevant length scales become comparable to a system's natural correlation lengths, as commonly occurs in, e.g., biological systems, nanopores, and microfluidics. Here, we present a first principles theory for electromechanical phenomena in fluids. Our approach is based on the recently proposed hyperdensity functional theory [Samm\"uller et al, Phys. Rev. Lett. 133, 098201 (2024)] in which we treat the charge density as an observable of the system, with the intrinsic Helmholtz free energy functional dependent upon both density and electrostatic potential. Expressions for the coupling between number and charge densities emerge naturally in this formalism, avoiding the need to construct density-dependent and spatially-varying material parameters such as the dielectric constant. Furthermore, we make our theory practical by deriving a connection between hyperdensity functional theory and local molecular field theory, which facilitates machine learning explicit representations for the free energy functionals of systems with short-ranged electrostatic interactions, with long-ranged effects accounted for in a well-controlled mean field fashion.


**Translated Abstract**: 

流体中的电力机械学描述了数密度对电场的响应，因此提供了一种强有力的手段来控制液体的行为。尽管连续体方法在描述宏观物体中的电力机械现象方面已取得成功，但当相关长度尺度与系统的自然关联长度相当时，它们的使用变得可疑，这种情况通常发生在生物系统、纳米孔和微流控中。在这里，我们提出了一种基于第一原理的流体电力机械现象理论。我们的方法基于最近提出的超密度泛函理论（hyperdensity functional theory），其中我们将电荷密度视为系统的可观测量，内在的亥姆霍兹自由能泛函依赖于密度和电静势。数密度和电荷密度之间的耦合关系自然地在该形式中出现，避免了构建如介电常数等依赖于密度和空间变化的材料参数的需要。此外，我们通过推导超密度泛函理论与局部分子场理论之间的联系，使我们的理论更具实用性，从而为具有短程电静态相互作用的系统的自由能泛函的机器学习显式表征提供了便利，长程效应则以经过良好控制的均值场方式考虑。

**Summary**:

- (1): 本文研究电力机械学在流体中的应用，特别是在生物系统、纳米孔和微流控等情况下的相关长度尺度对现有理论的挑战。

- (2): 过去的方法主要是基于连续体理论，但在微观尺度下存在局限性，特别是在处理自然关联长度相当的情况时。本研究提出的基于超密度泛函理论（hyper-DFT）的方法允许将电荷密度作为可观测量，从而自然生成数密度与电荷密度之间的耦合关系，解决了以往方法中对材料参数依赖性构造的不足。

- (3): 本文贡献在于提出了一种基于第一原理的新理论框架，能够全面而有效地描述流体的电力机械现象，特别是在具有强电场时。

- (4): 本文的方法论基于超密度泛函理论，强调电荷密度与数密度的内在联系，并与局部分子场理论相结合，以实现对短程电静态相互作用的自由能泛函的机器学习表征。

- (5): 本文未提供具体的任务及性能指标，但提出的理论框架用于有效控制液体行为，支持其目标在电力机械学应用中表现出良好潜力。


## Robust Hallucination Detection in LLMs via Adaptive Token Selection
- **Url**: http://arxiv.org/abs/2504.07863v1
- **Authors**: ['Mengjia Niu', 'Hamed Haddadi', 'Guansong Pang']
- **Abstrat**: Hallucinations in large language models (LLMs) pose significant safety concerns that impede their broader deployment. Recent research in hallucination detection has demonstrated that LLMs' internal representations contain truthfulness hints, which can be harnessed for detector training. However, the performance of these detectors is heavily dependent on the internal representations of predetermined tokens, fluctuating considerably when working on free-form generations with varying lengths and sparse distributions of hallucinated entities. To address this, we propose HaMI, a novel approach that enables robust detection of hallucinations through adaptive selection and learning of critical tokens that are most indicative of hallucinations. We achieve this robustness by an innovative formulation of the Hallucination detection task as Multiple Instance (HaMI) learning over token-level representations within a sequence, thereby facilitating a joint optimisation of token selection and hallucination detection on generation sequences of diverse forms. Comprehensive experimental results on four hallucination benchmarks show that HaMI significantly outperforms existing state-of-the-art approaches.


**Translated Abstract**: 

大型语言模型（LLMs）中的幻觉现象对其更广泛的应用构成显著的安全隐患。近期的研究表明，LLMs的内部表示中包含真实度线索，这可以用于检测器的训练。然而，现有检测器的性能严重依赖于预定令牌的内部表示，当处理具有不同长度和稀疏的幻觉实体的自由生成时，性能波动显著。为了解决这一问题，我们提出了HaMI，这是一种新的方法，通过自适应选择和学习最能指示幻觉的关键令牌，来实现强健的幻觉检测。我们通过将幻觉检测任务创新性地表述为在序列的令牌级表示上进行的多实例（HaMI）学习，从而促进了令牌选择和幻觉检测在多种形式生成序列上的联合优化。对四个幻觉基准的全面实验结果表明，HaMI显著优于现有的最先进方法。

**Summary**:

- (1): 本文研究背景为大型语言模型（LLMs）在安全应用中的幻觉现象，这一问题影响了其可靠性和更广泛的部署。

- (2): 过去的方法集中在使用预定令牌和内部状态表示进行幻觉检测，主要问题在于它们对特定令牌的位置依赖，导致在自由生成时性能不稳。提出的方法HaMI通过自适应选择最具指示性的令牌来进行检测，显著增强了检测的鲁棒性，具有明确的动机。

- (3): 本文贡献在于提出了HaMI，一个通过自适应令牌选择实现强健幻觉检测的创新方法，并在多个基准上表现优越。

- (4): 本文提出的研究方法是将幻觉检测任务表述为在令牌级表示上的多实例（HaMI）学习，有效联合优化令牌选择与幻觉检测。

- (5): 该方法在四个幻觉基准任务上进行了全面评估，表现显著优于现有方法，能够支持其目标的实现。


## Reinforcing Clinical Decision Support through Multi-Agent Systems and Ethical AI Governance
- **Url**: http://arxiv.org/abs/2504.03699v2
- **Authors**: ['Ying-Jung Chen', 'Chi-Sheng Chen', 'Ahmad Albarqawi']
- **Abstrat**: In the age of data-driven medicine, it is paramount to include explainable and ethically managed artificial intelligence in explaining clinical decision support systems to achieve trustworthy and effective patient care. The focus of this paper is on a new architecture of a multi-agent system for clinical decision support that uses modular agents to analyze laboratory results, vital signs, and the clinical context and then integrates these results to drive predictions and validate outcomes. We describe our implementation with the eICU database to run lab-analysis-specific agents, vitals-only interpreters, and contextual reasoners and then run the prediction module and a validation agent. Everything is a transparent implementation of business logic, influenced by the principles of ethical AI governance such as Autonomy, Fairness, and Accountability. It provides visible results that this agent-based framework not only improves on interpretability and accuracy but also on reinforcing trust in AI-assisted decisions in an intensive care setting.


**Translated Abstract**: 

在数据驱动的医学时代，至关重要的是在解释临床决策支持系统中包含可解释和伦理管理的人工智能，以实现值得信赖和有效的患者护理。本文的重点是一个新的多代理系统架构，用于临床决策支持，利用模块化代理分析实验室结果、生命体征和临床背景，然后整合这些结果以推动预测和验证结果。我们描述了使用 eICU 数据库的实施，以运行实验室分析特定代理、仅限生命体征的解释器和上下文推理器，然后运行预测模块和验证代理。一切都是透明的业务逻辑实现，受到伦理 AI 治理原则如自主性、公平性和问责制的影响。结果表明，这种基于代理的框架不仅提高了解释性和准确性，还增强了对 ICU 环境中 AI 辅助决策的信任。

**Summary**:

- (1): 本文的研究背景是数据驱动的医学发展，强调在临床决策支持系统中引入可解释和伦理管理的人工智能，以提供有效的患者护理。

- (2): 过去的方法主要依赖传统的 AI 模型，如基于规则或统计的方法，存在灵活性、透明性和监督性不足的问题。提出的多代理系统架构采用模块化设计，反映临床团队的决策方式，并侧重于伦理 AI，这改进了模型的解释性和问责制，解决了传统方法的不足。

- (3): 该论文的贡献在于提出了一种新的多代理系统架构，使临床决策支持更具可解释性和可靠性，同时提高了对 AI 辅助决策的信任。

- (4): 本文提出的研究方法是采用多代理系统 (MAS)，将决策过程分解为各自处理不同任务的模块化代理，包括实验室结果分析、生命体征监测和上下文判断。

- (5): 该方法在 eICU 数据库上进行了验证，能够提供有组织的预测，识别关键预后指标，并增强了对 AI 辅助医疗决策的信任，表现达到了其目标。


## Foreign Signal Radar
- **Url**: http://arxiv.org/abs/2504.07855v1
- **Authors**: ['Wei Jiao']
- **Abstrat**: We introduce a new machine learning approach to detect value-relevant foreign information for both domestic and multinational companies. Candidate foreign signals include lagged returns of stock markets and individual stocks across 47 foreign markets. By training over 100,000 models, we capture stock-specific, time-varying relationships between foreign signals and U.S. stock returns. Foreign signals exhibit out-of-sample return predictability for a subset of U.S. stocks across domestic and multinational companies. Valuable foreign signals are not concentrated in those largest foreign markets nor foreign firms in the same industry as U.S. firms. Signal importance analysis reveals the price discovery of foreign information is significantly slower for information from emerging and low-media-coverage markets and among stocks with lower foreign institutional ownership but is accelerated during the COVID-19 crisis. Our study suggests that machine learning-based investment strategies leveraging foreign signals can emerge as important mechanisms to improve the market efficiency of foreign information.


**Translated Abstract**: 本文介绍了一种新的机器学习方法，用于检测对国内和跨国公司具有价值相关的外国信息。候选的外国信号包括47个外国市场的滞后股票市场和个股收益。通过训练超过100,000个模型，我们捕捉了外国信号与美国股票回报之间特定于股票、时间变化的关系。外国信号在部分美国股票中表现出样本外收益可预测性，涵盖国内和跨国公司。有价值的外国信号并不集中在最大外国市场或与美国公司在同一行业的外国公司中。信号重要性分析显示，来自新兴市场和媒体覆盖率低的市场的信息价格发现显著较慢，并且在外国机构持股较低的股票中表现如此，但在COVID-19危机期间加速。本研究表明，利用外国信号的基于机器学习的投资策略可能成为提高外国信息市场效率的重要机制。

**Summary**:

- (1): 本文的研究背景是探索与美国国内和跨国公司股票回报相关的外国信息，以提高市场效率。

- (2): 过去的方法主要是基于传统经济模型，往往无法捕捉复杂的动态关系，且面临信息摩擦和市场效率低下的问题。提出的方法通过使用机器学习技术，能够训练大规模模型来适应不断变化的信号关系，具有良好的动机。

- (3): 本文的贡献在于提出了一种基于机器学习的分析框架，用于识别和利用外国信号，从而改善股票市场中的信息效率。

- (4): 本文的研究方法是通过训练超过100,000个机器学习模型，捕捉不同外国市场股票的滞后收益与美国股票回报之间的动态关系。

- (5): 方法在样本外收益可预测性任务上取得了成功，对部分美国股票具有预判能力，表明其有效性支持了提升市场效率的目标。


## Learning convolution operators on compact Abelian groups
- **Url**: http://arxiv.org/abs/2501.05279v3
- **Authors**: ['Emilia Magnani', 'Ernesto De Vito', 'Philipp Hennig', 'Lorenzo Rosasco']
- **Abstrat**: We consider the problem of learning convolution operators associated to compact Abelian groups. We study a regularization-based approach and provide corresponding learning guarantees under natural regularity conditions on the convolution kernel. More precisely, we assume the convolution kernel is a function in a translation invariant Hilbert space and analyze a natural ridge regression (RR) estimator. Building on existing results for RR, we characterize the accuracy of the estimator in terms of finite sample bounds. Interestingly, regularity assumptions which are classical in the analysis of RR, have a novel and natural interpretation in terms of space/frequency localization. Theoretical results are illustrated by numerical simulations.


**Translated Abstract**: 

我们考虑与紧致阿贝尔群相关的卷积算子学习问题。我们研究了一种基于正则化的方法，并在卷积核的自然正则性条件下提供相应的学习保障。更准确地说，我们假设卷积核是一个平移不变的希尔伯特空间中的函数，并分析了一种自然的岭回归 (Ridge Regression, RR) 估计器。基于现有的 RR 结果，我们以有限样本界限的形式表征估计器的准确性。有趣的是，正则性假设在 RR 分析中是经典的，并且在空间/频率局部化方面具有新颖和自然的解释。理论结果通过数值模拟进行说明。

**Summary**:

- (1): 本文的研究背景是随着机器学习应用的扩展，分析无限维空间中输入/输出函数的学习问题，特别是关于卷积算子的学习。

- (2): 过去的方法主要集中在神经网络和核方法，但对于卷积算子的学习保障研究较少，且存在对正则性与局部化特征处理不足的问题。本文提出的方法通过特定的正则化，利用平移不变的希尔伯特空间中的核来改进学习过程，并通过频率区域的局部化特性提供新的理论支持。

- (3): 本文的贡献在于提出并分析了一种新颖的岭回归估计器，为卷积算子的学习设置提供了理论保障，并揭示了正则性条件在空间/频率局部化中的新解释。

- (4): 本文提出的研究方法是基于定义卷积的紧致阿贝尔群中的卷积运算，利用岭回归进行估计，同时结合了谐波和傅里叶分析的方法。

- (5): 本文的方法在涉及随机信号与图像复原任务中实现了理论上的学习保障，并通过数值模拟验证了其性能，说明该方法能够达到其研究目标。


## Soybean Disease Detection via Interpretable Hybrid CNN-GNN: Integrating MobileNetV2 and GraphSAGE with Cross-Modal Attention
- **Url**: http://arxiv.org/abs/2503.01284v2
- **Authors**: ['Md Abrar Jahin', 'Soudeep Shahriar', 'M. F. Mridha', 'Md. Jakir Hossen', 'Nilanjan Dey']
- **Abstrat**: Soybean leaf disease detection is critical for agricultural productivity but faces challenges due to visually similar symptoms and limited interpretability in conventional methods. While Convolutional Neural Networks (CNNs) excel in spatial feature extraction, they often neglect inter-image relational dependencies, leading to misclassifications. This paper proposes an interpretable hybrid Sequential CNN-Graph Neural Network (GNN) framework that synergizes MobileNetV2 for localized feature extraction and GraphSAGE for relational modeling. The framework constructs a graph where nodes represent leaf images, with edges defined by cosine similarity-based adjacency matrices and adaptive neighborhood sampling. This design captures fine-grained lesion features and global symptom patterns, addressing inter-class similarity challenges. Cross-modal interpretability is achieved via Grad-CAM and Eigen-CAM visualizations, generating heatmaps to highlight disease-influential regions. Evaluated on a dataset of ten soybean leaf diseases, the model achieves $97.16\%$ accuracy, surpassing standalone CNNs ($\le95.04\%$) and traditional machine learning models ($\le77.05\%$). Ablation studies validate the sequential architecture's superiority over parallel or single-model configurations. With only 2.3 million parameters, the lightweight MobileNetV2-GraphSAGE combination ensures computational efficiency, enabling real-time deployment in resource-constrained environments. The proposed approach bridges the gap between accurate classification and practical applicability, offering a robust, interpretable tool for agricultural diagnostics while advancing CNN-GNN integration in plant pathology research.


**Translated Abstract**:

大豆叶病检测对农业生产力至关重要，但由于视觉相似的症状和传统方法的有限可解释性而面临挑战。尽管卷积神经网络（CNN）在空间特征提取方面表现优异，但它们往往忽视图像间的关系依赖性，从而导致误分类。本文提出了一种可解释的混合序列CNN-图神经网络（GNN）框架，结合MobileNetV2进行局部特征提取和GraphSAGE进行关系建模。该框架构建了一个图，在该图中节点代表叶子图像，边由基于余弦相似度的邻接矩阵和自适应邻域采样定义。这种设计捕捉了细粒度病变特征和全局症状模式，解决了类别间相似性挑战。通过Grad-CAM和Eigen-CAM可视化实现跨模态可解释性，生成热图以突出影响疾病的区域。在一个包含十种大豆叶病的数据集上进行评估，该模型实现了97.16%的准确率，超过了单独的CNN（≤95.04%）和传统机器学习模型（≤77.05%）。消融研究验证了序列架构相较于并行或单一模型配置的优越性。仅具有230万参数的轻量级MobileNetV2-GraphSAGE组合确保了计算效率，使其能够在资源受限的环境中实时部署。该方法弥合了准确分类和实际应用之间的差距，为农业诊断提供了一个稳健且可解释的工具，同时推动了植物病理学研究中的CNN-GNN整合。

**Summary**:

- (1): 本文的研究背景是大豆（Glycine max）作为一种重要的农作物，面临由多种病害导致的生产损失，传统的人工检测方法效率低且主观性强，无法满足大规模自动化的需求。

- (2): 过去的方法主要依赖卷积神经网络（CNN）进行图像分类，但通常忽略图像间的关系信息，导致在症状相似的情况下出现分类错误。本文提出的混合方法结合了CNN和图神经网络（GNN），有效解决了传统方法的局限性，增强了对局部特征及图像间关系的提取。

- (3): 本文的贡献在于提出了一种新的可解释的混合序列CNN-GNN架构，结合MobileNetV2和GraphSAGE，提升了大豆叶病的检测准确性和模型可解释性。

- (4): 本文的研究方法包括设计一个混合架构，其中MobileNetV2用于提取局部特征，GraphSAGE用于建模图像间的关系，同时利用Grad-CAM和Eigen-CAM实现可解释性。

- (5): 本文的任务是检测十种大豆叶病，所提方法的准确率达到97.16%，明显高于现有模型的性能，支持了作者提出的目标。


## A Review of HPC-Accelerated CFD in National Security and Defense
- **Url**: http://arxiv.org/abs/2504.07837v1
- **Authors**: ['James Afful']
- **Abstrat**: Using High-Performance Computing (HPC), Computational Fluid Dynamics (CFD) now serves as an essential component in defense-related national security applications including missile interception and hypersonic propulsion as well as naval stealth optimization and urban hazard dispersion. This review combines two decades of open-source and public-domain research on HPC-accelerated CFD in defense, addressing three key questions: Which security-sensitive simulations have utilized open-source CFD frameworks such as OpenFOAM, SU2 and ADflow? Which HPC techniques, such as MPI domain decomposition and GPU acceleration together with hybrid parallelism best enhance open-source frameworks to manage large defense CFD simulations? Which technological advancements and research voids currently drive the directional development of the field? Examining several research studies sourced from NASA, DoD HPC centers, and academic institutions, scientific contributions have been classified into air, maritime, and space domains. Modular frameworks like NavyFOAM and SU2 and ADflow's adjoint-based solvers show how custom open-source solutions support workflows with rapid completion of multi-million cell simulations. The conclusion highlights new trends that combine exascale readiness with machine learning surrogate models for real-time CFD applications and interdisciplinary HPC-driven multi-physics integration to deliver practical insights for improving CFD use in defense research and development.


**Translated Abstract**: 

利用高性能计算（HPC），计算流体动力学（CFD）现在作为国防相关国家安全应用的重要组成部分，包括导弹拦截、超音速推进、海军隐形优化和城市危害扩散。这项综述结合了20年来关于国防中HPC加速CFD的开源和公共领域研究，解决了三个关键问题：哪些安全敏感的模拟已利用开源CFD框架，如OpenFOAM、SU2和ADflow？哪些HPC技术，例如MPI域分解和GPU加速以及混合并行性，最好地增强开源框架以管理大型国防CFD模拟？哪些技术进步和研究空白正在推动该领域的方向发展？通过检视来自NASA、国防部HPC中心和学术机构的多个研究，科学贡献被分类到航空、海洋和空间领域。像NavyFOAM和SU2以及ADflow的伴随求解器等模块化框架显示了定制开源解决方案如何支持快速完成数百万单元模拟的工作流程。结论强调了结合超级计算准备与机器学习代理模型用于实时CFD应用和跨学科HPC驱动的多物理集成的新趋势，以提供实用见解以改善国防研发中的CFD使用。

**Summary**:

- (1): 本文研究背景是高性能计算（HPC）在国防相关国家安全应用中的重要性，特别是计算流体动力学（CFD）在导弹拦截、超音速推进和城市危害扩散中的应用。

- (2): 过去的方法主要依赖传统CFD框架，面临难以处理大规模模拟的挑战。本文提出利用开源CFD框架如OpenFOAM、SU2和ADflow，并结合HPC技术如MPI和GPU加速来优化模拟性能，从而解决大规模模拟中的计算效率问题。该方法得到良好激励，以支持国防安全任务的需求。

- (3): 本文的贡献在于汇总了二十年的HPC加速CFD研究，并探讨了新兴的模块化框架以及其在国防研究中的应用，并指出了未来技术发展的趋势。

- (4): 本文研究方法包括对来自NASA、国防部HPC中心和学术机构的研究进行分类，主要集中在空中、海洋和空间领域，以评估和比较不同的开源CFD框架及其性能。

- (5): 本文的技术在处理与国防相关的CFD模拟上取得了显著进展，能够完成数百万单元的快速模拟。这些性能支持了国防领域对实时CFD应用和多物理集成的目标。


## Universal Architectures for the Learning of Polyhedral Norms and Convex Regularizers
- **Url**: http://arxiv.org/abs/2503.19190v2
- **Authors**: ['Michael Unser', 'Stanislas Ducotterd']
- **Abstrat**: This paper addresses the task of learning convex regularizers to guide the reconstruction of images from limited data. By imposing that the reconstruction be amplitude-equivariant, we narrow down the class of admissible functionals to those that can be expressed as a power of a seminorm. We then show that such functionals can be approximated to arbitrary precision with the help of polyhedral norms. In particular, we identify two dual parameterizations of such systems: (i) a synthesis form with an $\ell_1$-penalty that involves some learnable dictionary; and (ii) an analysis form with an $\ell_\infty$-penalty that involves a trainable regularization operator. After having provided geometric insights and proved that the two forms are universal, we propose an implementation that relies on a specific architecture (tight frame with a weighted $\ell_1$ penalty) that is easy to train. We illustrate its use for denoising and the reconstruction of biomedical images. We find that the proposed framework outperforms the sparsity-based methods of compressed sensing, while it offers essentially the same convergence and robustness guarantees.


**Translated Abstract**:

本文探讨了学习凸正则项以指导从有限数据中重建图像的任务。通过强加重建为幅度等变的条件，我们将可接受的泛函类缩小为那些可表达为半范数的幂。然后，我们展示了借助多面体范数可以任意精确地逼近这些泛函。具体来说，我们确认了这类系统的两个对偶参数化： (i) 涉及可学习字典的合成（或原子）形式和 ℓ1 惩罚； (ii) 涉及可训练的正则化操作符的分析形式和 ℓ∞ 惩罚。在提供几何见解并证明这两种形式是通用后，我们提出了一种基于特定架构（带加权 ℓ1 惩罚的紧框架）的实现方法，该方法易于训练。我们展示了其在去噪和生物医学图像重建中的应用。我们发现，所提出的框架超越了基于稀疏性的压缩感知方法，同时提供了基本相同的收敛性和鲁棒性保证。

**Summary**:

- (1): 本文的研究背景是从有限数据中重建图像时需要有效的凸正则项，以改进图像重建质量。

- (2): 过去的方法主要集中在稀疏性基础的压缩感知技术上，其问题在于对重建精度的限制以及对噪声的敏感性。所提出的方法通过使用多面体范数进行空间重构，提升了重建精度并提供了更强的鲁棒性，因此能有效克服这些限制，这是动机明确的。

- (3): 本文的贡献在于提出了一种新的实现框架，能够通过学习和调节凸正则项来提高图像重建性能，同时强调了两种不同形式的通用性。

- (4): 本文的方法论包括将凸正则项参数化为合成形式和分析形式两种形式，利用多面体范数进行逼近，并基于紧框架架构进行实现。

- (5): 本文的任务包括去噪和生物医学图像重建，所实现的性能超越了传统的稀疏性方法，并在收敛性和鲁棒性方面提供了良好的支持。


## Pychop: Emulating Low-Precision Arithmetic in Numerical Methods and Neural Networks
- **Url**: http://arxiv.org/abs/2504.07835v1
- **Authors**: ['Erin Carson', 'Xinye Chen']
- **Abstrat**: Motivated by the growing demand for low-precision arithmetic in computational science, we exploit lower-precision emulation in Python -- widely regarded as the dominant programming language for numerical analysis and machine learning. Low-precision training has revolutionized deep learning by enabling more efficient computation and reduced memory and energy consumption while maintaining model fidelity. To better enable numerical experimentation with and exploration of low precision computation, we developed the Pychop library, which supports customizable floating-point formats and a comprehensive set of rounding modes in Python, allowing users to benefit from fast, low-precision emulation in numerous applications. Pychop also introduces interfaces for both PyTorch and JAX, enabling efficient low-precision emulation on GPUs for neural network training and inference with unparalleled flexibility.   In this paper, we offer a comprehensive exposition of the design, implementation, validation, and practical application of Pychop, establishing it as a foundational tool for advancing efficient mixed-precision algorithms. Furthermore, we present empirical results on low-precision emulation for image classification and object detection using published datasets, illustrating the sensitivity of the use of low precision and offering valuable insights into its impact. Pychop enables in-depth investigations into the effects of numerical precision, facilitates the development of novel hardware accelerators, and integrates seamlessly into existing deep learning workflows. Software and experimental code are publicly available at https://github.com/inEXASCALE/pychop.


**Translated Abstract**: 

鉴于对计算科学中低精度算术的日益增长的需求，我们在Python中利用低精度仿真，Python被广泛认为是数值分析和机器学习的主导编程语言。低精度训练通过提高计算效率和降低内存及能耗，同时保持模型的保真性，彻底改变了深度学习。为了更好地进行低精度计算的数值实验与探索，我们开发了Pychop库，支持可定制的浮点格式和全套舍入模式，允许用户在多个应用中受益于快速的低精度仿真。Pychop还为PyTorch和JAX引入了接口，实现了在GPU上进行高效的低精度仿真，为神经网络训练与推理提供了无与伦比的灵活性。本文全面展示了Pychop的设计、实现、验证及实际应用，确立其作为推进有效混合精度算法的基础工具。此外，我们还展示了在使用公开数据集进行图像分类和目标检测时的低精度仿真经验结果，说明了低精度使用的敏感性并提供了有价值的见解。Pychop促进了对数值精度影响的深入研究，推动新型硬件加速器的发展，并与现有深度学习工作流程无缝集成。软件和实验代码在https://github.com/inEXASCALE/pychop上公开可用。

**Summary**:

- (1): 本文的研究背景是计算科学中对低精度算术的日益需求，尤其是在数值分析和深度学习领域。

- (2): 过去的方法主要是利用现有的软件库来模拟低精度算术，这些方法面临的主要问题是灵活性不足和精度限制。所提出的Pychop方法通过支持可定制的浮点格式和多种舍入模式解决了这些问题，提供了更高的灵活性和效率，因此具有良好的动机。

- (3): 该论文的贡献在于开发了Pychop库，建立了一个支持低精度算术仿真、并能够集成到PyTorch和JAX等深度学习框架中的基础工具。

- (4): 本文提出的研究方法包括设计和实现Pychop库，进行了有效的低精度仿真，并通过经验结果验证其在实际应用中的效果。

- (5): 本文的方法在图像分类和目标检测任务上进行了实验，展示了低精度仿真的经验结果，表明该方法在各类应用中的性能可以支持其目标。


## CAGN-GAT Fusion: A Hybrid Contrastive Attentive Graph Neural Network for Network Intrusion Detection
- **Url**: http://arxiv.org/abs/2503.00961v2
- **Authors**: ['Md Abrar Jahin', 'Shahriar Soudeep', 'M. F. Mridha', 'Raihan Kabir', 'Md Rashedul Islam', 'Yutaka Watanobe']
- **Abstrat**: Cybersecurity threats are growing, making network intrusion detection essential. Traditional machine learning models remain effective in resource-limited environments due to their efficiency, requiring fewer parameters and less computational time. However, handling short and highly imbalanced datasets remains challenging. In this study, we propose the fusion of a Contrastive Attentive Graph Network and Graph Attention Network (CAGN-GAT Fusion) and benchmark it against 15 other models, including both Graph Neural Networks (GNNs) and traditional ML models. Our evaluation is conducted on four benchmark datasets (KDD-CUP-1999, NSL-KDD, UNSW-NB15, and CICIDS2017) using a short and proportionally imbalanced dataset with a constant size of 5000 samples to ensure fairness in comparison. Results show that CAGN-GAT Fusion demonstrates stable and competitive accuracy, recall, and F1-score, even though it does not achieve the highest performance in every dataset. Our analysis also highlights the impact of adaptive graph construction techniques, including small changes in connections (edge perturbation) and selective hiding of features (feature masking), improving detection performance. The findings confirm that GNNs, particularly CAGN-GAT Fusion, are robust and computationally efficient, making them well-suited for resource-constrained environments. Future work will explore GraphSAGE layers and multiview graph construction techniques to further enhance adaptability and detection accuracy.


**Translated Abstract**: 

网络安全威胁日益增长，使网络入侵检测变得至关重要。由于传统机器学习模型在资源有限的环境中仍然有效，因此它们的效率要求较少的参数和较少的计算时间。然而，处理短小且高度不平衡的数据集仍然具有挑战性。本研究提出了一种对比注意力图网络和图注意力网络融合（CAGN-GAT Fusion），并与15种其他模型（包括图神经网络（GNNs）和传统机器学习模型）进行基准测试。我们的评估在四个基准数据集（KDD-CUP-1999、NSL-KDD、UNSW-NB15和CICIDS2017）上进行，使用一个恒定为5000样本的短小且比例不平衡的数据集，以确保比较的公平性。结果表明，尽管在每个数据集中并未实现最高性能，但CAGN-GAT Fusion展现了稳定且具有竞争力的准确率、召回率和F1分数。我们的分析还强调了自适应图构建技术的影响，包括连接的小变化（边扰动）和特征的选择性隐藏（特征屏蔽），提高了检测性能。研究结果确认GNNs，特别是CAGN-GAT Fusion，具有鲁棒性和计算效率，使其非常适合资源有限的环境。未来的工作将探讨GraphSAGE层和多视图图构建技术以进一步增强适应性和检测准确性。

**Summary**:

- (1): 本文的研究背景是网络技术迅猛发展以及互联网连接设备数量的指数增长导致网络流量的复杂性和体量大幅增加，因此现代网络面临越来越多复杂的网络安全威胁。

- (2): 过去的方法包括随机森林（RF）、支持向量机（SVM）和XGBoost等传统机器学习模型，面临捕捉网络实体之间复杂关系和攻击行为的局限。与这些方法相比，所提出的CAGN-GAT Fusion结合了对比注意力图网络和图注意力网络，能够更好地处理复杂网络结构数据，提高检测性能，并且具备较强的计算效率。

- (3): 本文的贡献在于提出CAGN-GAT Fusion，一种框架融合了CAGN和GAT，展示了在资源受限环境下的鲁棒性和稳定性，此外进行了全面的基准测试，与15种模型进行比较，确保了性能评价的可靠性。

- (4): 本文采用了自适应图构建技术的研究方法，分析了边扰动和特征屏蔽对模型性能的影响。

- (5): 本文的方法在四个基准数据集（KDD-CUP-1999、NSL-KDD、UNSW-NB15和CICIDS2017）上的任务表现出稳定的准确率、召回率和F1分数，尽管未在所有数据集中达到最高性能，但结果足以支持研究目标。


## Comparing Next-Day Wildfire Predictability of MODIS and VIIRS Satellite Data
- **Url**: http://arxiv.org/abs/2503.08580v2
- **Authors**: ['Justus Karlsson', 'Yonghao Xu', 'Amanda Berg', 'Leif Haglund']
- **Abstrat**: Multiple studies have performed next-day fire prediction using satellite imagery. Two main satellites are used to detect wildfires: MODIS and VIIRS. Both satellites provide fire mask products, called MOD14 and VNP14, respectively. Studies have used one or the other, but there has been no comparison between them to determine which might be more suitable for next-day fire prediction. In this paper, we first evaluate how well VIIRS and MODIS data can be used to forecast wildfire spread one day ahead. We find that the model using VIIRS as input and VNP14 as target achieves the best results. Interestingly, the model using MODIS as input and VNP14 as target performs significantly better than using VNP14 as input and MOD14 as target. Next, we discuss why MOD14 might be harder to use for predicting next-day fires. We find that the MOD14 fire mask is highly stochastic and does not correlate with reasonable fire spread patterns. This is detrimental for machine learning tasks, as the model learns irrational patterns. Therefore, we conclude that MOD14 is unsuitable for next-day fire prediction and that VNP14 is a much better option. However, using MODIS input and VNP14 as target, we achieve a significant improvement in predictability. This indicates that an improved fire detection model is possible for MODIS. The full code and dataset is available online: https://github.com/justuskarlsson/wildfire-mod14-vnp14


**Translated Abstract**: 

多项研究利用卫星图像进行次日火灾预测。主要使用两颗卫星检测野火：MODIS和VIIRS。这两颗卫星都提供火灾掩膜产品，分别称为MOD14和VNP14。虽然已有研究采用其中一种进行预测，但尚无对比研究确定哪种卫星数据更适合于次日火灾预测。本文首先评估VIIRS和MODIS数据在预测火灾蔓延方面的有效性。研究发现，以VIIRS为输入且以VNP14为目标的模型取得最佳结果。值得注意的是，MODIS作为输入且以VNP14为目标的模型表现显著优于以VNP14为输入且以MOD14为目标的模型。接着，讨论了为何MOD14在预测次日火灾中可能更具挑战性。我们发现MOD14火灾掩膜高度随机，且与合理的火灾蔓延模式没有相关性。这对机器学习任务不利，因为模型学习不合理的模式。因此，我们得出结论，MOD14不适合用于次日火灾预测，而VNP14则是更好的选择。然而，使用MODIS作为输入且以VNP14为目标时，我们实现了显著的可预测性提升。这表明MODIS的火灾检测模型有改善的可能性。完整代码和数据集可以在线获得。

**Summary**:

- (1): 本文研究的背景是气候变化导致野火频率和严重性增加，准确预测野火行为对于管理和应对非常重要。

- (2): 以往的方法主要基于使用MODIS或VIIRS的数据进行火灾预测，存在的问题是缺乏对比研究、预测效果差异未被充分了解。本文提出的方法通过比较MODIS（MOD14）与VIIRS（VNP14）的表现，识别出VNP14更适合用于火灾预测，有效应对了随机性高和缺乏合理模式学习的问题，具备良好的动机。

- (3): 论文的贡献在于系统性地比较了MODIS和VIIRS在次日火灾预测中的准确性，得出了VNP14更适合预测的结论，同时表明改进MODIS检测模型的潜力。

- (4): 本文的研究方法包括两个步骤：首先，通过相同的深度学习模型比较VIIRS和MODIS的预测可行性；其次，评估影响预测准确性的原因，得到哪些数据源与实际火灾蔓延相关性更好的结论。

- (5): 本文的方法在次日火灾预测任务上实现了可见的改进，特别是使用MODIS输入和VNP14目标的配置，得出的结果支持了提升预测能力的目标。


## DG-STMTL: A Novel Graph Convolutional Network for Multi-Task Spatio-Temporal Traffic Forecasting
- **Url**: http://arxiv.org/abs/2504.07822v1
- **Authors**: ['Wanna Cui', 'Peizheng Wang', 'Faliang Yin']
- **Abstrat**: Spatio-temporal traffic prediction is crucial in intelligent transportation systems. The key challenge of accurate prediction is how to model the complex spatio-temporal dependencies and adapt to the inherent dynamics in data. Traditional Graph Convolutional Networks (GCNs) often struggle with static adjacency matrices that introduce domain bias or learnable matrices that may be overfitting to specific patterns. This challenge becomes more complex when considering Multi-Task Learning (MTL). While MTL has the potential to enhance prediction accuracy through task synergies, it can also face significant hurdles due to task interference. To overcome these challenges, this study introduces a novel MTL framework, Dynamic Group-wise Spatio-Temporal Multi-Task Learning (DG-STMTL). DG-STMTL proposes a hybrid adjacency matrix generation module that combines static matrices with dynamic ones through a task-specific gating mechanism. We also introduce a group-wise GCN module to enhance the modelling capability of spatio-temporal dependencies. We conduct extensive experiments on two real-world datasets to evaluate our method. Results show that our method outperforms other state-of-the-arts, indicating its effectiveness and robustness.


**Translated Abstract**: 

时空交通预测在智能交通系统中至关重要。准确预测的关键挑战在于如何建模复杂的时空依赖性并适应数据中的固有动态。传统的图卷积网络（GCNs）通常难以处理引入领域偏见的静态邻接矩阵或可能过拟合特定模式的可学习矩阵。当考虑多任务学习（MTL）时，这一挑战变得更为复杂。尽管MTL有潜力通过任务协同提高预测准确性，但也可能面临显著的干扰问题。为了解决这些挑战，本研究提出了一种新颖的多任务框架，动态组块时空多任务学习（DG-STMTL）。DG-STMTL提出了一种混合邻接矩阵生成模块，通过任务特定的门控机制将静态矩阵与动态矩阵相结合。我们还引入了组块 GCN 模块，以增强对时空依赖性的建模能力。我们在两个真实世界数据集上进行了广泛实验以评估我们的方法。结果表明，我们的方法优于其他先进方法，表明其有效性和鲁棒性。

**Summary**:

- (1): 本文研究背景是智能交通系统中的时空交通预测，其准确性对于资源效率和决策制定至关重要。

- (2): 以往方法主要是传统的图卷积网络（GCNs），存在使用静态邻接矩阵未能有效捕捉时空动态或使用可学习矩阵而导致过拟合的问题。本文提出的方法通过混合静态与动态邻接矩阵的方式，解决了这些问题，具有良好的动机性。

- (3): 论文的贡献在于提出了动态组块时空多任务学习（DG-STMTL）框架和两种信息共享机制，增强了对时空依赖性的建模能力。

- (4): 本文研究的方法论包括混合邻接矩阵生成模块和组块 GCN 模块，以实现对多任务间信息共享的有效管理。

- (5): 本文在两个真实世界数据集上进行了时空交通预测任务，实验结果显示其性能优于现有方法，支持了提出的目标。


# AGN
## Millimeter emission from supermassive black hole coronae
- **Url**: http://arxiv.org/abs/2504.07762v1
- **Authors**: ['S. del Palacio', 'C. Yang', 'S. Aalto', 'C. Ricci', 'B. Lankhaar', 'S. König', 'J. Becker Tjus', 'M. Magno', 'K. L. Smith', 'J. Yang', 'L. Barcos-Muñoz', 'F. Combes', 'S. Linden', 'C. Henkel', 'J. G. Mangum', 'S. Martín', 'G. Olander', 'G. Privon', 'C. Wethers', 'A. -K. Baczko', 'R. J. Beswick', 'I. García-Bernete', 'S. García-Burillo', 'E. González-Alfonso', 'M. Imanishi', 'T. Izumi', 'S. Muller', 'Y. Nishimura', 'M. Pereira-Santaella', 'P. P. van der Werf']
- **Abstrat**: Active Galactic Nuclei (AGN) host accreting supermassive black holes (SMBHs). The accretion can lead to the formation of a hot, X-ray emitting corona close to the SMBH capable of accelerating relativistic electrons. Observations in the millimetre (mm) band can probe its synchrotron emission. We provide a framework to derive physical information of SMBH coronae by modelling their spectral energy distribution (SED) from radio to far infrared frequencies. We also explore the possibilities of deriving additional information from mm observations, such as the SMBH mass, and studying high-redshift lensed sources. We introduce a corona emission model based on a one-zone spherical region with a hybrid thermal and non-thermal plasma. We investigate in detail how the corona SED depends on different parameters such as size, opacity, and magnetic field strength. Other galactic emission components from dust, ionised gas and diffuse relativistic electrons are also included in the SED fitting scheme. We apply our code consistently to a sample of radio-quiet AGN with strong indications of a coronal component in the mm. The detected mm emission from SMBH coronae is consistent with having a non-thermal relativistic particle population with an energy density that is ~0.5-10% of that in the thermal plasma. This requires magnetic energy densities close to equipartition with the thermal gas, and corona sizes of 60-250 gravitational radii. The model can also reproduce the observed correlation between mm emission and SMBH mass when accounting for uncertainties in the corona size. The mm band offers a unique window into the physics of SMBH coronae, enabling the study of highly dust-obscured sources and high-redshift lensed quasars. Gaining a deeper understanding of the relativistic particle population in SMBH coronae can provide key insights into their potential multiwavelength and neutrino emission.


**Translated Abstract**: 

活动星系核（AGN）宿主正在吸积的大质量黑洞（SMBH）。吸积过程可以导致在SMBH附近形成一个热的、发射X射线的冠，能够加速相对论电子。在毫米（mm）波段的观测可以探测到其同步辐射。我们提供一个框架，通过从无线电到远红外频率建模其光谱能量分布（SED）来推导SMBH冠的物理信息。我们还探讨了从毫米波观测中获得额外信息的可能性，如SMBH质量的推导和高红移透镜源的研究。我们引入了一种基于一个区域的冠辐射模型，该区域具有混合的热和非热等离子体。我们详细研究了冠SED如何依赖于不同参数，如大小、透明度和磁场强度。还包括来自尘埃、离子气体和扩散相对论电子的其他星系辐射成分在SED拟合方案中。我们将我们的代码一致地应用于一组具有强烈冠成分的无线电安静AGN样本。检测到的来自SMBH冠的毫米波辐射与具有相对论性粒子群的非热能量密度相符，能量密度约为热等离子体的0.5-10%。这需要磁能量密度接近与热气体的能量平衡，同时冠的大小为60-250个引力半径。该模型还可以在考虑冠大小的不确定性时重现毫米波辐射与SMBH质量之间的观察相关性。毫米波段为SMBH冠的物理学提供了独特窗口，使得对高度尘埃遮蔽的源和高红移透镜类Quasar的研究成为可能。深入理解SMBH冠中的相对论粒子群可以为它们潜在的多波长和中微子辐射提供关键见解。

**Summary**:

- (1): 本文的研究背景是研究活动星系核（AGN）中吸积超大质量黑洞（SMBH）形成的热、发射X射线的冠及其在毫米波段的同步辐射特性。

- (2): 过去的研究方法主要集中在通过观测AGN的辐射特征来推测冠的性质，存在缺乏明确的物理模型的问题。本文提出的基于单区球形区域的混合热与非热等离子体模型能够更深层次地揭示冠的光谱能量分布（SED），从而解决了传统方法的不足，具有充分的理论动机。

- (3): 本文的贡献在于建立了一种新的冠辐射模型，并通过拟合不同参数，提出了获取SMBH质量及研究高红移透镜源的新方法。

- (4): 本文的研究方法论涉及构建星系的光谱能量分布（SED）模型，详细探讨该模型如何受冠的大小、透明度和磁场强度等参数影响。

- (5): 本文的方法在一个具有强烈冠成分的无线电安静AGN样本上取得了成功，能够重现毫米波辐射与SMBH质量之间的相关性，表明该方法的性能支持了其研究目标。


## Gas excitation in galaxies and active galactic nuclei with He IIλ4686 and X-ray emission
- **Url**: http://arxiv.org/abs/2503.03496v3
- **Authors**: ['K. Kouroumpatzakis', 'J. Svoboda']
- **Abstrat**: The origin of He II emission in galaxies remains a debated topic, requiring ionizing photons with energies exceeding 54 eV. While massive stars, such as Wolf-Rayet stars, have been considered potential sources, their UV flux often fails to fully explain the observed He II emission. Recent studies suggest that X-ray binaries (XRBs) might contribute significantly to this ionization. We explore the relationship between X-ray and $\rm He~II \lambda4686$ emission in a statistically significant sample of galaxies, investigating whether X-ray sources, including active galactic nuclei (AGNs) and XRBs, serve as the primary mechanism for He II ionization across different galactic environments. We cross-matched a sample of known well-detected He II galaxies with the Chandra Source Catalog, yielding 165 galaxies with X-ray and $\rm He~II \lambda4686$ detections. The sources were classified into star-forming galaxies (SFGs) and AGNs based on the BPT diagram and a classification scheme defined for He II galaxies. We find a strong, linear correlation between X-ray and He II luminosity across AGNs and SFGs spanning over seven orders of magnitude. AGNs generally exhibit higher He II/H$\beta$ flux ratios, stronger extinction, and harder X-ray spectra. The O32 ratio of SFGs is tightly correlated with the H$\beta$ equivalent width ($\rm EW_{H\beta}$) but not with the He II/H$\beta$ ratio, suggesting a different excitation mechanism. We derive an O32--$\rm EW_{H\beta}$ line above which only AGNs of our sample reside. The tight correlation between X-ray and He II luminosity supports X-rays as the primary driver of He II excitation. While AGNs have one common ionization source, the central black hole, in SFGs low-energy species are mainly excited by UV emission related to star-forming activity, however, high-energy species like He II require the presence of XRBs.


**Translated Abstract**: 

在星系中，He II发射的来源仍是一个有争议的话题，需要能量超过54 eV的电离光子。虽然像Wolf-Rayet星这样的 massive stars 被认为是潜在的来源，但它们的紫外光通量通常无法充分解释观察到的He II发射。最近的研究表明，X射线双星（XRBs）可能对这种电离贡献显著。我们探讨了在一个统计上显著的星系样本中，X射线与He II λ4686的发射之间的关系，调查X射线源（包括活动星系核（AGNs）和XRBs）是否在不同的星系环境中作为He II电离的主要机制。我们将已知的He II星系与Chandra源目录交叉匹配，获得165个具有X射线和He II λ4686检测的星系。这些源根据BPT图和为He II星系定义的分类方案被分类为星形成星系（SFGs）和AGNs。我们发现X射线与He II光度之间存在强烈的线性关系，覆盖了七个数量级的范围。AGNs通常表现出更高的He II/Hβ光谱比、更强的消光和更硬的X射线光谱。SFGs的O32比率与Hβ等效宽度（EW_{Hβ}）紧密相关，但与He II/Hβ比率无关，表明不同的激发机制。我们得出一个O32—EW_{Hβ}线，以上仅存在我们的样本中的AGNs。X射线与He II光度之间的紧密相关性支持X射线作为He II激发的主要驱动机制。在AGNs中，中央黑洞是一个共同的电离源，而在SFGs中，低能种类主要通过与星形成活动相关的紫外光发光被激发，但像He II这样的高能种类则需要XRBs的存在。

**Summary**:

- (1): 本文的研究背景是He II发射的来源仍然不清楚，需要高于54 eV的电离光子。传统上认为Wolf-Rayet星是主要电离源，但它们的紫外光通量不足以解释观察结果，因此探讨XRBs作为另一种电离源的可能性。

- (2): 过去的方法主要通过分析UV光谱和X射线源进行对比，但未能完全解释He II的发射。不同于现有方法，本文通过大量样本的统计分析，结合XRBs和AGNs的数据，提出了X射线与He II之间的相关性。这种方法能够更系统地研究不同星系环境中的电离机制。

- (3): 本文的主要贡献在于提供了强直线相关的证据，表明X射线可能是驱动He II发射的主要机制，并揭示了AGNs与SFGs在激发机制上的不同。

- (4): 本文的研究方法包括从Chandra源目录中交叉匹配已知的He II星系，并通过BPT图对样本进行分类，分析X射线和He II光度之间的关系，得出统计结果。

- (5): 本文探讨的任务是分析X射线与He II发射的关系，取得了数据支持的强线性相关性，证明了X射线作为He II的主要激发源的能力，设定了明确的研究目标。


# ALMA
## Orbit design for mitigating interstellar scattering effects in Earth-space VLBI observations of Sgr A*
- **Url**: http://arxiv.org/abs/2504.07892v1
- **Authors**: ['Aditya Tamar', 'Ben Hudson', 'Daniel C. M. Palumbo']
- **Abstrat**: (abridged) The black hole Sagittarius A* (Sgr A*) is a prime target for next-generation Earth-space very-long-baseline interferometry missions such as the Black Hole Explorer (BHEX), which aims to probe baselines of the order of 20 G$\lambda$. At these baselines, Sgr A* observations will be affected by the diffractive scattering effects from the interstellar medium (ISM). Therefore, we study how different parameter choices for turbulence in the ISM affect BHEX's observational capabilities to probe strong lensing features of Sgr A*. By using a simple geometric model of concentric Gaussian rings for Sgr A*'s photon ring signal and observing at 320 GHz, we find that the BHEX-ALMA baseline has the required sensitivity to observe Sgr A* for a broad range of values of the power-law index of density fluctuations in the ISM and the inner scale of turbulence. For other baselines with moderate sensitivities, a strong need for observations at shorter scales of $\approx$ 13.5 G$\lambda$ is identified. For this purpose, an orbit migration scheme is proposed. It is modeled using both chemical propulsion (CP)-based Hohmann transfers and electric propulsion (EP)-based orbit raising with the result that a CP-based transfer can be performed in a matter of hours, but with a significantly higher fuel requirement as compared to EP, which however requires a transfer time of around 6 weeks. The consequences of these orbits for probing Sgr A*'s spacetime is studied by quantifying the spatial resolution, temporal resolution and the angular sampling of the photon ring signal in the Fourier coverage of each of these orbits. We show that higher orbits isolate spacetime features while sacrificing both, signal lost to scattering and temporal resolution, but gain greater access to the morphology of the photon ring.


**Translated Abstract**: 

黑洞人马座A*（Sgr A*）是下一代地球-太空长基线干涉测量任务的主要目标，例如黑洞探测器（Black Hole Explorer, BHEX），该任务旨在探测约20 Gλ的基线。在这些基线下，Sgr A*的观察将受到星际介质（ISM）中微扰散射效应的影响。因此，我们研究了ISM中不同湍流参数选择对BHEX探测Sgr A*强透镜特征的观测能力的影响。通过使用同心高斯环的简单几何模型来表示Sgr A*的光子环信号，并在320 GHz下进行观察，我们发现BHEX-ALMA基线在ISM中多种密度波动功率律指数和湍流的内尺度值范围内具有探测Sgr A*所需的灵敏度。对于灵敏度适中的其他基线，明确需在约13.5 Gλ下进行观测。为此，提出了一种轨道迁移方案，采用化学推进（CP）基础的霍曼转移和电推进（EP）基础的轨道提升进行建模，结果表明，CP基础的转移在数小时内可以完成，但与EP相比需更高的燃料，但EP的转移时间约为6周。通过量化每种轨道的光子环信号的空间分辨率、时间分辨率和角采样，研究了这些轨道对探测Sgr A*时空的影响。我们表明，更高的轨道可以隔离时空特征，但牺牲了散射损失的信号和时间分辨率，同时获得了更好地访问光子环形态的能力。因此，我们发现低地球轨道和参考BHEX轨道之间的轨道可以为Sgr A*的参数空间提供丰富的访问信息。

**Summary**:

- (1): 该文章的研究背景是针对黑洞人马座A*（Sgr A*）的观测，尤其是在星际介质的微扰散射影响下，探讨在20 Gλ范围内进行地球-太空长基线干涉测量的新方法。

- (2): 过去的方法主要集中于地面基于VLBI的观测，但受限于地球直径，导致基线长度的限制，从而影响观测的角分辨率。提出的方法通过设计高轨道来补充现有问题，允许更长的基线而不受地球限制，具有良好的动机。

- (3): 本文的贡献在于提出一种新的轨道设计方案，利用化学推进和电推进方法来应对星际介质的散射效应，提高对Sgr A*光子环特征的观测能力。

- (4): 研究方法是在320 GHz下使用简单的几何模型，分析不同湍流参数对BHEX的观测能力影响，并量化轨道变化对光子环信号的空间和时间分辨率。

- (5): 本文提出的方法在探测Sgr A*的光子环上取得了高灵敏度和分辨率，支持其目标，能够提供丰富的关于黑洞时空和光子环形态的信息。


## Resolved ALMA [CII] 158 micron Observations at Cosmic Noon: ISM Structure and Dynamics of Starbursting QSO SDSSJ1000
- **Url**: http://arxiv.org/abs/2504.07325v1
- **Authors**: ['Christopher Rooney', 'Bo Peng', 'Amit Vishwas', 'Gordon Stacey', 'Thomas Nikola', 'Cody Lamarche', 'Catie Ball', 'Carl Ferkinhoff', 'Drew Brisbin', 'Steven Hailey-Dunsheath']
- **Abstrat**: We present spatially resolved Alma Band-9 observations of the [CII] 158 $\mu$m fine structure line from an optically selected quasar, SDSS J100038.01+020822.4 (J1000), at z=1.8275. By utilizing [OI] 63 $\mu$m line observations from Herschel/PACS and constructing a detailed dust SED using Herschel and Spitzer archival imaging data, we show that the [CII] line emission is well explained by a photodissociation region (PDR) model, in which the emission arises from the surfaces of molecular clouds exposed to far-UV radiation fields $\sim 5\cdot10^3$ times the local interstellar radiation field (G$_0$). We find a factor of 30 variation in spatially resolved [CII]/Far-IR continuum across the source which is explained by the reduced fraction of cooling via [CII] line emission at such high far-UV field strengths. By matching derived PDR parameters to the observed far-IR line and continuum intensities we derive cloud size-scales and find that typical cloud radii in J1000 are $\sim$3.5 pc perhaps indicating an ISM that is highly fractured due to intense star formation activity. We model the galaxy dynamically and find that the [CII] emission is contained within a compact, dynamically cold disk with v/$\sigma$=6.2, consistent with cosmological simulations. We also report the discovery of a companion galaxy to j1000 confirmed by the detection of [CII] and use recently obtained JWST/NirCAM imaging of the system to argue for J1000 being an interacting system. With total stellar mass $\sim 1.5 \times 10^{10}$ M$_\odot$ and main-component dynamical mass $\gtrsim 10^{11}$ M$_\odot$, the J1000 system is a progenitor to the most massive galaxies seen in the local Universe.


**Translated Abstract**: 

我们展示了从光学选定的类星体 SDSS J100038.01+020822.4 (J1000)（在 z=1.8275）进行的空间分辨的 ALMA Band-9 [CII] 158 μm 细结构线观测。通过利用 Herschel/PACS 的 [OI] 63 μm 线观测，并构建详细的尘埃 SED（光谱能量分布），我们表明 [CII] 线发射可以通过光解离区（PDR）模型很好地解释，其中发射来自暴露于远紫外辐射场的分子云表面，这种辐射场强度约为局部星际辐射场的 5000 倍 (G$_0$)。我们发现源中空间分辨的 [CII]/Far-IR 连续体比率有 30 倍的变化，这种变化可通过在如此高的远紫外场强度下通过 [CII] 线发射冷却的减少比例来解释。通过将衍生的 PDR 参数与观察到的远红外线和连续体强度匹配，我们推导出云的大小尺度，发现 J1000 中典型的云半径约为 3.5 pc，这可能表明由于强烈的星形成活动，其星际介质是高度破碎的。我们动态建模该星系，发现 [CII] 发射被局限在一个致密、动态冷却的盘中，v/$\sigma$=6.2，与宇宙学模拟一致。我们还报告了对 J1000 配偶星系的发现，通过检测到 [CII] 证实，并利用最近获得的 JWST/NirCAM 成像论证 J1000 是一个相互作用的系统。此系统的总星系质量约为 1.5 × 10^{10} M$_\odot$，主成分动力质量大于等于 10^{11} M$_\odot$，J1000 系统是当地宇宙中最大星系的前体。

**Summary**:

- (1): 本文研究背景为宇宙午后（z ∼ 1−3）星形成率密度（SFRD）的高峰，探讨该时期星系演化的理解。

- (2): 过去的方法包括使用远红外（FIR）细结构线观测，但受限于地面观测的传输窗口以及尘埃消光影响。而本文的方法通过 ALMA Band-9 的高频观察克服了这些局限，能够更清晰地捕捉 [CII] 线发射。

- (3): 本文贡献在于通过 [CII] 线和尘埃 SED 的结合，深入解析了 J1000 的星际介质结构与动态特征，提供了对强烈星形成活动的认识。

- (4): 本文研究方法包括空间分辨的 ALMA [CII] 观测、Herschel/PACS 的 [OI] 线观测及尘埃 SED 构建，结合 PDR 模型分析发射机理。

- (5): 本文在量化 J1000 中 [CII] 发射特征及动力学特征的任务上取得了成功，支持了对该系统作为大质量星系前体的目标。

