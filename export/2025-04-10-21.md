# blackhole
# M87
# galaxy
## The Lyman-alpha and Continuum Origins Survey II: the uneventful journey of escaping Ly$α$ and ionizing radiation through the neutral ISM and CGM of galaxies
- **Url**: http://arxiv.org/abs/2504.07074v1
- **Authors**: ['A. Saldana-Lopez', 'M. J. Hayes', 'A. Le Reste', 'C. Scarlata', 'J. Melinder', 'A. Henry', 'R. Amorin', 'H. Atek', 'O. Bait', 'J. Chisholm', 'A. E. Jaskot', 'I. Jung', 'Zhiyuan Ji', 'L. Komarova', 'F. Leclercq', 'G. Ostlin', 'A. Runnholm', 'T. X. Thuan', 'X. Xu']
- **Abstrat**: One of the current challenges in galaxy evolution studies is to establish the mechanisms that govern the escape of ionizing radiation from galaxies. In this work, we investigate the connection between Lyman Continuum (LyC) escape and the conditions of the Circumgalactic Medium (CGM), as probed by Ly$\alpha$ halos (LAHs) in emission. We use Ly$\alpha$ and UV continuum imaging data from the Lyman alpha and Continuum Origins Survey (LaCOS), targeting 42 nearby ($z \simeq 0.3$), star-forming galaxies with LyC observations (escape fractions of $f_{\rm esc}^{\rm LyC} \simeq 0.01-0.49$). LaCOS galaxies show extended Ly$\alpha$ emission ubiquitously, with LyC emitters (LCEs) having more compact Ly$\alpha$ morphologies relative to the UV size than non-LCEs, and Ly$\alpha$ spatial offsets that do not exceed the extent of the UV continuum. We model the diffuse LAHs using a combined Sersic plus exponential 2D profile, and find that the characteristic scale length of the Ly$\alpha$ is ten times the scale length of the UV, on average. We unveil a tight anti-correlation between $f_{\rm esc}^{\rm LyC}$ and the Ly$\alpha$ Halo Fraction (HF, or contribution of the halo to the total Ly$\alpha$ luminosity), that we propose as a new LyC indicator. Our observations also show that the HF scales positively with the neutral gas in the ISM, revealing a picture in which Ly$\alpha$ and LyC photons in LCEs emerge through clear sight-lines directly from the central starbursts and, in the case of Ly$\alpha$, minimizing the number of scattering interactions in the CGM. The properties of LAHs in LaCOS resemble those of LAHs at $z \geq 3$, suggesting a lack of evolution in the $f_{\rm esc}^{\rm LyC}$ predictors that rely on the spatial properties of Ly$\alpha$, and ensuring the applicability of these indicators to observations of high-redshift galaxies.


**Translated Abstract**: 

当前星系演化研究中的一个挑战是确定控制电离辐射从星系逃逸的机制。本文探讨了电离宇宙背景（LyC）逃逸与由发射的氘氢α（Lyα）晕探测到的环星系介质（CGM）条件之间的关系。我们利用来自氘氢及连续起源调查（LaCOS）的氘氢α和紫外线（UV）连续成像数据，针对42个邻近（z ≃ 0.3）星形成星系进行观察，这些星系具有LyC观察（逃逸分数fescLyC ≃ 0.01-0.49）。LaCOS星系普遍显示出延伸的Lyα发射，LyC发射者（LCEs）的Lyα形态相较于非LCEs而言更为紧凑，且Lyα的空间偏离不超过UV连续的范围。我们用结合的Sersic及指数2D模型对扩展的Lyα晕进行建模，发现Lyα的特征尺度长度平均是UV的十倍。我们揭示了fescLyC与Lyα晕分数（HF）之间的紧密反比关系，并提出HF作为一种新型LyC指示器。我们的观察还显示HF与ISM中的中性气体正相关，揭示出在LyC发射者中，Lyα和LyC光子通过来自中心星爆的清晰视线直接出现，且在Lyα的情况下，最小化了在CGM中的散射交互。LaCOS中的Lyα晕特性与z ≥ 3下的Lyα晕相似，表明依赖于Lyα空间特性的fescLyC预测符号没有演化，确保这些指示器适用于高红移星系的观察。

**Summary**:

- (1): 本文研究旨在探讨星系中电离辐射逃逸的机制，其中LyC逃逸与环星系介质条件之间的联系是一个重要课题。

- (2): 过去的方法主要通过氘氢α发射观察LyC逃逸，但在逃逸分数的测量精度和对中性气体影响的理解方面存在局限。与之不同，本文通过全面的LaCOS项目，引入Lyα晕的空间特性作为新的指标，能够更好地对LyC逃逸进行解释。

- (3): 本文对Lyα晕的特征进行了分析，揭示了LyC逃逸的新指示器HF，并展示了Lyα和LyC光子逃逸的机制。

- (4): 本文采用Lyα和UV成像数据，对42个近邻星系的Lyα发射进行了建模，并分析其与LyC逃逸的关系。

- (5): 本文在逃逸分数（fescLyC）和Lyα晕分数（HF）之间实现了显著的反比关系，为理解星系中LyC逃逸的机制提供了数据支持，且所获得的结果支持其研究目标。


## New empirical mass-loss recipe for UV radiation line-driven winds of hot stars across various metallicities
- **Url**: http://arxiv.org/abs/2504.07073v1
- **Authors**: ['D. Pauli', 'L. M. Oskinova', 'W. -R. Hamann', 'A. A. C. Sander', 'Jorick S. Vink', 'M. Bernini-Peron', 'J. Josiek', 'R. R. Lefever', 'H. Sana', 'V. Ramachandran']
- **Abstrat**: The winds of massive stars remove a significant fraction of their mass, strongly impacting their evolution. As a star evolves, the rate at which it loses mass changes. In stellar evolution codes, different mass-loss recipes are employed for different evolutionary stages. The choice of the recipes is user-dependent and the conditions for switching between them are poorly defined. Focusing on hot stars, we aim to produce a physically motivated, empirically calibrated mass-loss recipe suitable for a wide range of metallicities. We want to provide a ready-to-use universal recipe that eliminates the need for switching between recipes for hot stars during stellar evolution calculations. We compile a sample of hot stars with reliable stellar and wind parameters in the Galaxy and the Magellanic Clouds. The sample is used to determine the dependence of the mass-loss rate on the basic stellar parameters. We find that independent of evolutionary stage and temperature, the wind mass-loss rate is a function of the electron-scattering Eddington parameter ($\Gamma_e$) and metallicity (Z), being in line with expectations of radiation-driven wind theory. Our derived scaling relation provides an adequate ($\Delta$log($\dot{M}$/(M$_\odot$/yr)) = 0.43) and broadly applicable mass-loss recipe for hot stars. The newly derived mass-loss recipe covers nearly the entire parameter space of hot stars with UV radiation-driven winds and eliminates the need for interpolation between mass-loss formulae at different evolutionary stages when applied in stellar evolution models. Examples of stellar evolution calculations using our new recipe reveal that the predictions on the ionizing fluxes and final fates of massive stars, especially at low metallicity, differ significantly from models that use the standard mass-loss rates, impacting our understanding of stellar populations at low metallicity and in the young Universe.


**Translated Abstract**: 

大质量星的风会去除其相当部分的质量，强烈影响其演化。随着恒星的演化，质量损失的速率会发生变化。在恒星演化模型中，不同的质量损失方案被用于不同的演化阶段。选择这些方案的标准取决于用户，而切换方案的条件定义不明确。本文聚焦于热星，旨在生成一个在各种金属丰度下适用的物理动机和经验校准的质量损失方案。我们希望提供一个现成的通用方案，消除在恒星演化计算中切换热星方案的需求。我们编制了银河系和梅西尼亚云中具有可靠恒星和风参数的热星样本，这一样本用于确定质量损失率与基本恒星参数之间的依赖关系。我们发现，无论演化阶段和温度如何，风的质量损失率都是电子散射Eddington参数（$\Gamma_e$）和金属丰度（Z）的函数，符合辐射驱动风理论的预期。我们推导的标度关系提供了一种适当且广泛适用的热星质量损失方案。新推导的质量损失方案覆盖了几乎所有具有紫外辐射驱动风的热星参数空间，使得在恒星演化模型中应用时不再需要在不同演化阶段之间进行插值。使用我们新方案进行的恒星演化计算显示，尤其在低金属丰度下，对于离子化通量和大质量恒星最终命运的预测与使用标准质量损失率的模型存在显著差异，影响了我们对低金属丰度恒星族群及年轻宇宙的理解。

**Summary**:

- (1): 本文的研究背景是大质量星的风在演化过程中会去除显著的质量，从而影响其演化路径及最终命运。

- (2): 过去的方法采用在不同演化阶段使用不同的质量损失方案，但常常导致在转变时有突兀或简单插值的不足。与现有方法不同的是，本文提出了一种通用的质量损失方案，避免了切换的复杂性，并能够更准确地适应不同金属丰度的情况。

- (3): 本文的贡献在于建立了一个适用于多种金属丰度的普遍性质量损失方案，并有效预测了大质量恒星的离子化通量和最终命运，尤其在低金属丰度环境中的应用。

- (4): 本文的研究方法是通过编制银河系与梅西尼亚云中热星的样本，确定质量损失率与基础恒星参数间的依赖关系，并推导出基于$\Gamma_e$和Z的质量损失率标度关系。

- (5): 本文提出的方法在预测大质量恒星的离子化通量及最终命运的任务上表现出显著的改进，尤其是在低金属丰度情况下的效果更加明显，支持了作者的研究目标。


## Non-Gaussianity of Tensor Induced Density Perturbations
- **Url**: http://arxiv.org/abs/2504.07063v1
- **Authors**: ['Mariam Abdelaziz', 'Pritha Bari', 'Sabino Matarrese', 'Angelo Ricciardone']
- **Abstrat**: We investigate the non-Gaussianity of second-order matter density perturbations induced by primordial gravitational waves (GWs). These tensor-induced scalar modes arise from local fluctuations in the GWs energy density, which is quadratic in tensor perturbations. The resulting second-order density contrast follows a chi-squared distribution, naturally exhibiting significant non-Gaussianity. We compute the bispectrum of these tensor-induced scalar modes and analyze its dependence on various primordial GWs power spectra, including scale-invariant, blue-tilted, Gaussian-bump, and monochromatic sources. We find that the bispectrum shape is inherently sensitive to the underlying GWs spectrum by construction. In particular, Gaussian-bump and monochromatic sources produce a strong signal peaking in the equilateral configuration, similar to the effect of scalar-induced tensor modes. Our findings reveal a new way to probe primordial GWs via galaxy surveys and highlight a unique feature of tensor-induced density perturbations, otherwise mimicking linear ones on sub-horizon scales.


**Translated Abstract**: 

我们研究了由原始引力波（GWs）诱导的二阶物质密度扰动的非高斯性。这些张量诱导的标量模式源于引力波能量密度的局部波动，该波动在张量扰动中是二次的。由此产生的二阶密度对比度遵循卡方分布，自然表现出显著的非高斯性。我们计算了这些张量诱导的标量模式的双谱，并分析了其对各种原始GWs功率谱的依赖，包括尺度不变、蓝倾斜、高斯峰和单色源。我们发现，双谱形状从构造上对潜在的GWs谱确实非常敏感。特别是，高斯峰和单色源在等边配置中产生强信号，类似于标量诱导的张量模式的效应。我们的发现揭示了一种通过星系巡天探测原始GWs的新方法，并强调了张量诱导的密度扰动的独特特征，这些特征在亚视界尺度上会模仿线性扰动。

**Summary**:

- (1): 本文的研究背景是宇宙膨胀模型与原始引力波（GWs）对宇宙大尺度结构形成的影响，特别是元宇宙中引力波如何通过局部波动和张量模式影响物质密度扰动。

- (2): 过去的方法主要集中在直接或间接检测引力波，例如利用宇宙微波背景辐射（CMB）和脉冲星时序阵列（PTA）的信号。然而，这些方法面临着确认信号来源的挑战，尤其是难以区分宇宙学与天体物理信号。本文提出的方法通过探测张量诱导的标量模式在物质大尺度结构上的影响来间接检测原始引力波，从而弥补了现有方法的不足。

- (3): 本文的贡献在于揭示了通过星系巡天提供获取原始引力波信息的新方法，计算了张量诱导的标量模式的双谱，并展示了不同原始引力波功率谱如何影响这些模式的非高斯性特征。

- (4): 本文提出的研究方法是计算由线性张量模式诱导的二阶标量扰动的双谱，并对其与不同类型的原始引力波功率谱之间的关系进行分析，以探讨其在大尺度结构中的影响。

- (5): 本文的目标是通过引力波诱导的修正来间接探测原始引力波，利用即将到来的大尺度结构巡天数据，如Euclid和LSST等，进行有效的物质功率谱估计。通过该方法，不仅可以确认原始引力波的存在，还可以在未检测到的情况下为其幅度提供重要的限制。


## The Lyman-alpha and Continuum Origins Survey I: Survey description and Ly$α$ imaging
- **Url**: http://arxiv.org/abs/2504.07056v1
- **Authors**: ['Alexandra Le Reste', 'Claudia Scarlata', 'Matthew Hayes', 'Jens Melinder', 'Alberto Saldana-Lopez', 'Axel Runnholm', 'Yu-Heng Lin', 'Ricardo O. Amorín', 'Hakim Atek', 'Sanchayeeta Borthakur', 'Cody A. Carr', 'Sophia R. Flury', 'Mauro Giavalisco', 'Alaina Henry', 'Anne E. Jaskot', 'Zhiyuan Ji', 'Intae Jung', 'Floriane Leclercq', 'Rui Marques-Chaves', 'Stephan R. McCandliss', 'M. S. Oey', 'Göran Östlin', 'Swara Ravindranath', 'Daniel Schaerer', 'Trinh X. Thuan', 'Xinfeng Xu']
- **Abstrat**: Understanding the mechanisms driving the escape of ionizing or Lyman continuum (LyC) emission from the interstellar medium of galaxies is necessary to constrain the evolution of Reionization, and the sources responsible for it. While progress has been made into identifying the global galaxy properties linked to the escape fraction of ionizing radiation, f$_{esc}^{LyC}$, little is currently known about how spatially resolved galaxy properties impact this parameter. We present Hubble Space Telescope (HST) imaging data obtained as part of the Lyman $\alpha$ and Continuum Origins Survey (LaCOS). LaCOS consists of HST imaging in 5 filters covering rest-frame optical and UV bands for a subsample of 42 galaxies in the Low redshift Lyman Continuum Survey, 22 being Lyman continuum emitters ($f_{esc}^{LyC}=0.01-0.49$). These data allow for investigations of the connection between sub-kpc stellar and nebular properties, including Ly$\alpha$ emission, and $f_{esc}^{LyC}$. Here, we describe the sample selection, observations and data reduction methods. Additionally, we present results on the link between global and resolved Ly$\alpha$ photometry and $f_{esc}^{LyC}$. We find similar trends between global photometric observables ($L_{Ly\alpha}$, $EW_{Ly\alpha}$, $f_{esc}^{Ly\alpha}$, $r_{50}$, $\Sigma_{SFR}$) and $f_{esc}^{LyC}$ as previously found with spectroscopy, but the correlations generally show a slightly smaller degree of correlations. However, we do find strong correlations between Ly$\alpha$ observables ($L_{Ly\alpha}$,$EW_{Ly\alpha}$) and $f_{esc}^{LyC}$ when measured in a small aperture around the brightest UV source in each galaxy. We interpret these results as evidence that LyC photons escaping on the line-of-sight are contributed by a small number of UV-bright compact regions in most galaxies in our sample.


**Translated Abstract**: 

理解驱动银河系中电离或莱曼连续（LyC）辐射从星际介质中逃逸的机制对于约束重电离的演化及其源头是必要的。虽然在识别与电离辐射逃逸分数 f$_{esc}^{LyC}$ 相关的全球星系特性方面取得了进展，但目前对空间分辨的星系属性如何影响该参数知之甚少。我们展示了作为莱曼α和连续性起源巡天（LaCOS）一部分的哈勃太空望远镜（HST）成像数据。LaCOS包括对42个银河系子样本的HST成像，在5个滤波器中覆盖了静息帧光学和紫外波段，其中22个为莱曼连续发射体（f$_{esc}^{LyC}$ = 0.01-0.49）。这些数据使得研究亚千个天文单位的恒星和气体特性，包括Lyα发射与 f$_{esc}^{LyC}$ 之间的联系成为可能。在这里，我们描述了样本选择、观测和数据处理方法。此外，我们还展示了全球和解析的Lyα光度与 f$_{esc}^{LyC}$ 之间的联系。我们发现全球光度可观测量（L$_{Lyα}$、EW$_{Lyα}$、f$_{esc}^{Lyα}$、r$_{50}$、Σ$_{SFR}$）与 f$_{esc}^{LyC}$ 之间的趋势与以往谱学研究相似，但相关性通常略微减弱。然而，当在每个星系中最明亮的紫外源周围的小孔径内测量时，我们发现Lyα可观测量（L$_{Lyα}$、EW$_{Lyα}$）与 f$_{esc}^{LyC}$ 之间存在强相关性。我们将这些结果解释为证据，表明在大多数样本星系中，沿视线逃逸的LyC光子是由少数紫外亮的紧凑区域贡献的。

**Summary**:

- (1): 本文的研究背景是理解电离辐射（尤其是LyC辐射）从星系中逃逸的机制，以约束重电离的演化和源头。

- (2): 过去的方法主要关注全球星系特性对电离辐射逃逸分数 f$_{esc}^{LyC}$ 的影响，但对空间分辨的属性研究较少，限制了对逃逸机制的全面理解。本文提出的方法，通过哈勃太空望远镜成像数据，将研究焦点转向亚千个天文单位的星系特性，来填补这一空白。

- (3): 本文的贡献在于提供了新的HST成像数据，揭示了Lyα发射与LyC逃逸分数之间的关系，尤其是在小孔径内的强相关性。

- (4): 本文的研究方法包括样本选择、HST的多滤波器成像及数据处理，通过分析Lyα的全局和分辨率光度来考察其与LyC逃逸的关系。

- (5): 本文的方法在探讨Lyα光度与 f$_{esc}^{LyC}$之间的联系上取得了显著的性能，支持了研究其影响因素与机制的目标。


## Microlensing at Cosmological Distances: Event Rate Predictions in the Warhol Arc of MACS 0416
- **Url**: http://arxiv.org/abs/2504.07039v1
- **Authors**: ['J. M. Palencia', 'J. M. Diego', 'L. Dai', 'M. Pascale', 'R. Windhorst', 'A. M. Koekemoer', 'Sung Kei Li', 'B. J. Kavanagh', 'Fengwu Sun', 'Amruth Alfred', 'Ashish K. Meena', 'Thomas J. Broadhurst', 'Patrick L. Kelly', 'Derek Perera', 'Hayley Williams', 'Adi Zitrin']
- **Abstrat**: Highly magnified stars ($\mu$ $>$ 100) are now outinely identified as transient events at cosmological distances thanks to microlensing by intra-cluster stars near the critical curves of galaxy clusters. Using the {\it James Webb} Space Telescope (JWST) in combination with the {\it Hubble} Space Telescope (HST), we outline here an analytical framework that is applied to the Warhol arc (at $z=0.94$) in the MACS 0416 galaxy cluster (at $z=0.396)$ where over a dozen microlensed stars have been detected to date. This method is general and can be applied to other lensed arcs. Within this lensed galaxy we fit the spatially resolved SED spanned by eight JWST-NIRCam filters combined with three ACS filters, for accurate lensed star predictions in 2D. With this tool we can generate 2D maps of microlensed stars for well resolved arcs in general, including dependence on wavelength and limiting apparent magnitude, for comparison with with planned cadenced campaigns for JWST and Hubble, for constraining directly the IMF and the level of dark matter substructure.


**Translated Abstract**: 

由于透镜星体（μ > 100）通过引力透镜效应在宇宙距离上被识别为瞬态事件，因此可以通过靠近星系团临界曲线的星体进行计数。本文利用{\it 哈勃}太空望远镜（HST）和{\it 詹姆斯·韦伯}太空望远镜（JWST），为MACS 0416星系团内的Warhol弧（z = 0.94）建立一个分析框架，目前在该区域已探测到十几颗透镜星体。此方法具有普遍性，可应用于其他透镜弧。在此透镜星系中，我们通过结合八个JWST-NIRCam滤光片和三个ACS滤光片的空间分辨光谱能量分布（SED）拟合，进行二维透镜星体预测。借助此工具，我们可以生成一般已解析弧的透镜星体的二维图，并考虑波长和极限亮度的依赖性，以便与JWST和Hubble计划的有节奏观测活动进行比较，直接约束初始质量函数（IMF）和暗物质小结构的水平。

**Summary**:

- (1): 本文研究背景为引力透镜作用下的星系团在探测宇宙远方的高亮度明星方面的潜力。

- (2): 过去的方法主要依赖于单一的观测手段，例如使用单一过滤器的望远镜，存在的主要问题在于无法准确预测和映射透镜星体的位置和亮度。与现有方法相比，本文提出了一种结合JWST和HST多波长数据的先进分析框架，以解决这些问题，具有充分的动机。

- (3): 本文的贡献在于建立了一个新的分析框架，用于预测和绘制透镜星体的二维分布，理论上能够精确约束IMF和暗物质小结构的性质。

- (4): 本文的研究方法是结合JWST-NIRCam和ACS滤光片的数据，通过拟合空间分辨光谱能量分布（SED）来实现2D透镜星体的预测。

- (5): 本文所采用的方法在探测和绘制透镜星体及其光谱方面取得了有效成果，可以支持其对IMF和暗物质结构的约束目标。


## Recent star formation in 0.5<z<1.5 quiescent galaxies
- **Url**: http://arxiv.org/abs/2504.05511v2
- **Authors**: ['Michael J. Rutkowski', 'Bonnabelle Zabelle', 'Tyler Hagen', 'Seth Cohen', 'Christopher Conselice', 'Norman Grogin', 'Yicheng Guo', 'Matthew Hayes', 'Sugata Kaviraj', 'Anton Koekemoer', 'Ray A. Lucas', 'Kameswara Bharadwaj Mantha', 'Alec Martin', 'Vihang Mehta', 'Bahram Mobasher', 'Nimish Hathi', 'Kalina V. Nedkova', "Robert O'Connell", 'Marc Rafelski', 'Claudia Scarlata', 'Harry I. Teplitz', 'Xin Wang', 'Rogier Windhorst', 'Aaron Yung', 'the UVCANDELS Team']
- **Abstrat**: Observations of massive, quiescent galaxies reveal a relatively uniform evolution: following prolific star formation in the early universe, these galaxies quench and transition to their characteristic quiescent state in the local universe. The debate on the relative role and frequency of the process(es) driving this evolution is robust. In this letter, we identify 0.5<z<1.5 massive, quiescent galaxies in the HST/UVCANDELS extragalactic deep fields using traditional color selection methods and model their spectral energy distributions, which incorporates novel UV images. This analysis reveals ~15% of massive, quiescent galaxies have experienced minor, recent star formation(<10% of total stellar mass within the past ~1Gyr). We find only a marginal, positive correlation between the probability for recent star formation and a measure of the richness of the local environment from a statistical analysis. Assuming the recent star formation present in these quiescent galaxies is physically linked to the local environment, these results suggest only a minor role for dynamic external processes (galaxy mergers and interactions) in the formation and evolution of these galaxies at this redshift.


**Translated Abstract**: 

对大型、静止星系的观测显示出相对均匀的演化：在早期宇宙经历了丰富的恒星形成后，这些星系被抑制，并过渡到地方宇宙中所特有的静止状态。关于驱动这一演化过程的相对作用和频率的辩论依然激烈。在这封信中，我们利用传统的颜色选择方法，以及新型的紫外成像，识别了HST/UVCANDELS深空场中0.5 < z < 1.5的大型静止星系，并对其光谱能量分布进行了建模。分析结果显示，约15%的大型静止星系在过去约1亿年内经历了小规模的近期恒星形成（少于总恒星质量的10%）。我们发现，近期恒星形成的概率与环境丰富度的统计分析之间只有微弱的正相关性。假设这些静止星系中存在的近期恒星形成与局部环境存在物理联系，那么这些结果表明，动态外部过程（如星系合并和相互作用）在这个红移下对这些星系的形成和演化作用较小。

**Summary**:

- (1): 本文研究的背景是，理解高红移形成的星系如何转变为当地宇宙中观察到的静止星系，这是银河演化研究的一个主要目标。

- (2): 过去的方法主要依靠光学颜色、推测的恒星形成历史和元素丰度等观测证据进行分析。这些方法存在的问题是未能充分解释静止星系中存在的近期恒星形成，且可能未准确反映出这些星系的真实演化历史。本文提出的办法结合传统的颜色选择和新的紫外成像，能够更好地识别和建模这些星系，解决了以往方法的不足，动机良好。

- (3): 本文的贡献在于，发现约15%的静止星系经历了小规模的近期恒星形成，并揭示了这些星系与环境之间的微弱关系，从而补充了对静止星系演化的理解。

- (4): 本文采用的方法是使用HST/UVCANDELS深空场的多波段成像数据，通过光谱能量分布建模，分析和识别0.5 < z < 1.5的大型静止星系，重点关注它们近期的星形成历程。

- (5): 本文的方法在追踪和识别近期恒星形成的任务上表现出色，仅约15%的静止星系发生了这种现象。虽然结果表明动态外部过程在演化中的作用较小，但这些结论支持了研究团队的目标，提供了对静止星系演化更深入的理解。


## Binarity at LOw Metallicity (BLOeM): Enhanced multiplicity of early B-type dwarfs and giants at $Z=0.2\,{\rm Z}_\odot$
- **Url**: http://arxiv.org/abs/2503.21936v3
- **Authors**: ['J. I. Villaseñor', 'H. Sana', 'L. Mahy', 'T. Shenar', 'J. Bodensteiner', 'N. Britavskiy', 'D. J. Lennon', 'M. Moe', 'L. R. Patrick', 'M. Pawlak', 'D. M. Bowman', 'P. A. Crowther', 'S. E. de Mink', 'K. Deshmukh', 'C. J. Evans', 'M. Fabry', 'M. Fouesneau', 'G. Holgado', 'N. Langer', 'J. Maíz Apellániz', 'I. Mandel', 'L. M. Oskinova', 'D. Pauli', 'V. Ramachandran', 'M. Renzo', 'H. -W. Rix', 'D. F. Rocha', 'A. A. C. S. Sander', 'F. R. N. Schneider', 'K. Sen', 'S. Simón-Díaz', 'J. Th. van Loon', 'S. Toonen', 'J. S. Vink']
- **Abstrat**: Early B-type stars ($M_i=8-15$ M$_\odot$) are frequently in multiple systems, as evidenced by spectroscopic campaigns in the Milky Way (MW) and the Large Magellanic Cloud (LMC). Previous studies have shown no strong metallicity dependence in the close-binary (a>10 au) fraction or orbital-period distributions between the MW's solar metallicity (Z$_\odot$) and that of the LMC (Z=0.5 Z$_\odot$). However, similar analyses in more metal-poor environments are still scarce. We focus on 309 early B-type stars (luminosity classes III-V) from the Binarity at LOw Metallicity campaign in the Small Magellanic Cloud (SMC, Z=0.2 Z$_\odot$) using VLT/FLAMES multi-epoch spectroscopy. By applying binary detection criteria consistent with previous works, we identify 153 stars (91 SB1, 59 SB2, 3 SB3) exhibiting significant radial-velocity (RV) variations, resulting in an observed multiplicity fraction of $f^{obs}_{mult}=50\pm3\%$. Using Monte Carlo simulations to account for observational biases, we infer an intrinsic close-binary fraction of $f_{mult}=80\pm8\%$. A Markov chain Monte Carlo analysis of the peak-to-peak RV distribution ($\Delta{\rm RV}_{\rm max}$) confirms a high multiplicity fraction of $f_{mult}=78\pm5\%$. These findings suggest a possible anti-correlation between metallicity and the fraction of close B-type binaries, with the SMC multiplicity fraction significantly exceeding previous measurements in the LMC and MW. The enhanced fraction of close binaries at SMC's low metallicity may have broad implications for massive-star evolution in the early Universe. More frequent mass transfer and envelope stripping could boost the production of exotic transients, stripped supernovae, gravitational-wave progenitors, and sustained UV ionising flux, potentially affecting cosmic reionisation. Theoretical predictions of binary evolution under metal-poor conditions will provide a key test of our results.


**Translated Abstract**:

早期B型恒星（初始质量在8至15 M⊙之间）往往以多重系统存在，这已通过在银河系（MW）和大麦哲伦云（LMC）的光谱学研究得到证实。过去的研究表明，在MW的太阳金属丰度（Z⊙）和LMC（Z = 0.5 Z⊙）之间，近双星（a < 10 au）分数或轨道周期分布并未显示出强烈的金属依赖性。然而，对于更低金属丰度环境中大量恒星的类似分析仍然稀缺。我们针对309颗来自小麦哲伦云（SMC，Z = 0.2 Z⊙）的早期B型恒星（光度等级III-V）展开了Binarity at LOw Metallicity（BLOeM）活动，使用VLT/FLAMES进行多期光谱观测。通过应用与之前研究一致的双星检测标准，我们识别出了153颗显示显著径向速度（RV）变化的恒星（91 SB1、59 SB2、3 SB3），结果观测到的多重性分数为f^{obs}_{mult}=50\pm3\%。利用蒙特卡洛模拟来考虑观测偏差，我们推导出内在的近双星分数为f_{mult}=80\pm8\%。对峰值径向速度分布（ΔRV_{max}）的马尔科夫链蒙特卡洛分析进一步确认了较高的多重性分数f_{mult}=78\pm5\%。这些发现建议金属丰度与B型近双星的分数可能存在反相关关系，SMC区域的多重性分数显著高于之前在LMC和MW中的测量结果。SMC低金属丰度下的近双星较高分数可能对早期宇宙中的大质量恒星演化产生广泛影响。更频繁的质量转移和包层剥离可能提高奇异瞬态、剥层超新星、引力波起源体及持续的紫外线电离通量的产生，可能影响宇宙再电离。低金属环境下的双星演化理论预测将为我们的结果提供关键测试。

**Summary**:

- (1): 本文研究背景为早期B型恒星的多重性，对其在不同金属丰度环境下的分数及分布的分析。

- (2): 过去的研究主要集中于银河系和大麦哲伦云，发现多重性分数与金属丰度无强相关性，但缺乏低金属丰度环境的分析。本文通过小麦哲伦云的新样本，填补了这一研究空白，提供了更深入的低金属丰度对多重性影响的见解。

- (3): 本文的贡献在于提供了小麦哲伦云早期B型恒星的较高多重性分数的实证结果，揭示了金属丰度与B型近双星之间的可能反相关关系。

- (4): 研究方法包括使用VLT/FLAMES进行多期光谱观测，运用径向速度变化的观测标准识别双星，并通过蒙特卡洛模拟和马尔科夫链蒙特卡洛分析来推导和验证多重性分数。

- (5): 研究任务为确定小麦哲伦云早期B型恒星的多重性分数，结果显示内在近双星分数为80±8%，观测的多重性分数为50±3%。这些结果均支持金属丰度与多重性之间的反相关关系的理论推导。


## H, He-like recombination spectra VI: Quadrupole $l$-changing collisions
- **Url**: http://arxiv.org/abs/2504.03570v2
- **Authors**: ['E. Deliporanidou', 'N. R. Badnell', 'P. J. Storey', 'G. Del Zanna', 'G. J. Ferland']
- **Abstrat**: We have developed a simple analytic formula that well describes quadrupole $l$-changing collisions of the form $nl \rightarrow nl'$, as confirmed by comparison with numerical quantal Born calculations obtained with the program autostructure (Badnell 2011). Such formulae could easily be included in models of astrophysical plasma emission, such as the hydrogen and helium-like recombination spectra. When compared with the results of previous quantal calculations based upon an analytic solution of the time-dependent Schr\"odinger equation by Vrinceanu & Flannery (2001), we find relatively good agreement, with the exception of large $l > n/2$ transitions. We provide a tentative explanation for such discrepancies. However, we also show that the rates for quadrupole $l$-changing collisions are typically two orders of magnitude lower than the dipolar ones. Inclusion of the quadrupolar rates in a hydrogenic collisional-radiative model of nebular plasma shows minimal changes to the level populations, typically within 1% in nebular conditions. Simple and complete theories are now available for $l$-changing collisions suitable for astrophysical applications.


**Translated Abstract**: 

我们开发了一个简单的解析公式，可以很好地描述形式为 $nl \rightarrow nl'$ 的四极 $l$-变化碰撞，这通过与使用 autostructure 程序得到的数值量子 Born 计算进行比较得到了验证（Badnell 2011）。这样的公式可以很容易地纳入到天体物理等离子体发射模型中，例如氢和氦样的复合光谱。与基于 Vrinceanu & Flannery（2001）时间依赖薛定谔方程的解析解所做的先前量子计算结果相比，我们发现相对较好的一致性，除非在大的 $l > n/2$ 过渡中。我们提供了对这种差异的暂定解释。然而，我们还表明，四极 $l$-变化碰撞的比率通常低两个数量级于偶极碰撞。在氢离子碰撞辐射模型中纳入四极比率对能级人口的影响微乎其微，通常在天体条件下的变化在1%以内。目前已经有简单而完整的理论可以用于适合天体物理应用的 $l$-变化碰撞。

**Summary**:

- (1): 本文的研究背景是天体物理等离子体包含大量氢和氦，需要准确的非平衡态（non-LTE）碰撞辐射模型，包括多个电离和复合过程。

- (2): 过去的方法主要基于偶极 $l$-变化碰撞，存在对高阶多极 $l$-变化碰撞重视不足的问题。本文提出的解析公式提供了对四极 $l$-变化碰撞的描述，可以有效填补这一空白，特别是在处理大 $l$ 过渡时，该方法能够解决与先前方法的一些特定差异。该方法得到了很好的动机，即在现有文献中缺乏对这一现象的探讨。

- (3): 本文的贡献在于开发了一个新的、简单的解析公式，能够描述四极 $l$-变化碰撞，并且与数值结果相比具有良好的一致性，适合天体物理模型的应用。

- (4): 本文提出的研究方法包括使用时间依赖薛定谔方程（TDSE）和 Born 近似来计算 $l$-变化碰撞的比率系数，并通过数值评估和解析比较检验两者的一致性，分析差异来源。

- (5): 本文的方法在氢离子碰撞辐射模型中进行测试，表明纳入四极比率后能级人口变化范围通常在 1% 以内，说明所提方法在实现天体物理应用目标方面是有效的。


## Constraining the $z \sim 1$ IMF with {\it HST} and {\it JWST} lensed stars in MACS J0416.1-2403
- **Url**: http://arxiv.org/abs/2504.06992v1
- **Authors**: ['Sung Kei Li', 'Jose M. Diego', 'Ashish K. Meena', 'Jeremy Lim', 'Leo W. H. Fung', 'Arsen Levitskiy', 'James Nianias', 'Jose M. Palencia', 'Hayley Williams', 'Jiashuo Zhang', 'Alfred Amruth', 'Thomas J. Broadhurst', 'Wenlei Chen', 'Alexei V. Filippenko', 'Patrick L. Kelly', 'Anton M. Koekemoer', 'Derek Perera', 'Bangzheng Sun', 'Liliya L. R. Williams', 'Rogier A. Windhorst', 'Haojin Yan', 'Adi Zitrin']
- **Abstrat**: The understanding of galaxy properties and evolution is contingent on knowing the initial mass function (IMF), and yet to date, the IMF is constrained only to local galaxies. Individual stars are now becoming routinely detected at cosmological distances, where luminous stars such as supergiants in background galaxies critically lensed by galaxy clusters are temporarily further magnified by huge factors up to $10^{4}$ by intra-cluster stars, thus being detected as transients. The detection rate of these events depends on the abundance of luminous stars in the background galaxy and is thus sensitive to the IMF and the star formation history (SFH), especially for the blue supergiants detected as transients in the rest-frame UV/optical filters. As a proof of concept, we use simple SFH and IMF models constrained by spectral energy distribution (SED) to see how well we can predict the {\it HST} and {\it JWST} transient detection rate in a lensed arc dubbed ``Spock'' ($z = 1.0054$). We find that demanding a simultaneously fit of SED and rest-frame UV/optical transient detection rate places constraints on the IMF, independent of the assumed simple SFH model. We conclude our Bayesian likelihood analysis indicates that the data definitively prefer the ``Spock'' galaxy to have a Salpeter IMF ($\alpha = 2.35$) rather than a Top-heavy IMF ($\alpha = 1$) -- what is thought to be the case in the early universe -- given our methodology and assumptions with no clear excess of supergiants above the standard IMF.


**Translated Abstract**:

对银河系性质和演化的理解依赖于知道初始质量函数（IMF），然而到目前为止，IMF仅对局部星系进行了约束。随着个别恒星在宇宙距离上的常规探测，背景星系中由于星系团的强引力透镜作用而放大的亮恒星，例如超巨星，能够以高达$10^{4}$的巨大增益被临时探测到，表现为瞬态事件。这些事件的探测率依赖于背景星系中亮恒星的丰度，因此对IMF和星形成历史（SFH）敏感，特别是对于以瞬态形式探测到的蓝色超巨星（在重光程的UV/光学波段）。作为概念验证，我们使用简单的SFH和IMF模型，通过光谱能量分布（SED）约束，以预测在被称为“Spock”的引力透镜弧（z = 1.0054）中探测到的{\it HST}和{\it JWST}瞬态的率。我们发现，要求同时拟合SED和重光程UV/光学瞬态探测率对IMF施加了约束，无论所假设的简单SFH模型如何。我们的贝叶斯似然分析表明，数据明确偏好“Spock”星系具有Salpeter IMF（$\alpha = 2.35$），而非Top-heavy IMF（$\alpha = 1$），后者被认为是早期宇宙中可能的情况；在我们的研究方法和假设下，没有明显的超巨星数量超过标准IMF。

**Summary**:

- (1): 本文的研究背景是初始质量函数（IMF）对星系性质和演化的影响，目前IMF的约束主要基于局部星系。

- (2): 过去的方法主要通过拟合合成光谱对IMF进行研究，但受到星形成历史、金属丰度和尘埃消光等参数的严重退化影响，且依赖于恒星演化模型。本文提出了一种新的通过引力透镜现象探测高红移星系中亮恒星方法，规避了传统方法的这些问题。

- (3): 本文的贡献在于利用引力透镜技术提供了对高红移（z ≈ 1）星系中IMF的约束，为IMF的宇宙演化提供了新的视角。

- (4): 本文的研究方法是使用简单的星形成历史（SFH）和初始质量函数（IMF）模型，通过光谱能量分布（SED）拟合同时分析重光程UV/光学瞬态的探测率。

- (5): 本文在对“Spock”星系的分析中，得到了支持Salpeter IMF（$\alpha = 2.35$）的结果，相对于Top-heavy IMF（$\alpha = 1$）具有显著性能，表明所提出的方法有效实现了其研究目标。


## Galaxy infall models for arbitrary velocity directions
- **Url**: http://arxiv.org/abs/2501.13149v2
- **Authors**: ['Jenny Wagner', 'David Benisty']
- **Abstrat**: For most galaxies in the cosmos, our knowledge of their motion is limited to line-of-sight velocities from redshift observations. To determine the radial velocity between two galaxies the minor and major infall models were established by Karachentsev and Kashibadze (2006). Regardless of the background cosmology, our derivations reveal that these infall models approximate the total radial velocity between two galaxies by two different projections employing different information about the system. For galaxies having small angular separations $\theta$, all infall models agree that the radial velocity is the difference of their line-of-sight components. Applying these models to ca. $500$ halos of the Illustris-3 simulation, we find the perpendicular and tangential velocity parts to be non-negligible for more than 90% of all, more than 5000 infalling subhalos. Thus, even for $\theta < 10$ deg, the infall-model velocities deviate from the true radial velocity. Only for 30% we found the true one lay between the minor and major infall velocity. However, the infall models yield robust upper and lower bounds to the true radial velocity dispersion. Observed under $\theta < 10$ deg the velocity dispersion inferred from the sole difference of line-of-sight velocity components even coincides with the true one, justifying this approach for high-redshift groups and clusters. Based on these findings, we predict the radial velocity dispersion of the M81-group from the minor infall model (upper bound) $\sigma_{\mathrm{r,min}} = (193 \pm 42)~\mbox{km}/\mbox{s}$, from the major infall model (lower bound) $\sigma_{\mathrm{r,maj}} = (129 \pm 64) ~\mbox{km}/\mbox{s}$ and $\sigma_\mathrm{r,\Delta v} = (102 \pm 36)~\mbox{km}/\mbox{s}$ from the line-of-sight-velocity difference.


**Translated Abstract**:

对于宇宙中大多数星系，我们对它们运动的了解仅限于来自红移观测的视线速度。为了确定两颗星系之间的径向速度，Karachentsev 和 Kashibadze（2006）建立了次要和主要的下落模型。我们的推导表明，这些下落模型在任何背景宇宙学下都通过采用关于系统的不同信息，利用两种不同的投影来近似两颗星系之间的总径向速度。对于小角度分离的星系（θ），所有下落模型均认为径向速度是它们的视线分量之差。我们将这些模型应用于大约 500 个 Illustris-3 模拟的光晕，发现超过 90% 的 5000 个下落子光晕中，垂直和切向速度分量是不可忽视的。因此，即使对于 θ < 10°，下落模型的速度也偏离真实径向速度。我们发现只有 30% 的情况下，真实的径向速度位于次要和主要下落速度之间。然而，下落模型为真实径向速度分散性提供了可靠的上下界。在 θ < 10° 的情况下，从简单的视线速度分量差得出的速度分散性甚至与真实值相符，证明这种方法在高红移星系团和星系组中的有效性。基于这些发现，我们从次要下落模型预测 M81 组的径向速度分散性（上界）σ_{r,min} = (193 ± 42) km/s，从主要下落模型（下界）σ_{r,maj} = (129 ± 64) km/s 和来自视线速度差的σ_{r,Δv} = (102 ± 36) km/s。

**Summary**:

- (1): 本文研究宇宙中星系运动的相对速度，主要通过红移观测的视线速度获取信息；

- (2): 过去的方法包括次要和主要下落模型，面临的主要问题是无法准确处理垂直和切向速度分量，导致下落模型的速度与真实径向速度偏差。本文提出的模型通过不假设球对称性，包含所有速度分量，克服了这些问题。该方法能够更全面地了解星系的运动特征；

- (3): 文章的贡献在于通过扩展现有下落模型，量化切向速度对下落速度的影响，提供对星系间真实径向速度的更精确的估算方法；

- (4): 本文的方法是在不假设结构为球对称的前提下，推广下落模型，考虑了垂直和切向速度成分，并通过仿真验证对星系运动的影响；

- (5): 该方法在分析 Illustris-3 模拟数据中的星系组表现良好，能有效提供上界和下界的径向速度分散性预测，支持其研究目标的实现。


## Elusive helium stars in the gap between subdwarfs and Wolf-Rayet stars~II. Nonlinear pulsations of stripped helium stars
- **Url**: http://arxiv.org/abs/2504.06926v1
- **Authors**: ['Yu. A. Fadeyev', 'A. G. Kuranov', 'L. R. Yungelson']
- **Abstrat**: It is shown for the first time that the stripped helium stars with masses 2 to 7 solar mass which are formed in close binary systems in the so-called case B of mass-exchange and retained low-mass hydrogen-helium envelopes, experience nonlinear radial pulsations. Pulsations are excited by the kappa-mechanism due to helium ionization. The region of pulsation instability extends over Hertzsprung-Russel diagram from the red giants branch to the region of effective temperatures from about 30,000 K to about 50,000 K. Variations of stellar luminosity should be observed mostly in the ultraviolet. The amplitudes of pulsations of the studied models reach 0.8 stellar magnitude and increase, as the stellar radii decrease. Pulsation periods of stars with effective temperatures exceeding 10,000 K range from 0.17 to 8.5 day and decrease with decreasing radii. The stars have substantially larger effective temperatures than their companions, which could be Be-stars. They are components of relatively wide binaries with orbital periods up to several years. The number of pulsating moderate-mass stripped helium stars in the Galaxy is about 1000.


**Translated Abstract**: 

首次表明，在所谓的质量交换案例B中形成的剥离氦星（质量为2至7个太阳质量），在保留低质量氢氦包层的情况下，经历非线性径向脉动。脉动是由于氦电离引起的κ机制激发的。脉动不稳定性区域覆盖了赫茨春光-拉塞尔图的红巨星分支到有效温度约30,000 K至50,000 K的区域。恒星光度的变化主要在紫外线观测中可见。所研究模型的脉动幅度可达0.8个恒星星等，随恒星半径减小而增加。有效温度超过10,000 K的星星的脉动周期范围从0.17天到8.5天，且随着半径的减小而减小。这些星具有明显高于其伴星（可能是Be星）的有效温度，是具有多年轨道周期的相对宽的双星系统的组成部分。银河中脉动的中等质量剥离氦星的数量约为1000个。

**Summary**:

- (1): 本文研究背景为剥离氦星的脉动现象，特别是其在质量交换案例B中形成的情况。

- (2): 以往的方法多侧重于理论模型，但未能详细探讨剥离氦星的脉动机制。本文提出新的研究方法，通过κ机制解释相关现象，解决了之前对氦星脉动理解不足的问题，具有明确的动机。

- (3): 本文的主要贡献在于首次确认了剥离氦星在质量交换过程中经历非线性脉动，并确定了其脉动的不稳定性区域。

- (4): 本文拟采取理论分析与数值模拟相结合的研究方法，以探讨剥离氦星的脉动特性及其与伴星的关系。

- (5): 方法针对脉动现象达到的性能表明，剥离氦星的脉动周期和幅度与日常观测一致，支持了其在银河中存在约1000个脉动中等质量剥离氦星的目标。


## Correcting for interloper contamination in the power spectrum with neural networks
- **Url**: http://arxiv.org/abs/2504.06919v1
- **Authors**: ['Marina S. Cagliari', 'Azadeh Moradinezhad Dizgah', 'Francisco Villaescusa-Navarro']
- **Abstrat**: Modern slitless spectroscopic surveys, such as Euclid and the Roman Space Telescope, collect vast numbers of galaxy spectra but suffer from low signal-to-noise ratios. This often leads to incorrect redshift assignments when relying on a single emission line, due to noise spikes or contamination from non-target emission lines, commonly referred to as redshift interlopers. We propose a machine learning approach to correct the impact of interlopers at the level of measured summary statistics, focusing on the power spectrum monopole and line interlopers as a proof of concept. To model interloper effects, we use halo catalogs from the Quijote simulations as proxies for galaxies, displacing a fraction of halos by the distance corresponding to the redshift offset between target and interloper galaxies. This yields contaminated catalogs with varying interloper fractions across a wide range of cosmologies from the Quijote suite. We train a neural network on the power spectrum monopole, alone or combined with the bispectrum monopole, from contaminated mocks to estimate the interloper fraction and reconstruct the cleaned power spectrum. We evaluate performance in two settings: one with fixed cosmology and another where cosmological parameters vary under broad priors. In the fixed case, the network recovers the interloper fraction and corrects the power spectrum to better than 1% accuracy. When cosmology varies, performance degrades, but adding bispectrum information significantly improves results, reducing the interloper fraction error by 40-60%. We also study the method's performance as a function of the size of the training set and find that optimal strategies depend on the correlation between target and interloper samples: bispectrum information aids performance when target and interloper galaxies are uncorrelated, while tighter priors are more effective when the two are strongly correlated.


**Translated Abstract**: 

现代的无缝光谱调查，例如Euclid和罗曼空间望远镜，收集了大量的星系光谱，但由于信噪比低，常常导致错误的红移分配。依靠单个发射线进行测定时，噪声峰值或非目标发射线的污染会导致所谓的红移干扰者。我们提出了一种机器学习方法，在测量的总结统计水平上纠正干扰者的影响，重点关注功率谱单极和线干扰者作为概念验证。为了建模干扰者效应，我们利用Quijote模拟的光晕目录作为星系的代理，通过与目标和干扰星系之间红移偏移相对应的距离位移一部分光晕。这生成了具有不同干扰者比例的污染目录，涵盖Quijote套件中的广泛宇宙学。我们训练神经网络以估计干扰者比例并重建清洁的功率谱，使用来自污染模拟的功率谱单极，单独或与双谱单极结合。我们在两种设置中评估表现：一种是固定宇宙学，另一种是在宽先验下宇宙学参数变化。固定情况下，网络能以超过1%的准确率恢复干扰者比例并纠正功率谱。当宇宙学变化时，性能降低，但结合双谱信息显著改善结果，减少了40-60%的干扰者比例误差。我们还研究了方法性能与训练集规模的关系，发现最佳策略取决于目标与干扰样本之间的相关性：当目标与干扰星系不相关时，双谱信息有助于性能，而当两者强相关时，收紧的先验更加有效。

**Summary**:

- (1): 本文研究背景是现代无缝光谱调查如Euclid和罗曼空间望远镜的数据处理，面临低信噪比导致的红移干扰者问题，这影响了星系红shift的准确性。

- (2): 过去的方法主要通过目标选择方案或者直接在总结统计中建模干扰效应来解决干扰者问题。这些方法通常需要已知的干扰者比例作为输入，或依赖于有限的深度光谱观测。本文提出的方法通过直接从测量的总结统计中推断干扰者比例，并进行功率谱的污染校正，具有较好的动机。

- (3): 本文的贡献在于提出了一种新的机器学习方法，能够有效估计并校正干扰者对功率谱的影响，并展示了可扩展性，适用于大规模光谱调查。

- (4): 本文的研究方法基于神经网络，使用来自Quijote套件的模拟数据，输入被污染的功率谱单极，输出干扰者比例的均值和方差，以及校正后的功率谱。

- (5): 本文的方法在固定宇宙学和变化宇宙学条件下对干扰者比例进行了有效的估计，达到超过1%的正确性。在变化宇宙学情况下，尽管性能有所下降，但结合双谱信息后效果显著改善，支持了研究目标的实现。


## An Investigation of Disk Thickness in M51 from H-alpha, Pa-alpha, and Mid-Infrared Power Spectra
- **Url**: http://arxiv.org/abs/2504.05430v2
- **Authors**: ['Bruce G. Elmegreen', 'Daniela Calzetti', 'Angela Adamo', 'Karin Sandstrom', 'Daniel Dale', 'Varun Bajaj', 'Martha L. Boyer', 'Ana Duarte-Cabral', 'Ryan Chown', 'Matteo Correnti', 'Julianne J. Dalcanton', 'Bruce T. Draine', 'Brandt Gaches', 'John S. Gallagher III', 'Kathryn Grasha', 'Benjamin Gregg', 'Leslie K. Hunt', 'Kelsey E. Johnson', 'Robert Kennicutt, Jr.', 'Ralf S. Klessen', 'Adam K. Leroy', 'Sean Linden', 'Anna F. McLeod', 'Matteo Messa', 'Goran Ostlin', 'Mansi Padave', 'Julia Roman-Duval', 'J. D. Smith', 'Fabian Walter', 'Tony D. Weinbeck']
- **Abstrat**: Power spectra (PS) of high-resolution images of M51 (NGC 5194) taken with the Hubble Space Telescope and the James Webb Space Telescope have been examined for evidence of disk thickness in the form of a change in slope between large scales, which map two-dimensional correlated structures, and small scales, which map three-dimensional correlated structures. Such a slope change is observed here in H-alpha, and possibly Pa-alpha, using average PS of azimuthal intensity scans that avoid bright peaks. The physical scale of the slope change occurs at ~120 pc and ~170 pc for these two transitions, respectively. A radial dependence in the shape of the H-alpha PS also suggests that the length scale drops from ~180 pc at 5 kpc, to ~90 pc at 2 kpc, to ~25 pc in the central ~kpc. We interpret these lengths as comparable to the thicknesses of the star-forming disk traced by HII regions. The corresponding emission measure is ~100 times larger than what is expected from the diffuse ionized gas. PS of JWST Mid-IR Instrument (MIRI) images in 8 passbands have more gradual changes in slope, making it difficult to determine a specific value of the thickness for this emission.


**Translated Abstract**: 

本文考察了通过哈勃太空望远镜和詹姆斯·韦布太空望远镜获取的M51（NGC 5194）高分辨率图像的功率谱（PS），以寻找盘厚度的证据，表现为大尺度与小尺度之间斜率的变化。Hα和可能的Paα中观察到了这种斜率变化，利用避免亮峰的方位强度扫描的平均PS。斜率变化的物理尺度分别约为~120 pc和~170 pc。Hα PS的径向依赖性也表明，长度尺度从5 kpc处的~180 pc降至2 kpc处的~90 pc，再降至中心~kpc处的~25 pc。我们将这些长度解释为对应于由HII区域追踪的星形成盘的厚度。相应的发射度量比预期的弥漫离子气要大约高出100倍。JWST中红外仪（MIRI）图像的PS在8个波段中有更加渐进的斜率变化，使得确定该发射的特定厚度值变得困难。

**Summary**:

- (1): 本文研究的背景是寻找M51（NGC 5194）星系盘的厚度，通过分析不同波长的功率谱来推测其结构特征。

- (2): 过去的方法主要依赖于数值模拟和现有的功率谱分析，但某些研究未能在干扰点源的影响下检测到清晰的斜率变化。提出的方法通过选择几乎没有强亮点的方位扫描克服了这些问题，这种强度扫描方法相较于传统的二维功率谱分析具有更高的准确性和分辨率，能够有效观察星系的盘厚度。

- (3): 本文的贡献在于首次通过PS的方法为M51提供了星系盘厚度的新测量，且测得厚度在不同半径处呈现增加趋势，这是对已有文献的重要补充。

- (4): 本文的研究方法包括利用哈勃和詹姆斯·韦布太空望远镜的高分辨率图像，进行方位强度扫描以获得功率谱，并分析两维与三维结构之间的斜率变化，以此推断星系的厚度。

- (5): 本文方法主要集中在M51星系盘的厚度测量，结果表明在Hα和Paα波段的斜率变化信息支持了其研究目标，为后续对星系结构和动力学的分析提供了重要数据。


## FAST drift scan survey for HI intensity mapping: simulation on hunting HI filament with pairwise stacking
- **Url**: http://arxiv.org/abs/2411.03988v2
- **Authors**: ['Diyang Liu', 'Yichao Li', 'Denis Tramonte', 'Furen Deng', 'Jiaxin Wang', 'Yougang Wang', 'Xin Zhang', 'Xuelei Chen']
- **Abstrat**: Filaments stand as pivotal structures within the cosmic web. However, direct detection of the cold gas content of the filaments remains challenging due to its inherent low brightness temperature. With the TNG hydrodynamical simulations, we demonstrate the effectiveness of isolating faint filament HI signal from the FAST HI intensity mapping (IM) survey through pairwise stacking of galaxies, which yields an average HI filament signal amplitude of $\sim 0.29\ {\mu{\rm K}}$ at $z\simeq 0.1$. However, our simulations reveal a non-negligible contribution from HI-rich galaxies within or near the filaments. Particularly, the faint galaxies dominantly contribute to the extra filament HI signal. Our simulation also shows that the measurement uncertainty is produced by both thermal noise and background variation caused by brightness leakage from surrounding random galaxies. Given a fixed total observation time, a wide-field HI IM survey, which includes a large number of galaxy pairs, can simultaneously reduce thermal noise to below the filament signal level and minimize background variation to a negligible level. Through the end-to-end simulation, this work demonstrates the critical role of the galaxy pairwise stacking method in future filament HI detection, outlining a road map for filament HI detection in the next-generation HI IM surveys.


**Translated Abstract**:   

星际的冷气体在宇宙网络中占有重要地位。然而，由于其本征的低亮度温度，直接探测这些气体的内容物面临挑战。通过TNG流体动力学模拟，我们展示了通过对FAST HI强度测绘（IM）调查中的星系进行成对堆叠，来有效地隔离微弱的HI信号，该方法在z≈0.1时的平均HI信号幅度约为0.29 μK。然而，我们的模拟显示，在星系团内或附近的HI丰富星系也对HI信号提供了不可忽视的贡献。特别是，微弱星系主导了额外的HI信号。我们的模拟还表明，测量不确定性由热噪声和背景变化引起，而背景变化则是由于周围随机星系的亮度泄漏造成的。在固定的总观察时间内，广域HI IM调查包括大量的星系对，可以同时将热噪声降低到低于星际信号水平，并使背景变化降到微不足道的水平。通过端到端模拟，本研究展示了星系成对堆叠方法在未来星际HI探测中的关键作用，概述了下一代HI IM调查中的星际HI探测路线图。

**Summary**:

- (1): 本文研究的背景是星际冷气体在宇宙网络中至关重要，但因其低亮度温度直接探测非常具有挑战性。

- (2): 过去的方法主要依赖于单一的观测技术，存在探测灵敏度不足及信号干扰问题。本文提出的方法通过对星系进行成对堆叠，能够有效隔离微弱HI信号，解决了热噪声和背景变化问题。这种方法具备清晰的理论动机，能够在提升探测灵敏度的同时，降低测量不确定性。

- (3): 本文的贡献在于通过TNG流体动力学模拟验证了成对堆叠方法在微弱HI信号检出中的有效性，并为下一代HI IM调查提出了详细的实施路线图。

- (4): 本文的研究方法包括使用流体动力学模拟来预测HI信号，并结合成对堆叠技术进行数据分析，以提高对星际信号的检测能力。

- (5): 本文的方法在z≈0.1的条件下实现了约0.29 μK的HI信号检测，性能表现优于传统方法，能有效支持未来的研究目标。


## The ALMA-ATOMS survey: A sample of weak hot core candidates identified through line stacking
- **Url**: http://arxiv.org/abs/2504.06802v1
- **Authors**: ['Zi-Yang Li', 'Xunchuan Liu', 'Tie Liu', 'Sheng-Li Qin', 'Paul F. Goldsmith', 'Pablo García', 'Yaping Peng', 'Li Chen', 'Yunfan Jiao', 'Zhiping Kou', 'Chuanshou Li', 'Jiahang Zou', 'Mengyao Tang', 'Shanghuo Li', 'Meizhu Liu', 'Guido Garay', 'Fengwei Xu', 'Wenyu Jiao', 'Qiu-Yi Luo', 'Suinan Zhang', 'Qi-Lao Gu', 'Xiaofeng Mai', 'Yan-Kun Zhang', 'Jixiang Weng', 'Chang Won Lee', 'Patricio Sanhueza', 'Sami Dib', 'Swagat R. Das', 'Xindi Tang', 'Leonardo Bronfman', 'Prasanta Gorai', "Ken'ichi Tatematsu", 'Hong-Li Liu', 'Dongting Yang', 'Zhenying Zhang', 'Xianjin Shen']
- **Abstrat**: Hot cores represent critical astrophysical environments for high-mass star formation, distinguished by their rich spectra of organic molecular emission lines. We aim to utilize high-angular resolution molecular line data from ALMA to identify hot cores, with a particular focus on weak-emission candidates, and to provide one of the largest samples of hot core candidates. We propose to use spectral stacking and imaging techniques of complex organic molecules (COMs) in the ALMA-ATOMS survey, including line identification & weights, segmentation of line datacubes, resampling, stacking and normalization, moment 0 maps, and data analysis, to search for hot core candidates. We classify cores with dense emission of CH3OH and at least one molecule from the other six molecules as hot core candidates. In addition to the existing sample of 60 strong hot cores from the ALMA-ATOMS survey, we have detected 40 new weak candidates through stacking. All hot core candidates display compact emission from at least one of the other six COM species. For the strong sample, the stacking method provides molecular column density estimates that are consistent with previous fitting results. For the newly identified weak candidates, all species except CH3CHO show compact emission in the stacked image, which cannot be fully resolved spatially. These weak candidates exhibit column densities of COMs that are approximately one order of magnitude lower than those of the strong sample. The entire hot core sample, including the weak candidates, reveals tight correlations between the compact emission of CH3OH and other COM species, suggesting they may share a similar chemical environment for COMs, with CH3OH potentially acting as a precursor for other COMs. The molecular line stacking technique is used to identify hot core candidates in this work, leading to the identification of 40 new hot core candidates.


**Translated Abstract**: 

热核是高质量星际形成的重要天体环境，其特征在于丰富的有机分子发射谱。我们旨在利用来自阿塔卡马大毫米/亚毫米阵列（ALMA）的高角分辨率分子线数据来识别热核，特别关注弱发射候选体，并提供迄今为止最大的一组热核候选样本。我们提议使用光谱叠加和成像技术来搜索热核候选体，包括线识别与加权、数据立方体分段、重采样、叠加和归一化、时刻0图以及数据分析。我们将密集发射CH3OH及其他六种分子中至少一种分子的核心分类为热核候选体。除了现有的60个强热核样本外，我们通过叠加检测到了40个新的弱候选体。所有热核候选体均显示出至少一种其他有机分子物种的致密发射。强样本的叠加方法提供的分子柱密度估算与先前的拟合结果相一致。对于新识别的弱候选体，所有物种（除了CH3CHO）均在叠加图像中显示出致密发射，尽管这无法完全在空间上分辨。这些弱候选体的有机分子柱密度约比强样本低一个数量级。整个热核样本在CH3OH和其他有机分子物种的紧密发射之间显示出紧密的相关性，表明它们可能共享相似的有机分子化学环境，其中CH3OH可能作为其他有机分子的前体。在总共100个热核中，有43个在空间上与SiO和H13CO+的订婚CH3CHO发射相关，表明CH3CHO可能在广泛分布的冲击区域中形成。结合光谱线叠加技术的使用，本文工作成功识别出40个新的热核候选体。

**Summary**:

- (1): 本文研究背景为高质量星际形成中的热核的特性及其在星系演化中的重要性，尽管目前对热核的统计分析相对缺乏，尤其是弱发射候选体的研究。

- (2): 过去的方法主要是单点观测，存在灵敏度不足的问题，难以进行系统的统计研究。相比之下，本文提出的光谱叠加与成像技术能够提高对弱热核的探测灵敏度和效率。

- (3): 本文的主要贡献在于通过光谱叠加的方法识别了40个新的弱热核候选体，扩展了已存在的热核候选样本并揭示了CH3OH与其他有机分子的相关性。

- (4): 本文提出的研究方法包括使用ALMA数据进行光谱叠加、成像、数据分析，以及识别与定量不同有机分子（如CH3OH等）的致密发射。

- (5): 本文的方法在热核候选体的识别任务上取得了较好的性能，特别是对弱候选体的探测，支持了其目标，实现了样本数量的扩展和化学环境的推断。


## FOREVER22: Insights into star formation and clustering properties of protoclusters from simulations and JWST
- **Url**: http://arxiv.org/abs/2504.06788v1
- **Authors**: ['Kana Morokuma-Matsui', 'Hidenobu Yajima', 'Makito Abe']
- **Abstrat**: Using cosmological hydrodynamic simulations with radiative transfer, we investigate star formation and overdensity ($\delta$) in Coma-type cluster progenitors from $z=14$ to 6. Our simulations reproduce observed $M_{\rm star}$-SFR relations and $\delta$ at these redshifts. We find: (1) protocluster (PC) and mean-density field (MF) galaxies show similar $M_{\rm star}$-SFR relations, with PC galaxies extending to higher $M_{\rm star}$ and SFR. (2) UV-bright PC galaxies ($M_{\rm UV}\lesssim -20$~mag) have $>2$ mag higher UV attenuation and shallower UV slopes than MF galaxies. (3) $\delta$ increases with redshift, depending on observational parameters (e.g., $\delta\sim50$ at $z=14$ to $\delta\sim3$ at $z=6$ for a search volume of $\sim3000$~cMpc$^3$ and a limiting magnitude of $M_{\rm UV}=-17$~mag). These results indicate that enhanced star formation in PCs is driven by massive galaxy overdensity, not anomalously high specific SFR. While simulated $\delta$ agrees with observed PC candidates (potential Coma progenitors), some MF galaxies show comparable $\delta$. We propose a robust PC identification method using both $\delta$ and $M_{\rm star}$ of the most massive member. Critical $M_{\rm star}$ thresholds for Coma progenitors are estimated ($10^{7.1}$ to $10^{10.2}$ M$_\odot$ from $z=14$ to 6). Comparison with JWST observations suggests GS-z14-0 and GS-z14-1, the current highest redshift holders, are likely progenitors of Coma-type clusters.


**Translated Abstract**: 

通过使用具有辐射传输的宇宙学氢动力学模拟，我们研究了从赤移$z=14$到$6$的类似Coma星系团前身的星形成和过密度($\delta$)。我们的模拟再现了这些红移下的观测$M_{\rm star}$-SFR关系和$\delta$。我们发现：（1）原型星系团（PC）和均值密度场（MF）星系在$M_{\rm star}$-SFR关系上表现相似，但PC星系在$M_{\rm star}$和SFR上更高。（2）UV明亮的PC星系（$M_{\rm UV}\lesssim -20$~mag）相较于MF星系具有$>2$ mag更高的UV衰减值和较平坦的UV斜率。（3）$\delta$随着红移的增加而增加，具体取决于观测参数（例如，在赤移$z=14$时$\delta\sim50$，在$z=6$时$\delta\sim3$，搜索体积约为$~3000$~cMpc$^3$，限界光度为$M_{\rm UV}=-17$~mag）。这些结果表明，PC中增强的星形成是由于大质量星系的过密度，而非异常高的特定SFR。虽然模拟的$\delta$与观察到的PC候选者（潜在的Coma前身）一致，但一些MF星系显示出可比的$\delta$。我们提出了一种基于$\delta$和最重成员的$M_{\rm star}$的稳健PC识别方法。估计了Coma前身的临界$M_{\rm star}$阈值（从$z=14$到$6$为$10^{7.1}$到$10^{10.2}$ M$_\odot$）。与JWST观察的比较表明，GS-z14-0和GS-z14-1这两个当前最高红移的持有者可能是Coma类型星系团的前身。

**Summary**:

- (1): 本文研究的背景是原型星系团（PC）在早期宇宙中的过密区域，它们预计将演变为当前的星系团，并在宇宙重离子化和化学演化中起到了重要作用。

- (2): 过去的方法主要依赖于深度光谱观测，如Lyman-$\alpha$发射以识别PC候选者，但由于依赖不同星系群体的过密区域，观察定义和选择过程复杂，结果不确定。本文提出的方法将结合$\delta$和最重成员的$M_{\rm star}$，旨在简化PC的识别过程，克服了前期方法的选样偏差问题，提供了更为稳健的识别框架。

- (3): 本文的贡献在于提供了一种新的PC识别方法，并成功从JWST观测中识别出新的高红移PC候选者，提高了对早期宇宙星形成活动的理解。

- (4): 本文的研究方法采用了宇宙学氢动力学模拟与辐射传输相结合的手段，模拟了不同红移下PC的星形成关联与过密度特征。

- (5): 本文使用的模拟和JWST观测支持了对高红移PC的识别，并在识别出诸如GS-z14-0和GS-z14-1等新候选者方面取得了成功，进一步验证了它们作为Coma类型星系团前身的潜力。


## Deep Learning solutions to singular ordinary differential equations: from special functions to spherical accretion
- **Url**: http://arxiv.org/abs/2409.20150v2
- **Authors**: ['R. Cayuso', 'M. Herrero-Valea', 'E. Barausse']
- **Abstrat**: Singular regular points often arise in differential equations describing physical phenomena such as fluid dynamics, electromagnetism, and gravitation. Traditional numerical techniques often fail or become unstable near these points, requiring the use of semi-analytical tools, such as series expansions and perturbative methods, in combination with numerical algorithms; or to invoke more sophisticated methods. In this work, we take an alternative route and leverage the power of machine learning to exploit Physics Informed Neural Networks (PINNs) as a modern approach to solving ordinary differential equations with singular points. PINNs utilize deep learning architectures to approximate solutions by embedding the differential equations into the loss function of the neural network. We discuss the advantages of PINNs in handling singularities, particularly their ability to bypass traditional grid-based methods and provide smooth approximations across irregular regions. Techniques for enhancing the accuracy of PINNs near singular points, such as adaptive loss weighting, are used in order to achieve high efficiency in the training of the network. We exemplify our results by studying four differential equations of interest in mathematics and gravitation -- the Legendre equation, the hypergeometric equation, the solution for black hole space-times in theories of Lorentz violating gravity, and the spherical accretion of a perfect fluid in a Schwarzschild geometry.


**Translated Abstract**: 

在描述物理现象（如流体动力学、电磁学和引力）的微分方程中，常常会出现奇异常规点。传统的数值技术往往在这些点附近失败或变得不稳定，要求使用半解析工具，例如级数展开和微扰方法，结合数值算法；或调用更复杂的方法。在这项工作中，我们采取了另一种途径，利用机器学习的力量，采用物理信息神经网络（PINNs）作为解决具有奇异点的常微分方程的现代方法。PINNs利用深度学习架构，通过将微分方程嵌入神经网络的损失函数中来近似解。我们讨论了PINNs处理奇异性的优势，特别是它们能够绕过传统的基于网格的方法，并在不规则区域提供平滑的近似。为了在奇异点附近提高PINNs的精度，采用了自适应损失加权等技术，以实现网络训练的高效性。我们通过研究四个在数学和引力中具有兴趣的微分方程 - 太阳系方程、超几何方程、洛伦兹违反引力理论中的黑洞时空解，以及施瓦西几何中完美流体的球形吸积，来说明我们的结果。

**Summary**:

- (1): 文章讨论了在描述流体动力学、电磁学和引力等物理现象的微分方程中，存在奇异常规点的问题。

- (2): 过去的方法包括传统的数值技术和半解析工具（如级数展开和微扰方法），这些方法在奇异点附近常常变得不稳定。所提出的方法采用物理信息神经网络（PINNs），利用深度学习架构将微分方程嵌入损失函数，从而避免了传统网格方法的问题，并在不规则区域提供了平滑的近似。

- (3): 论文的贡献在于将PINNs引入解决具有奇异点的常微分方程，提供了一种新的解决方案，展示了其在处理奇异性方面的优势。

- (4): 研究方法基于物理信息神经网络（PINNs），通过自适应损失加权技术提高在奇异点附近的准确性，从而实现高效的网络训练。

- (5): 方法在研究的四个微分方程任务（福德方程、超几何方程、黑洞时空解、施瓦西几何中的完美流体球形吸积）上表现出色，已证明其能力支持研究目标的实现。


## Measuring and predicting galaxy assembly bias across galaxy samples
- **Url**: http://arxiv.org/abs/2504.06770v1
- **Authors**: ['Sergio García-Moreno', 'Jonás Chaves-Montero']
- **Abstrat**: One of the most important effects shaping small-scale galaxy clustering is galaxy assembly bias, which refers to the dependence of galaxy clustering on halo properties. We investigate this effect using galaxy samples selected according to stellar mass, r-band magnitude, and broad-band colors from the largest hydrodynamical simulation of the IllustrisTNG suite. We find that galaxy assembly bias depends strongly upon the selection criteria, number density, and redshift of the sample, increasing or decreasing the clustering by as much as 25%. Interestingly, no single secondary halo property fully captures the strength of this effect for any galaxy population. Therefore, empirical approaches modeling galaxy assembly bias as a function of a single halo property cannot reproduce predictions from hydrodynamical simulations. We then study how galaxy assembly bias emerges from the interplay of halo assembly bias -- the dependence of halo clustering on properties other than mass -- and occupancy variation -- the correlation between galaxy occupation and secondary halo properties -- and provide an analytical expression that predicts the amount of galaxy assembly bias caused by any halo property. This expression facilitates understanding the dependence of galaxy assembly bias on halo properties and enables the straightforward incorporation of this effect into halo model approaches.


**Translated Abstract**: 

小尺度星系聚集的一个重要效应是星系组装偏差，这指的是星系聚集依赖于晕性质。我们使用来自最大水动力模拟的 IllustrisTNG 系列的星系样本，根据恒星质量、r带亮度和宽带颜色选择样本来研究此效应。我们发现星系组装偏差强烈依赖于选择标准、数量密度和样本的红移，聚集的增加或减少幅度可达 25%。有趣的是，没有单一的次级晕性质能够充分捕捉任何星系群体的该效应强度。因此，将星系组装偏差建模为单一晕性质的经验方法无法重现水动力模拟的预测。我们进一步研究了星系组装偏差如何从晕组装偏差（即晕聚集依赖于质量以外的性质）和占用变化（星系占用与次级晕性质的相关性）的相互作用中产生，并提供了一种解析表达式，可以预测任何晕性质引起的星系组装偏差。这一表达式有助于理解星系组装偏差对晕性质的依赖，并使这一效应能够轻松地纳入晕模型方法中。

**Summary**:

- (1): 本文的研究背景是星系聚集受到晕性质影响的星系组装偏差，其在小尺度星系聚集中的重要性，以及其对星系-晕关联的影响。

- (2): 过去的研究方法主要依赖于半解析模型，这些模型认为星系聚集严格依赖于晕质量。然而，这些方法无法捕捉到星系组装偏差的复杂性。在此，作者使用来自 IllustrisTNG 模拟的多个星系样本，提出了一种新方法，通过考虑晕的多种性质和占用变化的相互作用来解决问题，因此更全面，更有动机。

- (3): 本文的贡献在于揭示了星系组装偏差与多重选择标准和红移之间的强烈依赖关系，并提供了一种预测任意晕性质引起的星系组装偏差的解析表达式。

- (4): 本文研究的具体方法是在 IllustrisTNG 模拟中提取星系样本，通过分析星系聚集的变化及其与晕性质之间的关系来测量星系组装偏差。

- (5): 通过使用多种选择标准的星系样本，本文的研究显示星系组装偏差能够改变聚集程度最多达 25%。这些结果表明，提出的方法能够支持其研究目标，准确建模小尺度星系聚集。


## Unveiling two deeply embedded young protostars in the S68N Class 0 protostellar core with JWST/NIRSpec
- **Url**: http://arxiv.org/abs/2410.11095v2
- **Authors**: ['Valentin J. M. Le Gouellec', 'Ben W. P. Lew', 'Thomas P. Greene', 'Doug Johnstone', 'Antoine Gusdorf', 'Logan Francis', 'Curtis DeWitt', 'Michael Meyer', 'Łukasz Tychoniec', 'Ewine F. van Dishoeck', 'Mary Barsony', 'Klaus W. Hodapp', 'Massimo Robberto']
- **Abstrat**: The near-infrared (NIR) emission of the youngest protostars still needs to be characterized to better understand the evolution of their accretion and ejection activity. We analyze James Webb Space Telescope NIRSpec 1.7 -- 5.3 $\mu$m observations of two deeply embedded sources in the S68N protostellar core in Serpens. The North Central (NC) source exhibits a highly obscured spectrum (A_K ~ 4.8 mag) that is modeled with a pre-main-sequence photosphere and a hot disk component. The photospheric parameters are consistent with a young, low-mass photosphere, as suggested by the low surface gravity, log g of 1.95 $\pm$ 0.15 cm s$^{-2}$. The hot disk suggests that accretion onto the central protostellar embryo is ongoing, although prototypical accretion-tracing emission lines HI are not detected. The South Central (SC) source, which is even more embedded (A_K ~ 8 mag; no continuum is detected shortward of 3.6 $\mu$m) appears to be driving the large-scale S68N protostellar outflow, and launches a collimated hot molecular jet detected in \Ht and CO ro-vibrational lines. Shock modeling of the \Ht (ro)vibrational lines establishes that fast $C$-type shocks ($\geq$ 30 km s$^{-1}$), with high pre-shock density ($\geq$ $10^7$ cm$^{-3}$), and strong magnetic field (b ~ 3--10, where $B = b\,\times\,\sqrt{\textrm{n}_{\textrm{H}} (\textrm{cm}^{-3})}\,\mu\textrm{G}$) best match the data. The bright CO fundamental line forest suggests energetic excitation, with the contribution of non-LTE effects, ie irradiation pumping. Detected OH and CH$^{+}$ ro-vibrational lines support this hypothesis. These two Class 0 protostars seem to be in very young evolutionary stages and still have to acquire the bulk of their final stellar masses. These results demonstrate that JWST enables unprecedented diagnostics of these first stages of the protostellar evolutionary phase.


**Translated Abstract**: 

在该研究中，我们分析了詹姆斯·韦伯太空望远镜（JWST）在1.7至5.3微米波段对塞尔彭斯S68N原星核中两个深嵌入源的观察。北中源（North Central，NC）展示了高度被遮蔽的光谱（A_K约为4.8mag），其模型包括一个前主序光球和一个热盘组件。光球的参数与年轻的低质量光球一致，低表面重力log g约为1.95 ± 0.15 cm s^−2。热盘表明中央原星胚胎正在进行吸积，尽管未检测到典型的吸积发射线HI。南中源（South Central，SC）更加嵌入（A_K约为8mag；在3.6微米短波段未检测到连续光），似乎驱动着大规模的S68N原星外流，并发射了在H2和CO辐动线中检测到的定向热分子喷流。对H2（辐动）线的冲击建模表明，快速C型冲击（≥30 km s^−1）与高前冲密度（≥10^7 cm^−3）相结合，并伴有强磁场（b∼3-10）最好地符合数据，明亮的CO基本线森林表明能量激发，并存在非LTE效应，即辐照泵浦。检测到的OH和CH^+辐动线支持这一假设。这两个Class 0原星似乎处于非常年轻的演化阶段，尚需获得其最终恒星质量的绝大部分。结果表明，JWST能够提供对这些原星演化阶段的前所未有的诊断。

**Summary**:

- (1): 该研究的背景是研究年轻原星在吸积和喷流活动中的演化特征，特别是在Class 0原星阶段。

- (2): 过去的方法主要是通过地面望远镜观察近红外光谱，这些方法的局限性在于，许多年轻的原星由于高度被遮蔽而难以直接检测。该研究使用JWST进行的深入观察提供了对深嵌入源的全新视角，克服了之前方法的遮蔽限制。

- (3): 论文的贡献在于揭示了两个深嵌入的Class 0原星的物理特性，特别是它们的光谱特征和喷流活动，并展示了JWST在这种观察中的强大能力。

- (4): 本文采用JWST/NIRSpec对1.7至5.3微米波段进行观测，并通过模型分析光球和热盘组件的特征，结合冲击建模对喷流进行深入研究。

- (5): 论文在分析原星的光谱特征和喷流活动方面取得了显著进展，表明JWST能有效识别早期原星演化阶段的关键物理过程，从而支持研究目标的实现。


## Evidence of star cluster migration and merger in dwarf galaxies
- **Url**: http://arxiv.org/abs/2504.06749v1
- **Authors**: ['Mélina Poulain', 'Rory Smith', 'Pierre-Alain Duc', 'Francine R. Marleau', 'Rebecca Habas', 'Patrick R. Durrell', 'Jérémy Fensch', 'Sungsoon Lim', 'Oliver Müller', 'Sanjaya Paudel', 'Rubén Sánchez-Janssen']
- **Abstrat**: Nuclear star clusters (NSCs) are the densest stellar systems in the Universe. They can be found at the center of all galaxy types, but tend to favor galaxies of intermediate stellar mass around 10$^9\,$M$_{\odot}$[1, 2]. Currently, two main processes are under debate to explain their formation: in-situ star-formation from gas infall[3] and migration and merging of globular clusters (GCs) caused by dynamical friction[4]. Studies[5-9] of NSC stellar populations suggest that the former predominates in massive galaxies, the latter prevails in dwarf galaxies, and both contribute equally at intermediate mass. However, up to now, no ongoing merger of GCs has yet been observed to confirm this scenario. Here we report the serendipitous discovery of five dwarf galaxies with complex nuclear regions, characterized by multiple nuclei and tidal tails, using high resolution images from the Hubble Space Telescope. These structures have been reproduced in complementary N-body simulations, supporting the interpretation that they result from migrating and merging of star clusters. The small detection rate and short simulated timescales (below 100 Myr) of this process may explain why this has not been observed previously. This study highlights the need of large surveys with high resolution to fully map the migration scenario steps.


**Translated Abstract**: 

核星团（NSCs）是宇宙中最致密的恒星系统。它们存在于所有类型的星系中心，但更倾向于中等质量的星系，质量约为10^9 M_⊙。目前，关于它们形成的两种主要过程存在争论：由气体落入引起的原位恒星形成和由于动力学摩擦导致的星团（GCs）迁移与合并。对NSC恒星族群的研究表明，前者在大质量星系中占主导地位，而后者在矮星系中占优势，且在中等质量星系中两者贡献相当。然而，到目前为止，尚未观察到GCs的进行时合并以确认这一情景。我们报告了使用哈勃太空望远镜的高分辨率图像意外发现五个复杂的核区矮星系，这些星系具有多个核和潮汐尾巴。这些结构在互补的N体模拟中得到了再现，支持它们源于星团迁移与合并的解释。此过程的小检测率和模拟时间尺度（低于100百万年）可能解释了为何之前未观察到这一现象。该研究强调了需要进行高分辨率的大规模调查以全面映射迁移情景的步骤。

**Summary**:

- (1): 本文研究背景是核星团在星系中心的形成机制，尤其是在矮星系中星团迁移和合并的作用。

- (2): 过去的方法主要集中在星团形成的理论模型上，未能直接观察到星团迁移和合并的过程，导致这方面的证据缺失。本文通过高分辨率图像展示了实际的合并现象，从而解决了前述研究的不足。

- (3): 本文的贡献在于首次观察到矮星系中正在进行的星团迁移与合并过程，提供了直接的实证支持，并促使相关理论模型的修正。

- (4): 该研究的方法论包括使用哈勃太空望远镜的高分辨率影像以及N体模拟，以分析复杂的核区结构及其形成机制。

- (5): 本文研究的任务是识别和分析矮星系中的星团迁移及合并情况，结果显示了这些结构的存在并支持了理论模型，达成其研究目标。


## Revealing the ages of metal-rich RR Lyrae via kinematic label transfer
- **Url**: http://arxiv.org/abs/2504.06720v1
- **Authors**: ['HanYuan Zhang', 'Giuliano Iorio', 'Vasily Belokurov', 'N. Wyn Evans', 'Alexey Bobrick', "Valentina D'Orazi"]
- **Abstrat**: RR Lyrae stars have long been considered reliable tracers of old, metal-poor populations, primarily due to their prevalence in globular clusters and the Galactic halo. However, the discovery of a metal-rich subpopulation in the Galactic disc, kinematically colder and more rotationally supported, challenges this classical view. Understanding the age of these metal-rich RR Lyrae stars is crucial for constraining their formation pathways and assessing what Galactic populations they are tracing. In this work, we leverage the unprecedented astrometric precision of Gaia DR3 to infer the age distribution of metal-rich RR Lyrae stars through a kinematic comparison with O-rich Mira variables. Mira variables, with their well-established period-age relation, serve as a natural clock, allowing us to transfer age information to RR Lyrae stars via their phase-space properties. By applying this approach across different metallicity bins, we find that the most metal-rich RR Lyrae stars ($[\rm Fe/H] > -0.5$) exhibit kinematics consistent with a population significantly younger ($\approx 6-7$ Gyr) than typically assumed for RR Lyrae stars. In contrast, those with $-1 < [\rm Fe/H] < -0.5$ show properties more aligned with older ($\approx 9-11$ Gyr) populations. Interestingly, we also find evidence of a possible double age populations for the most metal-rich RR Lyrae, one younger with ages between 3 and 6 Gyr, and another one older ranging from 8 to 11 Gyr. These results provide strong evidence that metal-rich RR Lyrae stars in the Galactic field do not exclusively trace ancient populations. This finding challenges the current model of RR Lyrae formation and supports alternative formation scenarios, such as binary evolution.


**Translated Abstract**: RR Lyrae 星星长期以来被认为是古老、贫金属星群的可靠追踪者，主要因为它们在球状星团和银河晕中的普遍性。然而，在银河盘中发现的金属丰富的亚群，具有较冷的动力学特性和更支持旋转的特性，挑战了这一经典观点。了解这些金属富集的 RR Lyrae 星星的年龄对约束其形成途径及评估它们追踪的银河族群至关重要。在这项工作中，我们利用 Gaia DR3 的前所未有的天体测量精度，通过与富氧 Mira 变量的动力学比较推断了金属丰富 RR Lyrae 星的年龄分布。Mira 变量凭借其成熟的周期-年龄关系，作为一种自然时钟，使我们能够通过其相空间特性转移年龄信息到 RR Lyrae 星。通过在不同金属丰度区间应用这一方法，我们发现最金属丰富的 RR Lyrae 星（[Fe/H] > -0.5）展示了与显著年轻的群体（≈ 6-7 亿年）一致的动力学特征，反之，那些在 -1 < [Fe/H] < -0.5 的则表现出更古老（≈ 9-11 亿年）群体的特征。有趣的是，我们还发现最金属丰富的 RR Lyrae 星可能存在双重年龄的现象，一个年龄较小（3-6 亿年），另一个较大（8-11 亿年）。这些结果强有力地证明，银河场中的金属富集 RR Lyrae 星并不单纯追踪古老族群。这一发现挑战了当前 RR Lyrae 形成模型，并支持替代形成方案，例如双星演化。

**Summary**:

- (1): 本文的研究背景是 RR Lyrae 星星过去被认为是古老和贫金属星群的可靠追踪者，但在银河盘中发现金属丰富的亚群对这一观点提出了挑战。

- (2): 过去的方法主要基于星星的金属丰度与年龄的假设和动力学特征分析，但未能充分考虑金属丰富星群的出现。提出的方法通过与富氧 Mira 变量的动力学比较，解决了年龄估算的不确定性，具有明确的理论支持。

- (3): 本文的贡献在于首次利用 Gaia DR3 数据推断金属丰富的 RR Lyrae 星星的年龄分布，发现其年龄显著年轻并挑战现有的形成理论。

- (4): 研究方法包括利用动测数据通过与 Mira 变量的比较分类金属丰度区间，从而估算不同金属丰度 RR Lyrae 星的年龄。

- (5): 在任务上，本文方法成功推导出金属丰富 RR Lyrae 星的年龄，并达到约 6-7 亿年和 9-11 亿年的两组年龄分布。这些表现支持了作者关于其形成和演化路径的研究目标。


## Universal profile for cosmic birefringence tomography with radio galaxies
- **Url**: http://arxiv.org/abs/2504.06709v1
- **Authors**: ['Fumihiro Naokawa']
- **Abstrat**: We propose a new method to tomographically probe cosmic birefringence using radio galaxies. We show that the redshift evolution of the cosmic birefringence angle induced by a slow-rolling pseudoscalar field, which is a candidate for dynamical dark energy, is independent of the detailed model of the pseudoscalor field. This universal profile evolves predominantly at $z\lesssim10$. In contrast, if the origin is a dark matter-like pseudscalor field, the resulting birefringence angle tends to be negligible in the low-redshift regime. This new insight provides a strong motivation to independently test the cosmic birefringence using polarized astrophysical sources such as radio galaxies. We find that a sample size of $\order{10^5-10^6}$ is required to distinguish the profiles, which is achievable with ongoing and upcoming radio surveys such as ASKAP or SKA.


**Translated Abstract**: 

我们提出了一种新方法，通过射电星系对宇宙双折射进行层析探测。我们显示，由慢滚的伪标量场引起的宇宙双折射角的红移演化，与伪标量场的具体模型无关。这种普遍轮廓主要在红移 z ≲ 10 时演化。相比之下，若来源是类暗物质伪标量场，则导致的双折射角在低红移范围内趋于可以忽略。这一新见解为使用极化天体源（如射电星系）独立测试宇宙双折射提供了强有力的动机。我们发现，区分这些轮廓需要一个大小约为 O(10^5-10^6) 的样本，这在正在进行及未来的射电调查（如ASKAP或SKA）中是可实现的。

**Summary**:

- (1): 本文的研究背景是宇宙双折射，即光子在宇宙传播过程中偏振面的旋转，作为全球奇偶性违反的探测手段。

- (2): 过去的方法主要依赖于宇宙微波背景（CMB）极化数据进行双折射的测量，这些结果可能受限于前景辐射的未知系统误差，且仅提供有限的时效演化信息。本文提出的方法基于极化射电星系，能够克服这些限制并测试宇宙双折射的动态演化，因此具有良好的动机。

- (3): 文章的贡献在于提出了一个普遍的宇宙双折射演化轮廓，能够独立于CMB使用极化的天体源来进行测试，显著提高了对双折射的探测能力。

- (4): 本文提出的方法是通过射电星系的层析成像，探测由慢滚的伪标量场引起的宇宙双折射，利用分析红移演化特征。

- (5): 本文的任务是在探测宇宙双折射的过程中，实现对不同模型特征的区分，所需的样本规模为 O(10^5-10^6)，这一性能在未来的射电调查中是可实现的，可以支持他们的目标。


## Evolution of the Comptonizing medium of the black-hole candidate Swift J1727.8$-$1613 along the hard to hard-intermediate state transition using NICER
- **Url**: http://arxiv.org/abs/2504.06705v1
- **Authors**: ['Divya Rawat', 'Mariano Méndez', 'Federico García', 'Pierre Maggi']
- **Abstrat**: We analyse the properties of the Comptonizing medium in the black-hole X-ray binary Swift J1727.8$-$1613 using the time-dependent Comptonization model vkompth, using NICER observations of type-C QPOs in the hard and hard-intermediate states. During the 2023 outburst of the source, we measure the rms and phase lags of the QPO across 45 observations as the QPO frequency, $\nu_{\rm QPO}$, evolves from $\sim 0.3$ Hz to $\sim 7$ Hz. By simultaneously fitting the time-averaged spectrum of the source and the rms and lag spectra of the QPO, we derive the evolution of the disk and corona parameters. At $\nu_{\rm QPO} = 0.34$ Hz, the QPO phase lags are hard, with 10 keV photons lagging 0.5 keV photons by $\sim 0.5$ rad. As $\nu_{\rm QPO}$ increases, the lags for the same energy bands decrease, reaching near zero at $\nu_{\rm QPO} \sim 1.2$ Hz, and then reverse to soft lags of $\sim -1.1$ rad at $\nu_{\rm QPO} \sim 7$ Hz. Initially, the inner radius of the accretion disk is truncated at $\sim 30-40 R_g$ (assuming a 10 solar-mass black hole) and, as the QPO frequency increases, the truncation radius decreases down to $\sim 10 R_g$. Initially, two coronas of sizes of $\sim 6.5 \times 10^3$ km and $\sim 2 \times 10^3$ km, extend over the disk and are illuminated by different regions of the disk. As the QPO frequency increases, both the coronas shrink to $\sim 2 \times 10^3$ km at $\nu_{\rm QPO} = 2.5$ Hz. Following a data gap, one corona expands again, peaking at a size of $\sim 2 \times 10^4$ km. We interpret the evolution of the coronal size in the context of accompanying radio observations, discussing its implications for the interplay between the corona and the jet.


**Translated Abstract**: 

我们分析了黑洞X射线双星Swift J1727.8−1613中康普顿化介质的特性，使用时间依赖的康普顿化模型vkompth，通过NICER观测硬态和硬-中间态中的C型QPO。在2023年的源爆发中，我们测量了QPO的rms和相位延迟，随着QPO频率νQPO从大约0.3 Hz演变到大约7 Hz。通过同时拟合源的时间平均光谱和QPO的rms和延迟光谱，我们得出了盘和冕参数的演变。在νQPO = 0.34 Hz时，QPO相位延迟为硬延迟，10 keV光子延迟0.5 keV光子约0.5 rad。随着νQPO的增加，同一能量带的延迟减少，在νQPO ≈ 1.2 Hz时接近零，然后在νQPO ≈ 7 Hz时反转为软延迟约−1.1 rad。最初，吸积盘的内半径被截断在约30-40R_g（假设10个太阳质量的黑洞），随着QPO频率的增加，截断半径降低到约10R_g。最初，两个冕的大小分别为大约6.5×10^3 km和2×10^3 km，覆盖在盘上，并被盘的不同区域照亮。随着QPO频率的增加，这两个冕的大小在νQPO = 2.5 Hz时缩小到约2×10^3 km。经过数据间隙后，一个冕再次扩展，达到大小约2×10^4 km。我们在伴随的射电观测的背景下解释冕大小的演变，并讨论其对冕和喷流之间相互作用的影响。

**Summary**:


- (1): 本文研究黑洞X射线双星Swift J1727.8−1613的康普顿化介质的特性，尤其是其在硬态到硬-中间态转变过程中的演变。

- (2): 过去的方法主要基于静态模型，无法充分考虑动力学变化的问题。本文提出的vkompth时间依赖模型能够有效描述QPO频率变化对吸积盘和冕结构的影响。该方法解决了动态变化未被充分考虑的问题，具有良好的动机。

- (3): 本文的贡献在于通过对Swift J1727.8−1613的观测，揭示了其吸积盘和冕的演变过程，尤其是QPO频率变化对这些物理量的影响。

- (4): 本文的方法论采用时间依赖的康普顿化模型，结合NICER的观测数据，分析QPO的rms和相位延迟，进而导出吸积盘和冕的相关参数。

- (5): 本文在描述Swift J1727.8−1613的吸积盘和冕的演变任务上，展示了QPO频率从0.3 Hz到7 Hz的演变性能。研究结果能够支持其对吸积环境演变的理解目标。


## A multi-scale view of the magnetic field morphology in the hot molecular core G31.41+0.31
- **Url**: http://arxiv.org/abs/2504.06701v1
- **Authors**: ['C. Y. Law', 'M. T. Beltrán', 'R. S. Furuya', 'J. M. Girart', 'D. Galli', 'R. Cesaroni', 'L. Moscadelli', 'D. Arzoumanian', 'A. Lorenzani', 'M. Padovani', 'A. Sanna', 'G. Surcis']
- **Abstrat**: Multiscale studies of the morphology and strength of the magnetic field are crucial to properly unveil its role and relative importance in high-mass star and cluster formation. G31.41+0.31 (G31) is a hub-filament system that hosts a high-mass protocluster embedded in a hot molecular core (HMC). G31 is one of the few sources showing a clear hourglass morphology of the magnetic field on scales between 1000 au and a few 100 au in previous interferometric observations. This strongly suggests a field-regulated collapse. To complete the study of the magnetic field properties in this high-mass star-forming region, we carried out observations with the James Clerk Maxwell Telescope $850 \mu$m of the polarized dust emission. These observations had a spatial resolution of $\sim$0.2 pc at 3.75 kpc. The aim was to study the magnetic field in the whole cloud and to compare the magnetic field orientation toward the HMC from $\sim$50,000 au to $\sim$260 au scales. The large-scale ($\sim$5 pc) orientation of the magnetic field toward the position of the HMC is consistent with that observed at the core ($\sim$4,000 au) and circumstellar ($\sim$260 au) scales. The self-similarity of the magnetic field orientation at these different scales might arise from the brightest sources in the protocluster, whose collapse is dragging the magnetic field. These sources dominate the gravitational potential and the collapse in the HMC. The cloud-scale magnetic field strength of the G31 hub-filament system, which we estimated using the Davis-Chandrasekhar-Fermi method, is in the range 0.04--0.09 mG. The magnetic field orientation in the star-forming region shows a bimodal distribution, and it changes from an NW--SE direction in the north to an E--W direction in the south [abridged abstract].


**Translated Abstract**: 

多尺度研究磁场的形态和强度对于揭示其在高质量恒星和星团形成过程中的作用和相对重要性至关重要。G31.41+0.31（G31）是一个存在高质量原星团的中心-纤维系统，嵌套在一个热分子核心（HMC）中。G31是少数几个在1000 au到几百au尺度内展示明确沙漏形态的磁场的来源之一，之前的干涉观测强烈暗示了磁场调节下的坍塌。为了补充对这一高质量星形成区域磁场特性的研究，我们使用James Clerk Maxwell Telescope在850 µm波段观察了极化尘埃辐射。这些观测的空间分辨率约为0.2 pc，目标是研究整个云中的磁场，并比较从约50,000 au到260 au尺度上的热分子核心的磁场方向。磁场在大规模（约5 pc）朝向HMC的位置的方向与在核心（约4,000 au）和围绕恒星（约260 au）尺度的观测结果一致。在这些不同尺度上，磁场方向呈现自相似性，这可能源于原星团中最亮的源，其坍塌正在拖动磁场。这些源主导了HMC中的引力势和坍塌。我们使用Davis-Chandrasekhar-Fermi方法估算G31中心-纤维系统的云尺度磁场强度，范围为0.04到0.09 mG。星形成区域中的磁场方向显示出双峰分布，在北部的NW-SE方向和南部的E-W方向之间变化。这种方向变化发生在HMC附近，支持了云-云碰撞形成该星形成区域的情景。

**Summary**:

- (1): 本文研究的背景是磁场在大质量恒星和星团形成中的作用，尤其是在高质量分子云G31.41+0.31中。

- (2): 传统方法在不同尺度上对磁场的作用进行了有限的研究，通常在研究特定区域时缺乏连续的尺度视角。本文通过在更广泛的尺度（约50,000 au到260 au）上进行观察，提供了一种更全面的磁场分析。

- (3): 本文的贡献在于完成了对G31的多尺度磁场研究，验证了在不同尺度上的磁场自相似性，并揭示了影响星形成的潜在云-云碰撞机制。

- (4): 本文采用的研究方法包括使用James Clerk Maxwell Telescope对极化尘埃辐射进行观测，以评估整个云的磁场、分析不同尺度上的磁场方向及强度。

- (5): 本文方法支持研究云尺度磁场强度范围为0.04到0.09 mG，并揭示了磁场方向的双峰分布。结果支持本文对星形成机制和环境影响的研究目标。


## Deep Extragalactic VIsible Legacy Survey (DEVILS): New robust merger rates at intermediate redshifts
- **Url**: http://arxiv.org/abs/2504.06613v1
- **Authors**: ['Melissa F. Fuentealba-Fuentes', 'Luke J. M. Davies', 'Aaron S. G. Robotham', 'Robin H. W. Cook', 'Sabine Bellstedt', 'Claudia D. P. Lagos', 'Matías Bravo', 'Malgorzata Siudek']
- **Abstrat**: Mergers are fundamental to our understanding of the processes driving the evolution of the structure and morphology of galaxies, star formation, AGN activity, and the redistribution of stellar mass in the Universe. Determining the fraction and properties of mergers across cosmic time is critical to understanding the formation of the Universe we observe today. This fraction and its evolution also provide inputs and constraints for cosmological simulations, crucial for theoretical models of galaxy evolution. We present robust estimates of major close-pair fractions and merger rates at $0.2 < z < 0.9$ in the Deep Extragalactic VIsible Legacy Survey (DEVILS). We identify major mergers by selecting close-pairs with a projected spatial separation $r_{\mathrm{sep}} < 20$ h$^{-1}$ kpc and a radial velocity separation $v_{\mathrm{sep}} < 500$ km s$^{-1}$. For galaxies with stellar masses of log$_{10}$($M_\star$/$M_\odot$) = 10.66 $\pm$ 0.25 dex, we find a major close-pair fraction of $\approx 0.021$ at $0.2 < z < 0.34$ using a highly complete, unbiased spectroscopic sample. We extend these estimates to $0.2 < z < 0.9$ by combining the full probability distribution of redshifts for galaxies with high-quality spectroscopic, photometric, or grism measurements. Fitting a power-law $\gamma_{m} = A(1 + z)^m$, we find $A = 0.024 \pm 0.001$ and $m = 0.55 \pm 0.22$. Consistent with previous results, the shallow slope suggests weak redshift evolution in the merger fraction. When comparing with large hydrodynamical simulations, we also find consistent results. We convert close-pair fractions to merger rates using several literature prescriptions for merger timescales and provide all measurements for future studies.


**Translated Abstract**: 

合并是我们理解驱动星系结构和形态演化、恒星形成、活动星系核（AGN）活动以及宇宙中的恒星质量重新分布过程的基础。确定合并的比例和性质在洞悉我们今天观察到的宇宙的形成过程中至关重要。这一比率及其演变也为宇宙学模拟提供输入和约束，这是星系演化理论模型的关键。我们在深外星系可见遗产调查（Deep Extragalactic VIsible Legacy Survey，DEVILS）中，提供了在介于0.2 < z < 0.9内的主要近对星比例和合并率的稳健估计。通过选择具有投影空间分离$r_{\mathrm{sep}} < 20$ h$^{-1}$ kpc和径向速度分离$v_{\mathrm{sep}} < 500$ km s$^{-1}$的近对星来识别主要合并。对于具有$log_{10}(M_\star/M_\odot) = 10.66 \pm 0.25$ dex的星系，我们在0.2 < z < 0.34的范围内发现主要近对星比例约为0.021。通过结合高质量光谱、光度或光谱测量的星系的红移的全概率分布，我们将这些估计扩展到了0.2 < z < 0.9。在拟合幂律$\gamma_{m} = A(1 + z)^{m}$时，我们得到了$A = 0.024 \pm 0.001$和$m = 0.55 \pm 0.22$。与先前结果一致，较浅的斜率表明合并比例的红移演化较弱。与大型的水动力学模拟比较时，我们也得出了相似的结果。我们使用多个文献关于合并时间尺度的预设将近对星比例转化为合并率，并为未来研究提供了所有测量结果。

**Summary**:

- (1): 本文的研究背景是合并在宇宙学中的重要性，尤其在星系的形成和演化、恒星形成和AGN活动中驱动质量重新分配。

- (2): 过去的方法主要是找出接近的星系对，但存在样本不完整和观察偏倚的问题。本文提出的方法通过使用高完整性的光谱样本解决了这些问题，确保了测量结果的可靠性。

- (3): 本文的贡献在于提供了在介于0.2 < z < 0.9范围内的主要近对星比例和合并率的稳健估计，为理解合并的演化提供了新的数据支持。

- (4): 本文采用的研究方法是基于近对星的选择，通过测量星系的空间和速度分离，获得主要合并的比例，并对红移进行了分析。

- (5): 結果表明在0.2 < z < 0.34范围内，主要近对星比例约为0.021，且合并率估计结果一致，这为理解星系合并的演化提供了支持。


## A Galaxy with an Extremely Blue UV Slope $β=-3$ at $z=9.25$ Identified by JWST Spectroscopy: Evidence for a Weak Nebular Continuum and Efficient Ionizing Photon Escape?
- **Url**: http://arxiv.org/abs/2411.19893v2
- **Authors**: ['Hiroto Yanagisawa', 'Masami Ouchi', 'Kimihiko Nakajima', 'Yuichi Harikane', 'Seiji Fujimoto', 'Yoshiaki Ono', 'Hiroya Umeda', 'Minami Nakane', 'Hidenobu Yajima', 'Hajime Fukushima', 'Yi Xu']
- **Abstrat**: We investigate UV continuum slopes $\beta$ of 863 galaxies at $z=4-14$ using archival JWST/NIRSpec PRISM spectra obtained from major JWST GTO, ERS, and GO programs, including JADES, CEERS, and UNCOVER. Among these galaxies, we identify a remarkable galaxy at $z=9.25$, dubbed EBG-1, with a significantly blue UV slope $\beta=-2.99\pm0.15$, unlike the rest of the galaxies that exhibit red continua or ambiguous blue continua hindered by large uncertainties. We confirm that the $\beta$ value negligibly changes by the data reduction and fitting wavelength ranges for UV emission/absorption line masking. The extreme blue slope, $\beta=-3.0$, rules out significant contributions from dust extinction or AGN activity. Comparing with stellar and nebular emission models, we find that such a blue UV slope cannot be reproduced solely by stellar models even with very young, metal-poor, or top-heavy contiguous star formation associated with strong nebular continua making the UV slopes red, but with a high ionizing photon escape fraction, $f_\mathrm{esc}^\mathrm{ion} \gtrsim 0.5$, for a weak nebular continuum. While the H$\beta$ emission line is not detected, likely due to the limited sensitivity of the spectrum, we find moderately weak [O III] $\lambda\lambda$4959,5007 emission lines for the given star-formation rate ($3\, \mathrm{M_\odot}$ yr$^{-1}$) and stellar mass ($10^{8.0} \, \mathrm{M_\odot}$) that are about three times weaker than the average emission lines, again suggestive of the high ionizing photon escape fraction, $f_\mathrm{esc}^\mathrm{ion} \sim 0.7$ or more. EBG-1 would provide crucial insights into stellar and nebular continuum emission in high-redshift galaxies, serving as an example of the ionizing photon escaping site at the epoch of reionization.


**Translated Abstract**: 
我们研究了863个红移在4到14之间的星系的紫外线连续谱斜率β，使用从主要的JWST GTO、ERS和GO项目（包括JADES、CEERS和UNCOVER）获得的存档JWST/NIRSpec PRISM光谱。在这些星系中，我们发现了一个显著的星系，称为EBG-1，具备明显的蓝色紫外斜率β=-2.99±0.15，与其他星系的红色连续谱或因为较大的不确定性而模糊的蓝色连续谱不同。我们确认β值在数据处理和拟合波长范围（用于紫外光发射/吸收线掩蔽）变化时微不足道。极端的蓝色斜率β=-3.0排除了尘埃消光或活跃星系核（AGN）活动的显著贡献。根据恒星和星云发射模型，我们发现仅靠恒星模型无法再现如此蓝色的紫外斜率，甚至在极年轻、低金属丰度或顶部重的连续恒星形成与强星云连续谱相关的情况下，紫外斜率也会变红，而需要高的电离光子逃逸分数fesc^ion≳0.5，以实现弱星云连续谱。尽管Hβ发射线未被探测到，这可能是由于光谱的灵敏度有限，但我们发现[O III] λ4959,5007发射线的强度适中，对应的恒星形成率（3 M⊙ yr⁻¹）和恒星质量（10⁸.⁰ M⊙）比平均发射线弱三倍，进一步表明电离光子逃逸分数fesc^ion≈0.7或更高。EBG-1将为高红移星系的恒星和星云连续发射提供重要见解，并作为电离光子逃逸的实例，为再电离时期提供信息。

**Summary**:

- (1): 本文研究的背景是了解早期宇宙中星系的星形成过程，以及其释放的电离光子对此时宇宙再电离的贡献。

- (2): 以往的方法多采用光度测量来估算紫外斜率β，但此方法受到发射线污染的影响，导致不准确。本文提出的方法使用高质量的光谱数据，避免了此问题，通过对大样本的光谱分析，能够准确测量β值，因此动机合理。

- (3): 本文的贡献是发现并报告了一个具有极蓝紫外斜率的星系EBG-1，提供了一个可能的电离光子逃逸的示例，对高红移星系的研究和再电离过程理解具有重要意义。

- (4): 本文采用的方法包括使用JWST/NIRSpec PRISM光谱分析863个星系，以较准确地测量紫外线波长范围内的连续谱斜率β。

- (5): 本文的方法实现了EBG-1的紫外线斜率β的精确测量，该测量为-2.99±0.15。性能结果支持了作者探讨电离光子逃逸的目标及其对宇宙再电离的潜在影响。


## Exploring cosmological constraints of the weak gravitational lensing and galaxy clustering joint analysis in the CSST photometric survey
- **Url**: http://arxiv.org/abs/2410.19388v2
- **Authors**: ['Qi Xiong', 'Yan Gong', 'Xingchen Zhou', 'Hengjie Lin', 'Furen Deng', 'Ziwei Li', 'Ayodeji Ibitoye', 'Xuelei Chen', 'Zuhui Fan', 'Qi Guo', 'Ming Li', 'Yun Liu', 'Wenxiang Pei']
- **Abstrat**: We explore the joint weak lensing and galaxy clustering analysis from the photometric survey operated by the China Space Station Telescope (CSST), and study the strength of the cosmological constraints. We employ a high-resolution JiuTian-1G simulation to construct a partial-sky light cone to $z=3$ covering 100 deg$^2$, and obtain the CSST galaxy mock samples based on an improved semi-analytical model. We perform a multi-lens-plane algorithm to generate corresponding synthetic weak lensing maps and catalogs. Then we generate the mock data based on these catalogs considering the instrumental and observational effects of the CSST, and use the Markov Chain Monte Carlo (MCMC) method to perform the constraints. The covariance matrix includes non-Gaussian contributions and super-sample covariance terms, and the systematics from intrinsic alignments, galaxy bias, photometric redshift uncertainties, shear calibration, and non-linear effects are considered in the analysis. We find that the constraint result is comparable to that from Stage III surveys, and it can be significantly improved further in the full CSST survey with 17500 deg$^2$. This indicates the CSST photometric survey is powerful for exploring the Universe.


**Translated Abstract**: 

我们探索了由中国空间站望远镜（CSST）操作的光学调查的弱引力透镜和星系聚类的联合分析，并研究其对宇宙学约束力的强度。我们使用高分辨率的JiuTian-1G模拟构建了一个覆盖100度平方的z=3部分天空光锥，并基于改进的半解析模型获得了CSST星系伪样本。我们执行多透镜面算法来生成相应的合成弱透镜图和目录。然后，我们在考虑CSST的仪器和观测效应的基础上生成这些目录的伪数据，并使用马尔可夫链蒙特卡罗（MCMC）方法进行约束。协方差矩阵包括非高斯贡献和超样本协方差项，并考虑了内在排列、星系偏置、光谱红移不确定性、剪切校准和非线性效应等系统误差。我们发现约束结果与阶段III调查的结果相当，并且在17500度平方的完整CSST调查中可以显著改善。这表明CSST光学调查在探索宇宙方面具有强大力量。

**Summary**:

- (1): 本文研究背景为宇宙学的观察能力得到了显著提升，特别是关于宇宙大尺度结构（LSS）以及暗能量和暗物质的探索。

- (2): 过去的方法主要依赖于单独使用星系聚类或弱引力透镜进行宇宙学约束，这样的分析忽略了两者的联合效应。提出的方法通过联合分析这两者来克服这一局限，展示了更强的约束能力。这一方法充分强调了星系聚类和弱透镜在获取宇宙学信息中的协同作用。

- (3): 本文的贡献在于展示了CSST光学调查在弱透镜和星系聚类联合分析中的有效性，提供了具有竞争力的宇宙学约束结果，并指出未来调查可以进一步提高这些约束。

- (4): 本文采用的研究方法包括在JiuTian-1G模拟的基础上构建部分天空光锥，生成CSST星系伪样本，并使用MCMC方法对宇宙学和系统参数进行约束分析。

- (5): 本文旨在通过模仿CSST光学调查中的数据，生成关于弱透镜和星系聚类的功率谱，并取得了与阶段III调查相当的性能，表明其方法能够支持其目标。


## One-Dimensional Relativistic Self-Gravitating Systems
- **Url**: http://arxiv.org/abs/2504.06515v1
- **Authors**: ['Robert B. Mann']
- **Abstrat**: One of the oldest problems in physics is that of calculating the motion of $N$ particles under a specified mutual force: the $N$-body problem. Much is known about this problem if the specified force is non-relativistic gravity, and considerable progress has been made by considering the problem in one spatial dimension. Here, I review what is known about the relativistic gravitational $N$-body problem. Reduction to one spatial dimension has the feature of the absence of gravitational radiation, thereby allowing for a clear comparison between the physics of one-dimensional relativistic and non-relativistic self-gravitating systems. After describing how to obtain a relativistic theory of gravity coupled to $N$ point particles, I discuss in turn the two-body, three-body, four-body, and $N$-body problems. Quite general exact solutions can be obtained for the two-body problem, unlike the situation in general relativity in three spatial dimensions for which only highly specified solutions exist. The three-body problem exhibits mild forms of chaos, and provides one of the first theoretical settings in which relativistic chaos can be studied. For $N\geq 4$, other interesting features emerge. Relativistic self-gravitating systems have a number of interesting problems awaiting further investigation, providing us with a new frontier for exploring relativistic many-body systems.


**Translated Abstract**: 

物理学中最古老的问题之一是计算 N 粒子在特定相互作用下的运动：N 体问题。如果指定的力是非相对论重力，则对这个问题已有大量研究，并且通过考虑一维情况取得了相当大的进展。本文回顾了相对论重力 N 体问题的已知情况。缩减到一维空间的特征是缺乏引力辐射，从而使得一维相对论和非相对论自引力系统的物理特性之间可以进行清晰比较。在描述如何获得耦合 N 个点粒子的相对论重力理论后，我依次讨论了二体、三体、四体和 N 体问题。与三维广义相对论中的高度特定解决方案不同，二体问题可以获得非常一般的精确解。三体问题表现出温和形式的混沌，为研究相对论混沌提供了最早的理论框架之一。对于 N≥4 的情况，出现了其他有趣的特征。相对论自引力系统有许多有待进一步研究的问题，为探索相对论多体系统提供了新的前沿。

**Summary**:

- (1): 本文研究 N 体问题，即 N 粒子在特定相互作用下的运动，特别关注相对论重力和一维自引力系统。

- (2): 过去的研究主要集中在非相对论的重力上，并未涵盖相对论框架，造成对相对论影响的忽视。本文通过一维空间的视角提出了相对论自引力的框架，避免了引力辐射的影响，从而能更清晰地理解系统行为。

- (3): 论文的贡献在于引入了相对论自引力 N 体问题的框架，并明确区分了二体、三体和多体问题的特性，为未来相对论多体系统的研究奠定了基础。

- (4): 本文的研究方法包括建立耦合 N 个点粒子的相对论重力理论，并逐步分析不同体积情况下的行为，特别是结合了混沌理论的视角。

- (5): 方法针对二体和三体问题提供了较为彻底的解决方案，虽然 N≥4 的情况未完全解决，但展示了相对论自引力系统的复杂性，表现支持了作者探索的目标。


## Extraplanar [C II] and Halpha in the Edge-On Galaxy NGC 5775
- **Url**: http://arxiv.org/abs/2504.06483v1
- **Authors**: ['William T. Reach', 'Dario Fadda', 'Richard J. Rand', 'Gordon J. Stacey']
- **Abstrat**: Spiral galaxies are thin and susceptible to being disrupted vertically. The largest star clusters, and nuclear starbursts, generate enough energy from winds and supernovae to send disk material to the halo. % METHODS Observations of edge-on galaxies allow for the clearest view of vertical disruptions. We present new observations of the nearby, edge-on galaxy NGC 5775 with SOFIA [C II] 157.7 micron and archival images from Hubble in Halpha to search for extraplanar gas. The extraplanar [C II] extends 2 kpc from the midplane over much of the star-forming disk. The extraplanar [C II] at 2 kpc from the midplane approximately follows the rotation of the disk, with a lag of approximately 40 km/s; this lag is similar to what has been previously reported in Halpha. Significant vertical extensions (to 3 kpc) are seen on the northeast side of the galaxy, potentially due to super star clusters in the NGC 5775 disk combined with gravitational interaction with the companion galaxy NGC 5774. The Halpha narrow-band image reveals a narrow plume that extends 7 kpc from the nucleus and is almost exactly perpendicular to the disk. The plume shape is similar to that seen from the comparable galaxy NGC 3628 and may arise from the nuclear starburst. Alternatively, the Halpha plume could be a relic of past activity.


**Translated Abstract**: 

螺旋星系是薄的，易于在垂直方向上发生破坏。最大的星团和核星暴产生的风和超新星能量足以将盘面物质送入晕中。 边缘观测星系提供了观察垂直破坏的最佳视角。我们使用SOFIA对邻近的边缘观星系NGC 5775进行了新的观测，获取了[C II] 157.7微米的图像，并结合Hubble的Hα归档图像，寻找外平面气体。外平面[C II]在星形成盘的绝大部分范围内延伸到中平面之上2 kpc。距离中平面2 kpc的外平面[C II]大致跟随盘的自转，具有大约40 km/s的滞后；这一滞后与以往在Hα中报告的相似。东北侧明显的垂直延伸（达到3 kpc）可能是由于NGC 5775盘面中的超星团结合邻近星系NGC 5774的引力交互导致的。Hα窄带图像显示出一条从核心向外延伸7 kpc并几乎垂直于盘面的狭窄羽流。该羽流形状与可比星系NGC 3628的羽流形状相似，可能源于核星暴。或者，Hα羽流也可能是过去活动的遗迹。

**Summary**:

- (1): 本文研究背景为螺旋星系易受到垂直破坏，主要由于星团和超新星的能量影响星系结构和气体分布。

- (2): 过去的方法包括对边缘观星系的观测，存在对垂直气体分布的理解不足和缺乏系统性分析的问题。本文提出的新方法采用了SOFIA技术与Hubble图像结合的方式，旨在解决外平面气体的探测和分析不足。

- (3): 本文的贡献在于揭示了NGC 5775中外平面[C II]与Hα气体的分布和运动，尤其是在理解气体如何被星暴驱动向外扩展方面提供了新视角。

- (4): 本文的研究方法结合了最新的SOFIA观测数据和现有的Hubble图像，对NGC 5775进行了详细的气体分布及运动分析，特别是在不同高度的外平面气体。

- (5): 本文的研究任务主要关注外平面气体的分布与运动情况，获得的数据支持了对星系演化过程的深入理解，其性能在理论推导和观测匹配上都显示出较好的结果。


## Analytic calculation of dynamical friction for Plummer sphere in ultralight dark matter
- **Url**: http://arxiv.org/abs/2504.06448v1
- **Authors**: ['O. V. Barabash', 'T. V. Gorkavenko', 'V. M. Gorkavenko', 'O. M. Teslyk', 'N. S. Yakovenko', 'A. O. Zaporozhchenko', 'E. V. Gorbar']
- **Abstrat**: The dynamical friction force acting on a spatially extended probe (globular clusters and dwarf galaxies) moving in the environment of ultralight bosonic dark matter in the state of the Bose-Einstein condensate is determined. Modeling the probe as a Plumer sphere of radius $l_p$, the radial and tangential components of the dynamic friction force are found in an analytic form, which reduce in the limit $l_p \to 0$ to the corresponding analytic expressions obtained in the literature in the case of a point probe. The dependence of dynamical friction force on boson particle mass $m$ was analyzed and found to be non-monotonous in the interval $10^{-23} - 10^{-21}$eV.


**Translated Abstract**: 

本文确定了在超轻玻色暗物质环境中，作用于空间扩展探测器（如球状星团和矮星系）上的动力摩擦力。将探测器建模为半径为$l_p$的Plummer球，找到动力摩擦力的径向和切向分量的解析形式。在$l_p \to 0$的极限下，该结果还原为文献中对点探测器获得的相应解析表达式。分析了动力摩擦力对玻色子粒子质量$m$的依赖性，并发现其在$10^{-23}$至$10^{-21}$eV的范围内呈现非单调性。

**Summary**:

- (1): 本文的研究背景涉及到超轻暗物质（ULDM）对银河环境中物体运动的影响，特别是其对球状星团和矮星系的动力摩擦作用。

- (2): 过去的方法主要针对点探测器研究动力摩擦，但未考虑空间扩展对象的影响，导致对于更大规模物体（如球状星团）的摩擦力评估不足。本文通过建模为Plummer球，提供了一种新方法，能够解析计算扩展探测器的动力摩擦分量，有效解决了以往只针对点探测器的局限。

- (3): 本文的贡献在于提供了一种针对超轻玻色暗物质环境中运动的Plummer球的动力摩擦力的解析解，并探讨了其对相关物理现象的影响。

- (4): 本文提出的研究方法包括使用线性响应理论来计算运动Plummer球的动力摩擦力，并得到径向和切向分量的解析解。

- (5): 本文的研究任务是分析在超轻玻色暗物质环境中运动的Plummer球的动力摩擦力。通过对动力摩擦力与玻色子质量的依赖性进行分析，成果表明在$10^{-23}$至$10^{-21}$eV范围内表现出非单调性，支持了对该物理现象的深入理解。


# galaxies
## The Lyman-alpha and Continuum Origins Survey II: the uneventful journey of escaping Ly$α$ and ionizing radiation through the neutral ISM and CGM of galaxies
- **Url**: http://arxiv.org/abs/2504.07074v1
- **Authors**: ['A. Saldana-Lopez', 'M. J. Hayes', 'A. Le Reste', 'C. Scarlata', 'J. Melinder', 'A. Henry', 'R. Amorin', 'H. Atek', 'O. Bait', 'J. Chisholm', 'A. E. Jaskot', 'I. Jung', 'Zhiyuan Ji', 'L. Komarova', 'F. Leclercq', 'G. Ostlin', 'A. Runnholm', 'T. X. Thuan', 'X. Xu']
- **Abstrat**: One of the current challenges in galaxy evolution studies is to establish the mechanisms that govern the escape of ionizing radiation from galaxies. In this work, we investigate the connection between Lyman Continuum (LyC) escape and the conditions of the Circumgalactic Medium (CGM), as probed by Ly$\alpha$ halos (LAHs) in emission. We use Ly$\alpha$ and UV continuum imaging data from the Lyman alpha and Continuum Origins Survey (LaCOS), targeting 42 nearby ($z \simeq 0.3$), star-forming galaxies with LyC observations (escape fractions of $f_{\rm esc}^{\rm LyC} \simeq 0.01-0.49$). LaCOS galaxies show extended Ly$\alpha$ emission ubiquitously, with LyC emitters (LCEs) having more compact Ly$\alpha$ morphologies relative to the UV size than non-LCEs, and Ly$\alpha$ spatial offsets that do not exceed the extent of the UV continuum. We model the diffuse LAHs using a combined Sersic plus exponential 2D profile, and find that the characteristic scale length of the Ly$\alpha$ is ten times the scale length of the UV, on average. We unveil a tight anti-correlation between $f_{\rm esc}^{\rm LyC}$ and the Ly$\alpha$ Halo Fraction (HF, or contribution of the halo to the total Ly$\alpha$ luminosity), that we propose as a new LyC indicator. Our observations also show that the HF scales positively with the neutral gas in the ISM, revealing a picture in which Ly$\alpha$ and LyC photons in LCEs emerge through clear sight-lines directly from the central starbursts and, in the case of Ly$\alpha$, minimizing the number of scattering interactions in the CGM. The properties of LAHs in LaCOS resemble those of LAHs at $z \geq 3$, suggesting a lack of evolution in the $f_{\rm esc}^{\rm LyC}$ predictors that rely on the spatial properties of Ly$\alpha$, and ensuring the applicability of these indicators to observations of high-redshift galaxies.


**Translated Abstract**: 

当前星系演化研究面临的一个挑战是确立控制离子辐射从星系逃逸的机制。在这项研究中，我们调查了Lyman Continuum（LyC）逃逸与由Lyman-alpha（Lyα）光晕（LAHs）所探测的环状星系介质（CGM）条件之间的联系。我们利用来自Lyman alpha and Continuum Origins Survey（LaCOS）的Lyα和紫外续影像数据，针对42个附近（z ≈ 0.3）正在形成恒星的星系进行研究，并获得LyC观测（逃逸分数f_esc^LyC ≈ 0.01-0.49）。LaCOS星系普遍展现出扩展的Lyα发射，LyC发射者（LCEs）的Lyα形态相对于紫外光的尺寸更加紧凑，且Lyα的空间偏移未超过紫外续影像的范围。我们使用组合Sersic与指数2D模型来模拟扩散的LAHs，发现Lyα的特征尺度长度平均为紫外光的十倍。我们揭示了LyC逃逸分数f_esc^LyC与Lyα光晕分数（HF）之间紧密的反相关关系，并提出这作为新的LyC指示器。我们的观测还显示HF与ISM中的中性气体正相关，呈现出这样一个图景：在LCEs中，Lyα和LyC光子直接从中心恒星形成区清晰出现，对于Lyα来说，最小化了在CGM中散射互动的数量。LaCOS中LAHs的性质与z ≥ 3时的LAHs相似，表明依赖于Lyα空间性质的f_esc^LyC指示器没有演变，从而确保这些指示器可用于高红移星系的观测。

**Summary**:

- (1): 本文研究的背景是探讨控制离子辐射从星系逃逸的机制，以理解宇宙再电离的过程。

- (2): 过去的方法主要依赖LyC和Lyα的观测，而存在对这些光子与星系环境相互作用的理解不足的问题。本研究提出通过Lyα光晕与LyC逃逸的关系来建立新的LyC指示器，这一方法克服了对中性气体和星系成分影响的忽视。

- (3): 本文的贡献在于揭示了Lyα光晕分数HF与LyC逃逸分数之间的反相关关系，并提出这些作为新的超强LyC指示器，适用于高红移星系的观察。

- (4): 本文研究方法包括使用LaCOS的Lyα和紫外影像数据，针对42个附近星系进行Lyα光晕和LyC逃逸的定量分析，并结合模型拟合获得Lyα和UV的空间结构特征。

- (5): 本研究任务是在LyC逃逸的观测中揭示与Lyα光晕的关系，性能显示Lyα光晕分数HF与LyC逃逸呈明显的反相关趋势，支持了研究目标的实现。


## New empirical mass-loss recipe for UV radiation line-driven winds of hot stars across various metallicities
- **Url**: http://arxiv.org/abs/2504.07073v1
- **Authors**: ['D. Pauli', 'L. M. Oskinova', 'W. -R. Hamann', 'A. A. C. Sander', 'Jorick S. Vink', 'M. Bernini-Peron', 'J. Josiek', 'R. R. Lefever', 'H. Sana', 'V. Ramachandran']
- **Abstrat**: The winds of massive stars remove a significant fraction of their mass, strongly impacting their evolution. As a star evolves, the rate at which it loses mass changes. In stellar evolution codes, different mass-loss recipes are employed for different evolutionary stages. The choice of the recipes is user-dependent and the conditions for switching between them are poorly defined. Focusing on hot stars, we aim to produce a physically motivated, empirically calibrated mass-loss recipe suitable for a wide range of metallicities. We want to provide a ready-to-use universal recipe that eliminates the need for switching between recipes for hot stars during stellar evolution calculations. We compile a sample of hot stars with reliable stellar and wind parameters in the Galaxy and the Magellanic Clouds. The sample is used to determine the dependence of the mass-loss rate on the basic stellar parameters. We find that independent of evolutionary stage and temperature, the wind mass-loss rate is a function of the electron-scattering Eddington parameter ($\Gamma_e$) and metallicity (Z), being in line with expectations of radiation-driven wind theory. Our derived scaling relation provides an adequate ($\Delta$log($\dot{M}$/(M$_\odot$/yr)) = 0.43) and broadly applicable mass-loss recipe for hot stars. The newly derived mass-loss recipe covers nearly the entire parameter space of hot stars with UV radiation-driven winds and eliminates the need for interpolation between mass-loss formulae at different evolutionary stages when applied in stellar evolution models. Examples of stellar evolution calculations using our new recipe reveal that the predictions on the ionizing fluxes and final fates of massive stars, especially at low metallicity, differ significantly from models that use the standard mass-loss rates, impacting our understanding of stellar populations at low metallicity and in the young Universe.


**Translated Abstract**: 

大质量星体的风会移除大量质量，显著影响其演化。随着星体的演化，质量损失的速率会改变。在恒星演化模型中，不同的质量损失方案在不同的演化阶段中被采用。这些方案的选择依赖于用户，且在切换条件上定义不清。本研究聚焦于热星，旨在生成一种适用于广泛金属丰度、物理上有依据且经验校准的质量损失方案，提供一种即用的通用方案，消除在恒星演化计算中切换热星质量损失方案的需要。我们收集了银河系和大麦哲伦云中热星的可靠恒星与风参数样本。我们发现，无论演化阶段和温度如何，风的质量损失率都与电子散射Eddington参数（$\Gamma_e$）和金属丰度（Z）相关，符合辐射驱动风理论的预期。我们推导的尺度关系提供了一套适用性广泛的热星质量损失方案，覆盖了热星的几乎所有参数空间，并在输入恒星演化模型时消除了不同演化阶段间的质量损失公式的插值需求。使用我们新方案的恒星演化计算示例显示，特别是在低金属丰度下，针对电离通量和大质量恒星最终命运的预测与使用标准质量损失率的模型存在显著差异，这影响了我们对低金属丰度恒星群体及年轻宇宙的理解。

**Summary**:

- (1): 本文的研究背景是大质量恒星通过强烈的离子化辐射和强大的恒星风影响其周围环境，从而在星体形成和星系化学丰度的贡献中具有重要作用。

- (2): 过去的方法通常采用特定群体的分段质量损失方案，不同演化阶段对应不同的公式，导致模型之间存在突变和过于简单的插值。这些方法在低金属丰度情况下过高估计质量损失率，产生了显著误差。本文提出的方案旨在提供普适的质量损失表达式，消除不同演化阶段之间的切换需求，并具有明确的物理动机。

- (3): 本文的贡献在于提供了一种新型的热星质量损失方案，该方案不仅适用性广泛，还能准确覆盖大部分热星的质量损失参数空间，符合辐射驱动风理论。

- (4): 本文的研究方法是收集银河系和大麦哲伦云中热星的可靠恒星和风参数样本，分析这些样本以揭示质量损失率与基本恒星参数之间的关系，基于电子散射Eddington参数和金属丰度推导出新的质量损失关系。

- (5): 本文的方法在预测大质量星体的电离通量和最终命运方面显示出显著的改善，特别是在低金属丰度条件下。该性能支持理解青年宇宙和低金属丰度星群体的目标。


## Non-Gaussianity of Tensor Induced Density Perturbations
- **Url**: http://arxiv.org/abs/2504.07063v1
- **Authors**: ['Mariam Abdelaziz', 'Pritha Bari', 'Sabino Matarrese', 'Angelo Ricciardone']
- **Abstrat**: We investigate the non-Gaussianity of second-order matter density perturbations induced by primordial gravitational waves (GWs). These tensor-induced scalar modes arise from local fluctuations in the GWs energy density, which is quadratic in tensor perturbations. The resulting second-order density contrast follows a chi-squared distribution, naturally exhibiting significant non-Gaussianity. We compute the bispectrum of these tensor-induced scalar modes and analyze its dependence on various primordial GWs power spectra, including scale-invariant, blue-tilted, Gaussian-bump, and monochromatic sources. We find that the bispectrum shape is inherently sensitive to the underlying GWs spectrum by construction. In particular, Gaussian-bump and monochromatic sources produce a strong signal peaking in the equilateral configuration, similar to the effect of scalar-induced tensor modes. Our findings reveal a new way to probe primordial GWs via galaxy surveys and highlight a unique feature of tensor-induced density perturbations, otherwise mimicking linear ones on sub-horizon scales.


**Translated Abstract**: 

我们研究了由原始引力波（GWs）诱导的二阶物质密度扰动的非高斯性。这些张量诱导的标量模式源于GWs能量密度的局部波动，涉及张量扰动的平方。由此产生的二阶密度对比呈现卡方分布，自然表现出显著的非高斯性。我们计算了这些张量诱导的标量模式的双谱，并分析其对各种原始GWs功率谱的依赖性，包括尺度不变、蓝倾斜、高斯峰和单色源。我们发现双谱形状在构造上对基础GWs谱非常敏感。特别是，高斯峰和单色源产生的信号在等边配置中具有强信号，类似于标量诱导张量模式的效应。我们的发现揭示了一种通过星系调查探测原始GWs的新方法，并突出了张量诱导密度扰动的一个独特特征，此特征在超地平尺度上模仿线性扰动。

**Summary**:

- (1): 本文的研究背景是通过考虑张量（引力波）对宇宙大尺度结构的影响，探索如何从物质密度扰动中提取原始引力波的信息。

- (2): 以往的研究主要集中在原始引力波对宇宙微波背景辐射（CMB）的影响及其直接探测，面临数据解释困难和信号与噪声的区分问题。该研究提出通过二阶标量扰动来间接探测引力波，解决了之前方法中对线性测量的依赖。

- (3): 本文的贡献在于计算和分析张量诱导的标量模式的双谱形状，并展示了通过对大规模结构的观测能有效探测原始引力波。

- (4): 本文的方法论包括对张量诱导的标量模式的二阶密度扰动进行数学建模，计算其卡方分布，并针对不同类型的引力波谱设计实验。

- (5): 本文的方法针对二阶物质密度扰动的观测任务，实现了识别和分析张量诱导标量模式的能力，能够提供关于原始引力波的有意义限制，支持研究目标。


## The Lyman-alpha and Continuum Origins Survey I: Survey description and Ly$α$ imaging
- **Url**: http://arxiv.org/abs/2504.07056v1
- **Authors**: ['Alexandra Le Reste', 'Claudia Scarlata', 'Matthew Hayes', 'Jens Melinder', 'Alberto Saldana-Lopez', 'Axel Runnholm', 'Yu-Heng Lin', 'Ricardo O. Amorín', 'Hakim Atek', 'Sanchayeeta Borthakur', 'Cody A. Carr', 'Sophia R. Flury', 'Mauro Giavalisco', 'Alaina Henry', 'Anne E. Jaskot', 'Zhiyuan Ji', 'Intae Jung', 'Floriane Leclercq', 'Rui Marques-Chaves', 'Stephan R. McCandliss', 'M. S. Oey', 'Göran Östlin', 'Swara Ravindranath', 'Daniel Schaerer', 'Trinh X. Thuan', 'Xinfeng Xu']
- **Abstrat**: Understanding the mechanisms driving the escape of ionizing or Lyman continuum (LyC) emission from the interstellar medium of galaxies is necessary to constrain the evolution of Reionization, and the sources responsible for it. While progress has been made into identifying the global galaxy properties linked to the escape fraction of ionizing radiation, f$_{esc}^{LyC}$, little is currently known about how spatially resolved galaxy properties impact this parameter. We present Hubble Space Telescope (HST) imaging data obtained as part of the Lyman $\alpha$ and Continuum Origins Survey (LaCOS). LaCOS consists of HST imaging in 5 filters covering rest-frame optical and UV bands for a subsample of 42 galaxies in the Low redshift Lyman Continuum Survey, 22 being Lyman continuum emitters ($f_{esc}^{LyC}=0.01-0.49$). These data allow for investigations of the connection between sub-kpc stellar and nebular properties, including Ly$\alpha$ emission, and $f_{esc}^{LyC}$. Here, we describe the sample selection, observations and data reduction methods. Additionally, we present results on the link between global and resolved Ly$\alpha$ photometry and $f_{esc}^{LyC}$. We find similar trends between global photometric observables ($L_{Ly\alpha}$, $EW_{Ly\alpha}$, $f_{esc}^{Ly\alpha}$, $r_{50}$, $\Sigma_{SFR}$) and $f_{esc}^{LyC}$ as previously found with spectroscopy, but the correlations generally show a slightly smaller degree of correlations. However, we do find strong correlations between Ly$\alpha$ observables ($L_{Ly\alpha}$,$EW_{Ly\alpha}$) and $f_{esc}^{LyC}$ when measured in a small aperture around the brightest UV source in each galaxy. We interpret these results as evidence that LyC photons escaping on the line-of-sight are contributed by a small number of UV-bright compact regions in most galaxies in our sample.


**Translated Abstract**:  
理解驱动星系间介质中离子化或赖曼连续（LyC）辐射逃逸机制是限制再电离演化及其来源的必要条件。尽管已在全球星系特性与离子辐射逃逸分数f$_{esc}^{LyC}$之间的联系上取得了一定进展，但目前对空间分辨的星系特性如何影响这一参数知之甚少。我们展示了作为赖曼 $\alpha$ 和连续源研究（LaCOS）一部分获得的哈勃太空望远镜（HST）成像数据。LaCOS包含对42个星系的5个滤波器下的HST成像，这些星系是低红移赖曼连续研究的一部分，其中22个是赖曼连续辐射源（f$_{esc}^{LyC}=0.01-0.49$）。这些数据能够研究亚千秒差距的恒星和气体特性（包括Ly$\alpha$辐射）与$f_{esc}^{LyC}$之间的关系。我们在此描述样本选择、观测和数据处理方法。此外，我们展示了全球和分辨率Ly$\alpha$光度与$f_{esc}^{LyC}$之间的联系。我们发现，与以往光谱学研究中发现的趋势相似，全球光度观测量（L$_{Ly\alpha}$，EW$_{Ly\alpha}$，f$_{esc}^{Ly\alpha}$，r$_{50}$，$\Sigma_{SFR}$）与$f_{esc}^{LyC}$之间一致，但相关性通常较弱。然而，当在每个星系中最亮的UV源周围的小孔径内测量时，我们发现Ly$\alpha$观测量（L$_{Ly\alpha}$，EW$_{Ly\alpha}$）与$f_{esc}^{LyC}$之间存在强相关性。我们将这些结果解释为大多数我们样本中的星系中，沿视线逃逸的LyC光子由少量UV明亮的紧凑区域贡献。

**Summary**:

  - (1): 本文的研究背景是理解导致离子化辐射逃逸的机制，以约束宇宙再电离的发展及相关源。

  - (2): 过去的方法主要依赖于全球星系特性与离子辐射逃逸分数之间的统计关系，然而这些方法无法揭示空间分辨的信息。本文提出的方法通过使用HST成像数据和局部Ly$\alpha$观测，提供了空间分辨的星系特性与$f_{esc}^{LyC}$的直接关联，并且该方法有效克服了基于大范围获取数据的限制。

  - (3): 本文的贡献在于首次通过HST观察，揭示了Ly$\alpha$发射和离子化辐射逃逸之间的更精细的空间联系，强调了UV明亮区域对该现象的重要性。

  - (4): 本文的研究方法涵盖了样本选择、观测和数据处理，通过分析从HST获取的五个过滤器的成像数据，研究每个星系中Ly$\alpha$发射与$f_{esc}^{LyC}$的关系。

  - (5): 本文在Ly$\alpha$与$f_{esc}^{LyC}$的相关性研究上表现出强劲的相关性，这为了解在星系中LyC逃逸的机制提供了重要数据，表现出的方法能够支持他们的研究目标。


## Microlensing at Cosmological Distances: Event Rate Predictions in the Warhol Arc of MACS 0416
- **Url**: http://arxiv.org/abs/2504.07039v1
- **Authors**: ['J. M. Palencia', 'J. M. Diego', 'L. Dai', 'M. Pascale', 'R. Windhorst', 'A. M. Koekemoer', 'Sung Kei Li', 'B. J. Kavanagh', 'Fengwu Sun', 'Amruth Alfred', 'Ashish K. Meena', 'Thomas J. Broadhurst', 'Patrick L. Kelly', 'Derek Perera', 'Hayley Williams', 'Adi Zitrin']
- **Abstrat**: Highly magnified stars ($\mu$ $>$ 100) are now outinely identified as transient events at cosmological distances thanks to microlensing by intra-cluster stars near the critical curves of galaxy clusters. Using the {\it James Webb} Space Telescope (JWST) in combination with the {\it Hubble} Space Telescope (HST), we outline here an analytical framework that is applied to the Warhol arc (at $z=0.94$) in the MACS 0416 galaxy cluster (at $z=0.396)$ where over a dozen microlensed stars have been detected to date. This method is general and can be applied to other lensed arcs. Within this lensed galaxy we fit the spatially resolved SED spanned by eight JWST-NIRCam filters combined with three ACS filters, for accurate lensed star predictions in 2D. With this tool we can generate 2D maps of microlensed stars for well resolved arcs in general, including dependence on wavelength and limiting apparent magnitude, for comparison with with planned cadenced campaigns for JWST and Hubble, for constraining directly the IMF and the level of dark matter substructure.


**Translated Abstract**: 

由于星系团内的恒星通过引力微透镜现象导致的高度放大（μ > 100），现在可以在宇宙距离中常规地识别这些瞬时事件。利用詹姆斯·韦伯太空望远镜（JWST）与哈勃太空望远镜（HST）的结合，我们在MACS 0416星系团（z = 0.396）的Warhol弧（z = 0.94）中概述了一种分析框架，当前已发现十多颗微透镜恒星。该方法是通用的，可以应用于其他透镜弧。在该透镜星系中，我们通过结合八个JWST-NIRCam滤光片与三个ACS滤光片拟合空间分辨的SED，以准确预测二维的微透镜恒星。利用此工具，我们可以针对已良好解析的弧生成微透镜恒星的二维图，并考虑波长及限制的表观星等，以便与JWST和Hubble的计划观测进行比较，从而直接约束初始质量函数（IMF）和暗物质亚结构的水平。

**Summary**:

- (1): 本文的研究背景是星系团作为宇宙中最强引力透镜的作用，能够放大来自遥远星系的光线，从而使微透镜事件变得可见。

- (2): 过去的方法主要依赖于传统的图像和光谱分析，存在对微透镜事件的捕捉效率低和解析度不足的问题。提出的方法结合JWST与HST的观测数据，更高效地构建二维微透镜恒星的预测图，从而解决了传统方法的这些问题，并具有良好的动机。

- (3): 本文的贡献在于提出了一种新的分析框架，使得在MACS 0416星系团中能够高效且准确地识别和预测微透镜恒星，推进对宇宙早期星体和暗物质的研究。

- (4): 该研究方法论包括结合JWST和HST的数据，对微透镜恒星的空间分布进行详细的光谱分布拟合，并生成二维的微透镜恒星图。

- (5): 本文的方法在预测微透镜恒星及其事件率方面取得了显著成果，能够有效支持研究初始质量函数（IMF）和暗物质亚结构的目标。


## Recent star formation in 0.5<z<1.5 quiescent galaxies
- **Url**: http://arxiv.org/abs/2504.05511v2
- **Authors**: ['Michael J. Rutkowski', 'Bonnabelle Zabelle', 'Tyler Hagen', 'Seth Cohen', 'Christopher Conselice', 'Norman Grogin', 'Yicheng Guo', 'Matthew Hayes', 'Sugata Kaviraj', 'Anton Koekemoer', 'Ray A. Lucas', 'Kameswara Bharadwaj Mantha', 'Alec Martin', 'Vihang Mehta', 'Bahram Mobasher', 'Nimish Hathi', 'Kalina V. Nedkova', "Robert O'Connell", 'Marc Rafelski', 'Claudia Scarlata', 'Harry I. Teplitz', 'Xin Wang', 'Rogier Windhorst', 'Aaron Yung', 'the UVCANDELS Team']
- **Abstrat**: Observations of massive, quiescent galaxies reveal a relatively uniform evolution: following prolific star formation in the early universe, these galaxies quench and transition to their characteristic quiescent state in the local universe. The debate on the relative role and frequency of the process(es) driving this evolution is robust. In this letter, we identify 0.5<z<1.5 massive, quiescent galaxies in the HST/UVCANDELS extragalactic deep fields using traditional color selection methods and model their spectral energy distributions, which incorporates novel UV images. This analysis reveals ~15% of massive, quiescent galaxies have experienced minor, recent star formation(<10% of total stellar mass within the past ~1Gyr). We find only a marginal, positive correlation between the probability for recent star formation and a measure of the richness of the local environment from a statistical analysis. Assuming the recent star formation present in these quiescent galaxies is physically linked to the local environment, these results suggest only a minor role for dynamic external processes (galaxy mergers and interactions) in the formation and evolution of these galaxies at this redshift.


**Translated Abstract**: 观察大质量静息星系揭示出一种相对统一的演化过程：在早期宇宙经历了大量恒星形成后，这些星系趋于冷却，转变为在当地宇宙中特征性的静息状态。推动这种演化过程的相对作用和频率的争论仍然激烈。在这封信中，我们使用传统的颜色选择方法和新颖的紫外图像，在HST/UVCANDELS外星系深场中识别出0.5 < z < 1.5的大质量静息星系，并对其光谱能量分布进行建模。分析结果显示，约15%大质量静息星系在过去约1 Gyr内经历了小规模的近期恒星形成（<10%的总恒星质量）。通过统计分析，我们发现近期恒星形成的可能性与局部环境的丰富度之间仅存在边际上的正相关假设。这些结果表明，假设这些静息星系中存在的近期恒星形成与当地环境物理相关，动态外部过程（如星系并合和相互作用）在这些星系的形成和演化中可能仅起到次要作用。

**Summary**:

- (1): 该文章的研究背景是对于高红移星系（特别是大质量静息星系）向静息状态转化的普遍演化模型的理解，历史上对其演化历史的观察证据多样且复杂。

- (2): 过去的研究主要依赖于光学颜色、推断的星形成历史等方法，这些方法存在对物理过程理解的局限性。该论文通过结合新颖紫外图像和光谱能量分布建模的方法，解决了过去数据量不足的问题，并提供了更详细的近期恒星形成信息。

- (3): 论文的贡献在于识别0.5 < z < 1.5的大质量静息星系中约15%经历了小规模的近期恒星形成，同时评估了这些星系与局部环境之间的关系。

- (4): 该论文的研究方法利用传统颜色选择与新型紫外图像的结合，通过HST/UVCANDELS外星系深场数据识别和分析大质量静息星系的光谱特征。

- (5): 论文的任务为识别近期恒星形成的星系，所取得的结果显示约15%的静息星系经历了近期星形成，支持了提供的新理论，即动态外部过程在这些星系的形成和演化中作用较小。


## Binarity at LOw Metallicity (BLOeM): Enhanced multiplicity of early B-type dwarfs and giants at $Z=0.2\,{\rm Z}_\odot$
- **Url**: http://arxiv.org/abs/2503.21936v3
- **Authors**: ['J. I. Villaseñor', 'H. Sana', 'L. Mahy', 'T. Shenar', 'J. Bodensteiner', 'N. Britavskiy', 'D. J. Lennon', 'M. Moe', 'L. R. Patrick', 'M. Pawlak', 'D. M. Bowman', 'P. A. Crowther', 'S. E. de Mink', 'K. Deshmukh', 'C. J. Evans', 'M. Fabry', 'M. Fouesneau', 'G. Holgado', 'N. Langer', 'J. Maíz Apellániz', 'I. Mandel', 'L. M. Oskinova', 'D. Pauli', 'V. Ramachandran', 'M. Renzo', 'H. -W. Rix', 'D. F. Rocha', 'A. A. C. S. Sander', 'F. R. N. Schneider', 'K. Sen', 'S. Simón-Díaz', 'J. Th. van Loon', 'S. Toonen', 'J. S. Vink']
- **Abstrat**: Early B-type stars ($M_i=8-15$ M$_\odot$) are frequently in multiple systems, as evidenced by spectroscopic campaigns in the Milky Way (MW) and the Large Magellanic Cloud (LMC). Previous studies have shown no strong metallicity dependence in the close-binary (a>10 au) fraction or orbital-period distributions between the MW's solar metallicity (Z$_\odot$) and that of the LMC (Z=0.5 Z$_\odot$). However, similar analyses in more metal-poor environments are still scarce. We focus on 309 early B-type stars (luminosity classes III-V) from the Binarity at LOw Metallicity campaign in the Small Magellanic Cloud (SMC, Z=0.2 Z$_\odot$) using VLT/FLAMES multi-epoch spectroscopy. By applying binary detection criteria consistent with previous works, we identify 153 stars (91 SB1, 59 SB2, 3 SB3) exhibiting significant radial-velocity (RV) variations, resulting in an observed multiplicity fraction of $f^{obs}_{mult}=50\pm3\%$. Using Monte Carlo simulations to account for observational biases, we infer an intrinsic close-binary fraction of $f_{mult}=80\pm8\%$. A Markov chain Monte Carlo analysis of the peak-to-peak RV distribution ($\Delta{\rm RV}_{\rm max}$) confirms a high multiplicity fraction of $f_{mult}=78\pm5\%$. These findings suggest a possible anti-correlation between metallicity and the fraction of close B-type binaries, with the SMC multiplicity fraction significantly exceeding previous measurements in the LMC and MW. The enhanced fraction of close binaries at SMC's low metallicity may have broad implications for massive-star evolution in the early Universe. More frequent mass transfer and envelope stripping could boost the production of exotic transients, stripped supernovae, gravitational-wave progenitors, and sustained UV ionising flux, potentially affecting cosmic reionisation. Theoretical predictions of binary evolution under metal-poor conditions will provide a key test of our results.


**Translated Abstract**: 

早期B型恒星（初始质量在8到15 M⊙之间）常常处于多重系统中，这一点在银河系（MW）和大麦哲伦云（LMC）中的光谱观测活动中得到了证实。先前的研究表明，在银河系的太阳金属丰度（Z⊙）与LMC（Z=0.5 Z⊙）之间，近距双星（a<10 au）分数或轨道周期分布尚无明显的金属丰度依赖性。然而，在更贫金属环境中类似的分析仍然较少。我们专注于从小麦哲伦云（SMC，Z=0.2 Z⊙）的Binarity at LOw Metallicity（BLOeM）活动中选取的309颗早期B型恒星（光度等级III-V），使用VLT/FLAMES进行了多次观测光谱分析。通过应用与之前研究一致的双星检测标准，我们识别出153颗恒星（91 SB1, 59 SB2, 3 SB3）表现出显著的径向速度（RV）变化，从而得到观察到的多重性分数为$f^{obs}_{mult}=50\pm3\%$。利用Monte Carlo模拟来考虑观测偏差，我们推断内在的近距双星分数为$f_{mult}=80\pm8\%$。对峰-峰RV分布的Markov链蒙特卡罗分析（$\Delta{\rm RV}_{\rm max}$）确认了高的多重性分数$f_{mult}=78\pm5\%$。这些发现表明，金属丰度与近距B型双星分数之间可能存在反相关关系，SMC的多重性分数显著高于之前在LMC和银河系的测量。SMC低金属丰度下近距双星的增强比例可能对早期宇宙的质量星演化有广泛的影响。更频繁的质量传输和外壳剥离可能促进异常瞬态、剥壳超新星、引力波前体和持续的紫外线电离通量的产生，这可能影响宇宙再电离。理论上关于贫金属条件下双星演化的预测，将为我们的结果提供关键测试。

**Summary**:

- (1): 本文的研究背景是探讨早期B型星在多重系统中的存在情况，特别是在低金属丰度环境中这一现象的特征。

- (2): 以前的研究中，多重性分数和轨道周期的分布在银河系和大麦哲伦云之间并无显著的金属依赖性，而在低金属环境中的大量数据仍然较缺乏。提出的方法通过对小麦哲伦云中的早期B型恒星进行大规模的光谱观测和分析，从而填补这一数据空白，并且是基于与之前研究一致的双星检测标准。

- (3): 本文的贡献在于提供了小麦哲伦云低金属丰度下早期B型恒星的双星系统的多重性分数，发现其明显高于银河系和LMC的测量值。

- (4): 本文的研究方法包括使用VLT/FLAMES进行多次观测光谱分析，并通过应用Monte Carlo模拟和Markov链蒙特卡罗分析确定多重性分数。

- (5): 本文在识别出153颗有显著RV变化的B型恒星后，获得了内在近距双星分数为$f_{mult}=80\pm8\%$，并且根据$ \Delta{\rm RV}_{\rm max}$分析确认了高的多重性分数。这些性能支持了其研究目标，揭示了金属丰度对B型双星系统演化的影响。


## H, He-like recombination spectra VI: Quadrupole $l$-changing collisions
- **Url**: http://arxiv.org/abs/2504.03570v2
- **Authors**: ['E. Deliporanidou', 'N. R. Badnell', 'P. J. Storey', 'G. Del Zanna', 'G. J. Ferland']
- **Abstrat**: We have developed a simple analytic formula that well describes quadrupole $l$-changing collisions of the form $nl \rightarrow nl'$, as confirmed by comparison with numerical quantal Born calculations obtained with the program autostructure (Badnell 2011). Such formulae could easily be included in models of astrophysical plasma emission, such as the hydrogen and helium-like recombination spectra. When compared with the results of previous quantal calculations based upon an analytic solution of the time-dependent Schr\"odinger equation by Vrinceanu & Flannery (2001), we find relatively good agreement, with the exception of large $l > n/2$ transitions. We provide a tentative explanation for such discrepancies. However, we also show that the rates for quadrupole $l$-changing collisions are typically two orders of magnitude lower than the dipolar ones. Inclusion of the quadrupolar rates in a hydrogenic collisional-radiative model of nebular plasma shows minimal changes to the level populations, typically within 1% in nebular conditions. Simple and complete theories are now available for $l$-changing collisions suitable for astrophysical applications.


**Translated Abstract**: 

我们开发了一个简单的解析公式，能够很好地描述四极 $l$-变化碰撞的形式 $nl \rightarrow nl'$，这一点通过与使用程序autostructure（Badnell 2011）获得的数值量子Born计算的比较得到确认。这些公式可以很容易地纳入天体物理等离子体发射模型中，例如氢和氦类似物的重组光谱。与Vrinceanu和Flannery（2001）基于时间依赖的薛定谔方程的解析解的先前量子计算结果相比，我们发现相对较好的一致性，除了大 $l > n/2$ 的跃迁。我们对此类差异提供了初步解释。然而，我们还表明，四极 $l$-变化碰撞的速率通常比偶极的低两个数量级。将四极速率纳入氢离子碰撞辐射模型中显示，对能级种群的影响很小，通常在天体条件下仅为1%以内。现在可用简单且完整的理论来适用于天体物理的 $l$-变化碰撞。

**Summary**:

- (1): 本文研究的背景是宇宙中95%的重子物质组成的天体物理等离子体中，氢和氦的丰富性要求准确的非平衡辐射-碰撞模型来处理多种电离和重组合过程。

- (2): 过去的方法主要基于偶极 $l$-变化碰撞（Pengelly & Seaton 1964），存在多极碰撞的影响未被充分研究的问题。本文提出一种新分析方法，专注于四极 $l$-变化碰撞，通过比较量子和Born近似，提供更全面的理解，从而解决了以往研究的方法不足。

- (3): 本文的贡献在于开发了一个能够有效描述四极 $l$-变化碰撞的解析公式，并显示其在天体物理应用中的有效性，尤其是在氢和氦类似物重组光谱的模型中。

- (4): 本文采用的研究方法包括利用量子力学和Born近似的速率系数进行数值评估与分析比较，以识别不同近似方法之间的相似及差异。

- (5): 本文的方法主要任务是评估四极 $l$-变化碰撞的速率及其对气体等离子体的影响，结果表明这些速率的引入对能级种群的变化影响在1%以内，这表明所提出的方法满足其研究目标。


## Constraining the $z \sim 1$ IMF with {\it HST} and {\it JWST} lensed stars in MACS J0416.1-2403
- **Url**: http://arxiv.org/abs/2504.06992v1
- **Authors**: ['Sung Kei Li', 'Jose M. Diego', 'Ashish K. Meena', 'Jeremy Lim', 'Leo W. H. Fung', 'Arsen Levitskiy', 'James Nianias', 'Jose M. Palencia', 'Hayley Williams', 'Jiashuo Zhang', 'Alfred Amruth', 'Thomas J. Broadhurst', 'Wenlei Chen', 'Alexei V. Filippenko', 'Patrick L. Kelly', 'Anton M. Koekemoer', 'Derek Perera', 'Bangzheng Sun', 'Liliya L. R. Williams', 'Rogier A. Windhorst', 'Haojin Yan', 'Adi Zitrin']
- **Abstrat**: The understanding of galaxy properties and evolution is contingent on knowing the initial mass function (IMF), and yet to date, the IMF is constrained only to local galaxies. Individual stars are now becoming routinely detected at cosmological distances, where luminous stars such as supergiants in background galaxies critically lensed by galaxy clusters are temporarily further magnified by huge factors up to $10^{4}$ by intra-cluster stars, thus being detected as transients. The detection rate of these events depends on the abundance of luminous stars in the background galaxy and is thus sensitive to the IMF and the star formation history (SFH), especially for the blue supergiants detected as transients in the rest-frame UV/optical filters. As a proof of concept, we use simple SFH and IMF models constrained by spectral energy distribution (SED) to see how well we can predict the {\it HST} and {\it JWST} transient detection rate in a lensed arc dubbed ``Spock'' ($z = 1.0054$). We find that demanding a simultaneously fit of SED and rest-frame UV/optical transient detection rate places constraints on the IMF, independent of the assumed simple SFH model. We conclude our Bayesian likelihood analysis indicates that the data definitively prefer the ``Spock'' galaxy to have a Salpeter IMF ($\alpha = 2.35$) rather than a Top-heavy IMF ($\alpha = 1$) -- what is thought to be the case in the early universe -- given our methodology and assumptions with no clear excess of supergiants above the standard IMF.


**Translated Abstract**: 

对星系的属性和演化的理解依赖于初始质量函数（IMF）的知识，但迄今为止，IMF 仅在局部星系中受限。最近，在宇宙学距离上，个别恒星的探测变得越来越常见，其中背景星系中通过星系团强烈透镜作用的光亮恒星，临时被内部星系大幅放大（高达 $10^{4}$ 倍），因此被探测为瞬态。这些事件的探测率依赖于背景星系中光亮恒星的丰度，因此对 IMF 和恒星形成历史（SFH）敏感，尤其是在测得的瞬态中的蓝色超级巨星。作为概念验证，我们使用简单的 SFH 和 IMF 模型，通过光谱能量分布（SED）约束，来预测在 lensed arc “Spock” ($z = 1.0054$) 中，{\it HST} 和 {\it JWST} 的瞬态探测率。我们的研究发现，要求同时拟合 SED 和测得的瞬态探测率，可以独立于假设的简单 SFH 模型对 IMF 施加限制。我们的贝叶斯似然分析结果表明数据明确倾向于“Spock”星系具有 Salpeter IMF ($\alpha = 2.35$)，而非被认为是在早期宇宙的 Top-heavy IMF ($\alpha = 1$)，在我们的假设和方法下没有明显的超巨星过剩。

**Summary**:

- (1): 本文的研究背景是，初始质量函数（IMF）在了解星系属性和演化过程中至关重要，然而目前对IMF的研究仅限于局部星系。

- (2): 过去的方法主要通过拟合合成光谱来测量IMF，这种方法存在多参数之间的强烈退化现象，导致结果不可信。所提出的研究方法通过利用强透镜效应，结合 {\it HST} 和 {\it JWST} 对光亮恒星的直接探测，克服了这些问题，且有力地动机基于需直接测量高红移星系的IMF。

- (3): 本文的贡献在于首次利用透镜星系中光亮恒星的瞬态探测数据，对高红移星系的IMF进行了约束，支持了Salpeter IMF而非Top-heavy IMF的观点。

- (4): 本文提出的研究方法是通过简单的SFH和IMF模型，结合光谱能量分布（SED），同时考察瞬态探测率，以进行贝叶斯似然分析。

- (5): 本文在探测和约束星系“Spock”的IMF方面取得了成功，结果表明该星系倾向于Salpeter IMF，支持了研究者的理论目标。


## Galaxy infall models for arbitrary velocity directions
- **Url**: http://arxiv.org/abs/2501.13149v2
- **Authors**: ['Jenny Wagner', 'David Benisty']
- **Abstrat**: For most galaxies in the cosmos, our knowledge of their motion is limited to line-of-sight velocities from redshift observations. To determine the radial velocity between two galaxies the minor and major infall models were established by Karachentsev and Kashibadze (2006). Regardless of the background cosmology, our derivations reveal that these infall models approximate the total radial velocity between two galaxies by two different projections employing different information about the system. For galaxies having small angular separations $\theta$, all infall models agree that the radial velocity is the difference of their line-of-sight components. Applying these models to ca. $500$ halos of the Illustris-3 simulation, we find the perpendicular and tangential velocity parts to be non-negligible for more than 90% of all, more than 5000 infalling subhalos. Thus, even for $\theta < 10$ deg, the infall-model velocities deviate from the true radial velocity. Only for 30% we found the true one lay between the minor and major infall velocity. However, the infall models yield robust upper and lower bounds to the true radial velocity dispersion. Observed under $\theta < 10$ deg the velocity dispersion inferred from the sole difference of line-of-sight velocity components even coincides with the true one, justifying this approach for high-redshift groups and clusters. Based on these findings, we predict the radial velocity dispersion of the M81-group from the minor infall model (upper bound) $\sigma_{\mathrm{r,min}} = (193 \pm 42)~\mbox{km}/\mbox{s}$, from the major infall model (lower bound) $\sigma_{\mathrm{r,maj}} = (129 \pm 64) ~\mbox{km}/\mbox{s}$ and $\sigma_\mathrm{r,\Delta v} = (102 \pm 36)~\mbox{km}/\mbox{s}$ from the line-of-sight-velocity difference.


**Translated Abstract**:

对于宇宙中的大多数星系，我们对其运动的知识仅限于来自红移观测的视线速度。为了确定两个星系之间的径向速度，Karachentsev 和 Kashibadze（2006）建立了次要和主要的下落模型。无论背景宇宙学如何，我们的推导表明，这些下落模型通过采用不同的信息来近似两个星系之间的总径向速度。对于小角度分离的星系$\theta$，所有下落模型都一致认为，径向速度是它们视线速度分量之差。将这些模型应用于约500个Illustris-3模拟的晕，我们发现，对于超过90%及5000多个下落亚晕，垂直和切向速度部分是不可忽视的。因此，即使在$\theta < 10$度的情况下，下落模型速度也与真实的径向速度偏离。我们仅发现30%的情况下，真实速度位于次要和主要下落速度之间。然而，下落模型为真实的径向速度分散提供了稳健的上限和下限。在$\theta < 10$度下，从视线速度分量的仅差中推断出的速度分散甚至与真实速度一致，为高红移星系团和簇的这种方法提供了合理性。基于这些发现，我们预测M81团的径向速度分散，次要下落模型的上限$\sigma_{\mathrm{r,min}} = (193 \pm 42)~\mbox{km}/\mbox{s}$，主要下落模型的下限$\sigma_{\mathrm{r,maj}} = (129 \pm 64) ~\mbox{km}/\mbox{s}$，以及从视线速度差得出的$\sigma_\mathrm{r,\Delta v} = (102 \pm 36)~\mbox{km}/\mbox{s}$。

**Summary**:

- (1): 本文的研究背景是，对宇宙中大多数星系运动的了解仅限于来自红移观测的线速度，使得径向速度的测定变得复杂。

- (2): 过去的方法包括次要和主要下落模型（Karachentsev 和 Kashibadze，2006），这些方法在很大程度上忽视了观测者视线方向以外的速度分量，并假定宇宙结构是球对称的。提出的方法在于引入一般的双星运动模型，不再假设球对称性，量化切向速度对下落模型的影响。这种新方法合理且系统地解决了旧方法中的局限性。

- (3): 本文的贡献在于扩展了下落模型，考虑了垂直和切向速度分量，使其适用于更广泛的宇宙结构，并提供了对M81团径向速度分散的有效预测。

- (4): 研究方法论上，本文通过分析小角度分离星系的运动，建立了一般化的双星运动模型，定量评估不同速度分量对下落模型的影响。

- (5): 本文的方法在分析约500个Illustris-3模拟的晕时显示，超过90%的下落亚晕中的垂直和切向速度是不可忽视的，并且在$\theta < 10$度的情况下，推断出的速度分散与真实值一致，证明其有效性和目标实现的支持力。


## Elusive helium stars in the gap between subdwarfs and Wolf-Rayet stars~II. Nonlinear pulsations of stripped helium stars
- **Url**: http://arxiv.org/abs/2504.06926v1
- **Authors**: ['Yu. A. Fadeyev', 'A. G. Kuranov', 'L. R. Yungelson']
- **Abstrat**: It is shown for the first time that the stripped helium stars with masses 2 to 7 solar mass which are formed in close binary systems in the so-called case B of mass-exchange and retained low-mass hydrogen-helium envelopes, experience nonlinear radial pulsations. Pulsations are excited by the kappa-mechanism due to helium ionization. The region of pulsation instability extends over Hertzsprung-Russel diagram from the red giants branch to the region of effective temperatures from about 30,000 K to about 50,000 K. Variations of stellar luminosity should be observed mostly in the ultraviolet. The amplitudes of pulsations of the studied models reach 0.8 stellar magnitude and increase, as the stellar radii decrease. Pulsation periods of stars with effective temperatures exceeding 10,000 K range from 0.17 to 8.5 day and decrease with decreasing radii. The stars have substantially larger effective temperatures than their companions, which could be Be-stars. They are components of relatively wide binaries with orbital periods up to several years. The number of pulsating moderate-mass stripped helium stars in the Galaxy is about 1000.


**Translated Abstract**: 

首次显示出以质量 (2 - 7) M⊙ 形成的剥离氦星，在“案例B”质量交换的紧密双星系统中，经历非线性径向脉动。脉动由氦电离引起的κ机制激发。脉动不稳定区延伸至赫兹普龙-拉塞尔图，从红巨星分支到有效温度范围 4.5 ≲ log Teff ≲ 4.7。在紫外线中应主要观察到恒星光度的变化。研究模型的脉动幅度达到∆(Mb)=0.8，且随着恒星半径R的减小而增加。有效温度log Teff > 4的恒星的脉动周期范围在0.17天到8.5天之间，并随着R的减小而减小。这些恒星的有效温度远高于其可能的Be-star伴星。它们是轨道周期可达数年的相对宽双星的组成部分。银河系中的脉动中等质量剥离氦星数量约为1000颗。

**Summary**:

- (1): 本文研究的背景是剥离氦星的性质及其脉动行为，尤其是在质量为 (2 - 7) M⊙ 的氦星在双星系统中出现的非线性径向脉动。

- (2): 过去的方法主要集中在恒星脉动的理论建模上，通常忽略了氦星在双星系统中形成的复杂性。本文提出的理论考虑了氦电离引起的κ机制，填补了这一空白，从而提供了更准确的脉动行为解释。

- (3): 本文的贡献在于首次证明剥离氦星可能经历非线性径向脉动，并详细描述了脉动的不稳定区和脉动期间的性质。

- (4): 本文采用理论建模和数值模拟的方法，分析了剥离氦星的脉动特性及其与伴星的关系，采用赫兹普龙-拉塞尔图进行分类。

- (5): 本文所研究的脉动在有效温度范围 4.5 ≲ log Teff ≲ 4.7 的恒星中表现出显著的脉动行为，脉动幅度可达到 ∆(Mb)=0.8，表明所提方法支持了其目标。


## Correcting for interloper contamination in the power spectrum with neural networks
- **Url**: http://arxiv.org/abs/2504.06919v1
- **Authors**: ['Marina S. Cagliari', 'Azadeh Moradinezhad Dizgah', 'Francisco Villaescusa-Navarro']
- **Abstrat**: Modern slitless spectroscopic surveys, such as Euclid and the Roman Space Telescope, collect vast numbers of galaxy spectra but suffer from low signal-to-noise ratios. This often leads to incorrect redshift assignments when relying on a single emission line, due to noise spikes or contamination from non-target emission lines, commonly referred to as redshift interlopers. We propose a machine learning approach to correct the impact of interlopers at the level of measured summary statistics, focusing on the power spectrum monopole and line interlopers as a proof of concept. To model interloper effects, we use halo catalogs from the Quijote simulations as proxies for galaxies, displacing a fraction of halos by the distance corresponding to the redshift offset between target and interloper galaxies. This yields contaminated catalogs with varying interloper fractions across a wide range of cosmologies from the Quijote suite. We train a neural network on the power spectrum monopole, alone or combined with the bispectrum monopole, from contaminated mocks to estimate the interloper fraction and reconstruct the cleaned power spectrum. We evaluate performance in two settings: one with fixed cosmology and another where cosmological parameters vary under broad priors. In the fixed case, the network recovers the interloper fraction and corrects the power spectrum to better than 1% accuracy. When cosmology varies, performance degrades, but adding bispectrum information significantly improves results, reducing the interloper fraction error by 40-60%. We also study the method's performance as a function of the size of the training set and find that optimal strategies depend on the correlation between target and interloper samples: bispectrum information aids performance when target and interloper galaxies are uncorrelated, while tighter priors are more effective when the two are strongly correlated.


**Translated Abstract**: 

现代无缝光谱调查，如欧几里得（Euclid）和罗曼空间望远镜（Roman Space Telescope），收集大量的星系光谱，但受到低信噪比的影响。这常常导致在依赖单一发射线时的错误红移分配，因为噪声尖峰或来自非目标发射线的污染，通常称为红移干扰者。我们提出了一种机器学习方法，旨在从测量的总结统计量层面纠正干扰者的影响，集中于功率谱单极矩和线干扰者作为概念验证。为了模拟干扰者效应，我们利用来自Quijote模拟的哈罗目录作为星系的代理，通过目标星系与干扰者星系之间的红移偏移距离移动一部分哈罗，这样得到了不同宇宙学下的污染目录。我们训练一个神经网络，基于污染模型的功率谱单极矩（单独或结合双谱单极矩）来估算干扰者比例并重构清洁的功率谱。在两种情况下评估性能：一种是固定宇宙学，另一种是宇宙学参数在宽先验下变化。在固定情况下，网络准确地恢复了干扰者比例，并将功率谱纠正到1%以下的准确度。当宇宙学变化时，性能下降，但加入双谱信息显著改善了结果，将干扰者比例误差降低了40-60%。我们还研究了方法性能随训练集规模的变化，并发现最优策略依赖于目标与干扰者样本之间的相关性：当目标与干扰者星系无关时，双谱信息有助于性能，而当两者高度相关时，收紧先验更为有效。

**Summary**:

- (1): 本文研究背景为现代无缝光谱调查（如欧几里得和罗曼空间望远镜）在收集星系光谱时，由于低信噪比造成的红移干扰者导致的错误红移分配问题。

- (2): 过去的方法主要通过目标选择方案在目录级别识别并去除污染星系，或者直接在总结统计中建模干扰者的影响。这些方法需要干扰者比例作为输入或混杂参数，而可用的深度光谱观察的数据可能有限。本文提出的方法通过训练深度神经网络，从测量的总结统计直接推断干扰者比例并减少其对统计结果的影响，以解决传统方法的局限性。

- (3): 本文的贡献在于开发了一种新的方法，通过神经网络从干扰者污染的总结统计中推测干扰者比例，并提供功率谱单极矩的障碍清除。

- (4): 研究方法结合了Quijote模拟生成的染污模型，通过污染的功率谱单极矩和双谱单极矩作为输入来训练一个神经网络，输出干扰者比例的均值和方差，并纠正功率谱。

- (5): 本文的方法在固定宇宙学和变化宇宙学场景下，分别能将干扰者比例误差降低至1%以下，并在变化宇宙学情况下通过双谱信息将误差降低40-60%，显示其良好的性能支持研究目标。


## An Investigation of Disk Thickness in M51 from H-alpha, Pa-alpha, and Mid-Infrared Power Spectra
- **Url**: http://arxiv.org/abs/2504.05430v2
- **Authors**: ['Bruce G. Elmegreen', 'Daniela Calzetti', 'Angela Adamo', 'Karin Sandstrom', 'Daniel Dale', 'Varun Bajaj', 'Martha L. Boyer', 'Ana Duarte-Cabral', 'Ryan Chown', 'Matteo Correnti', 'Julianne J. Dalcanton', 'Bruce T. Draine', 'Brandt Gaches', 'John S. Gallagher III', 'Kathryn Grasha', 'Benjamin Gregg', 'Leslie K. Hunt', 'Kelsey E. Johnson', 'Robert Kennicutt, Jr.', 'Ralf S. Klessen', 'Adam K. Leroy', 'Sean Linden', 'Anna F. McLeod', 'Matteo Messa', 'Goran Ostlin', 'Mansi Padave', 'Julia Roman-Duval', 'J. D. Smith', 'Fabian Walter', 'Tony D. Weinbeck']
- **Abstrat**: Power spectra (PS) of high-resolution images of M51 (NGC 5194) taken with the Hubble Space Telescope and the James Webb Space Telescope have been examined for evidence of disk thickness in the form of a change in slope between large scales, which map two-dimensional correlated structures, and small scales, which map three-dimensional correlated structures. Such a slope change is observed here in H-alpha, and possibly Pa-alpha, using average PS of azimuthal intensity scans that avoid bright peaks. The physical scale of the slope change occurs at ~120 pc and ~170 pc for these two transitions, respectively. A radial dependence in the shape of the H-alpha PS also suggests that the length scale drops from ~180 pc at 5 kpc, to ~90 pc at 2 kpc, to ~25 pc in the central ~kpc. We interpret these lengths as comparable to the thicknesses of the star-forming disk traced by HII regions. The corresponding emission measure is ~100 times larger than what is expected from the diffuse ionized gas. PS of JWST Mid-IR Instrument (MIRI) images in 8 passbands have more gradual changes in slope, making it difficult to determine a specific value of the thickness for this emission.


**Translated Abstract**: 

本文研究了对大麦哲伦星云M51（NGC 5194）的高分辨率图像的功率谱（PS），以寻找与盘厚度相关的证据。结果显示，在H-alpha和可能的Pa-alpha中观察到了大尺度（二维相关结构）与小尺度（三维相关结构）之间的斜率变化。斜率变化的物理尺度分别为约120 pc和170 pc。H-alpha PS的形状还表现出径向依赖性，表明长度尺度从5 kpc处的180 pc降至2 kpc处的90 pc，再降至中心1 kpc处的25 pc。我们将这些长度与HII区域所追踪的星形成盘的厚度进行比较。对应的发射度约为预期的弥漫离子气体的100倍。JWST中红外成像（MIRI）的功率谱在8个波段中的斜率变化较为平缓，导致该发射的厚度特定值难以确定。

**Summary**:

- (1): 本文的研究背景是通过分析M51（NGC 5194）的H-alpha和Pa-alpha图像功率谱，寻找星系盘厚度的证据。

- (2): 过去的方法主要应用于对其他星系的功率谱测量，出现的问题包括空间分辨率不足导致无法清楚探测到厚度变化。与现有方法不同，本文的方法采用了一维强度扫描并选择无强点源的扫描，解决了在中远红外数据中受到点源和辐射曲线影响的困难。该方法的动机充分，旨在准确判断星系厚度。

- (3): 本文的贡献在于提供了M51盘厚度的新测量结果，包括径向厚度增加的发现，增强了对盘厚度与星形成环境的理解。

- (4): 本文提出的研究方法是使用Hubble和JWST获取的高分辨率图像，计算其功率谱以分析斜率变化，确定星系盘的厚度。

- (5): 本文在M51的H-alpha和Pa-alpha成像中实现了约120 pc和170 pc的厚度测量，支持了其目标，即更深入地理解星系的结构和动力学。


## FAST drift scan survey for HI intensity mapping: simulation on hunting HI filament with pairwise stacking
- **Url**: http://arxiv.org/abs/2411.03988v2
- **Authors**: ['Diyang Liu', 'Yichao Li', 'Denis Tramonte', 'Furen Deng', 'Jiaxin Wang', 'Yougang Wang', 'Xin Zhang', 'Xuelei Chen']
- **Abstrat**: Filaments stand as pivotal structures within the cosmic web. However, direct detection of the cold gas content of the filaments remains challenging due to its inherent low brightness temperature. With the TNG hydrodynamical simulations, we demonstrate the effectiveness of isolating faint filament HI signal from the FAST HI intensity mapping (IM) survey through pairwise stacking of galaxies, which yields an average HI filament signal amplitude of $\sim 0.29\ {\mu{\rm K}}$ at $z\simeq 0.1$. However, our simulations reveal a non-negligible contribution from HI-rich galaxies within or near the filaments. Particularly, the faint galaxies dominantly contribute to the extra filament HI signal. Our simulation also shows that the measurement uncertainty is produced by both thermal noise and background variation caused by brightness leakage from surrounding random galaxies. Given a fixed total observation time, a wide-field HI IM survey, which includes a large number of galaxy pairs, can simultaneously reduce thermal noise to below the filament signal level and minimize background variation to a negligible level. Through the end-to-end simulation, this work demonstrates the critical role of the galaxy pairwise stacking method in future filament HI detection, outlining a road map for filament HI detection in the next-generation HI IM surveys.


**Translated Abstract**: 

宇宙网内的细丝结构是关键构造，但由于其固有的低亮度温度，直接探测细丝中的冷气体内容物仍然具有挑战性。通过TNG流体动力学模拟，我们展示了如何通过对FAST HI强度测量（IM）调查中的星系进行配对堆叠，有效地隔离微弱的细丝HI信号，结果在z≈0.1时，获得的细丝HI信号幅度约为0.29μK。然而，我们的模拟显示，细丝内或附近的HI丰富星系对额外的细丝HI信号有显著贡献，尤其是微弱星系占主导地位。我们的模拟还表明，测量不确定性是由于热噪声和周围随机星系的亮度泄漏引起的背景变化所产生的。在固定总观测时间的情况下。如果可以同时提高HI IM调查中星系配对的数量，广域HI IM调查可以将热噪声降低到细丝信号水平以下，同时将背景变化减少到微不足道的水平。通过端到端的模拟，本工作展示了星系配对堆叠方法在未来细丝HI探测中的关键作用，为下一代HI IM调查中的细丝HI探测提供了路线图。

**Summary**:

- (1): 本文研究的背景是细丝结构在宇宙网中的重要性，但由于其低亮度温度，直接探测细丝中的冷气体内容物面临困难。

- (2): 过去的方法主要包括利用HI强度图进行观测，但存在较大的测量不确定性，尤其是来自背景星系的噪声和亮度泄漏问题。与先前方法不同，提出的方法通过星系配对堆叠有效隔离细丝HI信号，大大降低了热噪声和背景变化。

- (3): 文章的贡献在于展示了通过星系配对堆叠方法隔离细丝HI信号的有效性，并提出了一条明确的路线图以指导未来的细丝HI探测。

- (4): 本文所提出的研究方法涉及使用TNG流体动力学模拟进行端到端的模拟验证，涉及到配对堆叠技术以提高信号的测量精度。

- (5): 本文的方法在z≈0.1的情况下实现了约0.29μK的细丝HI信号幅度，足以支撑其探测细丝HI的目标。


## The ALMA-ATOMS survey: A sample of weak hot core candidates identified through line stacking
- **Url**: http://arxiv.org/abs/2504.06802v1
- **Authors**: ['Zi-Yang Li', 'Xunchuan Liu', 'Tie Liu', 'Sheng-Li Qin', 'Paul F. Goldsmith', 'Pablo García', 'Yaping Peng', 'Li Chen', 'Yunfan Jiao', 'Zhiping Kou', 'Chuanshou Li', 'Jiahang Zou', 'Mengyao Tang', 'Shanghuo Li', 'Meizhu Liu', 'Guido Garay', 'Fengwei Xu', 'Wenyu Jiao', 'Qiu-Yi Luo', 'Suinan Zhang', 'Qi-Lao Gu', 'Xiaofeng Mai', 'Yan-Kun Zhang', 'Jixiang Weng', 'Chang Won Lee', 'Patricio Sanhueza', 'Sami Dib', 'Swagat R. Das', 'Xindi Tang', 'Leonardo Bronfman', 'Prasanta Gorai', "Ken'ichi Tatematsu", 'Hong-Li Liu', 'Dongting Yang', 'Zhenying Zhang', 'Xianjin Shen']
- **Abstrat**: Hot cores represent critical astrophysical environments for high-mass star formation, distinguished by their rich spectra of organic molecular emission lines. We aim to utilize high-angular resolution molecular line data from ALMA to identify hot cores, with a particular focus on weak-emission candidates, and to provide one of the largest samples of hot core candidates. We propose to use spectral stacking and imaging techniques of complex organic molecules (COMs) in the ALMA-ATOMS survey, including line identification & weights, segmentation of line datacubes, resampling, stacking and normalization, moment 0 maps, and data analysis, to search for hot core candidates. We classify cores with dense emission of CH3OH and at least one molecule from the other six molecules as hot core candidates. In addition to the existing sample of 60 strong hot cores from the ALMA-ATOMS survey, we have detected 40 new weak candidates through stacking. All hot core candidates display compact emission from at least one of the other six COM species. For the strong sample, the stacking method provides molecular column density estimates that are consistent with previous fitting results. For the newly identified weak candidates, all species except CH3CHO show compact emission in the stacked image, which cannot be fully resolved spatially. These weak candidates exhibit column densities of COMs that are approximately one order of magnitude lower than those of the strong sample. The entire hot core sample, including the weak candidates, reveals tight correlations between the compact emission of CH3OH and other COM species, suggesting they may share a similar chemical environment for COMs, with CH3OH potentially acting as a precursor for other COMs. The molecular line stacking technique is used to identify hot core candidates in this work, leading to the identification of 40 new hot core candidates.


**Translated Abstract**: 

热核是高质量恒星形成的重要天体物理环境，以其丰富的有机分子发射线谱为特征。本研究旨在利用来自阿塔卡马大型毫米波和亚毫米波阵列（ALMA）的高角分辨率分子线数据来识别热核，特别关注弱发射候选体，并提供当前最大的热核候选样本之一。我们校正了阿塔卡马大气透明度监测（ATOMS）调查中的复杂有机分子的光谱堆叠和成像技术，包括线识别与权重、线数据立方体的分段、重采样、堆叠和归一化、时刻 0 图及数据分析，以寻找热核候选体。我们将具有稠密CH3OH发射及至少一种其他六种分子的核心归类为热核候选体。除了已存在的60个强热核样本外，我们通过堆叠检测到40个新的弱候选体。所有热核候选体均显示至少一种其他六种有机分子的紧凑发射。对于强样本，堆叠方法提供的分子柱密度估计与之前的拟合结果一致。对于新识别的弱候选体，除CH3CHO外，所有物种在堆叠图像中均显示紧凑发射，无法完全空间分辨。这些弱候选体的有机分子柱密度约比强样本低一个量级。包括弱候选体在内的整个热核样本揭示CH3OH与其他有机分子的紧凑发射之间存在紧密关联，表明它们可能共享相似的化学环境，而CH3OH可能作为其他有机分子的前驱。本文采用分子线堆叠技术识别热核候选体，识别出40个新的热核候选体。

**Summary**:

- (1): 本文研究背景是热核作为高质量恒星形成的重要环境，其特征为丰富的有机分子发射线，而当前对热核样本的综合统计分析相对较少。

- (2): 过去的方法主要基于单一波束的观测，存在灵敏度限制和无法解析具体热核的偏差问题。本文所提方法与现有方法不同，采用了光谱堆叠技术，这使得能更敏感地检测到较弱的热核，并克服了灵敏度的问题，动机合理。

- (3): 本文的贡献在于识别出40个新的弱热核候选体，并提供了更系统、全面的热核候选样本。

- (4): 本文提出的研究方法包括使用光谱堆叠和成像技术，分析复杂有机分子的发射特征，并定义热核候选体。

- (5): 本文的方法在识别热核候选体方面取得了40个新的候选体，且与强样本的分子柱密度估计一致，这一表现能够支持其研究目标。


## FOREVER22: Insights into star formation and clustering properties of protoclusters from simulations and JWST
- **Url**: http://arxiv.org/abs/2504.06788v1
- **Authors**: ['Kana Morokuma-Matsui', 'Hidenobu Yajima', 'Makito Abe']
- **Abstrat**: Using cosmological hydrodynamic simulations with radiative transfer, we investigate star formation and overdensity ($\delta$) in Coma-type cluster progenitors from $z=14$ to 6. Our simulations reproduce observed $M_{\rm star}$-SFR relations and $\delta$ at these redshifts. We find: (1) protocluster (PC) and mean-density field (MF) galaxies show similar $M_{\rm star}$-SFR relations, with PC galaxies extending to higher $M_{\rm star}$ and SFR. (2) UV-bright PC galaxies ($M_{\rm UV}\lesssim -20$~mag) have $>2$ mag higher UV attenuation and shallower UV slopes than MF galaxies. (3) $\delta$ increases with redshift, depending on observational parameters (e.g., $\delta\sim50$ at $z=14$ to $\delta\sim3$ at $z=6$ for a search volume of $\sim3000$~cMpc$^3$ and a limiting magnitude of $M_{\rm UV}=-17$~mag). These results indicate that enhanced star formation in PCs is driven by massive galaxy overdensity, not anomalously high specific SFR. While simulated $\delta$ agrees with observed PC candidates (potential Coma progenitors), some MF galaxies show comparable $\delta$. We propose a robust PC identification method using both $\delta$ and $M_{\rm star}$ of the most massive member. Critical $M_{\rm star}$ thresholds for Coma progenitors are estimated ($10^{7.1}$ to $10^{10.2}$ M$_\odot$ from $z=14$ to 6). Comparison with JWST observations suggests GS-z14-0 and GS-z14-1, the current highest redshift holders, are likely progenitors of Coma-type clusters.


**Translated Abstract**: 

通过使用带有辐射传输的宇宙学疏水动力学模拟，我们研究了从红移 $z=14$ 到 $z=6$ 的 Coma 型星团祖先的恒星形成和过密度 ($\delta$) 情况。我们的模拟重现了这些红移下观测到的 $M_{\rm star}$-SFR 关系和 $\delta$。我们发现：(1) 原型星团 (PC) 和平均密度场 (MF) 星系展示了相似的 $M_{\rm star}$-SFR 关系，其中 PC 星系具有更高的 $M_{\rm star}$ 和 SFR。(2) UV明亮的 PC 星系 ($M_{\rm UV}\lesssim -20$~mag) 相比 MF 星系具有更高的 UV 衰减 (>2 mag) 和更平坦的 UV 坡度。(3) $\delta$ 随着红移增加而变化，取决于观测参数（例如，$\delta\sim50$ 在 $z=14$ 时到 $\delta\sim3$在 $z=6$ 的搜索体积约为 $3000$~cMpc$^3$和限制星等 $M_{\rm UV}=-17$~mag）。这些结果表明，PC 中的增强恒星形成是由大量星系过密度驱动的，而不是异常高的特定 SFR。虽然模拟的 $\delta$ 与已观察的 PC 候选者（潜在的 Coma 祖先）一致，但某些 MF 星系表现出可比较的 $\delta$。我们提出了一种使用 $\delta$ 和最重成员的 $M_{\rm star}$ 的稳健 PC 识别方法。估计 Coma 祖先的临界 $M_{\rm star}$ 阈值为 ($10^{7.1}$ 到 $10^{10.2}$ M$_\odot$ 从 $z=14$ 到 6)。与 JWST 观察的比较表明，GS-z14-0 和 GS-z14-1，当前红移最高的持有者，可能是 Coma 型星团的祖先。

**Summary**:

- (1): 本文的研究背景是原型星团（PC）作为早期宇宙中过密区域，未来会形成今天的星系团，具有重要的宇宙再电离和化学演化驱动作用。

- (2): 过去的方法主要是基于活动红移$z\sim 6-7$的Lyman-$\alpha$发射来识别PC候选者，方法的局限在于对各种星系种群（如LAE、LBG和其他辐射源）的识别依赖，可能会导致样本选择偏差。本文提出的新方法结合了$\delta$和最重成员的$M_{\rm star}$，以克服这些识别和分析中的不确定性，具有较强的动机性。

- (3): 本文的贡献在于提供了对Coma型星团祖先的恒星形成和过密度特性的系统性理解，验证了由高星系过密度驱动的增强恒星形成的观点。

- (4): 本文的研究方法为使用宇宙学疏水动力学模拟与辐射传输相结合，计算从$z=14$到6的PC和MF星系的$M_{\rm star}$-SFR关系及$\delta$特性。

- (5): 本文在比较PC候选者的数量密度和星系质量阈值等方面取得了积极的成果，这些表现与其研究目的高度一致。


## Deep Learning solutions to singular ordinary differential equations: from special functions to spherical accretion
- **Url**: http://arxiv.org/abs/2409.20150v2
- **Authors**: ['R. Cayuso', 'M. Herrero-Valea', 'E. Barausse']
- **Abstrat**: Singular regular points often arise in differential equations describing physical phenomena such as fluid dynamics, electromagnetism, and gravitation. Traditional numerical techniques often fail or become unstable near these points, requiring the use of semi-analytical tools, such as series expansions and perturbative methods, in combination with numerical algorithms; or to invoke more sophisticated methods. In this work, we take an alternative route and leverage the power of machine learning to exploit Physics Informed Neural Networks (PINNs) as a modern approach to solving ordinary differential equations with singular points. PINNs utilize deep learning architectures to approximate solutions by embedding the differential equations into the loss function of the neural network. We discuss the advantages of PINNs in handling singularities, particularly their ability to bypass traditional grid-based methods and provide smooth approximations across irregular regions. Techniques for enhancing the accuracy of PINNs near singular points, such as adaptive loss weighting, are used in order to achieve high efficiency in the training of the network. We exemplify our results by studying four differential equations of interest in mathematics and gravitation -- the Legendre equation, the hypergeometric equation, the solution for black hole space-times in theories of Lorentz violating gravity, and the spherical accretion of a perfect fluid in a Schwarzschild geometry.


**Translated Abstract**:

奇异常规点常常出现在描述物理现象（如流体动力学、电磁学和引力）的微分方程中。传统的数值技术在这些点附近常常失败或变得不稳定，这要求使用半解析工具，如级数展开和微扰方法，以及数值算法，或采用更复杂的方法。在这项工作中，我们采取了另一种途径，利用机器学习的力量，利用物理信息神经网络（PINNs）作为解决具有奇异点的常微分方程的现代方法。PINNs通过将微分方程嵌入神经网络的损失函数中，利用深度学习架构来逼近解。我们讨论了PINNs在处理奇异性方面的优势，特别是它们能够绕过传统的基于网格的方法，并在不规则区域提供平滑的逼近。使用自适应损失加权等技术来提高PINNs在奇异点附近的准确性，以实现网络训练的高效率。我们通过研究四个在数学和引力中感兴趣的微分方程来证明我们的结果——勒让德方程、超几何方程、在Lorentz违反引力理论中的黑洞时空解，以及在施瓦兹schild几何下完美流体的球形吸积。

**Summary**:

- (1): 本文研究背景是奇异常规点在描述流体动力学、电磁学和引力等物理现象中的出现。

- (2): 过去的方法包括传统的数值技术和半解析工具（如级数展开和微扰方法），它们在奇异点附近常常失败或不稳定。本文提出的方法利用物理信息神经网络（PINNs），与现有方法不同的是，它通过深度学习架构嵌入微分方程于损失函数中，能够在不规则区域提供平滑解。该方法通过自适应损失加权等技术解决了过去方法的不足，并且具有合理的动机。

- (3): 本文的贡献在于提出一种新的基于PINNs的方法，解决了常微分方程奇异点的求解问题，并展示了其在处理复杂物理现象时的优势。

- (4): 本文的研究方法是使用物理信息神经网络（PINNs），通过深度学习架构逼近微分方程的解，并在训练过程中采用自适应损失加权来提高准确性。

- (5): 本文针对四个微分方程的求解进行了研究，包括勒让德方程、超几何方程、黑洞时空解和完美流体的球形吸积，所取得的性能表明该方法有效支持了研究目标。


## Measuring and predicting galaxy assembly bias across galaxy samples
- **Url**: http://arxiv.org/abs/2504.06770v1
- **Authors**: ['Sergio García-Moreno', 'Jonás Chaves-Montero']
- **Abstrat**: One of the most important effects shaping small-scale galaxy clustering is galaxy assembly bias, which refers to the dependence of galaxy clustering on halo properties. We investigate this effect using galaxy samples selected according to stellar mass, r-band magnitude, and broad-band colors from the largest hydrodynamical simulation of the IllustrisTNG suite. We find that galaxy assembly bias depends strongly upon the selection criteria, number density, and redshift of the sample, increasing or decreasing the clustering by as much as 25%. Interestingly, no single secondary halo property fully captures the strength of this effect for any galaxy population. Therefore, empirical approaches modeling galaxy assembly bias as a function of a single halo property cannot reproduce predictions from hydrodynamical simulations. We then study how galaxy assembly bias emerges from the interplay of halo assembly bias -- the dependence of halo clustering on properties other than mass -- and occupancy variation -- the correlation between galaxy occupation and secondary halo properties -- and provide an analytical expression that predicts the amount of galaxy assembly bias caused by any halo property. This expression facilitates understanding the dependence of galaxy assembly bias on halo properties and enables the straightforward incorporation of this effect into halo model approaches.


**Translated Abstract**:  
在小尺度星系聚集性的重要影响因素之一是星系组装偏差，它指的是星系聚集性与晕特性的依赖关系。我们使用来自IllustrisTNG套件的最大水动力模拟中的恒星质量、r波段亮度和宽带颜色选择的星系样本来研究这一效应。我们发现星系组装偏差强烈依赖于选择标准、数密度和样本的红移，聚集性可能增加或减少多达25%。有趣的是，没有单一的次级晕特性能够完全捕捉任何星系种群的这一效应的强度。因此，基于单一晕特性建模星系组装偏差的经验方法无法重现水动力模拟的预测。然后，我们研究星系组装偏差如何源于晕组装偏差（晕聚集性对除质量以外的特性依赖）和占有变化（星系占有与次级晕特性之间的相关性）的相互作用，并提供一个分析表达式，预测任何晕特性引起的星系组装偏差的量。这一表达式有助于理解星系组装偏差对晕特性的依赖关系，并使这一效应能够方便地融入晕模型方法中。

**Summary**:

- (1): 本文研究的背景是星系生成和成长与晕的特性及分布密切相关，探讨星系聚集性对晕特性依赖的影响（即星系组装偏差）。

- (2): 过去的方法主要依靠半解析模型和水动力模拟，指出星系组装偏差通过晕的次级特性影响聚集性，但并未明确检测到此偏差；这些方法不能完全捕捉星系群体的偏差强度。本文提出的方法是通过考虑晕组装偏差与占有变化的相互作用，提供一个分析表达式，解决了传统方法中单一特性无法涵盖整体效应的问题，具有合理动机。

- (3): 本文的贡献在于明确了星系组装偏差的机制，提供了一个能够准确预测位于不同条件下的星系组装偏差的分析公式，并提出了如何将这一效应整合到晕模型方法中。

- (4): 本文的研究方法包括利用最大的IllustrisTNG水动力模拟，通过选择不同的星系样本（恒星质量、r波段亮度和宽带颜色）来测量星系组装偏差，并研究晕组装偏差与占有变化之间的相互作用。

- (5): 本文未具体列出某项任务的具体表现指标，但提到星系组装偏差可能会提高或降低聚集性达25%。这一性能支持了其准确建模小尺度星系聚集性的目标。


## Unveiling two deeply embedded young protostars in the S68N Class 0 protostellar core with JWST/NIRSpec
- **Url**: http://arxiv.org/abs/2410.11095v2
- **Authors**: ['Valentin J. M. Le Gouellec', 'Ben W. P. Lew', 'Thomas P. Greene', 'Doug Johnstone', 'Antoine Gusdorf', 'Logan Francis', 'Curtis DeWitt', 'Michael Meyer', 'Łukasz Tychoniec', 'Ewine F. van Dishoeck', 'Mary Barsony', 'Klaus W. Hodapp', 'Massimo Robberto']
- **Abstrat**: The near-infrared (NIR) emission of the youngest protostars still needs to be characterized to better understand the evolution of their accretion and ejection activity. We analyze James Webb Space Telescope NIRSpec 1.7 -- 5.3 $\mu$m observations of two deeply embedded sources in the S68N protostellar core in Serpens. The North Central (NC) source exhibits a highly obscured spectrum (A_K ~ 4.8 mag) that is modeled with a pre-main-sequence photosphere and a hot disk component. The photospheric parameters are consistent with a young, low-mass photosphere, as suggested by the low surface gravity, log g of 1.95 $\pm$ 0.15 cm s$^{-2}$. The hot disk suggests that accretion onto the central protostellar embryo is ongoing, although prototypical accretion-tracing emission lines HI are not detected. The South Central (SC) source, which is even more embedded (A_K ~ 8 mag; no continuum is detected shortward of 3.6 $\mu$m) appears to be driving the large-scale S68N protostellar outflow, and launches a collimated hot molecular jet detected in \Ht and CO ro-vibrational lines. Shock modeling of the \Ht (ro)vibrational lines establishes that fast $C$-type shocks ($\geq$ 30 km s$^{-1}$), with high pre-shock density ($\geq$ $10^7$ cm$^{-3}$), and strong magnetic field (b ~ 3--10, where $B = b\,\times\,\sqrt{\textrm{n}_{\textrm{H}} (\textrm{cm}^{-3})}\,\mu\textrm{G}$) best match the data. The bright CO fundamental line forest suggests energetic excitation, with the contribution of non-LTE effects, ie irradiation pumping. Detected OH and CH$^{+}$ ro-vibrational lines support this hypothesis. These two Class 0 protostars seem to be in very young evolutionary stages and still have to acquire the bulk of their final stellar masses. These results demonstrate that JWST enables unprecedented diagnostics of these first stages of the protostellar evolutionary phase.


**Translated Abstract**: 

年轻原恒星的近红外（NIR）发射仍需被表征，以更好地理解其吸积和喷流活动的演化。我们分析了詹姆斯·韦布空间望远镜（James Webb Space Telescope）NIRSpec 1.7 - 5.3 μm 观测到的两个深嵌入源在S68N原恒星核心中的数据。北中央（North Central, NC）源显示出高度被遮掩的光谱（A_K ~ 4.8 mag），该光谱被建模为一个前主序光球及一个热盘组件。光球的参数与年轻、低质量光球一致，表明低表面重力，log g为1.95 ± 0.15 cm s^(-2)。热盘表明中心原恒星胚胎正在进行吸积，尽管未检测到典型的吸积指示发射线HI。南中央（South Central, SC）源则更为嵌入（A_K ~ 8 mag；在3.6 μm之前未探测到连续体），它似乎在驱动大尺度的S68N原恒星喷流，并发射了在H₂和CO振动线中探测到的定向热分子喷流。H₂（振动）线的冲击建模显示，快速C型冲击（≥ 30 km s^(-1)）及高前冲密度（≥ 10^7 cm^(-3)）与强磁场（b ~ 3-10，B = b × √n_H（cm^(-3)）μG）最符合数据。明亮的CO基本线森林表明存在能量激发，辅以非LTE效应的参与，即辐照泵浦。检测到的OH和CH⁺振动线支持了这个假设。这两颗Class 0原恒星似乎处于非常年轻的演化阶段，仍需获得其最终恒星质量的大部分。这些结果表明JWST能够对原恒星演化阶段的最初阶段进行前所未有的诊断。

**Summary**:

- (1): 本文的研究背景是年轻原恒星在原恒星阶段大部分质量的吸积尚不清楚，尤其是在S68N原恒星核心的深嵌入源的演变。

- (2): 过去的方法主要依赖于地基观测，无法深入分析被遮挡的原恒星的内部特性，特别是在吸积活动和喷流方面。与现有方法相比，本文采用JWST的近红外技术，对深嵌入的源进行了高分辨率的光谱观测，有效解决了对嵌入源进行详细分析的难题。

- (3): 本文的贡献在于首次利用JWST探测并分析S68N原恒星核心中的两个深嵌入原恒星的光谱特征，提供了关于吸积、喷流及其物理条件的新见解。

- (4): 本文提出的研究方法包括对JWST/NIRSpec 1.7 - 5.3 μm数据的分析，采用了模型拟合和冲击建模的方法评估原恒星的光谱及其发射线的行为。

- (5): 本文在探测到的样本中展示了吸积和喷流行为的详细模型，表明两颗Class 0原恒星处于非常初始的演化阶段，结果支持了对原恒星演化过程的更深入理解。


## Evidence of star cluster migration and merger in dwarf galaxies
- **Url**: http://arxiv.org/abs/2504.06749v1
- **Authors**: ['Mélina Poulain', 'Rory Smith', 'Pierre-Alain Duc', 'Francine R. Marleau', 'Rebecca Habas', 'Patrick R. Durrell', 'Jérémy Fensch', 'Sungsoon Lim', 'Oliver Müller', 'Sanjaya Paudel', 'Rubén Sánchez-Janssen']
- **Abstrat**: Nuclear star clusters (NSCs) are the densest stellar systems in the Universe. They can be found at the center of all galaxy types, but tend to favor galaxies of intermediate stellar mass around 10$^9\,$M$_{\odot}$[1, 2]. Currently, two main processes are under debate to explain their formation: in-situ star-formation from gas infall[3] and migration and merging of globular clusters (GCs) caused by dynamical friction[4]. Studies[5-9] of NSC stellar populations suggest that the former predominates in massive galaxies, the latter prevails in dwarf galaxies, and both contribute equally at intermediate mass. However, up to now, no ongoing merger of GCs has yet been observed to confirm this scenario. Here we report the serendipitous discovery of five dwarf galaxies with complex nuclear regions, characterized by multiple nuclei and tidal tails, using high resolution images from the Hubble Space Telescope. These structures have been reproduced in complementary N-body simulations, supporting the interpretation that they result from migrating and merging of star clusters. The small detection rate and short simulated timescales (below 100 Myr) of this process may explain why this has not been observed previously. This study highlights the need of large surveys with high resolution to fully map the migration scenario steps.


**Translated Abstract**: 

核星团（NSCs）是宇宙中最密集的恒星系统。它们可以在所有类型的星系中心找到，但往往更倾向于大约10^9 M⊙的中等恒星质量的星系。目前，关于它们形成的两种主要过程仍在辩论中：来自气体降落的原位恒星形成，以及由于动力摩擦引起的球状星团（GCs）的迁移和合并。对NSC恒星群体的研究表明，前者在大质量星系中占主导地位，后者在矮星系中占主导地位，二者在中等质量星系中贡献相同。然而，迄今为止尚未观察到GCs的正在进行的合并以确认这一情景。我们在这里报告了意外发现的五个矮星系，其复杂的核区特征为多个核和潮汐尾，利用哈勃空间望远镜的高分辨率图像。这些结构在补充的N体模拟中得到了再现，支持它们源于恒星团的迁移和合并的解释。这一过程的稀少检测率和短小的模拟时间尺度（低于100百万年）可能解释了此前为何未被观察到。这项研究强调了需要进行大规模高分辨率调查以全面描绘迁移情景的过程。

**Summary**:

- (1): 本文的研究背景是核星团（NSCs）在各类型星系中心的存在及其形成机制的争论，特别是在矮星系中球状星团（GCs）的迁移与合并。

- (2): 以往的方法主要集中在恒星形成与集群合并的理论上，但缺乏直接观察到正在进行的GCs合并的证据。本文提出的方法通过高分辨率的哈勃空间望远镜图像提供来自复杂核区的直接证据，解决了以往方法缺乏实证支持的问题，该方法具有较强的动机基础。

- (3): 本文的贡献在于首次报告了五个具复杂核区的矮星系，并通过高分辨率图像和N体模拟确认了GCs的迁移和合并过程。

- (4): 本文采用的研究方法包括高分辨率哈勃空间望远镜图像分析及N体模拟，以展示恒星团迁移和合并的结构。

- (5): 本文通过对五个矮星系的研究揭示了GCs合并的存在，虽然没有定量评估性能，但所取得的结果支持其研究目标，即显著提升对核星团形成机制的理解。


## Revealing the ages of metal-rich RR Lyrae via kinematic label transfer
- **Url**: http://arxiv.org/abs/2504.06720v1
- **Authors**: ['HanYuan Zhang', 'Giuliano Iorio', 'Vasily Belokurov', 'N. Wyn Evans', 'Alexey Bobrick', "Valentina D'Orazi"]
- **Abstrat**: RR Lyrae stars have long been considered reliable tracers of old, metal-poor populations, primarily due to their prevalence in globular clusters and the Galactic halo. However, the discovery of a metal-rich subpopulation in the Galactic disc, kinematically colder and more rotationally supported, challenges this classical view. Understanding the age of these metal-rich RR Lyrae stars is crucial for constraining their formation pathways and assessing what Galactic populations they are tracing. In this work, we leverage the unprecedented astrometric precision of Gaia DR3 to infer the age distribution of metal-rich RR Lyrae stars through a kinematic comparison with O-rich Mira variables. Mira variables, with their well-established period-age relation, serve as a natural clock, allowing us to transfer age information to RR Lyrae stars via their phase-space properties. By applying this approach across different metallicity bins, we find that the most metal-rich RR Lyrae stars ($[\rm Fe/H] > -0.5$) exhibit kinematics consistent with a population significantly younger ($\approx 6-7$ Gyr) than typically assumed for RR Lyrae stars. In contrast, those with $-1 < [\rm Fe/H] < -0.5$ show properties more aligned with older ($\approx 9-11$ Gyr) populations. Interestingly, we also find evidence of a possible double age populations for the most metal-rich RR Lyrae, one younger with ages between 3 and 6 Gyr, and another one older ranging from 8 to 11 Gyr. These results provide strong evidence that metal-rich RR Lyrae stars in the Galactic field do not exclusively trace ancient populations. This finding challenges the current model of RR Lyrae formation and supports alternative formation scenarios, such as binary evolution.


**Translated Abstract**: 

RR Lyrae 星长期以来被认为是追踪古老金属贫乏群体的可靠标志，主要因其在球状星团和银河晕中的普遍性。然而，在银河盘中发现的金属丰富亚群体，运动学上较冷且更具旋转支撑，挑战了这种经典观点。理解这些金属丰富的RR Lyrae 星的年龄对于约束它们的形成路径和评估它们所追踪的银河群体至关重要。在这项工作中，我们利用Gaia DR3所提供的前所未有的天文测量精度，通过与富氧的Mira变星进行运动学比较，推断金属丰富的RR Lyrae 星的年龄分布。Mira变星具有良好的周期-年龄关系，可以作为自然时钟，使我们可以通过它们的相位空间特性将年龄信息转移到RR Lyrae 星。通过在不同金属丰度区间应用该方法，我们发现最金属丰富的RR Lyrae 星（[$\rm Fe/H] > -0.5$）的运动学与显著年轻的群体（约6-7亿年）一致，而那些金属丰度在$-1 < [\rm Fe/H] < -0.5$的星则显示出与较老（约9-11亿年）群体更一致的特征。有趣的是，我们还发现了金属丰富的RR Lyrae星可能存在双年龄群体，其中一个年轻，年龄在3至6亿年之间，另一个较老，范围在8至11亿年。 这些结果强烈表明，银河场中的金属丰富的RR Lyrae 星并不专门追踪古老的群体。本发现挑战了目前的RR Lyrae形成模型，支持其他形成场景，如双星演化。

**Summary**:

- (1): 本文研究背景是RR Lyrae 星传统上被认为是宇宙中古老金属贫乏群体的经典标志，但最近发现的金属丰富亚群体提出了这一观点的挑战。

- (2): 过去的研究主要依靠运动学、光变曲线和金属丰度关系来估计RR Lyrae 星的年龄，但这些方法未能准确反映金属丰富亚群体的年龄。本文提出的方法通过将RR Lyrae 星与具有契合的Mira变星进行运动学对比，更好地推断年龄，从而解决过去的局限性，该方法具有良好的动机，能够更准确地评估金属丰富RR Lyrae星的年龄分布。 

- (3): 本文的贡献在于首次揭示了金属丰富RR Lyrae 星群体的年龄特征，发现其年龄显著不同于传统观念的结果，并提出可能存在双年龄群体的观点。

- (4): 本文的研究方法是利用Gaia DR3的高精度数据，通过与O-rich Mira变星的运动学比较，来推断不同金属丰度区间的RR Lyrae 星的年龄。

- (5): 本文的方法在推断金属丰富RR Lyrae 星的年龄方面取得显著进展，表现出这些星的年轻性与已有模型的差异。这一性能增强了作者的研究目标，实现了对银河星群体形成路径的深入理解。


## Universal profile for cosmic birefringence tomography with radio galaxies
- **Url**: http://arxiv.org/abs/2504.06709v1
- **Authors**: ['Fumihiro Naokawa']
- **Abstrat**: We propose a new method to tomographically probe cosmic birefringence using radio galaxies. We show that the redshift evolution of the cosmic birefringence angle induced by a slow-rolling pseudoscalar field, which is a candidate for dynamical dark energy, is independent of the detailed model of the pseudoscalor field. This universal profile evolves predominantly at $z\lesssim10$. In contrast, if the origin is a dark matter-like pseudscalor field, the resulting birefringence angle tends to be negligible in the low-redshift regime. This new insight provides a strong motivation to independently test the cosmic birefringence using polarized astrophysical sources such as radio galaxies. We find that a sample size of $\order{10^5-10^6}$ is required to distinguish the profiles, which is achievable with ongoing and upcoming radio surveys such as ASKAP or SKA.


**Translated Abstract**: 

我们提出了一种新方法，利用射电星系进行宇宙双折射的层析成像探测。我们展示了由慢滚动的伪标量场引起的宇宙双折射角的红移演化与伪标量场的详细模型无关。这种普遍特征主要在 $z \lesssim 10$ 时演化。相反，如果起源是类似暗物质的伪标量场，结果的双折射角在低红移范围内往往可以忽略。这个新见解为使用极化天体源（如射电星系）独立测试宇宙双折射提供了强有力的动机。我们发现需要约 $10^5-10^6$ 的样本量来区分这些特征，这在正在进行和即将进行的射电调查（如ASKAP或SKA）中是可实现的。

**Summary**:

- (1): 本文的研究背景是宇宙双折射的研究，该现象通过光子传播过程中的极化平面旋转探测全球性质的违背，以及其与暗能量或暗物质相关性。

- (2): 过去的方法主要依赖于宇宙微波背景（CMB）数据进行双折射角的测量，但这仍然存在测量系统误差和对时间演化的有限信息的问题。与现有方法不同，所提出的方法利用极化射电星系进行层析成像，能有效独立测试双折射并克服CMB方法的局限性，因此具有充分的动机。

- (3): 本文的贡献是在低红shift环境下提出了一种新的探测宇宙双折射的普遍特征，同时为利用极化射电星系的未来调查提供了支持。

- (4): 本文提出的研究方法是基于极化射电星系的层析成像技术，分析从伪标量场引起的宇宙双折射角度及其时间演化。

- (5): 所提出的方法在识别宇宙双折射特征方面，要求样本量达到 $10^5-10^6$，这一目标可以通过未来的射电探测（如ASKAP或SKA）实现，从而支持研究者对宇宙双折射的深入探讨。


## Evolution of the Comptonizing medium of the black-hole candidate Swift J1727.8$-$1613 along the hard to hard-intermediate state transition using NICER
- **Url**: http://arxiv.org/abs/2504.06705v1
- **Authors**: ['Divya Rawat', 'Mariano Méndez', 'Federico García', 'Pierre Maggi']
- **Abstrat**: We analyse the properties of the Comptonizing medium in the black-hole X-ray binary Swift J1727.8$-$1613 using the time-dependent Comptonization model vkompth, using NICER observations of type-C QPOs in the hard and hard-intermediate states. During the 2023 outburst of the source, we measure the rms and phase lags of the QPO across 45 observations as the QPO frequency, $\nu_{\rm QPO}$, evolves from $\sim 0.3$ Hz to $\sim 7$ Hz. By simultaneously fitting the time-averaged spectrum of the source and the rms and lag spectra of the QPO, we derive the evolution of the disk and corona parameters. At $\nu_{\rm QPO} = 0.34$ Hz, the QPO phase lags are hard, with 10 keV photons lagging 0.5 keV photons by $\sim 0.5$ rad. As $\nu_{\rm QPO}$ increases, the lags for the same energy bands decrease, reaching near zero at $\nu_{\rm QPO} \sim 1.2$ Hz, and then reverse to soft lags of $\sim -1.1$ rad at $\nu_{\rm QPO} \sim 7$ Hz. Initially, the inner radius of the accretion disk is truncated at $\sim 30-40 R_g$ (assuming a 10 solar-mass black hole) and, as the QPO frequency increases, the truncation radius decreases down to $\sim 10 R_g$. Initially, two coronas of sizes of $\sim 6.5 \times 10^3$ km and $\sim 2 \times 10^3$ km, extend over the disk and are illuminated by different regions of the disk. As the QPO frequency increases, both the coronas shrink to $\sim 2 \times 10^3$ km at $\nu_{\rm QPO} = 2.5$ Hz. Following a data gap, one corona expands again, peaking at a size of $\sim 2 \times 10^4$ km. We interpret the evolution of the coronal size in the context of accompanying radio observations, discussing its implications for the interplay between the corona and the jet.


**Translated Abstract**: 

我们分析了黑洞 X 射线双星 Swift J1727.8−1613 中康普顿化介质的特性，采用时间依赖的康普顿化模型 vkompth，利用 NICER 在硬态和硬中间态下对 Type-C QPO 的观测。在此源的 2023 年爆发期间，我们测量了 QPO 的 rms 和相位滞后，跨越 45 次观测，QPO 频率 νQPO 从 ∼ 0.3 Hz 发展到 ∼ 7 Hz。通过同时拟合该源的时间平均光谱及 QPO 的 rms 和滞后光谱，我们得到了盘和冕的参数演变。在 νQPO = 0.34 Hz 时，相位滞后为硬滞后，10 keV 光子滞后于 0.5 keV 光子的约 0.5 rad。随着 νQPO 的增加，相同能量带的滞后降低，在 νQPO ∼ 1.2 Hz 时接近于零，然后在 νQPO ∼ 7 Hz 时反转为软滞后约 -1.1 rad。初始情况下，吸积盘的内部半径在 ∼ 30-40 Rg 处被截断（假设为 10 个太阳质量的黑洞），随着 QPO 频率的增加，截断半径降至约 10 Rg。最初，两个冕的大小约为 ∼ 6.5 × 10^3 km 和 ∼ 2 × 10^3 km，分别延伸超过盘，并受到盘不同区域的照射。随着 QPO 频率的提高，这两个冕缩小至在 νQPO = 2.5 Hz 时的 ∼ 2 × 10^3 km。在数据缺口之后，一个冕再次扩展，最大达到 ∼ 2 × 10^4 km。我们在伴随的射电观测背景下解释了冕体积的演变，并讨论它对冕与喷流相互作用的影响。

**Summary**:

- (1): 本文研究的背景是黑洞 X 射线双星（BHXB）系统在出爆发期间经历显著的 X 射线波动，包括光谱特征和模式变化，尤其是 QPO 现象。

- (2): 过去的方法主要是基于时间平均光谱和频域分析，但这些方法未考虑随时间变化的康普顿化过程。本文的方法则采用时间依赖的康普顿化模型 vkompth，能够更好地跟踪 QPO 频率的演变，并解决了以往方法对动态特性的忽视。

- (3): 本文的贡献在于通过调整和拟合发射谱、rms 和滞后谱，揭示了在不同 QPO 状态下吸积盘和冕介质参数的演变，阐明了这两者与喷流之间的相互作用。

- (4): 本文提出的研究方法是通过 NICER 对 Swift J1727.8−1613 的 QPO 观测，结合时间依赖的康普顿化模型 vkompth，分析 QPO 频率变化时的光谱和冕体积演变。

- (5): 本文在实现了 QPO 频率从 ∼ 0.3 Hz 到 ∼ 7 Hz 的演变分析上取得了较好的性能。这种性能支持了他们评估吸积过程及其与黑洞喷流之间相互作用的目标。


## A multi-scale view of the magnetic field morphology in the hot molecular core G31.41+0.31
- **Url**: http://arxiv.org/abs/2504.06701v1
- **Authors**: ['C. Y. Law', 'M. T. Beltrán', 'R. S. Furuya', 'J. M. Girart', 'D. Galli', 'R. Cesaroni', 'L. Moscadelli', 'D. Arzoumanian', 'A. Lorenzani', 'M. Padovani', 'A. Sanna', 'G. Surcis']
- **Abstrat**: Multiscale studies of the morphology and strength of the magnetic field are crucial to properly unveil its role and relative importance in high-mass star and cluster formation. G31.41+0.31 (G31) is a hub-filament system that hosts a high-mass protocluster embedded in a hot molecular core (HMC). G31 is one of the few sources showing a clear hourglass morphology of the magnetic field on scales between 1000 au and a few 100 au in previous interferometric observations. This strongly suggests a field-regulated collapse. To complete the study of the magnetic field properties in this high-mass star-forming region, we carried out observations with the James Clerk Maxwell Telescope $850 \mu$m of the polarized dust emission. These observations had a spatial resolution of $\sim$0.2 pc at 3.75 kpc. The aim was to study the magnetic field in the whole cloud and to compare the magnetic field orientation toward the HMC from $\sim$50,000 au to $\sim$260 au scales. The large-scale ($\sim$5 pc) orientation of the magnetic field toward the position of the HMC is consistent with that observed at the core ($\sim$4,000 au) and circumstellar ($\sim$260 au) scales. The self-similarity of the magnetic field orientation at these different scales might arise from the brightest sources in the protocluster, whose collapse is dragging the magnetic field. These sources dominate the gravitational potential and the collapse in the HMC. The cloud-scale magnetic field strength of the G31 hub-filament system, which we estimated using the Davis-Chandrasekhar-Fermi method, is in the range 0.04--0.09 mG. The magnetic field orientation in the star-forming region shows a bimodal distribution, and it changes from an NW--SE direction in the north to an E--W direction in the south [abridged abstract].


**Translated Abstract**: 
多尺度研究磁场的形态和强度对于揭示其在高质量恒星和星团形成中的作用及相对重要性至关重要。G31.41+0.31（G31）是一个中心-细丝系统，内部嵌套着一个高质量的前驱星团，并位于一个热分子核心（HMC）内。G31是少数几种在1000 au到几百au尺度上展示明确沙漏形态的磁场源之一，之前的干涉观测强烈表明这可能是受磁场调控的坍缩。为了完成对此高质量星形成区磁场特性的研究，我们使用詹姆斯·克拉克·麦克斯韦望远镜进行了850微米极化尘埃发射的观测。这些观测的空间分辨率约为0.2 pc（3.75 kpc）。研究的目的是分析整个云团中的磁场，并比较从约50,000 au到约260 au尺度的HMC磁场方向。这一大尺度（约5 pc）向HMC位置的磁场方向与核心（约4,000 au）和恒星级（约260 au）尺度的观察结果一致。从这些不同尺度的磁场方向自相似性可能源于前驱星团中最亮的源，这些源的坍缩正在拖拽磁场。这些源主导了HMC中的引力势能以及坍缩。我们使用Davis-Chandrasekhar-Fermi方法估算的G31中心-细丝系统的云规模磁场强度范围为0.04到0.09 mG。星形成区中的磁场方向显示出双峰分布，且从北部的西北-东南方向转变为南部的东西方向。方向变化发生在HMC的近旁，支持云-云碰撞形成该星形成区的情景。不同的磁场方向可能是碰撞云的原始方向的遗迹。

**Summary**:

- (1): 本文的研究背景是磁场在高质量恒星和星团形成过程中的重要性，尤其是在大尺度到小尺度的不同层面上。

- (2): 过去的方法主要是依赖于在有限区域的分辨率较低的干涉观测，存在研究尺度有限的问题。与之不同，文中采用了新的大尺度观测方法，通过对整个云团的综合研究，弥补了先前的局限性，为揭示不同尺度的磁场特性提供了更全面的视角。

- (3): 本文的贡献在于首次对G31.41+0.31进行多尺度的磁场研究，揭示了其在星形成机制中的复杂而重要的作用，并提供了磁场方向可能的起源情景。

- (4): 本文的方法论包括使用詹姆斯·克拉克·麦克斯韦望远镜进行850微米的极化尘埃发射观测，结合Davis-Chandrasekhar-Fermi方法评估云规模磁场的强度，并对不同尺度下的磁场方向进行比较分析。

- (5): 本文所提的方法在研究G31区域的磁场方向和强度方面取得了重要的发现，支持了以云-云碰撞为形成机制的假设，从而进一步推动了对高质量恒星和星团形成过程的理解。


## Deep Extragalactic VIsible Legacy Survey (DEVILS): New robust merger rates at intermediate redshifts
- **Url**: http://arxiv.org/abs/2504.06613v1
- **Authors**: ['Melissa F. Fuentealba-Fuentes', 'Luke J. M. Davies', 'Aaron S. G. Robotham', 'Robin H. W. Cook', 'Sabine Bellstedt', 'Claudia D. P. Lagos', 'Matías Bravo', 'Malgorzata Siudek']
- **Abstrat**: Mergers are fundamental to our understanding of the processes driving the evolution of the structure and morphology of galaxies, star formation, AGN activity, and the redistribution of stellar mass in the Universe. Determining the fraction and properties of mergers across cosmic time is critical to understanding the formation of the Universe we observe today. This fraction and its evolution also provide inputs and constraints for cosmological simulations, crucial for theoretical models of galaxy evolution. We present robust estimates of major close-pair fractions and merger rates at $0.2 < z < 0.9$ in the Deep Extragalactic VIsible Legacy Survey (DEVILS). We identify major mergers by selecting close-pairs with a projected spatial separation $r_{\mathrm{sep}} < 20$ h$^{-1}$ kpc and a radial velocity separation $v_{\mathrm{sep}} < 500$ km s$^{-1}$. For galaxies with stellar masses of log$_{10}$($M_\star$/$M_\odot$) = 10.66 $\pm$ 0.25 dex, we find a major close-pair fraction of $\approx 0.021$ at $0.2 < z < 0.34$ using a highly complete, unbiased spectroscopic sample. We extend these estimates to $0.2 < z < 0.9$ by combining the full probability distribution of redshifts for galaxies with high-quality spectroscopic, photometric, or grism measurements. Fitting a power-law $\gamma_{m} = A(1 + z)^m$, we find $A = 0.024 \pm 0.001$ and $m = 0.55 \pm 0.22$. Consistent with previous results, the shallow slope suggests weak redshift evolution in the merger fraction. When comparing with large hydrodynamical simulations, we also find consistent results. We convert close-pair fractions to merger rates using several literature prescriptions for merger timescales and provide all measurements for future studies.


**Translated Abstract**:

合并在理解驱动星系结构和形态演化、恒星形成、活动星系核（AGN）活性及宇宙中恒星质量再分配过程方面至关重要。确定宇宙中的合并频率及其属性对于理解我们今天所观察到的宇宙形成至关重要。本文在深外星系可见光遗产调查（DEVILS）中提出了在0.2 < z < 0.9范围内的主要临近对的比例和合并率的可靠估计。我们通过选择投影空间分离小于20 h$^{-1}$ kpc以及径向速度分离小于500 km s$^{-1}$的临近对来识别主要合并。对质量为 log$_{10}$(M$_{*}$/M$_{\odot}$) = 10.66 ± 0.25 dex的星系，我们在0.2 < z < 0.34的范围内发现主要临近对的比例约为0.021。通过结合高质量光谱、光度或光谱测量的红shift全概率分布，我们将这些估计扩展到0.2 < z < 0.9。拟合幂律关系，我们得到A = 0.024 ± 0.001和m = 0.55 ± 0.22。与之前的结果一致，较浅的斜率表明合并比例在红shift上的演化微弱。与大型流体动力学模拟比较的结果也基本一致。我们使用文献中多个合并时间尺度的公式将临近对比例转换为合并率，并为未来研究提供了所有测量数据。

**Summary**:

- (1): 本文的研究背景是星系合并在宇宙结构和星系形成中的重要性，以及对合并率的理解对于表征宇宙演化至关重要。

- (2): 过去的方法主要依靠光谱样本来识别合并，存在样本不完整及偏差问题。本文通过利用更全面的观测数据和合并时间尺度的文献，提出了一种新的统计估计方法，解决了这些问题。

- (3): 本文的贡献在于提供了在0.2 < z < 0.9范围内的主要合并率的可靠估计，并确认合并比例的红shift演化效应较弱。

- (4): 研究方法包括选择组建在特定空间与速度条件下的临近星系对，利用高质量光谱和光度数据扩展至广泛的红shift范围，并通过拟合幂律关系估计合并率。

- (5): 本文在0.2 < z < 0.9范围内成功获取了合并率的测定，验证了该方法能有效支持其研究目标。


## A Galaxy with an Extremely Blue UV Slope $β=-3$ at $z=9.25$ Identified by JWST Spectroscopy: Evidence for a Weak Nebular Continuum and Efficient Ionizing Photon Escape?
- **Url**: http://arxiv.org/abs/2411.19893v2
- **Authors**: ['Hiroto Yanagisawa', 'Masami Ouchi', 'Kimihiko Nakajima', 'Yuichi Harikane', 'Seiji Fujimoto', 'Yoshiaki Ono', 'Hiroya Umeda', 'Minami Nakane', 'Hidenobu Yajima', 'Hajime Fukushima', 'Yi Xu']
- **Abstrat**: We investigate UV continuum slopes $\beta$ of 863 galaxies at $z=4-14$ using archival JWST/NIRSpec PRISM spectra obtained from major JWST GTO, ERS, and GO programs, including JADES, CEERS, and UNCOVER. Among these galaxies, we identify a remarkable galaxy at $z=9.25$, dubbed EBG-1, with a significantly blue UV slope $\beta=-2.99\pm0.15$, unlike the rest of the galaxies that exhibit red continua or ambiguous blue continua hindered by large uncertainties. We confirm that the $\beta$ value negligibly changes by the data reduction and fitting wavelength ranges for UV emission/absorption line masking. The extreme blue slope, $\beta=-3.0$, rules out significant contributions from dust extinction or AGN activity. Comparing with stellar and nebular emission models, we find that such a blue UV slope cannot be reproduced solely by stellar models even with very young, metal-poor, or top-heavy contiguous star formation associated with strong nebular continua making the UV slopes red, but with a high ionizing photon escape fraction, $f_\mathrm{esc}^\mathrm{ion} \gtrsim 0.5$, for a weak nebular continuum. While the H$\beta$ emission line is not detected, likely due to the limited sensitivity of the spectrum, we find moderately weak [O III] $\lambda\lambda$4959,5007 emission lines for the given star-formation rate ($3\, \mathrm{M_\odot}$ yr$^{-1}$) and stellar mass ($10^{8.0} \, \mathrm{M_\odot}$) that are about three times weaker than the average emission lines, again suggestive of the high ionizing photon escape fraction, $f_\mathrm{esc}^\mathrm{ion} \sim 0.7$ or more. EBG-1 would provide crucial insights into stellar and nebular continuum emission in high-redshift galaxies, serving as an example of the ionizing photon escaping site at the epoch of reionization.


**Translated Abstract**: 

本文探讨了863个红移在4到14之间的星系的紫外连续波段斜率β，利用从主要的JWST GTO、ERS和GO项目（包括JADES、CEERS和UNCOVER）获得的档案JWST/NIRSpec PRISM光谱。在这些星系中，我们发现了一个显著的星系EBG-1，其红移为9.25，具有显著的蓝色紫外斜率β=-2.99±0.15，这与其他整体呈现红色或不明确的蓝色斜率的星系不同。我们确认β值在数据处理和光谱波长范围中的变化微乎其微。极端的蓝斜率β=-3.0排除了尘埃消光或活跃星系核（AGN）活动的显著贡献。与恒星和星云发射模型比较，我们发现这种蓝色紫外斜率不能仅通过恒星模型再现，即使是在非常年轻、金属贫乏或顶部重的连续恒星形成伴随强星云连续体的情况下，但具有高的特殊电离光子逸出分数fescion≥0.5。虽然Hβ发射线未被检测到，可能是由于光谱的敏感度限制，我们发现[O III] λλ4959,5007发射线相对较弱，结合给定的星形成速率（3 M⊙/yr）和星系质量（10⁸.⁰ M⊙），其强度比平均发射线弱约三倍，再次暗示了高的特殊电离光子逸出分数fescion∼0.7或更高。EBG-1为高红移星系中的恒星和星云连续体发射提供了重要见解，作为大爆炸重离子化时期电离光子逸出的实例。

**Summary**:

- (1): 本文研究早期宇宙中星系的电离光子逸出特征，关注高红移星系的形成与演化，特别是其紫外斜率（β）对电离光子逃逸的重要性。

- (2): 以往的方法主要依赖光度法来估算紫外斜率β，但这种方法受到发射线干扰，导致结果不准确。相比之下，本文采用高质量的光谱数据进行精确测量，克服了发射线影响。

- (3): 本文贡献在于识别出一个极端蓝色紫外斜率（β=-2.99±0.15）的星系EBG-1，提供了对高红移星系的全新视角，特别是电离光子逃逸和弱星云连续体的研究。

- (4): 研究方法包括分析来自多个JWST项目的大规模光谱数据，精确测定和比较星系的紫外斜率与相关的发射线强度，以确定电离光子逸出分数。

- (5): 研究显示EBG-1具有较高的电离光子逸出分数（fescion≈0.7），表明其在驱动宇宙重离子化过程中的潜在作用，证明了本文目标的可行性。


## Exploring cosmological constraints of the weak gravitational lensing and galaxy clustering joint analysis in the CSST photometric survey
- **Url**: http://arxiv.org/abs/2410.19388v2
- **Authors**: ['Qi Xiong', 'Yan Gong', 'Xingchen Zhou', 'Hengjie Lin', 'Furen Deng', 'Ziwei Li', 'Ayodeji Ibitoye', 'Xuelei Chen', 'Zuhui Fan', 'Qi Guo', 'Ming Li', 'Yun Liu', 'Wenxiang Pei']
- **Abstrat**: We explore the joint weak lensing and galaxy clustering analysis from the photometric survey operated by the China Space Station Telescope (CSST), and study the strength of the cosmological constraints. We employ a high-resolution JiuTian-1G simulation to construct a partial-sky light cone to $z=3$ covering 100 deg$^2$, and obtain the CSST galaxy mock samples based on an improved semi-analytical model. We perform a multi-lens-plane algorithm to generate corresponding synthetic weak lensing maps and catalogs. Then we generate the mock data based on these catalogs considering the instrumental and observational effects of the CSST, and use the Markov Chain Monte Carlo (MCMC) method to perform the constraints. The covariance matrix includes non-Gaussian contributions and super-sample covariance terms, and the systematics from intrinsic alignments, galaxy bias, photometric redshift uncertainties, shear calibration, and non-linear effects are considered in the analysis. We find that the constraint result is comparable to that from Stage III surveys, and it can be significantly improved further in the full CSST survey with 17500 deg$^2$. This indicates the CSST photometric survey is powerful for exploring the Universe.


**Translated Abstract**: 

我们探讨了中国空间站望远镜（CSST）进行的光学测量中，弱引力透镜效应和星系聚类联合分析的强大宇宙学约束。我们利用高分辨率的JiuTian-1G模拟构建了一个覆盖100平方度、红移达到3的部分天空光锥，并基于改进的半解析模型获得了CSST星系的模拟样本。我们采用多透镜面算法生成对应的合成弱透镜图像和目录。随后，我们根据这些目录生成考虑了CSST的仪器和观测效应的模拟数据，并使用马尔可夫链蒙特卡罗（MCMC）方法进行约束分析。协方差矩阵中包含非高斯成分和超样本协方差项，并考虑了内在对齐、星系偏差、光谱红移不确定性、剪切标定和非线性效应等系统误差。我们发现约束结果与第三阶段调查相当，并且在覆盖17500平方度的完整CSST调查中可以显著改善。这表明CSST光学调查在探索宇宙方面具有强大的潜力。

**Summary**:

- (1): 本文研究宇宙学约束的背景是，通过更准确的观察手段探索宇宙的组成，特别是暗能量和暗物质的本质。

- (2): 过去常用的方法是单一的星系聚类或弱引力透镜效应分析，存在相互独立、无法综合信息的问题。本文提出的方法结合两者的优点，通过联合分析解决了单一方法的局限性，并且为深入了解宇宙结构提供了更有力的支持。

- (3): 本文的贡献在于通过使用CSST的光学测量，展示了弱引力透镜和星系聚类联合分析的潜力，并证明该方法能够提供与第三阶段调查相当的宇宙学约束。

- (4): 本文采用的方法包括构建光锥、生成模拟星系目录、生成弱透镜图像，并使用MCMC方法进行参数约束分析，考虑了多个系统误差因素。

- (5): 本文的方法在约束宇宙学参数方面实现了与第三阶段调查相似的性能，并且在全CSST调查中有潜力获得显著改善，支持其研究目标。


## One-Dimensional Relativistic Self-Gravitating Systems
- **Url**: http://arxiv.org/abs/2504.06515v1
- **Authors**: ['Robert B. Mann']
- **Abstrat**: One of the oldest problems in physics is that of calculating the motion of $N$ particles under a specified mutual force: the $N$-body problem. Much is known about this problem if the specified force is non-relativistic gravity, and considerable progress has been made by considering the problem in one spatial dimension. Here, I review what is known about the relativistic gravitational $N$-body problem. Reduction to one spatial dimension has the feature of the absence of gravitational radiation, thereby allowing for a clear comparison between the physics of one-dimensional relativistic and non-relativistic self-gravitating systems. After describing how to obtain a relativistic theory of gravity coupled to $N$ point particles, I discuss in turn the two-body, three-body, four-body, and $N$-body problems. Quite general exact solutions can be obtained for the two-body problem, unlike the situation in general relativity in three spatial dimensions for which only highly specified solutions exist. The three-body problem exhibits mild forms of chaos, and provides one of the first theoretical settings in which relativistic chaos can be studied. For $N\geq 4$, other interesting features emerge. Relativistic self-gravitating systems have a number of interesting problems awaiting further investigation, providing us with a new frontier for exploring relativistic many-body systems.


**Translated Abstract**: 

物理学中最古老的问题之一是计算在指定相互作用力下，$N$ 个粒子运动的问题：$N$ 体问题。如果指定的力是非相对论引力，已知该问题的许多信息，并且已经通过考虑一维情况取得了相当大的进展。在这里，我回顾了与相对论引力 $N$ 体问题相关的已知内容。将问题简化为一维的特征是没有引力辐射，因此能够清晰地比较一维相对论和非相对论自引力系统的物理。在描述如何获得与 $N$ 个点粒子耦合的相对论重力理论后，我依次讨论了两体、三体、四体及 $N$ 体问题。对于两体问题，可以得到相当一般的精确解，这与三维空间中的广义相对论情况不同，后者仅存在高度特定的解。三体问题表现出轻微的混沌形式，并提供了一个研究相对论混沌的理论背景。对于 $N \geq 4$，出现了其他有趣的特征。相对论自引力系统中存在诸多有趣的问题等待进一步研究，为探索相对论多体系统提供了新的前沿。

**Summary**:

- (1): 本文背景为$N$ 体问题，即在指定相互作用力下， $N$ 个粒子的运动；该问题在多个物理子领域中均有重要地位，尤其是引力相互作用的挑战性。

- (2): 过去的方法主要集中在非相对论引力的情境下，面临缺乏通用解的问题，尤其在三维空间情况下无解。而提出的方法通过研究一维相对论自引力系统（ROGS），避免了引力辐射问题，能够获得更加清晰的物理比较。这种方法有效地解决了非相对论情况下无法实现的相对论特性研究问题，具有良好的动机。

- (3): 本文的贡献在于系统回顾了一维相对论重力$N$ 体问题，提供了两体问题的精确解及其混沌现象的初步分析，推动了对高维情形相对论的理解。

- (4): 研究方法主要是构建一维相对论重力理论，结合$N$ 个点粒子，通过分析不同体数（2, 3, 4, 和 N）下的问题，来探索相对论自引力系统的性质。

- (5): 本文的方法在解决相对论自引力系统中的多体问题上取得了理论性成果，并探讨了相对论混沌现象，支持了对相对论多体系统的深入研究目标。


## Extraplanar [C II] and Halpha in the Edge-On Galaxy NGC 5775
- **Url**: http://arxiv.org/abs/2504.06483v1
- **Authors**: ['William T. Reach', 'Dario Fadda', 'Richard J. Rand', 'Gordon J. Stacey']
- **Abstrat**: Spiral galaxies are thin and susceptible to being disrupted vertically. The largest star clusters, and nuclear starbursts, generate enough energy from winds and supernovae to send disk material to the halo. % METHODS Observations of edge-on galaxies allow for the clearest view of vertical disruptions. We present new observations of the nearby, edge-on galaxy NGC 5775 with SOFIA [C II] 157.7 micron and archival images from Hubble in Halpha to search for extraplanar gas. The extraplanar [C II] extends 2 kpc from the midplane over much of the star-forming disk. The extraplanar [C II] at 2 kpc from the midplane approximately follows the rotation of the disk, with a lag of approximately 40 km/s; this lag is similar to what has been previously reported in Halpha. Significant vertical extensions (to 3 kpc) are seen on the northeast side of the galaxy, potentially due to super star clusters in the NGC 5775 disk combined with gravitational interaction with the companion galaxy NGC 5774. The Halpha narrow-band image reveals a narrow plume that extends 7 kpc from the nucleus and is almost exactly perpendicular to the disk. The plume shape is similar to that seen from the comparable galaxy NGC 3628 and may arise from the nuclear starburst. Alternatively, the Halpha plume could be a relic of past activity.


**Translated Abstract**:  

螺旋星系是薄的，容易在垂直方向上受到扰动。最大的星团和核星爆发产生的能量足以通过风和超新星将盘面物质送入晕。对边缘性星系的观察允许我们最清晰地观察垂直扰动。我们展示了对附近的边缘性星系NGC 5775的新观察，使用SOFIA的[C II] 157.7微米以及Hubble的Hα归档图像，以搜索外平面气体。外平面[C II]在星形成盘的中平面上方延伸了2 kpc。在中平面上方2 kpc的外平面[C II]大致跟随盘的旋转，速度延迟约为40千米/秒；这个延迟与之前在Hα中报告的相似。东南侧显示出显著的垂直延伸（至3 kpc），可能是由于NGC 5775磁盘中的超级星团与伴星系NGC 5774的引力相互作用结合而成。Hα窄带图像显示出一条狭窄的羽流，延伸至核区7 kpc，几乎与盘面垂直。羽流的形状与相似星系NGC 3628中看到的相似，可能源于核星爆发。或者，Hα羽流可能是过去活动的遗迹。

**Summary**:

- (1): 本文研究背景为螺旋星系在垂直方向上的扰动，尤其是星爆发和星团对气体流动的影响。

- (2): 过去的研究方法主要采用对边缘性星系的观测，面临空间分辨率和对外平面气体的检测能力的挑战。本文提出的方法结合了SOFIA的高灵敏度在远红外波段的观察，与Hubble的Hα图像相结合，能够更有效地探测外平面气体，解决了磁盘中气体延伸检测的不足。

- (3): 本文的贡献在于提供了对NGC 5775外平面气体分布的新视角，揭示了其与星团活动及伴星系的引力相互作用之间的关联。

- (4): 研究方法包括使用SOFIA的远红外光谱观测[C II]线以及Hubble的Hα观测，旨在分析NGC 5775星系中的气体分布和动力学。

- (5): 实验在检测NGC 5775中外平面气体的分布和动态方面取得了显著结果，支持了对星系演化机制的进一步理解。


## Analytic calculation of dynamical friction for Plummer sphere in ultralight dark matter
- **Url**: http://arxiv.org/abs/2504.06448v1
- **Authors**: ['O. V. Barabash', 'T. V. Gorkavenko', 'V. M. Gorkavenko', 'O. M. Teslyk', 'N. S. Yakovenko', 'A. O. Zaporozhchenko', 'E. V. Gorbar']
- **Abstrat**: The dynamical friction force acting on a spatially extended probe (globular clusters and dwarf galaxies) moving in the environment of ultralight bosonic dark matter in the state of the Bose-Einstein condensate is determined. Modeling the probe as a Plumer sphere of radius $l_p$, the radial and tangential components of the dynamic friction force are found in an analytic form, which reduce in the limit $l_p \to 0$ to the corresponding analytic expressions obtained in the literature in the case of a point probe. The dependence of dynamical friction force on boson particle mass $m$ was analyzed and found to be non-monotonous in the interval $10^{-23} - 10^{-21}$eV.


**Translated Abstract**: 

本文确定了在超轻玻色暗物质以玻色-爱因斯坦凝聚态环境中移动的空间扩展探针（如球状星团和矮星系）所受到的动力摩擦力。将探针建模为半径为 $l_p$ 的 Plummer 球，找到了动力摩擦力的径向和切向分量的解析形式，在 $l_p \to 0$ 的极限下可归结为文献中得到的点探针的相应解析表达式。研究了动力摩擦力对玻色子粒子质量 $m$ 的依赖，发现在 $10^{-23} - 10^{-21}$ eV 范围内呈现非单调性。

**Summary**:

- (1): 本文研究了在超轻玻色暗物质环境中移动的天体（如球状星团和矮星系）所受到的动力摩擦力。

- (2): 过去的研究主要集中在点探针的动力摩擦力上，未考虑物体的空间扩展性，导致了对更大质量扩展天体的摩擦力分析不足。本文提出的方法通过将探针建模为 Plummer 球来解决这一问题，从而更好地描述大尺度天体的动力摩擦特性。

- (3): 文章的贡献在于提供了 Plummer 球在超轻玻色暗物质环境中动力摩擦力的解析计算，包括其径向和切向分量的确切表达式。

- (4): 本文提出的研究方法是在稳态下研究半径为 $l_p$ 的 Plummer 球在超轻暗物质环境中的圆周运动，通过傅里叶变换及相关理论计算动力摩擦力。

- (5): 本文的方法在解析计算 Plummer 球的动力摩擦力方面取得了显著进展，特别是在 $10^{-23} - 10^{-21}$ eV 范围内揭示了其对玻色子质量的非单调依赖性，从而支持了其研究目标。


# machine learning
## Sculpting Subspaces: Constrained Full Fine-Tuning in LLMs for Continual Learning
- **Url**: http://arxiv.org/abs/2504.07097v1
- **Authors**: ['Nikhil Shivakumar Nayak', 'Krishnateja Killamsetty', 'Ligong Han', 'Abhishek Bhandwaldar', 'Prateek Chanda', 'Kai Xu', 'Hao Wang', 'Aldo Pareja', 'Oleg Silkin', 'Mustafa Eyceoz', 'Akash Srivastava']
- **Abstrat**: Continual learning in large language models (LLMs) is prone to catastrophic forgetting, where adapting to new tasks significantly degrades performance on previously learned ones. Existing methods typically rely on low-rank, parameter-efficient updates that limit the model's expressivity and introduce additional parameters per task, leading to scalability issues. To address these limitations, we propose a novel continual full fine-tuning approach leveraging adaptive singular value decomposition (SVD). Our method dynamically identifies task-specific low-rank parameter subspaces and constrains updates to be orthogonal to critical directions associated with prior tasks, thus effectively minimizing interference without additional parameter overhead or storing previous task gradients. We evaluate our approach extensively on standard continual learning benchmarks using both encoder-decoder (T5-Large) and decoder-only (LLaMA-2 7B) models, spanning diverse tasks including classification, generation, and reasoning. Empirically, our method achieves state-of-the-art results, up to 7% higher average accuracy than recent baselines like O-LoRA, and notably maintains the model's general linguistic capabilities, instruction-following accuracy, and safety throughout the continual learning process by reducing forgetting to near-negligible levels. Our adaptive SVD framework effectively balances model plasticity and knowledge retention, providing a practical, theoretically grounded, and computationally scalable solution for continual learning scenarios in large language models.


**Translated Abstract**: 

在大型语言模型（LLMs）中，持续学习容易导致灾难性遗忘，即适应新任务会显著降低在先前学习任务上的性能。现有方法通常依赖于低秩的参数高效更新，限制了模型的表现力，并且每个任务引入了额外参数，导致可扩展性问题。为了解决这些局限性，我们提出了一种新颖的持续全微调方法，利用自适应奇异值分解（SVD）。我们的方法动态识别特定于任务的低秩参数子空间，并将更新约束为与先前任务相关的关键方向正交，从而有效地最小化干扰，而无需额外的参数开销或存储先前任务梯度。我们在标准持续学习基准上对我们的方法进行了广泛评估，使用了编码器-解码器模型（T5-Large）和仅解码器模型（LLaMA-2 7B），涵盖了分类、生成和推理等多种任务。实证表明，我们的方法在平均准确率上达到了最高的结果，比最近的基线（如O-LoRA）高出7%，并在整个持续学习过程中显著保持了模型的一般语言能力、指令跟随准确性和安全性，通过将遗忘降低到近乎可忽略的水平。我们的自适应SVD框架有效地平衡了模型的可塑性和知识保留，为大型语言模型中的持续学习场景提供了一种实用、理论基础扎实且计算上可扩展的解决方案。

**Summary**:

- (1): 本文的研究背景是大型语言模型（LLMs）在持续学习中容易发生的灾难性遗忘，即在适应新任务时会显著降低已经学习任务的性能。

- (2): 过去的方法主要依赖于参数高效的微调技术，如Adapters和LoRA。这些方法的问题在于限制了模型的表现力，并且为每个新任务引入了额外的参数，增加了内存占用和推理复杂性。与之不同，本文提出的方法使用自适应低秩子空间更新，以奇异值分解（SVD）为指导，动态识别低秩参数子空间，避免了额外的参数负担和存储先前任务梯度的问题，具备较强的动机。

- (3): 本文的贡献在于提出了一种能够有效减少遗忘、保持模型表现力并且避免参数增长的持续全微调方法。

- (4): 本文提出的研究方法是基于奇异值分解（SVD）进行自适应低秩子空间更新，约束新的梯度更新为与先前任务表示正交，从而最小化干扰。

- (5): 本文的方法在标准持续学习基准上进行了广泛评估，使用了T5-Large和LLaMA-2 7B模型，涵盖分类、生成和推理等任务，达到了比O-LoRA方法高出7%的平均准确率，支持了模型在持续学习过程中的有效性和性能目标。


## Neural Motion Simulator: Pushing the Limit of World Models in Reinforcement Learning
- **Url**: http://arxiv.org/abs/2504.07095v1
- **Authors**: ['Chenjie Hao', 'Weyl Lu', 'Yifan Xu', 'Yubei Chen']
- **Abstrat**: An embodied system must not only model the patterns of the external world but also understand its own motion dynamics. A motion dynamic model is essential for efficient skill acquisition and effective planning. In this work, we introduce the neural motion simulator (MoSim), a world model that predicts the future physical state of an embodied system based on current observations and actions. MoSim achieves state-of-the-art performance in physical state prediction and provides competitive performance across a range of downstream tasks. This works shows that when a world model is accurate enough and performs precise long-horizon predictions, it can facilitate efficient skill acquisition in imagined worlds and even enable zero-shot reinforcement learning. Furthermore, MoSim can transform any model-free reinforcement learning (RL) algorithm into a model-based approach, effectively decoupling physical environment modeling from RL algorithm development. This separation allows for independent advancements in RL algorithms and world modeling, significantly improving sample efficiency and enhancing generalization capabilities. Our findings highlight that world models for motion dynamics is a promising direction for developing more versatile and capable embodied systems.


**Translated Abstract**: 

一个具身系统不仅必须建模外部世界的模式，还必须理解自身的运动动态。运动动态模型对于高效技能获取和有效规划至关重要。在这项工作中，我们引入了神经运动模拟器（Neural Motion Simulator, MoSim），这是一个基于当前观察和动作预测具身系统未来物理状态的世界模型。MoSim在物理状态预测中实现了最先进的性能，并在一系列下游任务中提供了具有竞争力的表现。该工作表明，当世界模型足够准确并能够进行精确的长时间预测时，它可以促进在想象的世界中高效技能获取，甚至实现零-shot 强化学习。此外，MoSim可以将任何无模型强化学习（Reinforcement Learning, RL）算法转变为基于模型的方法，有效地将物理环境建模与RL算法开发解耦。这种分离允许RL算法和世界建模的独立进步，显著提高了样本效率并增强了泛化能力。我们的发现突出了运动动态的世界模型是开发更通用和更强大具身系统的一个有前景的方向。

**Summary**:

- (1): 本文研究背景是具身系统需要同时建模外部世界和自身运动动态，以实现高效的技能获取和有效的规划。

- (2): 过去的方法通常侧重于环境建模，却缺乏对自身运动动态的理解，导致在长期预测和技能训练中效率低下。提出的方法MoSim通过准确的长期预测，解决了这些问题，提供了更有效的技能获取途径，是一个具有良好动机的研究方向。

- (3): 本文的贡献在于引入了神经运动模拟器（MoSim），实现了最先进的物理状态预测性能，并支持将无模型强化学习算法转变为基于模型的方法，从而显著提高样本效率和泛化能力。

- (4): 本文提出的方法论是使用MoSim作为世界模型进行物理状态预测，以支持技能获取和规划，同时解耦物理环境建模与RL算法，使两者可以独立改进。

- (5): MoSim在多个下游任务中表现出竞争力的性能，支持其在想象的世界中实现高效技能获取和零-shot强化学习的目标。


## Are We Done with Object-Centric Learning?
- **Url**: http://arxiv.org/abs/2504.07092v1
- **Authors**: ['Alexander Rubinstein', 'Ameya Prabhu', 'Matthias Bethge', 'Seong Joon Oh']
- **Abstrat**: Object-centric learning (OCL) seeks to learn representations that only encode an object, isolated from other objects or background cues in a scene. This approach underpins various aims, including out-of-distribution (OOD) generalization, sample-efficient composition, and modeling of structured environments. Most research has focused on developing unsupervised mechanisms that separate objects into discrete slots in the representation space, evaluated using unsupervised object discovery. However, with recent sample-efficient segmentation models, we can separate objects in the pixel space and encode them independently. This achieves remarkable zero-shot performance on OOD object discovery benchmarks, is scalable to foundation models, and can handle a variable number of slots out-of-the-box. Hence, the goal of OCL methods to obtain object-centric representations has been largely achieved. Despite this progress, a key question remains: How does the ability to separate objects within a scene contribute to broader OCL objectives, such as OOD generalization? We address this by investigating the OOD generalization challenge caused by spurious background cues through the lens of OCL. We propose a novel, training-free probe called $\textbf{Object-Centric Classification with Applied Masks (OCCAM)}$, demonstrating that segmentation-based encoding of individual objects significantly outperforms slot-based OCL methods. However, challenges in real-world applications remain. We provide the toolbox for the OCL community to use scalable object-centric representations, and focus on practical applications and fundamental questions, such as understanding object perception in human cognition. Our code is available $\href{https://github.com/AlexanderRubinstein/OCCAM}{here}$.


**Translated Abstract**: 

目标中心学习（Object-centric learning, OCL）旨在学习仅编码对象的表示，这些表示与场景中其他对象或背景线索相隔离。这一方法支持多种目标，包括分布外（Out-of-distribution, OOD）泛化、样本有效组合以及结构化环境建模。大多数研究集中于开发无监督机制，将对象分离为表示空间中的离散插槽，使用无监督对象发现进行评估。然而，随着近期样本有效的分割模型的出现，我们可以在像素空间中分离对象并独立编码。这在OOD对象发现基准上实现了显著的零样本性能，可以扩展到基础模型，并能够开箱即用地处理可变数量的插槽。因此，OCL方法获得对象中心表示的目标在很大程度上已实现。尽管取得了这一进展，但一个关键问题依然存在：在场景中分离对象的能力如何促进OCL更广泛的目标，如OOD泛化？我们通过OCL的视角探讨了由虚假背景线索引起的OOD泛化挑战。我们提出了一种新的、无训练的探测器，称为“应用掩码的对象中心分类（Object-Centric Classification with Applied Masks, OCCAM）”，证明基于分割的个体对象编码明显优于基于插槽的OCL方法。然而，现实应用中仍然存在挑战。我们为OCL社区提供了一个工具箱，以便利用可扩展的对象中心表示，并关注实际应用和基本问题，如理解人类认知中的对象感知。我们的代码可在此处获取。

**Summary**:

- (1): 文章的研究背景是目标中心学习（OCL）旨在独立编码复杂场景中的每一个前景对象，从而忽略背景线索，并为诸如OOD泛化和结构化环境建模等多种目标提供支持。

- (2): 过去的方法主要是“插槽中心”方法，它们试图将对象分开并编码到插槽中，但效果有限且缺乏实证支持。作者提出了OCCAM方法，这种方法通过样本有效的分割模型在像素空间中分离对象并独立编码，能有效提升性能，同时无需额外训练，有效解决了插槽中心方法的局限性。

- (3): 本文的贡献在于提出了一种新方法（OCCAM），能够通过分割生成对象中心表示，显著提升OOD泛化能力，并且提供了OCL工具箱以支持实际应用和科学探讨。

- (4): 本文提出的研究方法包括采用OCCAM探测器进行对象中心分类，分为两阶段：第一阶段生成对象中心表示，第二阶段在包含干扰背景的情况下识别相关的对象特征进行分类。

- (5): 本文的研究在OOD对象发现任务上表现出色，OCCAM在处理虚假背景时提供了显著的零样本分类性能，显示了其能够支持目标中心学习的整体目标。


## A Differentiable, End-to-End Forward Model for 21 cm Cosmology: Estimating the Foreground, Instrument, and Signal Joint Posterior
- **Url**: http://arxiv.org/abs/2504.07090v1
- **Authors**: ['Nicholas Kern']
- **Abstrat**: We present a differentiable, end-to-end Bayesian forward modeling framework for line intensity mapping cosmology experiments, with a specific focus on low-frequency radio telescopes targeting the redshifted 21 cm line from neutral hydrogen as a cosmological probe. Our framework is capable of posterior density estimation of the cosmological signal jointly with foreground and telescope parameters at the field level. Our key aim is to be able to optimize the model's high-dimensional, non-linear, and ill-conditioned parameter space, while also sampling from it to perform robust uncertainty quantification within a Bayesian framework. We show how a differentiable programming paradigm, accelerated by recent advances in machine learning software and hardware, can make this computationally-demanding, end-to-end Bayesian approach feasible. We demonstrate a proof-of-concept on a simplified signal recovery problem for the Hydrogen Epoch of Reionization Array experiment, highlighting the framework's ability to build confidence in early 21 cm signal detections even in the presence of poorly understood foregrounds and instrumental systematics. We use a Hessian-preconditioned Hamiltonian Monte Carlo algorithm to efficiently sample our parameter space with a dimensionality approaching $N\sim10^5$, which enables joint, end-to-end nuisance parameter marginalization over foreground and instrumental terms. Lastly, we introduce a new spherical harmonic formalism that is a complete and orthogonal basis on the cut sky relevant to drift-scan radio surveys, which we call the spherical stripe harmonic formalism, and it's associated three-dimensional basis, the spherical stripe Fourier-Bessel formalism.


**Translated Abstract**: 

我们提出了一种可微分的端到端贝叶斯前向建模框架，专注于低频无线电望远镜的线强度映射宇宙学实验，主要目标是红移21厘米线的中性氢作为宇宙学探针。我们的框架能够在场级别上联合进行宇宙信号、前景和望远镜参数的后验密度估计。我们旨在优化模型的高维、非线性和病态参数空间，同时在贝叶斯框架内进行采样以进行稳健的不确定性量化。我们展示了如何利用最近的机器学习软件和硬件进展，加速实现这种计算要求较高的端到端贝叶斯方法的可行性。我们在氢再电离实验（Hydrogen Epoch of Reionization Array）上展示了概念验证，突出了该框架在存在不太了解的前景和仪器系统误差时，增强对早期21厘米信号检测的信心。我们使用海森预条件汉密尔顿蒙特卡洛算法有效地对参数空间进行采样，维度接近N∼10^5，实现了对前景和仪器项的联合端到端干扰参数边际化。最后，我们引入了一种新的球谐形式，这是与漂移扫描无线电调查相关的切天空上完整且正交的基，我们称之为球面条纹谐波形式，以及与之相关的三维基，称为球面条纹傅里叶-贝塞尔形式。

**Summary**:

- (1): 本文的研究背景是在高红移宇宙的研究，特别是在宇宙微波背景辐射（CMB）到黑暗能量驱动的扩展之间的时期，尤其是关于中性氢的红移21厘米线的探测。

- (2): 过去的方法主要集中在信号分离上，但由于强烈的天文前景干扰，导致直接检测21厘米信号非常困难。提出的方法通过可微分编程和贝叶斯推断来优化高维参数空间，并有效采样，解决了传统方法中系统误差和信号检测能力不足的问题。该方法具有充分的动机，可以提高早期信号检测的信心。

- (3): 本文的贡献在于提供了一种新的端到端贝叶斯建模框架，能够在存在干扰参数的情况下进行联合后验密度估计，并引入了新的球谐形式用于漂移扫描无线电调查。

- (4): 本文提出的研究方法包括使用可微分编程和Hessian预条件汉密尔顿蒙特卡洛算法，以高效地对接近10^5维的参数空间进行采样，以实现对干扰参数的边际化。

- (5): 在氢再电离实验的信号恢复任务中，方法展示了对早期21厘米信号的检测和不确定性量化能力，说明其性能能够支持提高早期信号检测信心的目标。


## AssistanceZero: Scalably Solving Assistance Games
- **Url**: http://arxiv.org/abs/2504.07091v1
- **Authors**: ['Cassidy Laidlaw', 'Eli Bronstein', 'Timothy Guo', 'Dylan Feng', 'Lukas Berglund', 'Justin Svegliato', 'Stuart Russell', 'Anca Dragan']
- **Abstrat**: Assistance games are a promising alternative to reinforcement learning from human feedback (RLHF) for training AI assistants. Assistance games resolve key drawbacks of RLHF, such as incentives for deceptive behavior, by explicitly modeling the interaction between assistant and user as a two-player game where the assistant cannot observe their shared goal. Despite their potential, assistance games have only been explored in simple settings. Scaling them to more complex environments is difficult because it requires both solving intractable decision-making problems under uncertainty and accurately modeling human users' behavior. We present the first scalable approach to solving assistance games and apply it to a new, challenging Minecraft-based assistance game with over $10^{400}$ possible goals. Our approach, AssistanceZero, extends AlphaZero with a neural network that predicts human actions and rewards, enabling it to plan under uncertainty. We show that AssistanceZero outperforms model-free RL algorithms and imitation learning in the Minecraft-based assistance game. In a human study, our AssistanceZero-trained assistant significantly reduces the number of actions participants take to complete building tasks in Minecraft. Our results suggest that assistance games are a tractable framework for training effective AI assistants in complex environments. Our code and models are available at https://github.com/cassidylaidlaw/minecraft-building-assistance-game.


**Translated Abstract**: 

辅助游戏是训练人工智能助手的一种有前景的替代方案，解决了基于人类反馈的强化学习（RLHF）的一些关键缺陷。辅助游戏通过将助手和用户之间的互动明确建模为一个两人游戏，解决了RLHF中的欺骗性行为激励等问题。然而，虽然辅助游戏具有潜力，但迄今为止仅在简单环境中进行了探索。将其扩展到更复杂的环境很困难，因为这需要在不确定性下解决复杂的决策问题并准确建模人类用户的行为。我们提出了第一个可扩展的辅助游戏解决方案，并将其应用于一个新的挑战性的Minecraft基础辅助游戏，具有超过10^400个可能的目标。我们的方法AssistanceZero扩展了AlphaZero，使用神经网络预测人类的动作和奖励，从而使其能够在不确定性下进行规划。我们展示了AssistanceZero在Minecraft基础辅助游戏中优于无模型强化学习算法和模仿学习。在一项人类研究中，我们的AssistanceZero训练助手显著减少了参与者在Minecraft中完成建筑任务所需的动作数量。我们的结果表明，辅助游戏是训练复杂环境中有效人工智能助手的可行框架。

**Summary**:

- (1): 本文背景是基于人类反馈的强化学习（RLHF）在训练人工智能助手时存在欺骗性行为激励及缺乏对用户目标不确定性的处理等缺陷。

- (2): 过去的方法主要是RLHF，有欺骗性问题和不鼓励助手向用户询问的局限。提出的AssistanceZero方法不同于这些方法，它通过将助手和用户的互动建模为一个两人游戏来解决这些问题，并使用神经网络预测人类的动作和奖励，从而能够在不确定性下进行有效规划。

- (3): 本文的贡献在于首次提出了可扩展的辅助游戏解决方案，并在复杂环境（Minecraft基础辅助游戏）中展示了其有效性，同时解决了人类模型和规划的问题。

- (4): 本文提出的研究方法是AssistanceZero，它扩展了AlphaZero，通过结合蒙特卡罗树搜索（MCTS）和具有多个头的神经网络来分离预测与行动。

- (5): 在Minecraft基础辅助游戏任务中，AssistanceZero训练的助手在参与者完成建筑任务时显著减少了所需动作数量，其性能支持了辅助游戏作为有效训练框架的目标。


## A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths to Reproducibility
- **Url**: http://arxiv.org/abs/2504.07086v1
- **Authors**: ['Andreas Hochlehnert', 'Hardik Bhatnagar', 'Vishaal Udandarao', 'Samuel Albanie', 'Ameya Prabhu', 'Matthias Bethge']
- **Abstrat**: Reasoning has emerged as the next major frontier for language models (LMs), with rapid advances from both academic and industrial labs. However, this progress often outpaces methodological rigor, with many evaluations relying on benchmarking practices that lack transparency, robustness, or statistical grounding. In this work, we conduct a comprehensive empirical study and find that current mathematical reasoning benchmarks are highly sensitive to subtle implementation choices - including decoding parameters, random seeds, prompt formatting, and even hardware and software-framework configurations. Performance gains reported in recent studies frequently hinge on unclear comparisons or unreported sources of variance. To address these issues, we propose a standardized evaluation framework with clearly defined best practices and reporting standards. Using this framework, we reassess recent methods and find that reinforcement learning (RL) approaches yield only modest improvements - far below prior claims - and are prone to overfitting, especially on small-scale benchmarks like AIME24. In contrast, supervised finetuning (SFT) methods show consistently stronger generalization. To foster reproducibility, we release all code, prompts, and model outputs, for reasoning benchmarks, establishing more rigorous foundations for future work.


**Translated Abstract**: 

推理已经成为语言模型（LMs）的下一个主要前沿，来自学术界和工业实验室的快速进展。然而，这种进展往往超出方法论的严格性，许多评估依赖于缺乏透明度、鲁棒性或统计基础的基准实践。在这项工作中，我们进行了一项全面的实证研究，发现当前的数学推理基准对微小的实现选择的敏感性很高，包括解码参数、随机种子、提示格式，以及甚至硬件和软件框架配置。最近研究中报告的性能提升通常依赖于不明确的比较或未报告的方差来源。为了解决这些问题，我们提出了一个标准化评估框架，具有明确定义的最佳实践和报告标准。利用此框架，我们重新评估了近期方法，发现强化学习（RL）方法仅产生适度的改进，远低于先前的声称，并且在小规模基准（如AIME'24）上容易过拟合。相比之下，监督微调（SFT）方法显示出持续的强泛化能力。为了促进可重复性，我们发布了所有代码、提示和模型输出，建立了未来工作的更严格基础。

**Summary**:

- (1): 本文的研究背景是探讨语言模型（LMs）在推理方面的快速进展，以及当前的基准评估中缺乏方法论的严格性和透明度的问题。

- (2): 过去的方法主要是强化学习（RL）和监督微调（SFT），存在性能提升依赖不明确比较和方差未报告的问题。本文提出的标准化评估框架与现有方法相比，明确了最佳实践和报告标准，并通过此框架重新评估方法，从而解决了之前方法中的不透明和不一致性问题。

- (3): 本文的贡献在于提出了一个标准化评估框架，重新评估了现有方法，发现强化学习方法的改进有限，并通过提供代码和数据来促进研究的可重复性。

- (4): 本文提出的研究方法包括应用一个标准化的评估框架，评估增强性能的语言模型，并识别影响推理性能的实现选择。

- (5): 本文针对AIME'24基准任务，方法的性能显示出强化学习的改进远低于先前的声称，而监督微调在泛化能力上表现更强。但整体性能是否能够支持其改进目标仍有待验证。


## Identifying Unknown Stochastic Dynamics via Finite expression methods
- **Url**: http://arxiv.org/abs/2504.07085v1
- **Authors**: ['Senwei Liang', 'Chunmei Wang', 'Xingjian Xu']
- **Abstrat**: Modeling stochastic differential equations (SDEs) is crucial for understanding complex dynamical systems in various scientific fields. Recent methods often employ neural network-based models, which typically represent SDEs through a combination of deterministic and stochastic terms. However, these models usually lack interpretability and have difficulty generalizing beyond their training domain. This paper introduces the Finite Expression Method (FEX), a symbolic learning approach designed to derive interpretable mathematical representations of the deterministic component of SDEs. For the stochastic component, we integrate FEX with advanced generative modeling techniques to provide a comprehensive representation of SDEs. The numerical experiments on linear, nonlinear, and multidimensional SDEs demonstrate that FEX generalizes well beyond the training domain and delivers more accurate long-term predictions compared to neural network-based methods. The symbolic expressions identified by FEX not only improve prediction accuracy but also offer valuable scientific insights into the underlying dynamics of the systems, paving the way for new scientific discoveries.


**Translated Abstract**: 

建模随机微分方程（SDEs）对于理解各个科学领域中的复杂动态系统至关重要。最近的方法通常采用基于神经网络的模型，这些模型通常通过确定性和随机性条款的组合来表示SDEs。然而，这些模型通常缺乏可解释性，并且在训练域之外的泛化能力较差。本文介绍了有限表达法（FEX），一种旨在推导SDEs的确定性成分的可解释数学表示的符号学习方法。对于随机成分，我们将FEX与先进的生成建模技术结合，以提供SDEs的综合表示。在线性、非线性和多维SDEs的数值实验中，FEX显示出良好的泛化能力，并且在长期预测方面相较于基于神经网络的方法更为准确。FEX识别的符号表达不仅提高了预测精度，还为系统的基础动态提供了有价值的科学见解，为新的科学发现铺平了道路。

**Summary**:

- (1): 本文研究的背景是随机微分方程（SDEs）在建模受随机噪声和不确定性影响的系统中的重要性，这些方程在自然科学、工业和社会等多个领域被广泛应用。

- (2): 过去的方法主要使用基于神经网络的模型，这些模型在表示SDEs时存在可解释性不足和泛化能力差的问题。所提出的方法FEX通过符号学习提供了可解释的确定性成分表示，并通过生成建模技术改进了随机成分，来解决这些问题，因此这个方法是合理的。

- (3): 本文的贡献在于引入了FEX，能够有效地推导出SDEs的确定性成分的数学表示，并且在数值实验中展现出优于传统神经网络模型的泛化能力和预测精度。

- (4): 本文提出的研究方法是有限表达法（FEX），将数学表达的发现视为组合优化问题，并通过强化学习（RL）自动识别未知的SDEs，从而提高建模的透明度和可解释性。

- (5): 该方法在处理线性、非线性和多维SDEs的长时间预测任务中获得了更高的预测准确性，验证了其在超越训练域方面的有效性，支持了他们的研究目标。


## Distributional Autoencoders Know the Score
- **Url**: http://arxiv.org/abs/2502.11583v2
- **Authors**: ['Andrej Leban']
- **Abstrat**: This work presents novel and desirable properties of a recently introduced class of autoencoders - the Distributional Principal Autoencoder (DPA) - which combines distributionally correct reconstruction with principal components-like interpretability of the encodings. First, we show formally that the level sets of the encoder orient themselves exactly with regard to the score of the data distribution. This both explains the method's often remarkable performance in disentangling the factors of variation of the data, as well as opens up possibilities of recovering its distribution while having access to samples only. In settings where the score itself has physical meaning - such as when the data obeys the Boltzmann distribution - we demonstrate that the method can recover scientifically important quantities such as the minimum free energy path. Second, we prove that if the data lies on a manifold that can be approximated by the encoder, the optimal encoder's components beyond the dimension of the manifold will carry absolutely no additional information about the data distribution. This promises potentially new ways of determining the number of relevant dimensions of the data. The results thus demonstrate that the DPA elegantly combines two often disparate goals of unsupervised learning: the learning of the data distribution and the learning of the intrinsic data dimensionality.


**Translated Abstract**: 

本研究展示了一种新型自编码器类——分布主成分自编码器（DPA）的新颖且可取的特性，该编码器结合了分布正确的重构与类似主成分分析的编码可解释性。首先，我们正式证明了编码器的水平集与数据分布的得分完全一致。这不仅解释了该方法在解耦数据变化因素方面的卓越性能，还开辟了仅在访问样本时恢复数据分布的可能性。在得分具有物理意义的背景下（例如数据遵循玻尔兹曼分布时），我们展示了该方法能够恢复科学上重要的量，如最小自由能路径。其次，我们证明，如果数据位于一个能够通过编码器近似的流形上，则最优编码器在流形维度之外的成分对数据分布没有任何额外信息。这为确定数据的相关维数提供了潜在的新方法。因此，该结果展示了 DPA优雅地结合了无监督学习的两个常常对立的目标：学习数据分布和学习内在数据维度。

**Summary**:

- (1): 本文的研究背景是自编码器在无监督学习中的应用，特别是如何有效重构数据分布并解释编码的内在结构。

- (2): 以往的方法主要依赖于多种评分规则和重构目标，但往往面临分布不一致或无法有效解耦数据变化等问题。DPA通过引入能量得分方法，确保分布性重构和主成分可解释性，从而解决了这些问题，具有明确的理论动机。

- (3): 本文的贡献在于证明了DPA在别的自编码器所未能做到的两个重要性质：水平集与数据得分一致以及在维度约简中提供对数据分布新的理解。

- (4): 研究方法涉及将数据映射到一个流形，通过公式化编码器与流形之间的关系，优化编码器以最小化重构的方差，并利用能量得分进行条件重构。

- (5): 本文通过应用于分子动力学的案例，展示了DPA能够近似不同稳定状态之间的最小自由能路径，该模型的表现支持其目标。


## Hogwild! Inference: Parallel LLM Generation via Concurrent Attention
- **Url**: http://arxiv.org/abs/2504.06261v2
- **Authors**: ['Gleb Rodionov', 'Roman Garipov', 'Alina Shutova', 'George Yakushev', 'Vage Egiazarian', 'Anton Sinitsin', 'Denis Kuznedelev', 'Dan Alistarh']
- **Abstrat**: Large Language Models (LLMs) have demonstrated the ability to tackle increasingly complex tasks through advanced reasoning, long-form content generation, and tool use. Solving these tasks often involves long inference-time computations. In human problem solving, a common strategy to expedite work is collaboration: by dividing the problem into sub-tasks, exploring different strategies concurrently, etc. Recent research has shown that LLMs can also operate in parallel by implementing explicit cooperation frameworks, such as voting mechanisms or the explicit creation of independent sub-tasks that can be executed in parallel. However, each of these frameworks may not be suitable for all types of tasks, which can hinder their applicability. In this work, we propose a different design approach: we run LLM "workers" in parallel , allowing them to synchronize via a concurrently-updated attention cache and prompt these workers to decide how best to collaborate. Our approach allows the instances to come up with their own collaboration strategy for the problem at hand, all the while "seeing" each other's partial progress in the concurrent cache. We implement this approach via Hogwild! Inference: a parallel LLM inference engine where multiple instances of the same LLM run in parallel with the same attention cache, with "instant" access to each other's generated tokens. Hogwild! inference takes advantage of Rotary Position Embeddings (RoPE) to avoid recomputation while improving parallel hardware utilization. We find that modern reasoning-capable LLMs can perform inference with shared Key-Value cache out of the box, without additional fine-tuning.


**Translated Abstract**: 

大型语言模型（LLMs）展示了通过先进推理、长篇内容生成和工具使用处理日益复杂任务的能力。解决这些任务通常涉及较长的推理时间计算。在人类问题解决中，加快工作的常见策略是协作：通过将问题拆分为子任务、同时探索不同策略等。近期研究表明，LLMs也可以通过实施显式合作框架（如投票机制或明确创建独立的子任务并行执行）进行并行操作。然而，这些框架可能不适用于所有类型的任务，从而限制其适用性。本文提出了一种不同的设计方法：我们并行运行LLM “工人”，允许它们通过同时更新的注意力缓存进行同步，并提示这些工人决定如何最好地合作。我们的方法允许实例根据手头问题生成自己的合作策略，同时“看到”对方在并行缓存中的部分进展。我们通过Hogwild!推理实现了这一方法：一个并行LLM推理引擎，其中多个相同的LLM实例并行运行，使用相同的注意力缓存，并即时访问彼此生成的标记。Hogwild!推理利用旋转位置嵌入（RoPE）来避免重复计算，同时提高并行硬件的利用率。我们发现现代具备推理能力的LLMs可以在没有额外微调的情况下，自然适应共享的键值缓存进行推理。

**Summary**:

- (1): 本文的研究背景是大型语言模型（LLMs）在解决复杂任务时的推理与协作能力的提升。

- (2): 过去的方法包括通过投票机制或创建独立的子任务来实现LLMs的显式合作。这些方法存在适用性有限的问题。与现有方法不同的是，提出的方法允许LLM工人在没有预定义框架的情况下并行运行，通过共享缓存同步生成进度，从而应对协作策略的动态变化。

- (3): 本文的贡献在于提出了一种新的并行推理协议（Hogwild!推理），允许LLM工人自主决定合作策略，提升协作的灵活性和效率。

- (4): 本文提出的研究方法是Hogwild!推理，引入并行LLM工人和共享注意力缓存的机制，使LLM能够实时对彼此的进度进行反馈并调整策略。

- (5): 本文的方法在推理复杂任务上表现出色，能够有效利用共享缓存，且无需额外微调。方法的性能支持了高效协作的目标。


## A Concise Mathematical Description of Active Inference in Discrete Time
- **Url**: http://arxiv.org/abs/2406.07726v3
- **Authors**: ['Jesse van Oostrum', 'Carlotta Langer', 'Nihat Ay']
- **Abstrat**: In this paper we present a concise mathematical description of active inference in discrete time. The main part of the paper serves as a basic introduction to the topic, including a detailed example of the action selection mechanism. The appendix discusses the more subtle mathematical details, targeting readers who have already studied the active inference literature but struggle to make sense of the mathematical details and derivations. Throughout, we emphasize precise and standard mathematical notation, ensuring consistency with existing texts and linking all equations to widely used references on active inference. Additionally, we provide Python code that implements the action selection and learning mechanisms described in this paper and is compatible with pymdp environments.


**Translated Abstract**: 

在本文中，我们提供了对离散时间活动推理的简洁数学描述。论文的主要部分作为该主题的基本介绍，包括行动选择机制的详细示例。附录讨论了更精微的数学细节，目标读者是已经研究过活动推理文献但难以理解数学细节和推导的读者。我们强调精确和标准的数学符号，确保与现有文献的一致性，并将所有方程与广泛使用的活动推理参考文献关联。此外，我们提供了实现本文中所描述的选择行动和学习机制的Python代码，兼容pymdp环境。

**Summary**:

- (1): 本文研究的背景是活动推理理论，该理论描述了代理在环境中的行动选择和学习机制。

- (2): 过去的方法主要以复杂的数学推导和不够清晰的符号表示为主，使得读者难以理解。本文提出的方法在于提供了一种标准化且精确的数学描述，强调明确的依赖关系，帮助读者更易于理解。

- (3): 本文的贡献在于提供了活动推理在离散时间下的数学描述和详细示例，并兼顾了已有文献的一致性。同时，附录提供了数学推导的细节，有助于熟悉活动推理的读者加深理解。

- (4): 本文提出的研究方法包括对活动推理的推理和学习机制的分解，利用概率分布模型明确描述了代理如何进行行动选择。

- (5): 本文未具体提及在特定任务上达到的性能，但提供的Python代码可在pymdp环境中实现所需机制，足以支持理论目标的实现。


## DeduCE: Deductive Consistency as a Framework to Evaluate LLM Reasoning
- **Url**: http://arxiv.org/abs/2504.07080v1
- **Authors**: ['Atharva Pandey', 'Kshitij Dubey', 'Rahul Sharma', 'Amit Sharma']
- **Abstrat**: Despite great performance on Olympiad-level reasoning problems, frontier large language models can still struggle on high school math when presented with novel problems outside standard benchmarks. Going beyond final accuracy, we propose a deductive consistency metric to analyze chain-of-thought output from language models (LMs).Formally, deductive reasoning involves two subtasks: understanding a set of input premises and inferring the conclusions that follow from them. The proposed metric studies LMs' performance on these subtasks, with the goal of explaining LMs' reasoning errors on novel problems: how well do LMs understand input premises with increasing context lengths, and how well can they infer conclusions over multiple reasoning hops? Since existing benchmarks may be memorized, we develop a pipeline to evaluate LMs' deductive consistency on novel, perturbed versions of benchmark problems. On novel grade school math problems (GSM-8k), we find that LMs are fairly robust to increasing number of input premises, but suffer significant accuracy decay as the number of reasoning hops is increased. Interestingly, these errors are masked in the original benchmark as all models achieve near 100% accuracy. As we increase the number of solution steps using a synthetic dataset, prediction over multiple hops still remains the major source of error compared to understanding input premises. Other factors, such as shifts in language style or natural propagation of early errors do not explain the trends. Our analysis provides a new view to characterize LM reasoning -- as computations over a window of input premises and reasoning hops -- that can provide unified evaluation across problem domains.


**Translated Abstract**: 

尽管在奥林匹亚级推理问题上表现出色，但前沿的大型语言模型在面对标准基准之外的新问题时，仍可能在高中数学方面遇到困难。为了超越最终准确性，我们提出了一种演绎一致性指标，用于分析语言模型（LMs）的链式思维输出。正式的演绎推理涉及两个子任务：理解一组输入前提和推导出随之而来的结论。所提出的指标研究了 LMs 在这些子任务上的表现，旨在解释 LMs 在新问题上的推理错误：随着上下文长度的增加，LMs 理解输入前提的能力如何，以及它们在多个推理步骤中推导结论的能力如何。由于现有基准可能被记忆化，我们开发了一个管道以在新、扰动版本的基准问题上评估 LMs 的演绎一致性。在新的小学数学问题（GSM-8K）上，我们发现 LMs 对增加输入前提数量的情况相对稳健，但在推理步骤数量增加时会出现显著的准确性下降。有趣的是，这些错误在原始基准中被掩盖，因为所有模型的准确率均接近 100%。当我们使用合成数据集增加解决方案步骤数量时，多步骤推理的预测仍然是错误的主要来源，而理解输入前提的能力并不是。同样，语言风格的变化或早期错误的自然传播等其他因素并未解释这些趋势。我们的分析提供了一种新视角来表征 LM 推理——作为对输入前提和推理步骤的窗口进行计算——可以为不同问题领域提供统一的评估。

**Summary**:

- (1):本文研究背景是尽管大型语言模型（LMs）在奥林匹亚级推理问题上表现优异，但在新颖的高中数学问题上仍然会出现困难，特别是在超出标准基准时。

- (2):过去的方法通常基于准确性进行了评估，但未能深入理解 LM 在不同推理步骤中的表现和推理过程的整体一致性。所提出的方法通过引入演绎一致性指标来解决这些问题，能够从中段步骤分析推理过程，关注 LLMS 在理解输入前提和多步推理方面的能力，具有良好的动机。

- (3):论文的贡献在于提出了演绎一致性度量标准，并开发了一个评估管道，能够在新的扰动版本问题中评估 LMs 的推理能力，从而阐明了 LMs 在新问题中的推理错误。

- (4):研究方法论包括通过构建一个评估管道来评估 LMs 的演绎一致性，该管道结合了初始前提和部分正确推理步骤，从而提供了对 LM 推理新视角的评估。

- (5):在新的小学数学问题（GSM-8K）上，所提出的方法发现 LMs 对输入前提数量相对稳健，但在推理步骤数量增加时准确性显著下降。该性能揭示了 LMs 在推理能力上的局限，支持了论文的目标。


## Detecting AI-generated Artwork
- **Url**: http://arxiv.org/abs/2504.07078v1
- **Authors**: ['Meien Li', 'Mark Stamp']
- **Abstrat**: The high efficiency and quality of artwork generated by Artificial Intelligence (AI) has created new concerns and challenges for human artists. In particular, recent improvements in generative AI have made it difficult for people to distinguish between human-generated and AI-generated art. In this research, we consider the potential utility of various types of Machine Learning (ML) and Deep Learning (DL) models in distinguishing AI-generated artwork from human-generated artwork. We focus on three challenging artistic styles, namely, baroque, cubism, and expressionism. The learning models we test are Logistic Regression (LR), Support Vector Machine (SVM), Multilayer Perceptron (MLP), and Convolutional Neural Network (CNN). Our best experimental results yield a multiclass accuracy of 0.8208 over six classes, and an impressive accuracy of 0.9758 for the binary classification problem of distinguishing AI-generated from human-generated art.


**Translated Abstract**: 

人工智能（AI）生成的艺术作品效率高、质量好，给人类艺术家带来了新的关注和挑战。最近生成性AI的改进使得人们很难区分人类创作的艺术和AI创作的艺术。本研究考虑了多种机器学习（ML）和深度学习（DL）模型在区分AI生成的艺术作品与人类生成的艺术作品方面的潜在实用性。我们关注三种具有挑战性的艺术风格，即巴洛克（baroque）、立体主义（cubism）和表现主义（expressionism）。我们测试的学习模型有逻辑回归（Logistic Regression, LR）、支持向量机（Support Vector Machine, SVM）、多层感知器（Multilayer Perceptron, MLP）和卷积神经网络（Convolutional Neural Network, CNN）。我们的最佳实验结果在六个类别上取得了0.8208的多类准确率，而在区分AI生成和人类生成艺术的二元分类问题上取得了令人印象深刻的0.9758的准确率。

**Summary**:

- (1): 本文的研究背景是人工智能（AI）在艺术创作上的进步，使得区分人类艺术与AI生成艺术变得愈加困难，从而引发对人类艺术家的关注。

- (2): 过去的方法主要依赖于人工识别和一般的机器学习模型。这些方法在精度和可靠性上存在局限，不能有效区分不同风格的艺术作品。本文提出的方法通过广泛测试经典ML模型与DL模型，提供更准确的分类结果，从而有效解决了之前方法的不足之处。

- (3): 本文的贡献在于系统地比较了不同机器学习和深度学习模型在区分AI生成与人类生成艺术品上的表现，提供了新的视角和实证数据。

- (4): 本文采用的研究方法包括了逻辑回归（LR）、支持向量机（SVM）、多层感知器（MLP）和卷积神经网络（CNN）的实验，重点在于对巴洛克、立体主义和表现主义风格的艺术作品进行分类检测。

- (5): 论文在区分AI生成和人类生成艺术分类任务上取得了0.9758的准确率，这一结果支持了研究目标的实现，表明提出的方法在该任务上非常有效。


## Machine Learning Approach towards Quantum Error Mitigation for Accurate Molecular Energetics
- **Url**: http://arxiv.org/abs/2504.07077v1
- **Authors**: ['Srushti Patil', 'Dibyendu Mondal', 'Rahul Maitra']
- **Abstrat**: Despite significant efforts, the realization of the hybrid quantum-classical algorithms has predominantly been confined to proof-of-principles, mainly due to the hardware noise. With fault-tolerant implementation being a long-term goal, going beyond small molecules with existing error mitigation (EM) techniques with current noisy intermediate scale quantum (NISQ) devices has been a challenge. That being said, statistical learning methods are promising approaches to learning the noise and its subsequent mitigation. We devise a graph neural network and regression-based machine learning (ML) architecture for practical realization of EM techniques for molecular Hamiltonian without the requirement of the exponential overhead. Given the short coherence time of the quantum hardware, the ML model is trained with either ideal or mitigated expectation values over a judiciously chosen ensemble of shallow sub-circuits adhering to the native hardware architecture. The hardware connectivity network is mapped to a directed graph which encodes the information of the native gate noise profile to generate the features for the neural network. The training data is generated on-the-fly during ansatz construction thus removing the computational overhead. We demonstrate orders of magnitude improvements in predicted energy over a few strongly correlated molecules.


**Translated Abstract**: 

尽管付出了重大努力，混合量子-经典算法的实现主要局限于原理验证，这主要是由于硬件噪声。由于容错实现仍是长期目标，当前的噪声中等规模量子（NISQ）设备在现有误差减轻（EM）技术下突破小分子限制一直是一个挑战。然而，统计学习方法是学习噪声及其后续减轻的有希望的方法。我们设计了一种图神经网络和基于回归的机器学习（ML）架构，用于分子哈密顿量的EM技术的实际实现，而无需指数开销。考虑到量子硬件的短相干时间，ML模型通过理想或减轻的期望值在经过精心选择的符合本地硬件架构的浅子电路的集合中进行训练。硬件连接网络被映射为一个有向图，编码本地门噪声特征，为神经网络生成特征。在ansatz构建期间动态生成训练数据，从而消除了计算开销。我们在几个强相关分子的能量预测上展示了数量级的提升。

**Summary**:

- (1): 本文的研究背景是尽管混合量子-经典算法的潜力巨大，但由于硬件噪声限制了其实际应用，尤其是在处理大分子时，现有的误差减轻技术在当前的NISQ设备上面临挑战。

- (2): 过去的方法如零噪声外推（Zero Noise Extrapolation）、动态解耦（Dynamical Decoupling）和概率误差消除（Probabilistic Error Cancellation）等；它们的问题主要在于无法充分利用NISQ设备且存在指数运行时间。与之不同的是，本文提出的图神经网络和回归模型架构通过在本地硬件架构的浅子电路上生成特征，有效地降低了计算开销并改善了误差减轻效果。

- (3): 本文的贡献在于提出了一种新的基于机器学习的误差减轻技术，显著提升分子哈密顿量的能量预测精度，同时避免了传统方法的巨大计算成本。

- (4): 本文采用的研究方法是构建一个图神经网络，并结合回归分析，通过训练模型以处理在NISQ设备上的分子哈密顿量的误差，输入特征是基于硬件噪声特征的。

- (5): 本文的方法应用于强相关分子的能量预测，显示出数量级的性能提升，这种性能提升支持其进行更加准确的分子能量计算的目标。


## Estimation of embedding vectors in high dimensions
- **Url**: http://arxiv.org/abs/2312.07802v2
- **Authors**: ['Golara Ahmadi Azar', 'Melika Emami', 'Alyson Fletcher', 'Sundeep Rangan']
- **Abstrat**: Embeddings are a basic initial feature extraction step in many machine learning models, particularly in natural language processing. An embedding attempts to map data tokens to a low-dimensional space where similar tokens are mapped to vectors that are close to one another by some metric in the embedding space. A basic question is how well can such embedding be learned? To study this problem, we consider a simple probability model for discrete data where there is some "true" but unknown embedding where the correlation of random variables is related to the similarity of the embeddings. Under this model, it is shown that the embeddings can be learned by a variant of low-rank approximate message passing (AMP) method. The AMP approach enables precise predictions of the accuracy of the estimation in certain high-dimensional limits. In particular, the methodology provides insight on the relations of key parameters such as the number of samples per value, the frequency of the terms, and the strength of the embedding correlation on the probability distribution. Our theoretical findings are validated by simulations on both synthetic data and real text data.


**Translated Abstract**: 

嵌入是许多机器学习模型中基本的初始特征提取步骤，特别是在自然语言处理方面。嵌入试图将数据标记映射到一个低维空间，其中相似的标记根据嵌入空间中的某种度量被映射到彼此接近的向量。一个基本问题是这样的嵌入可以学到多好？为了研究这一问题，我们考虑了一个简单的离散数据的概率模型，其中存在某种“真实”的但未知的嵌入，随机变量的相关性与嵌入的相似性相关。在该模型下，证明了嵌入可以通过一种低秩近似消息传递（AMP）方法的变体进行学习。AMP方法能够在某些高维极限下精确预测估计的准确性。特别地，该方法提供了对关键参数之间关系的深入了解，例如每个值的样本数量、术语的频率以及嵌入相关性的强度。我们的理论发现通过对合成数据和真实文本数据的模拟得以验证。

**Summary**:

- (1): 本文的研究背景是嵌入在机器学习任务（尤其是自然语言处理）中的重要性，以及了解嵌入学习有效性的问题。

- (2): 过去的方法主要包括多种算法（如随机梯度下降等），但在得出精确收敛结果方面存在困难。本文提出的基于低秩近似消息传递（AMP）的新方法不仅解决了这一问题，还考虑了偏置项的影响，能提供更精准的性能预测，因此具有良好的动机。

- (3): 该论文的贡献在于发展了一种偏置低秩AMP方法，提供了准确的性能预测，并通过状态演化分析验证了其在高维情况下的表现。

- (4): 本文提出的研究方法是基于对离散随机变量的联合分布进行建模，并利用低秩矩阵分解和AMP方法进行最大似然估计。

- (5): 方法在合成数据集和真实文本数据集（如电影评论）上进行了验证，表明所提方法能够有效捕获参数，在一定规模下表现良好，支持了其研究目标。


## Enhancing Downstream Analysis in Genome Sequencing: Species Classification While Basecalling
- **Url**: http://arxiv.org/abs/2504.07065v1
- **Authors**: ['Riselda Kodra', 'Hadjer Benmeziane', 'Irem Boybat', 'William Andrew Simon']
- **Abstrat**: The ability to quickly and accurately identify microbial species in a sample, known as metagenomic profiling, is critical across various fields, from healthcare to environmental science. This paper introduces a novel method to profile signals coming from sequencing devices in parallel with determining their nucleotide sequences, a process known as basecalling, via a multi-objective deep neural network for simultaneous basecalling and multi-class genome classification. We introduce a new loss strategy where losses for basecalling and classification are back-propagated separately, with model weights combined for the shared layers, and a pre-configured ranking strategy allowing top-K species accuracy, giving users flexibility to choose between higher accuracy or higher speed at identifying the species. We achieve state-of-the-art basecalling accuracies, while classification accuracies meet and exceed the results of state-of-the-art binary classifiers, attaining an average of 92.5%/98.9% accuracy at identifying the top-1/3 species among a total of 17 genomes in the Wick bacterial dataset. The work presented here has implications for future studies in metagenomic profiling by accelerating the bottleneck step of matching the DNA sequence to the correct genome.


**Translated Abstract**: 

快速准确地识别样本中的微生物物种的能力，称为宏基因组分析，在医疗保健到环境科学等各个领域至关重要。本文介绍了一种新颖的方法，通过多目标深度神经网络同时进行基地调用和多类基因组分类，以剖析来自测序设备的信号。我们引入了一种新的损失策略，其中基地调用和分类的损失分别反向传播，模型权重结合共享层，并采用预配置的排名策略以实现 top-K 物种准确性，给予用户在识别物种时选择更高准确率或更高速度的灵活性。我们实现了最先进的基地调用准确率，而分类准确率达到并超过了现有二元分类器的结果，在Wick细菌数据集中识别17种基因组的前1/3物种时平均准确率为92.5% / 98.9%。本文所展示的工作对未来宏基因组分析研究有重要意义，因为它加快了将DNA序列匹配到正确基因组的瓶颈步骤。

**Summary**:

- (1): 本文的研究背景是随着基因组测序成本的大幅下降，宏基因组分析在多个领域（如医疗、环境科学）中变得重要。

- (2): 过去的方法包括基于比对和非比对的方法，这些方法在计算复杂性和内存消耗上存在差异。非比对方法在精确度（假阳性率）和召回率（假阴性率）之间有显著的权衡，而基于比对的方法在这两方面表现更好，但需要更高的内存和计算要求。提出的方法通过多目标深度学习网络同时进行基地调用和物种分类，有效地解决了现有方法的时间瓶颈和准确性问题，具有良好的动机。

- (3): 本文的贡献在于提出了一种新颖的损失策略，能够在进行基地调用的同时，提升多类基因组分类的准确性，提供了灵活的准确率与速度选项。

- (4): 研究方法论主要是使用多目标深度神经网络，在基地调用和基因组分类时采用不同的损失策略，并整合了共享层的模型权重。

- (5): 本文的方法在Wick细菌数据集上识别17种基因组的前1/3物种时，平均准确率达92.5%/98.9%。该性能支持了其在加速宏基因组分析方面的目标。


## Architecture independent generalization bounds for overparametrized deep ReLU networks
- **Url**: http://arxiv.org/abs/2504.05695v2
- **Authors**: ['Thomas Chen', 'Chun-Kai Kevin Chien', 'Patricia Muñoz Ewald', 'Andrew G. Moore']
- **Abstrat**: We prove that overparametrized neural networks are able to generalize with a test error that is independent of the level of overparametrization, and independent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds that only depend on the metric geometry of the test and training sets, on the regularity properties of the activation function, and on the operator norms of the weights and norms of biases. For overparametrized deep ReLU networks with a training sample size bounded by the input space dimension, we explicitly construct zero loss minimizers without use of gradient descent, and prove that the generalization error is independent of the network architecture.


**Translated Abstract**: 

我们证明过参数化神经网络能够以与过参数化程度无关的测试误差进行泛化，并且与Vapnik-Chervonenkis（VC）维度无关。我们证明的界限仅依赖于测试集和训练集的度量几何、激活函数的规则性属性以及权重的算子范数和偏置的范数。对于在输入空间维度受限的训练样本大小的过参数化深ReLU网络，我们明确构造无需梯度下降的零损失最小化器，并证明泛化误差与网络架构无关。

**Summary**:

- (1): 本文的研究背景是在于理解过参数化深度神经网络（如ReLU网络）的泛化能力及其对网络结构和复杂度的依赖性。

- (2): 过去的方法主要集中在Vapnik-Chervonenkis维度和模型复杂度对泛化能力的影响，但这些方法存在局限性，因为它们无法充分解释在深度学习中的良好泛化现象。本文提出的方法不同于现有方法，因为它证明了泛化误差独立于网络架构，并依赖于训练和测试集的几何特性，而不是模型复杂度。

- (3): 本文的贡献在于证明了过参数化神经网络的泛化误差与网络架构无关，并且提供了依赖于几何特性的明确界限，推动了对深度学习理论的理解。

- (4): 本文的研究方法是通过构造明确的零损失最小化器来探讨深ReLU网络的泛化性能，并利用激活函数的规则性和权重范数进行分析。

- (5): 本文方法在给定的过参数化深ReLU网络上进行了实证，证明了在训练样本大小受限的情况下，能够实现零损失的最小化性能，这一结果支持了其理论目标。


## Pruner: A Draft-then-Verify Exploration Mechanism to Accelerate Tensor Program Tuning
- **Url**: http://arxiv.org/abs/2402.02361v3
- **Authors**: ['Liang Qiao', 'Jun Shi', 'Xiaoyu Hao', 'Xi Fang', 'Sen Zhang', 'Minfan Zhao', 'Ziqi Zhu', 'Junshi Chen', 'Hong An', 'Xulong Tang', 'Bing Li', 'Honghui Yuan', 'Xinyang Wang']
- **Abstrat**: Tensor program tuning is essential for the efficient deployment of deep neural networks. Search-based approaches have demonstrated scalability and effectiveness in automatically finding high-performance programs for specific hardware. However, the search process is often inefficient, taking hours or even days to discover optimal programs due to the exploration mechanisms guided by an accurate but slow-learned cost model. Meanwhile, the learned cost model trained on one platform cannot seamlessly adapt online to another, which we call cross-platform online unawareness.   In this work, we propose Pruner and MoA-Pruner. Pruner is a "Draft-then-Verify" exploration mechanism that accelerates the schedule search process. Instead of applying the complex learned cost model to all explored candidates, Pruner drafts small-scale potential candidates by introducing a naive Symbol-based Analyzer (draft model), then identifies the best candidates by the learned cost model. MoA-Pruner introduces a Momentum online Adaptation strategy to address the cross-platform online unawareness.   We incorporate Pruner into the TVM and conduct extensive experiments on three GPU-based platforms. Results show considerable speedup in schedule search time. In online tuning scenarios, Pruner and MoA-Pruner achieve an average speedup of $2.6 \times$ and $4.82 \times$ compared to Ansor. In offline tuning scenarios, Pruner achieves an average speedup of $4.75 \times$ and $4.05\times$ compared to TenSet and TLP, respectively. Furthermore, Pruner achieves an average speedup of $4.08 \times$ compared to MetaSchedule on TensorCore.


**Translated Abstract**: 

张量程序调优对于深度神经网络的高效部署至关重要。基于搜索的方法展示了在特定硬件上自动寻找高性能程序的可扩展性和有效性。然而，由于探索机制受复杂且学习缓慢的成本模型的指导，搜索过程常常效率低下，可能需要数小时甚至数天才能发现最佳程序。同时，针对一个平台训练的学习成本模型无法无缝适应另一个平台，这被称为跨平台在线无意识。本文提出了Pruner和MoA-Pruner。Pruner是一种“草拟-验证”的探索机制，加速了调度搜索过程。Pruner通过引入简单的基于符号分析器（草拟模型）来草拟小规模的潜在候选项，然后通过学习的成本模型识别最佳候选项。MoA-Pruner引入了动量在线适应策略，以解决跨平台在线无意识的问题。我们将Pruner整合到TVM中，并在三个基于GPU的平台上进行了广泛实验。结果显示调度搜索时间显著加快。在在线调优场景中，Pruner和MoA-Pruner与Ansor相比平均加速了2.6倍和4.82倍。在离线调优场景中，Pruner与TenSet和TLP相比平均加速了4.75倍和4.05倍。此外，Pruner在TensorCore上与MetaSchedule相比平均加速了4.08倍。

**Summary**:

- (1): 本文的研究背景是针对深度神经网络的高效部署，强调张量程序调优的重要性。

- (2): 以往的方法主要是基于搜索的调优策略，存在搜索效率低下的问题，通常需要较长时间才能找到最佳程序。本文提出的Pruner通过“草拟-验证”机制，首先用简单模型草拟候选项，然后用复杂模型筛选，提高了效率。同时，MoA-Pruner引入了动量在线适应策略，解决了跨平台适应性劣的问题。

- (3): 论文的贡献在于提出了Pruner和MoA-Pruner两种新机制，有效加速了张量程序调优的搜索过程，并解决了跨平台适应性的挑战。

- (4): 本文的研究方法是将Pruner整合到TVM中，通过草拟潜在候选项和使用学习的成本模型进行验证，从而提升调优速度。

- (5): 在实验中，Pruner和MoA-Pruner在在线调优场景中实现了分别为2.6倍和4.82倍的加速；在离线调优场景中，Pruner分别实现了4.75倍和4.05倍的加速。这些性能结果支持了本文提出的加速目标。


## Automated Generation of Challenging Multiple-Choice Questions for Vision Language Model Evaluation
- **Url**: http://arxiv.org/abs/2501.03225v2
- **Authors**: ['Yuhui Zhang', 'Yuchang Su', 'Yiming Liu', 'Xiaohan Wang', 'James Burgess', 'Elaine Sui', 'Chenyu Wang', 'Josiah Aklilu', 'Alejandro Lozano', 'Anjiang Wei', 'Ludwig Schmidt', 'Serena Yeung-Levy']
- **Abstrat**: The rapid development of vision language models (VLMs) demands rigorous and reliable evaluation. However, current visual question answering (VQA) benchmarks often depend on open-ended questions, making accurate evaluation difficult due to the variability in natural language responses. To address this, we introduce AutoConverter, an agentic framework that automatically converts these open-ended questions into multiple-choice format, enabling objective evaluation while reducing the costly multiple-choice question creation process. Our experiments demonstrate that AutoConverter can generate correct and challenging multiple-choice questions, with VLMs demonstrating consistently similar or lower accuracy on these questions compared to human-created ones. Using AutoConverter, we construct VMCBench, a benchmark created by transforming 20 existing VQA datasets into a unified multiple-choice format, totaling 9,018 questions. We comprehensively evaluate 33 state-of-the-art VLMs on VMCBench, setting a new standard for scalable, consistent, and reproducible VLM evaluation.


**Translated Abstract**: 

快速发展的视觉语言模型（VLMs）需要严格和可靠的评估。然而，当前的视觉问答（VQA）基准往往依赖开放式问题，导致由于自然语言响应的多样性而难以进行有效评估。为了解决这个问题，我们提出了 AutoConverter，一个自动将开放式问题转换为多项选择题格式的框架，使评估更加客观，并减少了耗费时间的多项选择题创建过程。我们的实验表明，AutoConverter 可以生成正确且具有挑战性的多项选择题，VLMs 在这些问题上的准确率与人类创建的问题相比，表现出始终相似或更低的结果。采用 AutoConverter，我们构建了 VMCBench，这是一个通过将20个现有VQA数据集转换为统一的多项选择格式而创建的基准，总计9,018个问题。我们全面评估了33个最先进的VLMs，设定了可扩展、一致和可重复的VLM评估的新标准。

**Summary**:

- (1): 本文的研究背景是视觉语言模型（VLMs）的快速发展，迫切需要有效的评估方法来判断模型性能并指导进一步研究。

- (2): 过去的方法主要基于开放式问题和多项选择问题进行评估。开放式问题评估因自然语言响应的多样性而难以准确；而多项选择问题创造耗时且复杂。本文提出的方法是 AutoConverter，通过将开放式问题自动转换为多项选择格式，旨在提高评估的客观性和可重复性，有效解决了传统方法的局限。

- (3): 本文的贡献在于提出了 AutoConverter 这一框架，能够自动生成挑战性的多项选择问题，并构建了 VMCBench 基准，系统地评估了多个VLM。

- (4): 研究方法是通过一个多代理系统，使用 GPT-4o 自动将开放式问题转换成多项选择题，生成具有挑战性且正确的选择项，并通过迭代反馈确保问题的正确性和难度。

- (5): 本文方法在 VMCBench 任务上评估了33个最先进的VLM，结果表明其在多项选择问题上的准确度与人类创建的问题相当或更低，支持了其评估目标的实现。


## Generalized Semantic Contrastive Learning via Embedding Side Information for Few-Shot Object Detection
- **Url**: http://arxiv.org/abs/2504.07060v1
- **Authors**: ['Ruoyu Chen', 'Hua Zhang', 'Jingzhi Li', 'Li Liu', 'Zhen Huang', 'Xiaochun Cao']
- **Abstrat**: The objective of few-shot object detection (FSOD) is to detect novel objects with few training samples. The core challenge of this task is how to construct a generalized feature space for novel categories with limited data on the basis of the base category space, which could adapt the learned detection model to unknown scenarios. However, limited by insufficient samples for novel categories, two issues still exist: (1) the features of the novel category are easily implicitly represented by the features of the base category, leading to inseparable classifier boundaries, (2) novel categories with fewer data are not enough to fully represent the distribution, where the model fine-tuning is prone to overfitting. To address these issues, we introduce the side information to alleviate the negative influences derived from the feature space and sample viewpoints and formulate a novel generalized feature representation learning method for FSOD. Specifically, we first utilize embedding side information to construct a knowledge matrix to quantify the semantic relationship between the base and novel categories. Then, to strengthen the discrimination between semantically similar categories, we further develop contextual semantic supervised contrastive learning which embeds side information. Furthermore, to prevent overfitting problems caused by sparse samples, a side-information guided region-aware masked module is introduced to augment the diversity of samples, which finds and abandons biased information that discriminates between similar categories via counterfactual explanation, and refines the discriminative representation space further. Extensive experiments using ResNet and ViT backbones on PASCAL VOC, MS COCO, LVIS V1, FSOD-1K, and FSVOD-500 benchmarks demonstrate that our model outperforms the previous state-of-the-art methods, significantly improving the ability of FSOD in most shots/splits.


**Translated Abstract**: 

本文的目标是少量样本目标检测（FSOD），即在仅有少量训练样本的情况下检测新物体。该任务的核心挑战是如何基于基本类别空间为新类别构建一个通用特征空间，以便将学习到的检测模型适应未知场景。然而，受限于新类别样本的不足，仍然存在两个问题：（1）新类别的特征往往会被基本类别的特征隐式表示，从而导致分类边界难以分隔；（2）新类别的数据量较少，无法充分表示其分布，使得模型微调容易出现过拟合。为了解决这些问题，我们引入了边信息，以缓解特征空间和样本视角带来的负面影响，并提出了一种新型的通用特征表示学习方法。具体而言，我们首先利用嵌入边信息构建知识矩阵，以量化基本类别与新类别之间的语义关系。然后，进一步发展上下文语义监督对比学习，增强语义相似类别之间的区分度。此外，为了防止稀疏样本导致的过拟合问题，引入了边信息引导的区域感知掩蔽模块，增强样本的多样性，通过反事实解释找到并舍弃区分相似类别的偏见信息，进一步细化判别表示空间。通过在 PASCAL VOC、MS COCO、LVIS V1、FSOD-1K 和 FSVOD-500 等基准数据集上使用 ResNet 和 ViT 骨干网络进行的广泛实验表明，我们的模型在大多数样本/拆分上超越了之前的最先进方法，显著提高了 FSOD 的能力。代码已发布于 https://github.com/RuoyuChen10/CCL-FSOD。

**Summary**:

- (1): 本文研究背景为在数据稀缺场景中的少量样本目标检测（FSOD），该领域的检测模型通常依赖大规模标注训练样本。

- (2): 过去的方法主要是基于微调的方法，通过在基础类别上进行预训练，并在少量新类别上进行微调。但这些方法面临两个主要问题：新类别特征与基础类别特征的边界模糊，导致不可分割的分类器边界，以及新类别样本有限导致的过拟合。提议的方法通过引入边信息和语义监督对比学习来解决这些问题，有效提高了类别的可分性。

- (3): 本文的贡献包括提出了一种利用边信息构建知识矩阵的方法，发展了上下文语义监督对比学习，以及引入了区域感知掩蔽模块以增强样本多样性，从而提高了FSOD性能。

- (4): 本文的研究方法包括使用边信息构建知识矩阵以量化类别之间的语义关系，以及引入上下文语义监督对比学习和区域感知掩蔽模块以防止过拟合和增强样本多样性。

- (5): 在 PASCAL VOC、MS COCO、LVIS V1、FSOD-1K 和 FSVOD-500 等任务上，提出的方法实现了显著的性能提升，验证了其目标的有效性。


## $Π$-NeSy: A Possibilistic Neuro-Symbolic Approach
- **Url**: http://arxiv.org/abs/2504.07055v1
- **Authors**: ['Ismaïl Baaj', 'Pierre Marquis']
- **Abstrat**: In this article, we introduce a neuro-symbolic approach that combines a low-level perception task performed by a neural network with a high-level reasoning task performed by a possibilistic rule-based system. The goal is to be able to derive for each input instance the degree of possibility that it belongs to a target (meta-)concept. This (meta-)concept is connected to intermediate concepts by a possibilistic rule-based system. The probability of each intermediate concept for the input instance is inferred using a neural network. The connection between the low-level perception task and the high-level reasoning task lies in the transformation of neural network outputs modeled by probability distributions (through softmax activation) into possibility distributions. The use of intermediate concepts is valuable for the explanation purpose: using the rule-based system, the classification of an input instance as an element of the (meta-)concept can be justified by the fact that intermediate concepts have been recognized.   From the technical side, our contribution consists of the design of efficient methods for defining the matrix relation and the equation system associated with a possibilistic rule-based system. The corresponding matrix and equation are key data structures used to perform inferences from a possibilistic rule-based system and to learn the values of the rule parameters in such a system according to a training data sample. Furthermore, leveraging recent results on the handling of inconsistent systems of fuzzy relational equations, an approach for learning rule parameters according to multiple training data samples is presented. Experiments carried out on the MNIST addition problems and the MNIST Sudoku puzzles problems highlight the effectiveness of our approach compared with state-of-the-art neuro-symbolic ones.


**Translated Abstract**:

在本文中，我们引入了一种神经符号方法，该方法将神经网络执行的低层感知任务与基于可能性的规则系统执行的高层推理任务相结合。目标是能够为每个输入实例推导出其属于目标（元）概念的可能度。该（元）概念通过基于可能性的规则系统与中间概念相连。对于输入实例，每个中间概念的概率是通过神经网络推断得出的。低层感知任务与高层推理任务之间的联系在于将通过softmax激活模型的概率分布转换为可能性分布。中间概念的使用对于解释目的而言是有价值的：使用规则系统，可以通过识别中间概念来证明将输入实例分类为（元）概念元素的合理性。从技术层面来看，我们的贡献是设计有效的方法来定义与基于可能性的规则系统相关的矩阵关系和方程系统。相应的矩阵和方程是用于从基于可能性的规则系统进行推理以及根据训练数据样本学习规则参数值的关键数据结构。此外，借助处理模糊关系方程不一致系统的最新成果，提出了一种根据多个训练数据样本学习规则参数的方法。在MNIST加法问题和MNIST数独难题上的实验突出显示了我们的方法与最先进的神经符号方法相比的有效性。

**Summary**:

- (1): 本文研究背景是结合低层神经网络感知和高层可能性规则系统推理，以实现对输入实例归属目标元概念的可能性评估。

- (2): 过去的方法多为独立的神经网络或符号推理系统，存在解释性差和知识推理不足的问题。提出的方法通过引入中间概念和可能性理论，解决了解释性和推理深度的问题，具有良好的动机。

- (3): 本文的贡献在于设计了有效的矩阵关系和方程系统，以支持基于可能性的规则系统的推理和学习，并提出了处理不一致模糊关系方程的学习方法。

- (4): 本文提出的研究方法包括利用神经网络推断中间概念的概率，结合基于可能性的规则系统进行推理，通过转换各层输出实现低层与高层任务的连接。

- (5): 本文在MNIST加法问题和MNIST数独问题上进行了实验，表现出优于现有神经符号方法的有效性，达到了研究目标。


## Beyond the Hype: Embeddings vs. Prompting for Multiclass Classification Tasks
- **Url**: http://arxiv.org/abs/2504.04277v2
- **Authors**: ['Marios Kokkodis', 'Richard Demsyn-Jones', 'Vijay Raghavan']
- **Abstrat**: Are traditional classification approaches irrelevant in this era of AI hype? We show that there are multiclass classification problems where predictive models holistically outperform LLM prompt-based frameworks. Given text and images from home-service project descriptions provided by Thumbtack customers, we build embeddings-based softmax models that predict the professional category (e.g., handyman, bathroom remodeling) associated with each problem description. We then compare against prompts that ask state-of-the-art LLM models to solve the same problem. We find that the embeddings approach outperforms the best LLM prompts in terms of accuracy, calibration, latency, and financial cost. In particular, the embeddings approach has 49.5% higher accuracy than the prompting approach, and its superiority is consistent across text-only, image-only, and text-image problem descriptions. Furthermore, it yields well-calibrated probabilities, which we later use as confidence signals to provide contextualized user experience during deployment. On the contrary, prompting scores are overly uninformative. Finally, the embeddings approach is 14 and 81 times faster than prompting in processing images and text respectively, while under realistic deployment assumptions, it can be up to 10 times cheaper. Based on these results, we deployed a variation of the embeddings approach, and through A/B testing we observed performance consistent with our offline analysis. Our study shows that for multiclass classification problems that can leverage proprietary datasets, an embeddings-based approach may yield unequivocally better results. Hence, scientists, practitioners, engineers, and business leaders can use our study to go beyond the hype and consider appropriate predictive models for their classification use cases.


**Translated Abstract**: 

在这个人工智能炒作的时代，传统的分类方法是否变得无关紧要？我们展示了一些多类分类问题，其中预测模型整体上优于基于提示的大型语言模型（LLM）框架。针对来自Thumbtack客户的家庭服务项目描述的文本和图像，我们构建了基于嵌入的softmax模型，以预测与每个问题描述相关的专业类别（例如，修理工、浴室改造）。然后我们将其与要求最新的LLM模型解决相同问题的提示进行比较。我们发现，嵌入方法在准确性、校准、延迟和财务成本方面均优于最佳的LLM提示。具体而言，嵌入方法的准确性比提示方法高出49.5%，并且其优势在文本、图像和文本图像问题描述之间是一致的。此外，它产生了良好校准的概率，我们将在部署期间将其作为信心信号提供上下文化用户体验。相反，提示分数过于无用。最后，在处理图像和文本时，嵌入方法的速度分别比提示快14倍和81倍，同时在现实部署假设下，它的成本可以低至提示的10倍。基于这些结果，我们部署了嵌入方法的变体，通过A/B测试，我们观察到的性能与我们的离线分析一致。我们的研究表明，对于可以利用专有数据集的多类分类问题，基于嵌入的方法可能会提供无可争议的更好结果。因此，科学家、从业者、工程师和商业领导者可以利用我们的研究，超越炒作，考虑适当的预测模型以应用于他们的分类用例。

**Summary**:

- (1): 本文研究的背景是近年来对人工智能技术的广泛关注，尤其是在大型语言模型（LLM）出现后，各公司开始探索基于AI的分类解决方案。

- (2): 过去的方法主要依赖于基于提示的LLM解决方案，存在准确性和信息反馈不足的问题。与之不同的是，本文提出的基于嵌入的方法能够在准确性以及计算效率上显著优于现有方法，从而有效解决了这些问题。

- (3): 本文的贡献在于证明了在多类分类任务中，利用嵌入的分类方法在准确性、延迟和经济成本上均优于基于LLM的提示方法，提供了实证支持。

- (4): 本文的研究方法包括构建基于嵌入的softmax模型，以处理来自Thumbtack客户的项目描述，通过对比最佳LLM提示评估模型性能。

- (5): 本文针对家庭服务项目描述的多类分类任务，基于嵌入的方法在准确性上比提示方法高出49.5%。其性能结果有力支持了研究目标，即在多类分类中优先采用嵌入方法。


## Unsolvable Problem Detection: Robust Understanding Evaluation for Large Multimodal Models
- **Url**: http://arxiv.org/abs/2403.20331v2
- **Authors**: ['Atsuyuki Miyai', 'Jingkang Yang', 'Jingyang Zhang', 'Yifei Ming', 'Qing Yu', 'Go Irie', 'Yixuan Li', 'Hai Li', 'Ziwei Liu', 'Kiyoharu Aizawa']
- **Abstrat**: This paper introduces a novel task to evaluate the robust understanding capability of Large Multimodal Models (LMMs), termed $\textbf{Unsolvable Problem Detection (UPD)}$. Multiple-choice question answering (MCQA) is widely used to assess the understanding capability of LMMs, but it does not guarantee that LMMs truly comprehend the answer. UPD assesses the LMM's ability to withhold answers when encountering unsolvable problems of MCQA, verifying whether the model truly understands the answer. UPD encompasses three problems: Absent Answer Detection (AAD), Incompatible Answer Set Detection (IASD), and Incompatible Visual Question Detection (IVQD), covering unsolvable cases like answer-lacking or incompatible choices and image-question mismatches. For the evaluation, we introduce the MM-UPD Bench, a benchmark for assessing performance across various ability dimensions. Our experiments reveal that even most LMMs, which demonstrate adequate performance on existing benchmarks, struggle significantly with MM-UPD, underscoring a novel aspect of trustworthiness that current benchmarks have overlooked. A detailed analysis shows that LMMs have different bottlenecks and chain-of-thought and self-reflection improved performance for LMMs with the bottleneck in their LLM capability. We hope our insights will enhance the broader understanding and development of more reliable LMMs.


**Translated Abstract**: 本文提出了一种新颖的任务，以评估大型多模态模型（LMMs）的稳健理解能力，称为“不可解问题检测（UPD）”。多项选择问答（MCQA）通常用于评估LMMs的理解能力，但并不能确保LMMs确实理解答案。UPD评估LMM在面对不可解的MCQA问题时保持回答的能力，从而验证模型是否确实理解答案。UPD涵盖三个问题：缺失答案检测（AAD）、不兼容答案集检测（IASD）和不兼容视觉问题检测（IVQD），覆盖诸如缺乏答案或选择不兼容以及图像与问题不匹配等不可解情况。为此，我们引入了MM-UPD Bench，这是一个用于评估不同能力维度表现的基准。我们的实验表明，即使大多数LMM在现有基准上表现良好，在MM-UPD上却显著挣扎，突显出当前基准未考虑的新型可信度方面。详细分析显示LMMs存在不同的瓶颈，思维链和自我反思能改善LMMs的性能。我们希望我们的见解能够增强对开发更可靠LMMs的更广泛理解。

**Summary**:

- (1): 本文的研究背景是大型多模态模型（LMMs）在各种应用中的能力提升及其理解能力的评估需求。

- (2): 过去的方法主要依赖多项选择问答（MCQA），但这些方法不能确保LMMs对答案的真实理解。所提出的方法“不可解问题检测（UPD）”则关注模型在面对不可解问题时的表现，以此提高对模型理解的验证，具有明确的动机。

- (3): 该论文的贡献在于提出了“不可解问题检测（UPD）”这一新任务，系统性地评估LMMs的理解能力，且开发了MM-UPD Bench基准。

- (4): 本文提出的研究方法集中于通过缺失答案检测（AAD）、不兼容答案集检测（IASD）和不兼容视觉问题检测（IVQD）三方面来评估LMMs的理解能力。

- (5): 在MM-UPD任务上，研究表明大多数LMMs在不可解问题上表现不佳，指出了过去评估方法的不足，支持了其目标的必要性。


## To Backtrack or Not to Backtrack: When Sequential Search Limits Model Reasoning
- **Url**: http://arxiv.org/abs/2504.07052v1
- **Authors**: ['Tian Qin', 'David Alvarez-Melis', 'Samy Jelassi', 'Eran Malach']
- **Abstrat**: Recent advancements in large language models have significantly improved their reasoning abilities, particularly through techniques involving search and backtracking. Backtracking naturally scales test-time compute by enabling sequential, linearized exploration via long chain-of-thought (CoT) generation. However, this is not the only strategy for scaling test-time compute: parallel sampling with best-of-n selection provides an alternative that generates diverse solutions simultaneously. Despite the growing adoption of sequential search, its advantages over parallel sampling--especially under a fixed compute budget remain poorly understood. In this paper, we systematically compare these two approaches on two challenging reasoning tasks: CountDown and Sudoku. Surprisingly, we find that sequential search underperforms parallel sampling on CountDown but outperforms it on Sudoku, suggesting that backtracking is not universally beneficial. We identify two factors that can cause backtracking to degrade performance: (1) training on fixed search traces can lock models into suboptimal strategies, and (2) explicit CoT supervision can discourage "implicit" (non-verbalized) reasoning. Extending our analysis to reinforcement learning (RL), we show that models with backtracking capabilities benefit significantly from RL fine-tuning, while models without backtracking see limited, mixed gains. Together, these findings challenge the assumption that backtracking universally enhances LLM reasoning, instead revealing a complex interaction between task structure, training data, model scale, and learning paradigm.


**Translated Abstract**: 

最近的大型语言模型（LLMs）的进展显著提高了它们的推理能力，特别是通过涉及搜索和回溯的技术。回溯通过支持长链式思考（CoT）生成的顺序线性化探索，自然扩展了测试时间的计算能力。然而，这并不是测试时间计算扩展的唯一策略：并行采样与最佳选择（best-of-n）提供了一种生成多样解决方案的替代方案。尽管顺序搜索的使用日益增长，但在固定计算预算下，它相对于并行采样的优势仍然认识不足。本文系统比较了这两种方法在两个具有挑战性的推理任务：CountDown和数独（Sudoku）上的表现。令人惊讶的是，我们发现“CountDown”中的顺序搜索表现不如并行采样，而在“数独”任务中则表现更佳，这表明回溯并非普遍有效。我们确定了两个可能导致回溯性能下降的因素：（1）基于固定搜索轨迹训练可能会使模型陷入次优策略，(2) 明确的CoT监督可能会抑制“隐式”（非口头）推理。将我们的分析扩展到强化学习（RL），我们展示了具备回溯能力的模型在RL微调中受益显著，而没有回溯能力的模型则获得有限且混合的收益。这些发现共同挑战了回溯普遍增强LLM推理的假设，揭示了任务结构、训练数据、模型规模和学习范式之间复杂的相互作用。

**Summary**:

- (1): 本文的研究背景是针对大型语言模型（LLMs）推理能力的提升，尤其是在应用回溯技术方面日益受到关注。

- (2): 过去的方法主要包括顺序自回归搜索（回溯）和并行采样。存在的问题是顺序搜索在某些任务中表现不佳，未能有效扩展模型的性能。本文提出了系统比较这两种方法，展示回溯在不同任务中性能也有差异，针对任务结构的不同调整了训练方式，从而解决了之前方法的局限性。

- (3): 本文的贡献在于通过具体实验揭示了顺序搜索与并行采样在CountDown和数独任务中的表现差异，以及确定了影响回溯有效性的两个关键因素（搜索偏见与冗长性），并探讨了强化学习方法在回溯模型中的积极作用。

- (4): 本文采用了比较实验的方法，分析了两种搜索策略在CountDown和数独任务下的表现。通过控制实验揭示了不同训练策略对模型性能的影响，并引入强化学习进行模型微调。

- (5): 本文的方法在CountDown和数独任务上进行测试，顺序搜索在CountDown任务中表现不佳，但在数独任务中表现优越，验证了模型的适用性，支持了提出回溯技术的有效性。


## MedPix 2.0: A Comprehensive Multimodal Biomedical Data set for Advanced AI Applications with Retrieval Augmented Generation and Knowledge Graphs
- **Url**: http://arxiv.org/abs/2407.02994v3
- **Authors**: ['Irene Siragusa', 'Salvatore Contino', 'Massimo La Ciura', 'Rosario Alicata', 'Roberto Pirrone']
- **Abstrat**: The increasing interest in developing Artificial Intelligence applications in the medical domain, suffers from the lack of high-quality data set, mainly due to privacy-related issues. In addition, the recent increase in Vision Language Models (VLM) leads to the need for multimodal medical data sets, where clinical reports and findings are attached to the corresponding medical scans. This paper illustrates the entire workflow for building the MedPix 2.0 data set. Starting with the well-known multimodal data set MedPix, mainly used by physicians, nurses, and healthcare students for Continuing Medical Education purposes, a semi-automatic pipeline was developed to extract visual and textual data followed by a manual curing procedure in which noisy samples were removed, thus creating a MongoDB database. Along with the data set, we developed a Graphical User Interface aimed at navigating efficiently the MongoDB instance and obtaining the raw data that can be easily used for training and/or fine-tuning VLMs. To enforce this point, in this work, we first recall DR-Minerva, a Retrieve Augmented Generation-based VLM model trained upon MedPix 2.0. DR-Minerva predicts the body part and the modality used to scan its input image. We also propose the extension of DR-Minerva with a Knowledge Graph that uses Llama 3.1 Instruct 8B, and leverages MedPix 2.0. The resulting architecture can be queried in a end-to-end manner, as a medical decision support system. MedPix 2.0 is available on GitHub https://github.com/CHILab1/MedPix-2.0


**Translated Abstract**: 

随着对医疗领域人工智能应用的日益关注，高质量数据集的缺乏仍然是一个主要问题，尤其是由于隐私相关的原因。此外，最近对视觉语言模型（VLM）的关注增加，促使对多模态医学数据集的需求，这些数据集将临床报告和发现附加到相应的医学扫描图像中。本文展示了构建MedPix 2.0数据集的整个工作流程。我们开发了一种半自动的管道从著名的多模态数据集MedPix中提取视觉和文本数据，并通过手动清理程序移除噪声样本，从而创建了一个MongoDB数据库。为了简化数据集的使用，我们开发了一个图形用户界面，以便高效地导航MongoDB实例并获取可用于训练和/或微调VLM的原始数据。为此，本文首先回顾了使用MedPix 2.0训练的基于检索增强生成（RAG）的VLM模型DR-Minerva。DR-Minerva能够预测输入图像使用的身体部位和扫描方式。我们还提出将DR-Minerva与使用Llama 3.1 Instruct 8B的知识图谱相结合，利用MedPix 2.0进行扩展。最终架构可以作为医疗决策支持系统以端到端的方式进行查询。MedPix 2.0可在GitHub上获取。

**Summary**:

- (1): 本文研究背景是医疗领域人工智能应用对高质量数据集的需求，主要受隐私问题的限制。

- (2): 过去的方法依赖于开放访问数据集和与医院合作，但是由于数据隐私和缺乏多模态数据，这些方法存在不足。提出的方法通过构建MedPix 2.0数据集，利用半自动管道和MongoDB数据库解决了数据稀缺和使用不便的问题，具有良好的动机。

- (3): 本文贡献在于创建了MedPix 2.0数据集，提供了一个高质量的多模态医学数据集，并开发了易于使用的图形用户界面。

- (4): 研究方法论包括使用半自动管道提取数据、手动清理数据创建MongoDB数据库，及构建DR-Minerva VLM模型与知识图谱。

- (5): 本文方法在医疗图像诊断任务上取得了良好的性能，通过知识图谱和VLM结合，能够为临床决策提供有效支持。


## Identifying Key Challenges of Hardness-Based Resampling
- **Url**: http://arxiv.org/abs/2504.07031v1
- **Authors**: ['Pawel Pukowski', 'Venet Osmani']
- **Abstrat**: Performance gap across classes remains a persistent challenge in machine learning, often attributed to variations in class hardness. One way to quantify class hardness is through sample complexity - the minimum number of samples required to effectively learn a given class. Sample complexity theory suggests that class hardness is driven by differences in the amount of data required for generalization. That is, harder classes need substantially more samples to achieve generalization. Therefore, hardness-based resampling is a promising approach to mitigate these performance disparities. While resampling has been studied extensively in data-imbalanced settings, its impact on balanced datasets remains unexplored.   This raises the fundamental question whether resampling is effective because it addresses data imbalance or hardness imbalance. We begin addressing this question by introducing class imbalance into balanced datasets and evaluate its effect on performance disparities. We oversample hard classes and undersample easy classes to bring hard classes closer to their sample complexity requirements while maintaining a constant dataset size for fairness. We estimate class-level hardness using the Area Under the Margin (AUM) hardness estimator and leverage it to compute resampling ratios. Using these ratios, we perform hardness-based resampling on the well-known CIFAR-10 and CIFAR-100 datasets.   Contrary to theoretical expectations, our results show that hardness-based resampling does not meaningfully affect class-wise performance disparities. To explain this discrepancy, we conduct detailed analyses to identify key challenges unique to hardness-based imbalance, distinguishing it from traditional data-based imbalance. Our insights help explain why theoretical sample complexity expectations fail to translate into practical performance gains and we provide guidelines for future research.


**Translated Abstract**: 

类之间的性能差距仍然是机器学习中的一个持续挑战，通常归因于类硬度的变化。一种量化类硬度的方法是通过样本复杂性——有效学习给定类所需的最小样本数。样本复杂性理论表明，类硬度是由生成所需数据量的差异驱动的。也就是说，更难的类需要显著更多的样本以达到泛化。因此，基于硬度的重采样是一种有前景的方法来减轻这些性能差异。尽管重采样在数据不平衡的设置中得到了广泛研究，但其对平衡数据集的影响仍未被探索。这就引发了一个基本问题，即重采样是因为它解决了数据不平衡还是硬度不平衡而有效。我们开始解决这个问题，通过在平衡数据集中引入类不平衡并评估其对性能差异的影响。我们对困难类进行过采样，对简单类进行欠采样，以使困难类更接近其样本复杂性要求，同时为了公平保持数据集大小不变。我们使用边际下的面积（AUM）硬度估计器估计类级别硬度，并利用其计算重采样比率。使用这些比率，我们对著名的CIFAR-10和CIFAR-100数据集进行硬度基础的重采样。与理论预期相反，我们的结果表明，基于硬度的重采样对类的性能差异没有显著影响。为了解释这一差异，我们进行了详细分析，以识别基于硬度的不平衡的独特关键挑战，将其与传统的数据不平衡区分开。我们的见解帮助解释了为何理论样本复杂性预期未能转化为实际性能提升，并为未来的研究提供了指导。

**Summary**:

- (1): 本文的研究背景是机器学习中的类之间性能差距问题，主要因类硬度变化导致。

- (2): 过去的方法主要是针对数据不平衡进行重采样，但未探索硬度不平衡的影响。本文提出的方法与现有方法不同，在平衡数据集中引入类不平衡，通过对困难类进行过采样和对简单类进行欠采样来解决问题。该方法从样本复杂性理论出发，旨在提高应对类硬度差异的有效性。

- (3): 本文的贡献在于提出了硬度基础的重采样方法，并通过详尽的分析揭示了该方法未能有效减少性能差距的关键挑战。

- (4): 本文提出的研究方法是在CIFAR-10和CIFAR-100数据集上进行硬度基础的重采样，采用边际下的面积（AUM）估计器评估类硬度，并计算重采样比率。

- (5): 本文在CIFAR-10和CIFAR-100数据集上的任务表现为通过重采样的方式进行性能评估。结果表明，基于硬度的重采样方法未能显著改善类的性能差距，这不支持其初衷的目标。


## Using ML filters to help automated vulnerability repairs: when it helps and when it doesn't
- **Url**: http://arxiv.org/abs/2504.07027v1
- **Authors**: ['Maria Camporese', 'Fabio Massacci']
- **Abstrat**: [Context:] The acceptance of candidate patches in automated program repair has been typically based on testing oracles. Testing requires typically a costly process of building the application while ML models can be used to quickly classify patches, thus allowing more candidate patches to be generated in a positive feedback loop. [Problem:] If the model predictions are unreliable (as in vulnerability detection) they can hardly replace the more reliable oracles based on testing. [New Idea:] We propose to use an ML model as a preliminary filter of candidate patches which is put in front of a traditional filter based on testing. [Preliminary Results:] We identify some theoretical bounds on the precision and recall of the ML algorithm that makes such operation meaningful in practice. With these bounds and the results published in the literature, we calculate how fast some of state-of-the art vulnerability detectors must be to be more effective over a traditional AVR pipeline such as APR4Vuln based just on testing.


**Translated Abstract**: 

[背景] 在自动程序修复中，候选补丁的接受通常基于测试验证。测试通常需要耗时的构建过程，而机器学习（ML）模型可以快速分类补丁，从而允许在积极反馈循环中生成更多候选补丁。[问题] 如果模型预测不可靠（如在漏洞检测中），则无法有效替代基于测试的更可靠验证。[新想法] 我们建议将机器学习模型作为候选补丁的初步过滤器，放置在基于测试的传统过滤器之前。[初步结果] 我们识别出ML算法的精度和召回率的一些理论界限，从而使这种操作在实践中具有意义。通过这些界限以及已发布文献中的结果，我们计算了一些最先进的漏洞检测器必须有多快，才能在基于测试的传统AVR流程如 APR4Vuln 中更为有效。

**Summary**:

- (1): 本文的研究背景是在自动程序修复（APR）中，候选补丁的接受依赖于测试验证，机器学习模型在快速分类补丁方面可能提供更有效的替代方案。

- (2): 过去的方法依赖于基于测试的过滤，面临高开销和低效的问题。与现有方法不同，本文提出将机器学习模型作为初步过滤器，从而在传统过滤器前提高效率。这种方法通过快速筛选不 promising 的补丁来解决上述问题。

- (3): 本文的贡献在于提出了将机器学习模型与测试过滤器结合的新方法，并确定了其在实际操作中有效的理论界限。

- (4): 研究方法论包括使用机器学习模型对潜在候选补丁进行初步分类，以便更快速地过滤掉无用补丁，随后将有效的补丁提交给传统测试进行验证。

- (5): 本文的方法在处理漏洞检测任务中提供了较好的性能，但在预处理和分类时间上仍面临挑战。当前模型可能不够有效以支持其目标，但初步结果显示出其潜在的有效性。


## Adapting GT2-FLS for Uncertainty Quantification: A Blueprint Calibration Strategy
- **Url**: http://arxiv.org/abs/2504.07017v1
- **Authors**: ['Yusuf Guven', 'Tufan Kumbasar']
- **Abstrat**: Uncertainty Quantification (UQ) is crucial for deploying reliable Deep Learning (DL) models in high-stakes applications. Recently, General Type-2 Fuzzy Logic Systems (GT2-FLSs) have been proven to be effective for UQ, offering Prediction Intervals (PIs) to capture uncertainty. However, existing methods often struggle with computational efficiency and adaptability, as generating PIs for new coverage levels $(\phi_d)$ typically requires retraining the model. Moreover, methods that directly estimate the entire conditional distribution for UQ are computationally expensive, limiting their scalability in real-world scenarios. This study addresses these challenges by proposing a blueprint calibration strategy for GT2-FLSs, enabling efficient adaptation to any desired $\phi_d$ without retraining. By exploring the relationship between $\alpha$-plane type reduced sets and uncertainty coverage, we develop two calibration methods: a lookup table-based approach and a derivative-free optimization algorithm. These methods allow GT2-FLSs to produce accurate and reliable PIs while significantly reducing computational overhead. Experimental results on high-dimensional datasets demonstrate that the calibrated GT2-FLS achieves superior performance in UQ, highlighting its potential for scalable and practical applications.


**Translated Abstract**: 

不确定性量化（UQ）对于在高风险应用中部署可靠的深度学习（DL）模型至关重要。最近，通用类型-2模糊逻辑系统（GT2-FLS）已被证明在UQ方面有效，提供了捕获不确定性的预测区间（PIs）。然而，现有方法经常在计算效率和适应性方面遇到困难，因为生成新的覆盖水平（ϕ_d）的PIs通常需要重新训练模型。此外，直接估计整个条件分布的方法计算成本高昂，限制了其在现实场景中的可扩展性。本研究通过提出一种GT2-FLS的蓝图校准策略来解决这些挑战，使得无需重新训练即可高效适应任何期望的ϕ_d。通过探索α平面Type Reduced Set与不确定性覆盖之间的关系，我们开发了两种校准方法：基于查找表的方法和无导数优化算法。这些方法使GT2-FLS能够生成准确且可靠的PIs，同时显著降低计算开销。在高维数据集上的实验结果表明，经过校准的GT2-FLS在UQ方面取得了优越的性能，突显了其在可扩展及实际应用中的潜力。

**Summary**:

- (1): 本文的研究背景是深度学习（DL）在高风险应用中的不确定性量化（UQ）对模型的可靠性至关重要。

- (2): 过去的方法主要依赖于类型-2模糊逻辑系统（T2-FLSs），生成预测区间（PIs）。这些方法面临的主要问题是计算效率低和适应性差，需要进行模型重训练。本文提出的蓝图校准策略不需要重训练即可针对新的覆盖水平（ϕ_d）进行适应，解决了校准时的计算开销和灵活性问题，因此该方法具有充分的动机。

- (3): 本文的贡献在于开发了一种蓝图校准策略，使得GT2-FLS能够高效适应不同的覆盖水平，提高了不确定性量化的效率和可靠性。

- (4): 本文提出的研究方法包括基于查找表的校准方法和无导数优化算法，这两种方法都能够有效地进行类型-2模糊逻辑系统校准。

- (5): 本文的方法在高维数据集上进行了实验，校准的GT2-FLS在不确定性量化方面实现了优越的性能，证明了其在可扩展性和实际应用中的潜力。


## FAME: Introducing Fuzzy Additive Models for Explainable AI
- **Url**: http://arxiv.org/abs/2504.07011v1
- **Authors**: ['Omer Bahadir Gokmen', 'Yusuf Guven', 'Tufan Kumbasar']
- **Abstrat**: In this study, we introduce the Fuzzy Additive Model (FAM) and FAM with Explainability (FAME) as a solution for Explainable Artificial Intelligence (XAI). The family consists of three layers: (1) a Projection Layer that compresses the input space, (2) a Fuzzy Layer built upon Single Input-Single Output Fuzzy Logic Systems (SFLS), where SFLS functions as subnetworks within an additive index model, and (3) an Aggregation Layer. This architecture integrates the interpretability of SFLS, which uses human-understandable if-then rules, with the explainability of input-output relationships, leveraging the additive model structure. Furthermore, using SFLS inherently addresses issues such as the curse of dimensionality and rule explosion. To further improve interpretability, we propose a method for sculpting antecedent space within FAM, transforming it into FAME. We show that FAME captures the input-output relationships with fewer active rules, thus improving clarity. To learn the FAM family, we present a deep learning framework. Through the presented comparative results, we demonstrate the promising potential of FAME in reducing model complexity while retaining interpretability, positioning it as a valuable tool for XAI.


**Translated Abstract**: 

在本研究中，我们引入了模糊加法模型（Fuzzy Additive Model, FAM）和具有可解释性的FAM（FAME），作为可解释人工智能（XAI）的解决方案。该模型由三个层次组成：（1）投影层，用于压缩输入空间；（2）模糊层，基于单输入单输出模糊逻辑系统（Single Input-Single Output Fuzzy Logic Systems, SFLS），SFLS作为加法指数模型中的子网络；（3）聚合层。该架构结合了SFLS的可解释性（使用人类可理解的“如果-那么”规则）和输入-输出关系的可解释性，利用加法模型结构。此外，使用SFLS自然解决了维度灾难和规则爆炸等问题。为了进一步提高可解释性，我们提出了一种在FAM中雕塑前件空间的方法，转变为FAME。我们展示了FAME能够以更少的活跃规则捕捉输入-输出关系，从而改善清晰度。为了学习FAM系列，我们提出了一个深度学习框架。通过比较结果，我们展示了FAME在减少模型复杂性的同时保留可解释性的良好潜力，使其成为XAI的有价值工具。

**Summary**:

- (1): 本文研究背景是深度学习（Deep Learning, DL）在应用中的透明性挑战，尤其是在关键任务应用中，强调需要可解释人工智能（XAI）来解决模型决策过程的不透明性问题。

- (2): 过去的方法主要是神经加法模型，通过结合加法指数模型和神经网络来降低DL的模糊性，但它们往往在处理高维数据时面临维度灾难和规则爆炸等问题。与现有方法不同，所提出的FAME模型引入了模糊逻辑系统（Fuzzy Logic Systems, FLS），使得可解释性更强，并通过模糊层和投影层减轻了上述问题，且其方法具有明确的动机。

- (3): 本文的贡献在于提出了一种新的Fuzzy Additive Model（FAM）及其可解释版本FAME，集成了深度学习与模糊逻辑的优点，改善了解释性和透明度。

- (4): 本文提出的研究方法包括三层结构的设计：投影层（用于输入空间压缩）、模糊层（基于SFLS的子网络）和聚合层（用于规则的汇总与加法），并在此基础上开发了一种深度学习框架。

- (5): 本文的方法在多输入单输出（Multi Input-Single Output, MFLS）任务上进行比较展示，结果表明FAM在性能上优于传统模型，而FAME在保持可解释性的同时仅有轻微的准确性下降，支持了其目标。


## Assumption-free fidelity bounds for hardware noise characterization
- **Url**: http://arxiv.org/abs/2504.07010v1
- **Authors**: ['Nicolo Colombo']
- **Abstrat**: In the Quantum Supremacy regime, quantum computers may overcome classical machines on several tasks if we can estimate, mitigate, or correct unavoidable hardware noise. Estimating the error requires classical simulations, which become unfeasible in the Quantum Supremacy regime. We leverage Machine Learning data-driven approaches and Conformal Prediction, a Machine Learning uncertainty quantification tool known for its mild assumptions and finite-sample validity, to find theoretically valid upper bounds of the fidelity between noiseless and noisy outputs of quantum devices. Under reasonable extrapolation assumptions, the proposed scheme applies to any Quantum Computing hardware, does not require modeling the device's noise sources, and can be used when classical simulations are unavailable, e.g. in the Quantum Supremacy regime.


**Translated Abstract**: 

在量子优势状态下，量子计算机在若干任务上可能超越传统机器，前提是我们能够估计、减轻或纠正不可避免的硬件噪声。估计错误需要进行经典模拟，而在量子优势状态下，这种模拟变得不可行。我们利用机器学习的数据驱动方法和符合预测（Conformal Prediction），一种以其温和性质和有限样本有效性而闻名的机器学习不确定性量化工具，找到无噪声和有噪声的量子设备输出之间的理论有效上界。在合理的外推假设下，所提出的方案适用于任何量子计算硬件，不需要对设备的噪声源进行建模，并且可以在经典模拟不可用时使用，例如在量子优势状态下。

**Summary**:


- (1): 本文的研究背景是量子计算的潜力尚未在实际应用中显现，而任务的可扩展性优势需要纠正由硬件噪声引起的错误。

- (2): 过去的方法包括依赖物理信息的噪声和错误模型（NEMs）的量子错误纠正算法，这些方法基于强假设，计算复杂，且在深度电路中不可靠。所提议的方法采用机器学习和符合预测，不需建模噪声源，适用于量子优势状态下的设备，解决了经典模拟不可用的问题。该方法具有良好的动机，因其可以广泛适用于各种量子硬件。

- (3): 论文的贡献在于提出了一种无假设的、基于符合预测的方案，用于量子硬件噪声的表征，并提供了可靠性保证，以应对类不可处理的量子计算系统。

- (4): 本文提出的研究方法论是利用符合预测来评估没有模型假设的量子硬件噪声，通过在不同大小的电路上进行校准和测试算法，以分析其有效性和效率。

- (5): 本文中的方法针对量子计算机的输出进行测试，并在量子优势状态下进行应用。尽管具体的性能指标尚未明确，但方法的设定与目标相符，并具有潜在的应用前景。


## Data-Driven Insights into Rare Earth Mineralization: Machine Learning Applications Using Functional Material Synthesis Data
- **Url**: http://arxiv.org/abs/2504.07007v1
- **Authors**: ['Juejing Liu', 'Xiaoxu Li', 'Yifu Feng', 'Zheming Wang', 'Kevin M. Rosso', 'Xiaofeng Guo', 'Xin Zhang']
- **Abstrat**: Quantitative understanding of rare earth element (REE) mineralization mechanisms, crucial for improving industrial separation, remains limited. This study leverages 1239 hydrothermal synthesis datapoints from material science as a surrogate for natural REE mineralization. We trained machine learning models (KNN, RF, XGBoost) using precursor, additive, and reaction data to predict product elements and phases, validating predictions with new experiments. XGBoost exhibited the highest accuracy, with feature importance analysis indicating thermodynamic properties were critical for predictions. Observed correlations among reaction parameters aligned with classical crystallization theory. Further XGBoost models successfully predicted reaction temperature and pH from precursor/product data. Our findings demonstrate the cross-disciplinary utility of material science data for geochemical understanding, underscore the need for research on less-studied REE minerals (e.g., carbonates, heavy REEs), and suggest potential to accelerate REE resource development.


**Translated Abstract**: 

对于稀土元素（REE）矿化机制的定量理解，对于改善工业分离至关重要，但目前仍然有限。本研究利用1239个来自材料科学的水热合成数据点作为自然REE矿化的替代。我们训练了机器学习模型（KNN、RF、XGBoost），使用前驱体、添加剂和反应数据来预测产品元素和相，并通过新的实验验证了预测。XGBoost展示了最高的准确性，特征重要性分析表明热力学属性对于预测至关重要。观察到的反应参数之间的关联与经典结晶理论一致。进一步的XGBoost模型成功预测了基于前驱体/产品数据的反应温度和pH值。我们的研究结果展示了材料科学数据在地球化学理解中的跨学科实用性，强调了对较少研究的REE矿物（如碳酸盐，重REE）进行研究的必要性，并表明有潜力加速REE资源开发。

**Summary**:

- (1): 本文的研究背景是对稀土元素矿化机制的定量理解有限，这对改善工业分离至关重要。

- (2): 过去的方法主要依赖于经验和传统的实验技艺，问题在于缺乏系统的预测能力。提出的方法是利用机器学习模型（如XGBoost）从材料科学的数据中进行预测，与现有方法相比，能够更准确地预测产品元素和相，通过实验验证其有效性，动机明确。

- (3): 本文的贡献在于提出了一种新的跨学科方法结合材料科学数据，提升了对稀土元素矿化的理解，并指出了进一步研究的方向。

- (4): 本文的研究方法涉及机器学习的应用，训练KNN、RF和XGBoost模型，利用水热合成数据点进行元素和相的预测，并进行特征重要性分析。

- (5): 方法在预测产品元素、相及反应条件（温度和pH值）方面表现出色，XGBoost模型提供了最高的准确率，能够支持其研究目标。


# AGN
## Deep Extragalactic VIsible Legacy Survey (DEVILS): New robust merger rates at intermediate redshifts
- **Url**: http://arxiv.org/abs/2504.06613v1
- **Authors**: ['Melissa F. Fuentealba-Fuentes', 'Luke J. M. Davies', 'Aaron S. G. Robotham', 'Robin H. W. Cook', 'Sabine Bellstedt', 'Claudia D. P. Lagos', 'Matías Bravo', 'Malgorzata Siudek']
- **Abstrat**: Mergers are fundamental to our understanding of the processes driving the evolution of the structure and morphology of galaxies, star formation, AGN activity, and the redistribution of stellar mass in the Universe. Determining the fraction and properties of mergers across cosmic time is critical to understanding the formation of the Universe we observe today. This fraction and its evolution also provide inputs and constraints for cosmological simulations, crucial for theoretical models of galaxy evolution. We present robust estimates of major close-pair fractions and merger rates at $0.2 < z < 0.9$ in the Deep Extragalactic VIsible Legacy Survey (DEVILS). We identify major mergers by selecting close-pairs with a projected spatial separation $r_{\mathrm{sep}} < 20$ h$^{-1}$ kpc and a radial velocity separation $v_{\mathrm{sep}} < 500$ km s$^{-1}$. For galaxies with stellar masses of log$_{10}$($M_\star$/$M_\odot$) = 10.66 $\pm$ 0.25 dex, we find a major close-pair fraction of $\approx 0.021$ at $0.2 < z < 0.34$ using a highly complete, unbiased spectroscopic sample. We extend these estimates to $0.2 < z < 0.9$ by combining the full probability distribution of redshifts for galaxies with high-quality spectroscopic, photometric, or grism measurements. Fitting a power-law $\gamma_{m} = A(1 + z)^m$, we find $A = 0.024 \pm 0.001$ and $m = 0.55 \pm 0.22$. Consistent with previous results, the shallow slope suggests weak redshift evolution in the merger fraction. When comparing with large hydrodynamical simulations, we also find consistent results. We convert close-pair fractions to merger rates using several literature prescriptions for merger timescales and provide all measurements for future studies.


**Translated Abstract**: 

合并是我们理解驱动星系结构和形态演化、恒星形成、活动星系核（AGN）活动和宇宙中恒星质量重新分配过程的关键。确定不同宇宙时期合并的比例和特性对于理解今天所观察到的宇宙的形成至关重要。这个比例及其演变也为宇宙学模拟提供输入和约束，这对星系演化的理论模型至关重要。我们在深层外系可见遗产调查（DEVILS）中提供了0.2 < 𝑧 < 0.9范围内重大的近对数比例和合并率的稳健估计。通过选择具有投影空间分离度 𝑟sep < 20 h$^{-1}$ kpc 和径向速度分离度 𝑣sep < 500 km/s 的近对，我们识别重大合并。对于质量为 log$_{10}$(𝑀★/𝑀⊙) = 10.66 ± 0.25 dex 的星系，我们在 0.2 < 𝑧 < 0.34 的范围内发现大约0.021的重大近对比例，使用一个高度完整、无偏见的光谱样本。通过结合具有高质量光谱、光度或光谱测量的星系的红移的完整概率分布，我们将这些估计扩展到0.2 < 𝑧 < 0.9。拟合功率定律 𝛾𝑚 = 𝐴(1 + 𝑧)𝑚，我们得到 𝐴 = 0.024 ± 0.001 和 𝑚 = 0.55 ± 0.22。与之前的结果一致，较浅的斜率表明合并比例的红移演化较弱。在与大型流体动力学模拟结果的比较中，我们也得到了相一致的结果。我们根据若干文献中对合并时间尺度的规定将近对比例转换为合并率，并为未来的研究提供所有测量数据。

**Summary**:

- (1): 该研究涉及合并在星系演化中的重要性，以及它如何影响星系结构、形态、恒星形成和AGN活动的过程。

- (2): 过去的方法包括使用近对星系和形态扰动的迹象来检测合并，但这些方法依赖于高质量光谱样本，且容易受到多种观测因素的偏倚。本文提出的方法通过定义近对的特定空间和速度分离标准，减少了这些偏倚，并提高了样本的完整性，具有充分的动机。

- (3): 本文的贡献在于提供了0.2 < 𝑧 < 0.9范围内的合并率的稳健估计，并通过结合多种红移测量方法，扩展了对合并特性的了解。

- (4): 在研究方法论上，本文采用了定义合并特征的空间和速度分离标准，并结合了高质量的光谱、光度和光谱测量，以获得更准确的合并率。

- (5): 本文任务是在不同红移范围内确定合并比例，并实现了与大型流体动力学模拟一致的结果。这些性能支持了他们的研究目标。


## A Galaxy with an Extremely Blue UV Slope $β=-3$ at $z=9.25$ Identified by JWST Spectroscopy: Evidence for a Weak Nebular Continuum and Efficient Ionizing Photon Escape?
- **Url**: http://arxiv.org/abs/2411.19893v2
- **Authors**: ['Hiroto Yanagisawa', 'Masami Ouchi', 'Kimihiko Nakajima', 'Yuichi Harikane', 'Seiji Fujimoto', 'Yoshiaki Ono', 'Hiroya Umeda', 'Minami Nakane', 'Hidenobu Yajima', 'Hajime Fukushima', 'Yi Xu']
- **Abstrat**: We investigate UV continuum slopes $\beta$ of 863 galaxies at $z=4-14$ using archival JWST/NIRSpec PRISM spectra obtained from major JWST GTO, ERS, and GO programs, including JADES, CEERS, and UNCOVER. Among these galaxies, we identify a remarkable galaxy at $z=9.25$, dubbed EBG-1, with a significantly blue UV slope $\beta=-2.99\pm0.15$, unlike the rest of the galaxies that exhibit red continua or ambiguous blue continua hindered by large uncertainties. We confirm that the $\beta$ value negligibly changes by the data reduction and fitting wavelength ranges for UV emission/absorption line masking. The extreme blue slope, $\beta=-3.0$, rules out significant contributions from dust extinction or AGN activity. Comparing with stellar and nebular emission models, we find that such a blue UV slope cannot be reproduced solely by stellar models even with very young, metal-poor, or top-heavy contiguous star formation associated with strong nebular continua making the UV slopes red, but with a high ionizing photon escape fraction, $f_\mathrm{esc}^\mathrm{ion} \gtrsim 0.5$, for a weak nebular continuum. While the H$\beta$ emission line is not detected, likely due to the limited sensitivity of the spectrum, we find moderately weak [O III] $\lambda\lambda$4959,5007 emission lines for the given star-formation rate ($3\, \mathrm{M_\odot}$ yr$^{-1}$) and stellar mass ($10^{8.0} \, \mathrm{M_\odot}$) that are about three times weaker than the average emission lines, again suggestive of the high ionizing photon escape fraction, $f_\mathrm{esc}^\mathrm{ion} \sim 0.7$ or more. EBG-1 would provide crucial insights into stellar and nebular continuum emission in high-redshift galaxies, serving as an example of the ionizing photon escaping site at the epoch of reionization.


**Translated Abstract**: 

我们使用来自主要JWST GTO、ERS和GO项目（包括JADES、CEERS和UNCOVER）的归档JWST/NIRSpec PRISM光谱研究863个在$z=4-14$的星系的UV连续谱斜率$\beta$。在这些星系中，我们发现了一颗显著的星系，称为EBG-1，位于$z=9.25$，其UV斜率为$\beta=-2.99 \pm 0.15$，与其他展现红色或模糊蓝色连续谱的星系明显不同。我们确认$\beta$值在数据处理和光谱范围调整中的变化微乎其微。极其蓝的斜率$\beta=-3.0$排除了尘埃消光或活动星系核（AGN）活动的显著贡献。与恒星和气体发射模型相比，我们发现如此蓝色的UV斜率无法仅由恒星模型再现，即使在非常年轻、金属贫乏或以顶部为重的连续恒星形成情况下，且需要高的电离光子逃逸率$f_\mathrm{esc}^\mathrm{ion} \gtrsim 0.5$，才能计算出弱的气体连续谱。虽然H$\beta$发射线未被探测到，这可能与光谱灵敏度有限有关，但我们发现了中等弱的[O III] $\lambda\lambda$4959,5007发射线，其强度相较于给定的星形成率（$3 \, \mathrm{M_\odot \, yr^{-1}}$）和恒星质量（$10^{8.0} \, \mathrm{M_\odot}$）约为平均发射线的三分之一，再次表明高电离光子逃逸率$f_\mathrm{esc}^\mathrm{ion} \sim 0.7$或更高。EBG-1将为高红移星系中的恒星和气体连续谱发射提供重要洞见，成为电离光子逃逸的例证，在再电离时期提供重要信息。

**Summary**:

  - (1): 本文的研究背景是宇宙早期星系初始恒星形成对宇宙再电离过程的贡献，特别关注于高红移星系的电离光子逃逸率。

  - (2): 过去的方法主要依赖于光度法测量UV连续谱斜率，但由于发射线的污染，测量存在较大不确定性。本文提出的基于JWST/NIRSpec PRISM光谱的直接光谱分析方法，可以更准确地测量UV斜率，克服了光度法中的不足。

  - (3): 本文的贡献在于确认了一颗具有极蓝UV斜率的高红移星系EBG-1，揭示其在高电离光子逃逸方面的重要性，并为理解高红移星系的恒星形成和气体状态提供了新证据。

  - (4): 本文采用JWST/NIRSpec PRISM光谱技术，研究目标星系的UV连续谱斜率，特别关注于电离光子逃逸率以及相关的气体发射线特征。

  - (5): 该方法在确定EBG-1星系的UV斜率（$\beta=-3.0$）及其电离光子逃逸率方面取得了成功，表明该星系可能在宇宙再电离中起重要作用，支持了研究团队的目标。


# ALMA
## Observing radio transients with Phased ALMA: Pulses from the Galactic Centre magnetar
- **Url**: http://arxiv.org/abs/2504.06234v2
- **Authors**: ['J. Vera-Casanova', 'M. Cruces', 'K. Liu', 'J. Wongphechauxsorn', 'C. A. Braga', 'M. Kramer', 'P. Torne', 'P. Limaye', 'M. C. Espinoza-Dupouy', 'L. Rodriguez']
- **Abstrat**: Radio transients, such as pulsars and Fast Radio Bursts (FRBs), are primarily detected at centimetre radio wavelengths, where higher luminosities are found. However, observations of sources in dense environments are heavily affected by propagation effects which may hinder a detection. Millimetre wave observations bypass this complication but require the largest radio telescopes to compensate for the lower flux densities. When used in phased mode, the ALMA radio telescope provides an equivalent dish size of 84m, being the most sensitive instrument at mm/sub mm. With its high time resolution it offers a unique opportunity to study radio transients in an unexplored window. We study the Galactic Centre (GC) magnetar, PSR J1745$-$2900, as a laboratory for magnetars in complex magneto-turbulent environments and to link with FRBs. We showcase the potential of ALMA in phased mode to observe radio transients and to achieve, for some sources, the first ever detections outside the cm wave range. We studied the GC magnetar using ALMA archival data of Sgr A* at Band 3 from the 2017 GMVA campaign. We searched in intensity and classified the pulses based on their circular and linear polarisation properties and arrival phase. We detected eight pulses with energies in the range of 10$^{29}$ erg. We constructed its cumulative energy distribution and we fit a power law, where the event rate scales with energy as $R \propto E^{\gamma}$. The result is an exponent of $\gamma = -2.4 \pm 0.1$. With the $\gamma -$value and the system properties of phased ALMA, we estimate that over 160 known pulsars could be detected by ALMA. For repeating FRBs, observing during their peak activity window could lead to several detections. We expect that ALMA's lower frequency bands with polarisation capabilities, will serve as a pioneer on mm wave searches for pulsars and to study complex environments involving radio transients.


**Translated Abstract**: 
射电瞬态，如脉冲星和快速射电暴（FRBs），主要在厘米射电波长上被探测，因在这些波长下的亮度较高。然而，在密集环境中观察源时，传播效应会严重影响探测。毫米波观察能够绕过这个问题，但需要最大的大型射电望远镜以补偿较低的通量密度。使用相位模式时，ALMA射电望远镜提供了约84米的等效口径，是毫米/子毫米波段最灵敏的仪器。结合其高时间分辨率，为研究射电瞬态提供了一个独特的机会。我们以银河中心（GC）磁星PSR J1745$-$2900作为复杂磁涡流环境下磁星的实验室，并与FRBs进行关联。我们展示了相位模式下ALMA观察射电瞬态的潜力，并首次在非厘米波段探测到了一些源。我们使用ALMA归档数据研究GC磁星及2017 GMVA活动中的Sgr A*。我们对强度进行了搜索，并根据圆极化和线极化特性及到达相位对脉冲进行了分类。我们检测到八个能量在10$^{29}$ erg范围内的脉冲。我们构建了其累积能量分布并拟合了幂律，其中事件率与能量的关系为$R \propto E^{\gamma}$，结果为指数$\gamma = -2.4 \pm 0.1$。依据这个$\gamma$值和相位ALMA的系统属性，我们估计ALMA可以探测到160个已知脉冲星。对于重复FRBs，在其高活动窗口期间观察可以导致多个检测。我们预计ALMA较低频率的带有极化能力的波段，会在毫米波搜索脉冲星及研究涉及射电瞬态的复杂环境方面发挥先锋作用。

**Summary**:

- (1): 本文研究的背景是射电瞬态（如脉冲星和FRBs）在厘米波范围的探测受限于密集环境中的传播效应，这使得在这种环境中使用毫米波的观察显得尤为重要。

- (2): 过去的方法主要通过大型射电望远镜在厘米波范围内进行观测，然而在复杂环境中的传播效应（如散射和色散）严重影响探测效果。本文提出使用相位模式下的ALMA，凭借其较大的等效口径和高时间分辨率，绕过了这些问题，从而能够在毫米波范围内更有效地探测瞬态。

- (3): 本文的贡献在于展示了相位ALMA在毫米波段观察射电瞬态的潜力，并首次在非厘米波段成功探测到银河中心的磁星脉冲。

- (4): 研究方法包括分析ALMA归档数据，针对Sgr A*的观测进行强度搜索，并根据极化特性以及到达相位对脉冲进行分类。

- (5): 本文通过探测到八个能量在10$^{29}$ erg范围内的脉冲，实现了对GC磁星的累积能量分布构建，结果表明事件率与能量关系为$\gamma = -2.4 \pm 0.1$，这支持了ALMA在探测脉冲星和FRBs方面的目标。


## The ALMA-ATOMS survey: A sample of weak hot core candidates identified through line stacking
- **Url**: http://arxiv.org/abs/2504.06802v1
- **Authors**: ['Zi-Yang Li', 'Xunchuan Liu', 'Tie Liu', 'Sheng-Li Qin', 'Paul F. Goldsmith', 'Pablo García', 'Yaping Peng', 'Li Chen', 'Yunfan Jiao', 'Zhiping Kou', 'Chuanshou Li', 'Jiahang Zou', 'Mengyao Tang', 'Shanghuo Li', 'Meizhu Liu', 'Guido Garay', 'Fengwei Xu', 'Wenyu Jiao', 'Qiu-Yi Luo', 'Suinan Zhang', 'Qi-Lao Gu', 'Xiaofeng Mai', 'Yan-Kun Zhang', 'Jixiang Weng', 'Chang Won Lee', 'Patricio Sanhueza', 'Sami Dib', 'Swagat R. Das', 'Xindi Tang', 'Leonardo Bronfman', 'Prasanta Gorai', "Ken'ichi Tatematsu", 'Hong-Li Liu', 'Dongting Yang', 'Zhenying Zhang', 'Xianjin Shen']
- **Abstrat**: Hot cores represent critical astrophysical environments for high-mass star formation, distinguished by their rich spectra of organic molecular emission lines. We aim to utilize high-angular resolution molecular line data from ALMA to identify hot cores, with a particular focus on weak-emission candidates, and to provide one of the largest samples of hot core candidates. We propose to use spectral stacking and imaging techniques of complex organic molecules (COMs) in the ALMA-ATOMS survey, including line identification & weights, segmentation of line datacubes, resampling, stacking and normalization, moment 0 maps, and data analysis, to search for hot core candidates. We classify cores with dense emission of CH3OH and at least one molecule from the other six molecules as hot core candidates. In addition to the existing sample of 60 strong hot cores from the ALMA-ATOMS survey, we have detected 40 new weak candidates through stacking. All hot core candidates display compact emission from at least one of the other six COM species. For the strong sample, the stacking method provides molecular column density estimates that are consistent with previous fitting results. For the newly identified weak candidates, all species except CH3CHO show compact emission in the stacked image, which cannot be fully resolved spatially. These weak candidates exhibit column densities of COMs that are approximately one order of magnitude lower than those of the strong sample. The entire hot core sample, including the weak candidates, reveals tight correlations between the compact emission of CH3OH and other COM species, suggesting they may share a similar chemical environment for COMs, with CH3OH potentially acting as a precursor for other COMs. The molecular line stacking technique is used to identify hot core candidates in this work, leading to the identification of 40 new hot core candidates.


**Translated Abstract**: 

热核心是高质量恒星形成的关键天体环境，其特点是丰富的有机分子发射线谱。我们旨在利用来自阿塔卡马大型毫米/亚毫米阵列（ALMA）的高角分辨率分子线数据来识别热核心，特别关注弱发射候选者，并提供迄今为止最大的热核心候选样本之一。我们提议使用光谱叠加和成像技术来进行ALMA-ATOMS调查，搜索热核心候选者。我们将具有密集CH3OH发射和至少一种其他六种分子的核心分类为热核候选者。除了现有的60个强热核心样本外，我们还通过叠加检测到了40个新的弱候选者。所有热核心候选者在各种有机分子物种中至少显示出一种的紧凑发射。对于强样本，叠加方法提供的分子柱密度估计与先前的拟合结果一致。新识别的弱候选者中，除CH3CHO外，所有物种在叠加图像中均显示出紧凑发射，空间上无法完全解决。这些弱候选者的有机分子柱密度比强样本低一个量级。整个热核心样本显示出CH3OH与其他有机分子的紧密相关性，表明它们可能共享相似的化学环境，CH3OH可能充当其他有机分子的前驱体。我们使用的分子线叠加技术识别了40个新的热核心候选者。

**Summary**:

- (1): 文章的研究背景是热核心在高质量恒星形成中的重要性，但现有研究对大量热核心样本的统计分析仍较为缺乏。

- (2): 过去的方法主要是单一目标案例研究，其局限于灵敏度，导致统计研究偏差。与之不同的是，该研究采用光谱叠加的方法，更灵敏地识别弱热核心候选者，并有效解决了传统方法的局限性。

- (3): 文章的贡献在于通过分子线叠加技术识别了40个新的弱热核心候选者，并提供了一个更大的热核心候选样本。

- (4): 研究方法论包括利用ALMA的高角度分辨率分子线数据进行光谱叠加与成像，涉及多种复杂有机分子及其发射线的分类和分析。

- (5): 该方法在识别热核心候选者上表现出色，识别的弱候选者的有机分子柱密度约低一个量级。通过叠加技术的易用性和灵敏度，该方法支持其识别弱热核心候选者的目标。

