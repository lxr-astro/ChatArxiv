# blackhole
## Notes on Quasinormal Modes of charged de Sitter Blackholes from Quiver Gauge Theories
- **Url**: http://arxiv.org/abs/2412.18359v3
- **Authors**: ['Pujun Liu', 'Rui-Dong Zhu']
- **Abstrat**: We give the connection formulae for ordinary differential equations with 5 and 6 (and in principle can be generalized to more) regular singularities from the data of instanton partition functions of quiver gauge theories. We check the consistency of these connection formulae by numerically computing the quasinormal modes (QNMs) of Reissner-Nordstr\"om de Sitter (RN-dS) blackhole. Analytic expressions are obtained for all the families of QNMs, including the photon-sphere modes, dS modes, and near-extremal modes. We also argue that a similar method can be applied to the dS-Kerr-Newman blackhole.


**Translated Abstract**: 

我们给出了连接公式，适用于具有5个和6个（原则上可以推广到更多）正则奇点的常微分方程，这些公式来自quiver规范理论的瞬子分区函数数据。我们通过数值计算Reissner-Nordström de Sitter (RN-dS) 黑洞的准正常模式（QNMs）来检查这些连接公式的一致性。我们获得了所有QNMs家族的解析表达式，包括光子圈模式、dS模式和近临界模式。我们还论证了类似的方法可以应用于dS-Kerr-Newman黑洞。

**Summary**:

- (1): 本文研究的背景是准正常模式（QNMs）在黑洞背景下对场的衰减特征和黑洞几何扰动的表征，以及其在引力波合并事件和宇宙强禁闭问题中的重要性。

- (2): 现有的方法包括Leaver的连分式方法、WKB方法、同调法等，这些方法通常技术性强且计算量大。与之不同，本文提出利用quiver规范理论的瞬子分区函数来获得微分方程的连接公式，这一方法可以有效简化QNMs的数值计算，并提供系统的解析表达式。

- (3): 本文的贡献在于检查了具有5和6个正则奇点的常微分方程的连接公式，并提供了Reissner-Nordström de Sitter (RN-dS) 黑洞多种QNMs的解析表达式，包括光子圈模式和近临界模式。

- (4): 本文的研究方法包括数值计算和解析推导，利用quiver规范理论的连接公式，首先数值验证其有效性，然后推导出多种类型的QNMs的解析表达式。

- (5): 本文在Reissner-Nordström de Sitter (RN-dS) 黑洞上的任务是计算准正常模式，其性能表现为在不同类型的模式上获得一致的解析表达式，这一表现支持了其研究目标。


# M87
## Distance to M87 as the Mode of the Modulus Distribution
- **Url**: http://arxiv.org/abs/2504.06034v1
- **Authors**: ['Mariusz Tarnopolski']
- **Abstrat**: de Grijs and Bono (ApJS 2020, 246, 3) compiled a list of distances to M87 from the literature published in the last 100 years. They reported the arithmetic mean of the three most stable tracers (Cepheids, tip of the red giant branch, and surface brightness fluctuations). The arithmetic mean is one of the measures of central tendency of a distribution; others are the median and mode. The three do not align for asymmetric distributions, which is the case for the distance moduli $\mu_0$ to M87. I construct a kernel density distribution of the set of $\mu_0$ and estimate the recommended distance to M87 as its mode, obtaining $\mu_0 = \left(31.06~\pm~0.001\,\textrm{(statistical)}\,^{+0.04}_{-0.06}\,\textrm{(systematic)}\right)$~mag, corresponding to \linebreak $D=16.29^{+0.30}_{-0.45}$~Mpc, which yields uncertainties smaller than those associated with the mean and median.


**Translated Abstract**: 
de Grijs和Bono（ApJS 2020, 246, 3）汇编了过去100年文献中关于M87距离的列表。他们报告了三种最稳定测量工具（Cepheid周期变星、红巨星支尖、表面亮度波动）的算术平均值。算术平均是分布的集中趋势的一种测量方法；还有其他方法如中位数和众数。对于不对称分布，这三者并不一致，而M87的距离模数μ₀就是一种不对称分布。我构建了μ₀集合的核密度分布，并将推荐的M87距离估算为其众数，得到μ₀ = (31.06 ± 0.001（统计）^{+0.04}_{-0.06}（系统）) mag，对应的D = 16.29^{+0.30}_{-0.45} Mpc，这样的不确定性小于均值和中位数相关的不确定性。

**Summary**:

- (1): 本文的研究背景是近年来关于M87距离的测量，涉及使用各种稳定的测量工具（如Cepheid周期变星和红巨星支尖等）进行的数据汇编和分析。

- (2): 过去的方法主要依赖于算术平均和其他集中趋势测量（如中位数和众数），但对于不对称分布并不适用。提出的方法通过构建核密度分布采用众数作为距离估算，这样可以解决不对称分布带来的问题，且基于众数的建议方法是合理的。

- (3): 本文的贡献在于提出了一种新的距离估计方法，即通过众数来评估M87的距离，提供了更小的不确定性并补充了已有的距离测量结果。

- (4): 本文的研究方法是在已有的距离模数数据基础上构建核密度分布，利用众数来精确估算M87的距离。

- (5): 本文的方法在测量M87的距离时，获得了μ₀ = (31.06 ± 0.001) mag对应的D = 16.29^{+0.30}_{-0.45} Mpc的结果，性能优于传统方法，支持了作者的研究目标。


## Testing black holes in a perfect fluid dark matter environment using quasinormal modes
- **Url**: http://arxiv.org/abs/2504.05641v1
- **Authors**: ['Qun Tan', 'Dong Liu', 'Jie Liang', 'Zheng-Wen Long']
- **Abstrat**: This research explores the quasinormal modes (QNMs) characteristics of charged black holes in a perfect fluid dark matter (PFDM) environment. Based on the Event Horizon Telescope (EHT) observations of the M87* black hole shadow, we implemented necessary constraints on the parameter space($a/M$,$\lambda/M$).We found that for lower values of the magnetic charge parameter, the effective range of the PFDM parameter is approximately between -0.2 and 0, while as the magnetic charge parameter increases, this effective range gradually extends toward more negative values. Then through sixth-order WKB method and time-domain method, we systematically analyzed the quasinormal oscillation spectra under scalar field and electromagnetic field perturbations. The results reveal that: the magnetic charge $a$ and PFDM parameters $\lambda$ modulate the effective potential barrier of black hole spacetime, profoundly influencing the response frequency and energy dissipation characteristics of external perturbations. The consistently negative imaginary part of QNMs across the entire physical parameter domain substantiates the dynamical stability of the investigated system. Moreover, we discovered differences in the parameter variation sensitivity between scalar field and electromagnetic field perturbations, providing a theoretical basis for distinguishing different field disturbances. These results not only unveil the modulation mechanisms of electromagnetic interactions and dark matter distribution on black hole spacetime structures but also offer potential observational evidence for future gravitational wave detection and black hole environment identification.


**Translated Abstract**: 

本研究探讨了完美流体暗物质（PFDM）环境中带电黑洞的准正常模（QNMs）特性。基于事件视界望远镜（EHT）对M87*黑洞阴影的观测，我们在参数空间（a/M，λ/M）上实施了必要的约束。我们发现对于较低的磁荷参数值，PFDM参数的有效范围大约在-0.2到0之间，而随着磁荷参数的增加，这一有效范围逐渐向更负值扩展。通过六阶WKB方法和时域方法，我们系统性地分析了在标量场和电磁场扰动下的准正常振荡光谱。结果揭示，磁荷a和PFDM参数λ调制了黑洞时空的有效势阱，深刻影响了外部扰动的响应频率和能量耗散特性。在整个物理参数域中，QNMs的虚部始终为负，证明了研究系统的动态稳定性。此外，我们发现标量场和电磁场扰动之间的参数变化灵敏度存在差异，为区分不同场扰动提供了理论基础。这些结果不仅揭示了电磁相互作用和暗物质分布对黑洞时空结构的调制机制，也为未来的引力波探测和黑洞环境识别提供了潜在的观测证据。

**Summary**:

- (1): 本文的研究背景是通过事件视界望远镜（EHT）观测M87*黑洞，验证黑洞的性质以及在完美流体暗物质（PFDM）环境中黑洞的行为。

- (2): 过去的方法主要是利用WKB和其他数值技术来计算黑洞的准正常模。问题在于参数空间约束的不足和对扰动特性的敏感性差。本文提出的方法通过综合使用六阶WKB和时域方法，系统性地分析了黑洞的准正常模，改进了对扰动特性的灵敏度，并让结果在更广的物理参数域中有效。

- (3): 本文的贡献在于通过实验结果揭示了磁荷和PFDM参数如何调制黑洞时空的有效势，提供了关于黑洞动力稳定性和扰动特性的理论基础，并为未来引力波探测提供了可能的观察证据。

- (4): 本文采用的研究方法主要包括使用六阶WKB方法和时域方法来分析黑洞在标量场和电磁场扰动下的准正常振荡光谱，揭示了不同参数对黑洞时空的影响。

- (5): 本研究的任务是分析带电黑洞在PFDM环境下的准正常模行为，取得的结果表明，确定了系统的动态稳定性，并展示了参数变化对扰动敏感性的影响，这些结果支持了他们的研究目标。


# galaxy
## Constraining the [CII] luminosity function from the power spectrum of line intensity maps at redshift 3.6
- **Url**: http://arxiv.org/abs/2504.06266v1
- **Authors**: ['Elena Marcuzzo', 'Cristiano Porciani', 'Emilio Romano-Díaz', 'Prachi Khatri']
- **Abstrat**: Forthcoming measurements of the line-intensity-mapping power spectrum (PS) are expected to set precious constraints on several quantities of astrophysical and cosmological interest. Our study targets the [CII] luminosity function (LF) at high redshift, which is still highly uncertain, in particular at the faint end. As an example of future opportunities, we present forecasts for the Deep Spectroscopic Survey (DSS) that will be conducted with the Fred Young Submillimeter Telescope at $z \simeq 3.6$ and also make predictions for eventual $10\times$ wider and/or $\sqrt{10}\times$ more sensitive surveys. The halo-occupation properties of [CII] emitters in the MARIGOLD simulations provide us with the motivation to abundance match two versions of the ALPINE LF against the halo mass function. We employ the resulting luminosity-mass relation within the halo model to predict the expected PS signal and its uncertainty. Finally, we use Bayesian inference to analyse mock PS data and forecast what constraints could be achieved on the first two moments of the LF and on Schechter fits. Depending on the actual LF, the DSS will measure the clustering and shot-noise amplitudes of the PS with a signal-to-noise ratio of $\sim 3$ or higher. However, degeneracies with the bias parameter and redshift-space distortions make it unfeasible to extract the first moment of the LF. Even the widest and most sensitive survey we consider can only constrain it with a $50\%$ uncertainty. By jointly fitting the PS and the LF, we directly constrain Schechter-function parameters. We find that the normalisation and the cutoff luminosity are precisely and accurately measured while the faint-end slope remains highly uncertain (unless the true value approaches $-2$). Overall, increasing the survey sensitivity at fixed sky coverage yields greater improvements than covering a larger area at fixed sensitivity.


**Translated Abstract**: 

即将进行的线强度映射功率谱（PS）测量预计将对多个天体物理和宇宙学的关键量设定重要约束。我们的研究针对高红移下[CII]光度函数（LF），在低光度端仍然高度不确定。作为未来机会的示例，我们提出了针对在z ≃ 3.6的Fred Young亚毫米望远镜进行的深度光谱调查（DSS）的预测，同时也对未来可能的10倍更大范围和/或√10倍更敏感的调查进行了预测。MARIGOLD模拟中的[CII]发射体的光晕占据性质为我们提供了与光晕质量函数相结合的ALPINE LF的两个版本进行丰度匹配的动机。我们利用所得到的光度-质量关系在光晕模型中预测预期的PS信号及其不确定性。最后，我们使用贝叶斯推断分析模拟PS数据，预测能够对LF的前两个时刻和Schechter拟合施加的约束。根据实际的LF，DSS将以约3或更高的信噪比测量PS的聚类和噪声幅度。然而，由于与偏差参数及红移空间扭曲的简并，使得提取LF的第一个时刻变得不可行。即使是我们考虑的范围最广、最灵敏的调查，也只能以50%的不确定性进行约束。通过联合拟合PS和LF，我们直接约束了Schechter函数参数。我们发现归一化和截止光度得到了精确和准确的测量，而低光度端斜率仍然高度不确定（除非真实值接近-2）。总体而言，在固定天空覆盖的情况下，提高调查灵敏度所带来的改进大于在固定灵敏度下覆盖更大区域。

**Summary**:

- (1): 本文的研究背景是探索高红移下[CII]光度函数（LF），特别是在低光度端的高度不确定性。

- (2): 过去的方法主要依赖于传统的光度函数和密度分布模型，但这些方法在低光度区存在较大不确定性。本文方法通过结合光晕模型和MARIGOLD模拟，利用光晕占据性质进行丰度匹配，弥补了上述不足，并且有明确的动力学基础。

- (3): 本文的贡献在于为高红移下[CII]光度函数的测量提供了新的预测和约束，包括对参数的精确测量和不确定性评估，尤其是对Schechter函数参数的直接约束。

- (4): 本文提出了一种基于光晕模型和贝叶斯推断的研究方法，通过模拟PS数据来分析光度函数的特性并进行约束。

- (5): 方法针对光度函数的约束任务实现了信噪比约为3的测量，虽然存在约50%的不确定性，但整体结果表明方法能够满足研究目标。


## A systematic method to identify runaways from star clusters produced from single-binary interactions: A case study of M67
- **Url**: http://arxiv.org/abs/2504.06252v1
- **Authors**: ['A. Herrera-Urquieta', 'N. Leigh', 'J. Pinto', 'G. Díaz-Cerda', 'S. M. Grondin', 'J. J. Webb', 'R. Mathieu', 'T. Ryu', 'A. Geller', 'M. Kounkel', 'S. Toonen', 'M. Vilaxa-Campos']
- **Abstrat**: One hypothesis for runaway stars (RSs) is that they are ejected from star clusters with high velocities relative to the cluster center-of-mass motion. There are two competing mechanisms for their production: supernova-based ejections in binaries, where one companion explodes, leaves no remnant, and launches the other companion at the instantaneous orbital velocity, and the disintegration of triples (or higher-order multiples), which produces a recoiled runaway binary (RB) and an RS. We search for RS candidates using data from the Gaia DR3 survey with a focus on triple disintegration since in this case the product is always a binary and a single star that should be moving in opposite directions. We created a systematic methodology to look for candidate RS-RB runaway pairs produced from the disintegration of bound three-body systems formed from single-binary interactions based on momentum conservation and causality. The method we use is general and can be applied to any cluster with a 5D kinematic data set. We used our criteria to search for these pairs in a 150 pc circular field of view surrounding the open cluster M67, which we used as a benchmark cluster to test the robustness of our method. Our results reveal only one RS-RB pair that is consistent with all of our selection criteria out of an initial sample of $10^8$ pairs.


**Translated Abstract**: 

一种对于逃逸星（RSs）的假设是它们以相对于星团质心运动的高速度被从星团中弹射出来。其产生机制主要有两个：一种是基于超新星的弹射机制，即双星中一个伴星爆炸后不留下残留物，另一伴星以瞬时轨道速度被弹射；另一种则是三体系统（或更高阶复合体）的解体，产生一个反冲的逃逸双星（RB）和一个RS。我们利用Gaia DR3数据集搜索RS候选者，并侧重于三体解体，因为在此情况下，产物总是一个双星和一个单星，且它们应朝相反方向运动。我们创建了一种系统的方法，以寻找从因单双星相互作用而形成的绑定三体系统的解体中产生的RS-RB逃逸对，基于动量守恒和因果关系。我们所用的方法是通用的，可以应用于任何具有5D运动数据集的星团。我们依据标准在M67开放星团周围150 pc的视场中搜索这些对，并用其作为基准星团来测试我们方法的健壮性。我们的结果显示，在初始样本的10^8对中，仅有一对RS-RB逃逸对符合我们所有的选择标准。

**Summary**:

- (1): 本文研究背景为逃逸星（RSs）的形成机制，主要关注星团中由于超新星爆炸和三体解体而产生的逃逸星现象。

- (2): 以往的方法主要集中于单一机制的研究，缺乏系统探讨三体解体所导致的逃逸双星（RB）和RS的关联性。本文提出的方法基于动量守恒，通过综合考虑多个相互作用，解决了以往方法的局限性，具有良好的动机。

- (3): 本文的贡献在于提出了一种新的系统性方法，能够有效识别来自星团的RS-RB逃逸对，尤其是涉及三体系统的解体。

- (4): 研究方法运用动量守恒和因果关系的原则，构建标准，以在星团周围的运动数据集中进行广泛搜索。

- (5): 本文在M67开放星团的研究中，仅识别出一对符合标准的RS-RB逃逸对，尽管样本量巨大（10^8对），但这个结果显示出了方法的有效性，尽管数量较少，依然支撑了相关目标的实现。


## The Resolved Structure of a Low Metallicity Photodissociation Region
- **Url**: http://arxiv.org/abs/2504.06247v1
- **Authors**: ['Ilyse Y. Clark', 'Karin Sandstrom', 'Mark Wolfire', 'Alberto D. Bolatto', 'Jeremy Chastenet', 'Daniel A. Dale', 'Brandt A. L. Gaches', 'Simon C. O. Glover', 'Javier R. Goicoechea', 'Karl D. Gordon', 'Brent Groves', 'Lindsey Hands', 'Ralf Klessen', 'Ilse De Looze', 'J. D. T. Smith', 'Dries Van De Putte', 'Stefanie K. Walch']
- **Abstrat**: Photodissociation Regions (PDRs) are key to understanding the feedback processes that shape interstellar matter in galaxies. One important type of PDR is the interface between HII regions and molecular clouds, where far-ultraviolet (FUV) radiation from massive stars heats gas and dissociates molecules. Photochemical models predict that the C/CO transition occurs deeper in the PDR compared to the H/H2 transition in low-metallicity environments, increasing the extent of CO-dark H2 gas. This prediction has been difficult to test outside the Milky Way due to the lack of high spatial resolution observations tracing H2 and CO. This study examines a low-metallicity PDR in the N13 region of the Small Magellanic Cloud (SMC) where we spatially resolve the ionization front, the H2 dissociation front, and the C/CO transition using 12CO J=2-1, 3-2 and [CI] (1-0) observations from the Atacama Large Millimeter/sub-mm Array (ALMA) and near-infrared spectroscopy of H2 vibrational lines from the James Webb Space Telescope (JWST). Our analysis shows that the separation between the H/H2 and C/CO boundaries is approximately 0.043 +-0.013(stat.) +- 0.0036(syst.) pc (equivalent to 0."146 +- 0."042 (stat.) +-0."012 (syst.) at the SMC's distance of 62 kpc), defining the spatial extent of the CO-dark H2 region. Compared to our plane-parallel PDR models, we find that a constant pressure model matches the observed structure better than a constant density one. Overall, we find that the PDR model does well at predicting the extent of the CO-dark H2 layer in N13. This study represents the first resolved benchmark for low metallicity PDRs.


**Translated Abstract**: 

光解离区（PDR）对于理解塑造星系中的星际物质的反馈过程至关重要。重要的一种PDR是HII区和分子云之间的界面，其中来自大质量恒星的远紫外（FUV）辐射加热气体并解离分子。光化学模型预测在低金属含量环境中，C/CO转变发生在PDR的更深层，增加了CO暗态H2气体的范围。由于缺乏高空间分辨率观测以追踪H2和CO，这一预测在银河系以外的验证一直很困难。本研究考察了小麦哲伦云（SMC）N13区的低金属含量PDR，在这里我们利用阿塔卡马大型毫米/亚毫米阵列（ALMA）的12CO J=2-1、3-2和[CI](1-0)观测以及詹姆斯·韦布太空望远镜（JWST）的H2振动线近红外光谱，空间分辨了电离前沿、H2解离前沿和C/CO转变。我们的分析表明，H/H2和C/CO边界间的分离约为0.043 ± 0.013（统计）± 0.0036（系统）pc（相当于在SMC距离62 kpc处为0.′′146 ± 0.′′042（统计）±0.′′012（系统）），定义了CO暗态H2区域的空间范围。与我们的平面平行PDR模型相比，我们发现常数压力模型更好地匹配了观察到的结构，而不是常数密度模型。总体而言，我们发现PDR模型在预测N13中的CO暗态H2层的范围方面表现良好。本研究代表了低金属含量PDR的第一个解决基准。

**Summary**:

- (1): 本文的研究背景是光解离区（PDR）是理解塑造星系间物质反馈过程的关键，尤其是HII区与分子云之间界面的光解离现象。

- (2): 过去的方法主要依赖于低分辨率观测，导致难以验证光化学模型的预测，尤其是对于C/CO转变和H/H2转变的分隔情况。本研究通过高空间分辨率的ALMA和JWST观测，解决了无法追踪H2和CO的不足，从而实现了对低金属质PDR的深入探讨。

- (3): 本文的贡献在于首次高分辨率地解析了小麦哲伦云N13区域中的低金属质光解离区的结构，并确认了H/H2和C/CO边界之间的精确分离距离，为进一步研究光解离区提供了基准。

- (4): 本研究采用ALMA和JWST的结合观测，分析了光解离区的电离前沿、H2解离前沿和C/CO转变，建立了一个基于常数压力的PDR模型，以更好地匹配观测到的结构。

- (5): 本文任务是在N13区域解析H/H2和C/CO的分隔，采用的高分辨率观测性能取得了较好的适配，确实支持了他们对结构的目标预测。


## SOFIA/upGREAT imaging spectroscopy of the [C II] 158 um fine structure line toward the Sgr A region in the Galactic center
- **Url**: http://arxiv.org/abs/2504.06228v1
- **Authors**: ['A. I. Harris', 'R. Güsten', 'M. A. Requena-Torres', 'D. Riquelme', 'M. R. Morris', 'G. J. Stacey', 'J. Stutzki', 'Y. Okada', 'E. Chambers', 'M. Mertens', 'C. Fischer']
- **Abstrat**: We present SOFIA/upGREAT velocity-resolved spectral imaging and analysis of the 158 um [C II] spectral line toward the central 80 by 43\,pc region of the Central Molecular Zone of the Galaxy. The field we imaged with 14" (0.6 pc) spatial and 1 km/s spectral resolution contains the Circum-Nuclear Disk (CND) around the central black hole Sgr A*, the neighboring thermal Arched Filaments, the nonthermal filaments of the Radio Arc, and the three luminous central star clusters. [C II] traces emission from the CND's inner edge to material orbiting at a distance of approximately 6 pc. Its velocity field reveals no sign of inflowing material nor interaction with winds from the Sgr A East supernova remnant. Wide-field imaging of the Sgr A region shows multiple circular segments, including the thermal Arched Filaments, that are centered on a region that includes the Quintuplet cluster. We examine the possibility that the Arched Filaments and other large-scale arcs trace transient excitation events from supernova blast waves. Along the Arched Filaments, comparisons among far-IR fine structure lines show changes in ionization state over small scales and that high-excitation lines are systematically shifted in position from the other lines. These also point to transient fast winds that shocked on the surface of the Arches cloud to produce additional local UV radiation to excite the Arched Filaments on a cloud surface illuminated by UV from hot stars.


**Translated Abstract**: 我们展示了SOFIA/upGREAT在银河中心的中央分子区的80 x 43 pc区域内对158 µm [C II]谱线的速度分辨光谱成像和分析。我们以14″（0.6 pc）的空间和1 km/s的光谱分辨率成像的场域包含围绕中心黑洞Sgr A*的环核盘（CND）、邻近的热弧形细丝、非热射电弧的以下分支和三个人口稠密的中心星团。 [C II]波段发射从CND内边缘追踪到距离约6 pc的物质。其速度场未显示任何流入物质的迹象，也没有迹象表明与Sgr A East超新星遗迹的风相互作用。对Sgr A区域的宽场成像显示出多个圆形段落，包括热弧形细丝，且这些段落围绕着包括五重星团的区域展开。我们考察了弧形细丝和其他大规模弧线是否反映来自超新星爆炸波的瞬态激发事件。在弧形细丝上，比较远红外的细结构谱线显示出小尺度上的电离状态变化，同时高激发谱线的位置系统性偏移于其他谱线。这些也指向在面临热大质量星辐射的弧云表面冲击的瞬态快速风，从而产生局部紫外辐射来激发在此表面上的弧形细丝。

**Summary**:

- (1): 本文研究银河中心的结构和动力学，特别关注与中央黑洞Sgr A*和周围区域关联的物理特征和气体运动。

- (2): 过去的研究方法主要依赖于较低分辨率的测量，不能有效揭示复杂的速度场和相互作用。提议的方法通过SOFIA/upGREAT进行高分辨率（14″和1 km/s）的光谱成像，克服了过去研究在细节捕捉上的不足。这一方法能提供更清晰的[ C II ]谱线图景，有助于解析银河中心的动量和结构。

- (3): 本文的贡献在于提供了一个关于[ C II ]细结构线的新视角，使得研究者能够详细分析了银河中心的物质分布、动态和激发过程。

- (4): 本文采用SOFIA/upGREAT进行速度解析的光谱成像，结合先前的动量模型，获取并分析了[ C II ]发射与吸收特征，以揭示银河中心的物理状态和运动特征。

- (5): 本文的方法在追踪银河中心的[ C II ]发射和速度场方面表现出色，能支持作者的目标，即深入理解该区域的物理和动力学特性。


## Optimal Follow-Up of Gravitational-Wave Events with the UltraViolet EXplorer (UVEX)
- **Url**: http://arxiv.org/abs/2502.17560v2
- **Authors**: ['Leo P. Singer', 'Alexander W. Criswell', 'Sydney C. Leggio', 'R. Weizmann Kiendrebeogo', 'Michael W. Coughlin', 'Hannah P. Earnshaw', 'Suvi Gezari', 'Brian W. Grefenstette', 'Fiona A. Harrison', 'Mansi M. Kasliwal', 'Brett M. Morris', 'Erik Tollerud', 'S. Bradley Cenko']
- **Abstrat**: The UltraViolet EXplorer (UVEX) is a wide-field ultraviolet space telescope selected as a NASA Medium-Class Explorer (MIDEX) mission for launch in 2030. UVEX will undertake deep, cadenced surveys of the entire sky to probe low mass galaxies and explore the ultraviolet (UV) time-domain sky, and it will carry the first rapidly deployable UV spectroscopic capability for a broad range of science applications. One of UVEX's prime objectives is to follow up gravitational wave (GW) binary neutron star mergers as targets of opportunity (ToOs), rapidly scanning across their localization regions to search for their kilonova (KN) counterparts. Early-time multiband ultraviolet light curves of KNe are key to explaining the interplay between jet and ejecta in binary neutron star mergers. Owing to high Galactic extinction in the ultraviolet and the variation of GW distance estimates over the sky, the sensitivity to kilonovae can vary significantly across the GW localization and even across the footprint of a single image given UVEX's large field of view. Good ToO observing strategies to trade off between area and depth are neither simple nor obvious. We present an optimal strategy for GW follow-up with UVEX in which exposure time is adjusted dynamically for each field individually to maximize the overall probability of detection. We model the scheduling problem using the expressive and powerful mathematical framework of mixed integer linear programming (MILP), and employ a state-of-the-art MILP solver to automatically generate observing plan timelines that achieve high probabilities of kilonova detection. We have implemented this strategy in an open-source astronomical scheduling software package called the Multi-Mission Multi-Messenger Observation Planning Toolkit (M4OPT), on GitHub at https://github.com/m4opt/m4opt.


**Translated Abstract**: 

超紫外探测器（UltraViolet EXplorer，UVEX）是一颗广域紫外空间望远镜，已被选为美国国家航空航天局（NASA）中型探测器（MIDEX）任务，计划于2030年发射。UVEX将进行全天空的深层、定期测量，以探测低质量星系并研究紫外（UV）时间域，且将携带首个快速部署的紫外光谱能力，以用于多种科学应用。UVEX的主要目标之一是跟进引力波（GW）双中子星合并事件，作为机会目标（ToOs），快速扫描其定位区域以搜索其千新星（kilonova，KN）对应体。早期多波段紫外光曲线对于解释双中子星合并中喷流与排放物之间的相互作用至关重要。由于天银河系中紫外光的高度消光以及GW距离估计在天空中的变化，千新星的探测灵敏度可能在GW定位区域内显著变化，甚至在给定UVEX的大视场图像的单一拍摄范围内也会变化。良好的机会目标观察策略在区域与深度之间的权衡既不简单也不明显。我们提出了一种使用UVEX进行GW跟进的最佳策略，根据每个场的情况动态调整曝光时间，以最大化总体探测概率。我们使用混合整数线性规划（MILP）的强大数学框架对调度问题进行了建模，并使用先进的MILP求解器自动生成观察计划时间线，以实现千新星高概率的探测。我们已在名为多任务多信使观测计划工具包（Multi-Mission Multi-Messenger Observation Planning Toolkit，M4OPT）的开源天文学调度软件包中实现了这一策略，代码托管在GitHub上。

**Summary**:

- (1): 本文的研究背景是引力波（GW）双中子星合并事件的探测及其千新星（KN）对应体的追踪。

- (2): 以往的方法未能有效平衡观察区域与深度的权衡，且对于高银河消光区域的千新星探测受到限制。本文提出的动态调整每个场曝光时间的方法，针对每个场地最大化探测概率，有效解决了上述问题，具有良好的动机。

- (3): 本文的贡献在于提出了一种新的最佳跟进策略，能够在GW事件探测中实现更高的千新星探测概率。

- (4): 本文研究采用混合整数线性规划（MILP）模型对调度问题进行建模，并利用高效的MILP求解器生成观测计划。

- (5): 本文方法在千新星探测任务中实现了高的探测概率，支持了通过UVEX对引力波事件的跟进目标。


## Impact of MvdW Equation of State and Neutrino Mass on r and s Process Heavy Element Nucleosynthesis in Spiral, Elliptical and Dwarf Galactic Environments and Kilonovae Events
- **Url**: http://arxiv.org/abs/2504.06191v1
- **Authors**: ['Keith Andrew', 'Eric Steinfelds', 'Kristopher Andrew']
- **Abstrat**: We present an analysis of heavy element production with massive neutrinos in galaxies of varying types (spiral, elliptical, and dwarf) and kilonovae events by incorporating a Multicomponent van der Waals (MvdW) equation of state (EoS) for the opacity functions. This EoS is applied to derive opacities and calculate the yields of isotopes formed in r-process and s-process nucleosynthesis, with and without the influence of neutrino masses or oscillations. We look at both the lanthanide and actinide sequences using the MvdW parameters that involve the interaction strength and excluded volume effects. Our results reflect the characteristic differences found in r and s processes in the synthesis and long-term evolution of isotopes from the U, Th, and Sr chain across galactic environments. The inclusion of neutrino masses enhances the neutron-to-proton ratio, favoring heavier r-process isotopes and altering the overall galactic yields by cross section suppression. These findings offer insights into the interplay of nuclear physics and astrophysical environments, highlighting the sensitivity of nucleosynthetic pathways to EoS modifications and neutrino physics. We compare these results to metallicity profiles of similar models: the Galactic Leaky Box, the Galactic Inflow, and the Galactic Closed Box models and to the kilonova event GW170781.


**Translated Abstract**: 

我们呈现了对不同类型的星系（螺旋星系、椭圆星系和矮星系）及类似于GW170817的千新星事件中，重元素生产的分析，使用了包含质量中微子的多组分范德瓦尔斯（MvdW）状态方程（EoS）来定义不透明度函数。应用该状态方程导出不透明度并计算在快速（r-process）和慢速（s-process）核合成中形成的同位素产量，探讨了中微子质量或振荡的影响。我们研究了使用涉及相互作用强度和排斥体积效应的MvdW参数的镧系元素和锕系元素序列。结果反映了在不同星系环境中，U、Th和Sr链的同位素合成和长期演化中，r和s过程的特征差异。中微子质量的引入增强了中子与质子的比率，偏向较重的r过程同位素，并通过截面抑制改变了整体银河产量。这些发现提供了核物理与天体物理环境相互作用的见解，强调了核合成途径对EoS修正和中微子物理的敏感性。我们将这些结果与类似模型的金属丰度剖面进行比较：银河泄漏箱模型、银河流入模型和银河封闭箱模型，以及千新星事件GW170781进行比较。

**Summary**:

- (1): 本文研究重元素在不同类型星系（螺旋、椭圆和矮星系）及千新星事件中的生产，特别关注包括中微子质量的影响。

- (2): 过去的方法主要探讨已知的核合成过程，未能精确考虑中微子的质量和振荡影响；本文提出的MvdW状态方程能很好地整合这些因素，解决了传统方法对重元素生成缺乏全面性的局限，具有良好的动机。

- (3): 本文的贡献在于揭示了中微子质量和MvdW状态方程在重元素合成过程中的作用，提供了金属丰度模型的新视角。

- (4): 本文的方法论包括使用MvdW状态方程来计算不透明度及同位素产量，分析r和s过程的不同，同步考虑中微子的质量影响。

- (5): 该方法在理解不同星系环境中重元素合成的机制上表现出色，支持了本文的研究目标，特别是在解释r和s过程同位素合成的结果方面。


## Primordial Features in light of the Effective Field Theory of Large Scale Structure
- **Url**: http://arxiv.org/abs/2504.06183v1
- **Authors**: ['Rodrigo Calderon', 'Theo Simon', 'Arman Shafieloo', 'Dhiraj Kumar Hazra']
- **Abstrat**: While the simplest inflationary models predict a power-law form of the primordial power spectrum (PPS), various UV complete scenarios predict features on top of the standard power law that leave characteristic imprints in the late-time distribution of matter, encoded in the galaxy power spectrum. In this work, we assess the validity of the Effective Field Theory of Large Scale Structure (EFTofLSS) and the IR-resummation scheme of PyBird in the context of primordial (oscillatory) features. We find an excellent agreement at the level of the matter power spectrum between N-body simulations and the one-loop EFT predictions, for models commonly studied in the literature. We then apply the EFTofLSS to the galaxy power spectrum measurements from BOSS LRG and eBOSS QSO to constrain specific global and local features in the PPS. We demonstrate that while such features can improve the fit to cosmic microwave background (CMB) data, they may result in a poorer fit to clustering measurements at low redshift. The resulting constraints on the amplitude of the primordial oscillations are competitive with those obtained from CMB data, despite the well-known damping of oscillations due to non-linear structure formation processes. For the first time in this context, we jointly analyze the galaxy power spectrum (monopole and quadrupole) in combination with Planck CMB data to derive strong constraints on the amplitude of primordial features. This work highlights the EFTofLSS as a powerful tool for testing early universe scenarios on scales that complement CMB observations.


**Translated Abstract**: 

虽然最简单的膨胀模型预测原始功率谱（PPS）呈幂律形式，但各种紫外完备的场景预测在标准幂律上方存在特征，这些特征在后期物质分布中留下特征性印记，编码在星系功率谱中。我们评估了大型结构的有效场论（EFTofLSS）和PyBird的红外重整化方案在原始（振荡）特征方面的有效性。我们发现，对于文献中常见的模型，N体模拟与一循环EFT预测在物质功率谱水平上具有良好的一致性。然后，我们将EFTofLSS应用于来自BOSS LRG和eBOSS QSO的星系功率谱测量，以约束PPS中的特定全球和局部特征。我们证明，尽管这些特征可以改善对宇宙微波背景（CMB）数据的拟合，但在低红移下的聚类测量可能会导致较差的拟合。通过考虑非线性结构形成过程导致的振荡减弱，得到的对原始振荡幅度的约束与CMB数据获得的结果具有竞争力。首次在这个背景中，我们联合作用星系功率谱（单极和四极）与Planck CMB数据，得出原始特征幅度的强约束。这项工作突出了EFTofLSS作为在补充CMB观测的尺度上检验早期宇宙场景的强大工具。

**Summary**:

- (1): 本文研究的背景是膨胀模型预测的原始功率谱的主要特征，以及这些特征对后期物质分布的影响，特别是在星系聚类中的体现。

- (2): 过去的方法主要依赖于线性扰动理论，往往无法充分预测宇宙结构形成中的非线性效应，导致对原始特征的损失。本文提出的EFTofLSS方法能更好地处理这些非线性效应，并结合红外重整化技术，可以较准确地描述宇宙微波背景和大型结构的特征。

- (3): 本文的贡献在于首次将EFTofLSS应用于星系功率谱的数据分析，并且联如何CMB数据共同约束原始特征幅度，为理论模型提供了更强的验证依据。

- (4): 本文采用的研究方法是使用EFTofLSS结合MCMC分析，对BOSS和eBOSS的星系功率谱进行模型拟合和约束。

- (5): 通过对PPS的不同特征进行约束，所提出的方法在CMB和LSS中显示出竞争力的结果，表明其能够有效支持早期宇宙模型的验证目标。


## On Soft Clustering For Correlation Estimators: Model Uncertainty, Differentiability, and Surrogates
- **Url**: http://arxiv.org/abs/2504.06174v1
- **Authors**: ['Edward Berman', 'Sneh Pandya', 'Jacqueline McCleary', 'Marko Shuntov', 'Caitlin Casey', 'Nicole Drakos', 'Andreas Faisst', 'Steven Gillman', 'Ghassem Gozaliasl', 'Natalie Hogg', 'Jeyhan Kartaltepe', 'Anton Koekemoer', 'Wilfried Mercier', 'Diana Scognamiglio', 'COSMOS-Web', ':', 'The JWST Cosmic Origins Survey']
- **Abstrat**: Properly estimating correlations between objects at different spatial scales necessitates $\mathcal{O}(n^2)$ distance calculations. For this reason, most widely adopted packages for estimating correlations use clustering algorithms to approximate local trends. However, methods for quantifying the error introduced by this clustering have been understudied. In response, we present an algorithm for estimating correlations that is probabilistic in the way that it clusters objects, enabling us to quantify the uncertainty caused by clustering simply through model inference. These soft clustering assignments enable correlation estimators that are theoretically differentiable with respect to their input catalogs. Thus, we also build a theoretical framework for differentiable correlation functions and describe their utility in comparison to existing surrogate models. Notably, we find that repeated normalization and distance function calls slow gradient calculations and that sparse Jacobians destabilize precision, pointing towards either approximate or surrogate methods as a necessary solution to exact gradients from correlation functions. To that end, we close with a discussion of surrogate models as proxies for correlation functions. We provide an example that demonstrates the efficacy of surrogate models to enable gradient-based optimization of astrophysical model parameters, successfully minimizing a correlation function output. Our numerical experiments cover science cases across cosmology, from point spread function (PSF) modeling efforts to gravitational simulations to galaxy intrinsic alignment (IA).


**Translated Abstract**: 

在不同空间尺度上正确估计物体之间的相关性需要进行$\mathcal{O}(n^2)$的距离计算。因此，大多数广泛采用的相关性估计软件包使用聚类算法来近似局部趋势。然而，量化这种聚类引入的误差的方法研究不够充分。对此，我们提出了一种以概率方式聚类物体的相关性估计算法，使我们能够通过模型推理量化聚类引起的不确定性。这些软聚类分配使得相关性估计器在理论上可以对其输入目录进行可微分。因此，我们还构建了可微分相关函数的理论框架，并描述了它们与现有代理模型的效用。值得注意的是，我们发现重复的归一化和距离函数调用会减慢梯度计算，并且稀疏雅可比矩阵会不稳定精度，这表明近似或代理方法是从相关函数获得精确梯度的必要解决方案。因此，我们以讨论代理模型作为相关函数的代理结束。我们提供了一个示例，展示了代理模型在实现天体物理模型参数的基于梯度的优化中有效性，成功最小化了相关函数输出。我们的数值实验覆盖了多个宇宙学科学案例，从点扩散函数（PSF）建模工作到引力模拟，再到星系内在排列（IA）。

**Summary**:

- (1): 本文的研究背景涉及在宇宙学中准确估计不同空间尺度物体之间的相关性，这通常需要大规模的距离计算。

- (2): 过去的方法通常依赖于聚类算法来简化计算，但这些方法忽视了聚类带来的模糊不确定性。新提出的方法采用概率聚类，使得在推理过程中能够量化这种不确定性，解决了传统方法中的问题，具有较强的必要性。

- (3): 本文的贡献在于提出了一种新的可微分相关性估计方法，并建立了理论框架，展示了如何通过概率聚类量化不确定性，并对比现有的代理模型。

- (4): 本文的方法论涉及将对象聚类分配为概率性的，建立可微分相关函数的理论框架，并通过实验验证其有效性。

- (5): 本文在多种宇宙学任务中（如PSF建模和引力模拟）进行了数值实验，成功实现了相关函数输出的最小化，表明其性能达到了研究目标。


## Investigating Embedded Structures and Gas Kinematics in the IRDC Hosting Bubble N59-North
- **Url**: http://arxiv.org/abs/2504.06170v1
- **Authors**: ['A. K. Maity', 'L. K. Dewangan', 'O. R. Jadhav', 'Saurabh Sharma', 'Ram Kesh Yadav', 'Y. Fukui', 'H. Sano', 'T. Inoue']
- **Abstrat**: We present a multi-wavelength study of an extended area hosting the bubble N59-North to explore the physical processes driving massive star formation (MSF). The Spitzer 8 $\mu$m image reveals an elongated/filamentary infrared-dark cloud (length $\sim$28 pc) associated with N59-North, which contains several protostars and seven ATLASGAL dust clumps at the same distance. The existence of this filament is confirmed through $^{13}$CO and NH$_3$ molecular line data in a velocity range of [95, 106] km s$^{-1}$. All dust clumps satisfy Kauffmann & Pillai's condition for MSF. Using Spitzer 8 $\mu$m image, a new embedded hub-filament system candidate (C-HFS) is investigated toward the ATLASGAL clump, located near the filament's central region. MeerKAT 1.3 GHz continuum emission, detected for the first time toward C-HFS, reveals an ultracompact HII region driven by a B2-type star, suggesting an early stage of HFS with minimal feedback from the young massive star. The comparison of the position-velocity (PV) and position-position-velocity (PPV) diagrams with existing theoretical models suggests that rotation, central collapse, and end-dominated collapse are not responsible for the observed gas motion in the filament. The PPV diagram indicates the expansion of N59-North by revealing blue- and red-shifted gas velocities at the edge of the bubble. Based on comparisons with magnetohydrodynamic simulations, this study suggests that cloud-cloud collision (CCC) led to the formation of the filament, likely giving it a conical structure with gas converging toward its central region, where C-HFS is located. Overall, the study supports multi-scale filamentary mass accretion for MSF, likely triggered by CCC.


**Translated Abstract**: 

我们呈现了一项多波长研究，探索了一个包含 N59-North 泡沫的扩展区域，以探讨驱动大质量恒星形成（MSF）的物理过程。Spitzer 8 µm 图像揭示了与 N59-North 相关的细长/长丝状红外暗云（长度约 28 pc），其中包含几个原恒星和七个 ATLASGAL 尘埃团块。通过 $^{13}$CO 和 NH$_3$ 分子线数据在 [95, 106] km s$^{-1}$ 的速度范围内确认了该长丝的存在。所有尘埃团块都满足 Kauffmann & Pillai 的 MSF 条件。利用 Spitzer 8 µm 图像研究了位于长丝中央区域附近的 ATLASGAL 团块的嵌入式中心-长丝系统候选者（C-HFS）。首次检测到 MeerKAT 1.3 GHz 连续波辐射，显示 C-HFS 驱动着一个由 B2 型恒星驱动的超紧凑 HII 区，这表明这个早期阶段的 HFS 对年轻大质量恒星的反馈影响较小。位置-速度（PV）和位置-位置-速度（PPV）图与现有理论模型的比较表明，旋转、中心坍缩和末端主导的坍缩并不导致观察到的长丝中的气体运动。PPV 图通过揭示泡沫边缘的蓝移和红移气体速度，指示 N59-North 的扩张。基于与磁流体动力学模拟的比较，本研究建议云-云碰撞（CCC）导致长丝的形成，可能赋予其一个锥形结构，气体向其中央区域汇聚，C-HFS 就位于该处。总体而言，本研究支持多尺度的长丝质量汇聚用于大质量恒星形成，可能由 CCC 触发。

**Summary**:

- (1): 本文的研究背景是探索大质量恒星形成（MSF）过程的物理机制，尤其关注泡沫 N59-North 中的嵌入结构和气体动力学。

- (2): 以往的研究主要依赖于单波长的观测方法，缺乏对长丝形成环境的综合理解。以往方法不能有效揭示气体运动的驱动机制和形成过程，而本文采用多波长观测手段，从多个角度深入分析，有助于克服这些不足。

- (3): 本文的贡献在于首次揭示了 N59-North 中的长丝结构及其关联的超紧凑 HII 区，并提出了云-云碰撞（CCC）在长丝形成中的重要作用，丰富了对大质量恒星形成的理解。

- (4): 本文采用了多波长的数据集，结合 $^{13}$CO 和 NH$_3$ 分子线数据进行详细的动力学分析，以探讨 IRDC 中的物理环境和恒星形成过程。

- (5): 本文的方法在揭示云-云碰撞与长丝形成之间的联系方面进行了有效的分析，支持了研究目标，并为进一步理解大质量恒星的形成过程提供了有力的证据。


## The low multipoles in the Pantheon+SH0ES data
- **Url**: http://arxiv.org/abs/2403.17741v2
- **Authors**: ['Francesco Sorrenti', 'Ruth Durrer', 'Martin Kunz']
- **Abstrat**: In previous work we have shown that the dipole in the low redshift supernovae of the Pantheon+SH0ES data does not agree with the one inferred from the velocity of the solar system as obtained from CMB data. We interpreted this as the presence of significant bulk velocities. In this paper we study the monopole, dipole and quadrupole in the Pantheon+SH0ES data. We find that in addition to the dipole also both, the monopole and the quadrupole are detected with high significance. They are of similar amplitudes as the bulk flow. While the monopole is only significant at very low redshift, the quadrupole even increases with redshift.


**Translated Abstract**: 

在之前的工作中，我们已显示出低红移的Pantheon+SH0ES超新星数据中的偶极与根据CMB数据推测的太阳系速度不一致。我们将其解释为存在显著的体积速度。本文研究了Pantheon+SH0ES数据中的单极、偶极和四极分量。我们发现除了偶极外，单极和四极也以高显著性被检测到。这些分量的幅度与体积流相似。尽管单极仅在非常低红移下显著，但四极甚至随着红移的增加而增加。

**Summary**:

- (1): 本文研究背景为宇宙中的大规模结构均匀性和各向同性假设, 特别是关于CMB对太阳系运动的影响以及其在超新星数据中的不一致性。

- (2): 过去的方法主要集中在对超新星数据中仅分析偶极，并已发现其与CMB推测的速度不一致。现有方法的问题在于未考虑其他多极成分。本文提出的方法包括单极与四极分析，这解决了对整体动力学理解的局限性，并得到良好动机。

- (3): 本文的贡献在于首次同时检测到Pantheon+SH0ES数据中的单极和四极，表明其与体积流有类似幅度，为理解宇宙大尺度结构提供了新视角。

- (4): 本文采用的研究方法包括对低红移超新星数据的单极、偶极和四极分量的详细分析，结合了体积速度的影响，以评估多重立体结构的存在。

- (5): 本文的方法在检测多极成分及其幅度上取得了显著的成果，四极的增加随着红移的增加而增强，支持了其探讨大尺度宇宙结构的目标。


## Constraints on dark energy and modified gravity from the BOSS Full-Shape and DESI BAO data
- **Url**: http://arxiv.org/abs/2409.08971v2
- **Authors**: ['Petter Taule', 'Marco Marinucci', 'Giorgia Biselli', 'Massimo Pietroni', 'Filippo Vernizzi']
- **Abstrat**: We constrain dark energy and modified gravity within the effective field theory of dark energy framework using the full-shape BOSS galaxy power spectrum, combined with Planck cosmic microwave background (CMB) data and recent baryon acoustic oscillations (BAO) measurements from DESI. Specifically, we focus on a varying braiding parameter $\alpha_{\rm B}$, a running of the ``effective'' Planck mass $\alpha_{\rm M}$, and a constant dark energy equation of state $w$. The analysis is performed with two of these parameters at a time, including all the other standard cosmological parameters and marginalizing over bias and nuisance parameters. The full-shape galaxy power spectrum is modeled using the effective field theory of large-scale structure up to 1-loop order in perturbation theory. We find that the CMB data is most sensitive to $\alpha_{\rm B}$, and that adding large-scale structure information only slightly changes the parameter constraints. However, the large-scale structure data significantly improve the bounds on $\alpha_{\rm M}$ and $w$ by a factor of two. This improvement is driven by background information contained in the BAO, which breaks the degeneracy with $H_0$ in the CMB. We confirm this by comparing the BOSS full-shape information with BOSS BAO, finding no significant differences. This is likely to change with future high-precision full-shape data from Euclid and DESI however, to which the pipeline developed here is immediately applicable.


**Translated Abstract**: 

我们利用BOSS星系功率谱的全形数据，结合Planck宇宙微波背景（CMB）数据和来自DESI的最新重子声学振荡（BAO）测量，对暗能量和修改重力进行了约束。具体而言，我们关注一个变化的编织参数αB，一个“有效”的Planck质量的变化参数αM，以及一个恒定的暗能量状态方程w。分析是针对其中两个参数进行的，同时考虑所有其他标准宇宙学参数，并对偏差和干扰参数进行边缘化。全形星系功率谱的建模使用了有效大尺度结构的场论（EFTofLSS），最高到一阶微扰理论。我们发现CMB数据对αB最为敏感，而添加大尺度结构信息仅略微改变参数约束。然而，大尺度结构数据显著改善了对αM和w的限制，提升了约束程度约两倍。这种改进源于BAO中包含的背景信息，它打破了CMB中与H0的解耦。通过比较BOSS全形信息和BOSS BAO，我们发现它们之间没有显著差异。然而，未来来自Euclid和DESI的高精度全形数据很可能会改变这一点，所开发的管道立即适用于这些数据。

**Summary**:

- (1): 本文研究的背景是测试广义相对论（GR）在宇宙尺度上的有效性，以及揭示暗能量的性质，这些都是宇宙学中的重大目标。

- (2): 过去的方法主要依赖于下述观测数据：CMB、BAO、fσ8、ISW-LSS交叉相关和弱透镜数据。这些方法面临的问题是缺乏能够有效约束超越ΛCDM模型的通用框架。本文采用的EFTofDE模型独立于特定理论先验，能够全面描述暗能量及其对重力的修改，使用这种框架能够在没有理论假设的情况下进行分析。

- (3): 本文的贡献在于利用BOSS星系功率谱全形数据，与DESI和Planck数据结合，对暗能量和修改重力进行更精确的约束，并展示了全形数据相对于BAO数据的额外约束能力。

- (4): 本文提出的研究方法是结合BOSS的全形星系功率谱与CMB和BAO数据，利用有效场论的框架对星系的演化进行1-loop级建模。此外，还提出了新的参数化策略，以处理与H0的解耦问题。

- (5): 通过在本文的框架下进行的数据分析，本文在约束αM和w等参数上实现了显著的表现，所取得的性能支持了揭示暗能量和修改重力特性的目标。


## Dimming Starlight with Dark Compact Objects
- **Url**: http://arxiv.org/abs/2409.08322v2
- **Authors**: ['Joseph Bramante', 'Melissa D. Diamond', 'J. Leo Kim']
- **Abstrat**: We demonstrate a new technique to search for dark compact objects. When dark matter comprising a dark compact object interacts with photons, the compact object can disperse light traveling though it. As these objects pass between Earth and a distant star, they act as "lampshades" that dim the star. We examine how dimming effects from clumps of dark matter in the Galaxy could be searched for in microlensing surveys, which measure the brightness of stars as a function of time. Using the EROS-2 and OGLE surveys, we show that a dimming analysis of existing data can be used to constrain dark sectors, and could be used to discover dark matter in compact objects.


**Translated Abstract**:

我们演示了一种新的技术来搜索暗紧凑物体。当由暗物质组成的暗紧凑物体与光子相互作用时，紧凑物体可以使通过的光线发生散射。当这些物体在地球与遥远恒星之间经过时，它们像“灯罩”一样使恒星的光亮度变暗。我们检查了在银河中暗物质的团块如何通过微透镜观测进行搜索，这些观测测量恒星亮度随时间的变化。利用EROS-2和OGLE观测，我们展示了现有数据的暗淡分析如何用来约束暗物质领域，并可能用于发现暗物质中的紧凑物体。

**Summary**:

- (1): 本文的研究背景是关于原始黑洞（PBHs）和大质量紧凑光环物体（MACHOs）作为暗物质候选者的研究，特别是在寻找超越标准模型（BSM）物理的背景下。

- (2): 过去的方法主要集中在微透镜搜索，但这些方法通常针对极为紧凑和重的物体，忽视了较轻或扩散的物体。本文提出的方法通过搜索暗物质散射引起的光线暗淡，从而扩大了对这些目标的探测能力，解决了传统方法不足以探测较松散物体的问题。

- (3): 本文的贡献在于提出了一种新的暗物质搜索技术，利用光线暗淡现象和现有微透镜数据来约束暗物质模型，扩大了对暗物质物体的探测范围。

- (4): 本文研究的方法论包括使用微透镜观测中的亮度变化数据，定义暗淡事件为亮度下降，并通过调整爱因斯坦半径为物体的实际物理半径，进行数据分析。

- (5): 本文的任务是通过现有的EROS-2和OGLE数据分析实现对暗物质的约束。所提出的方法在识别暗淡事件方面具有竞争力，能够支持作者对压制暗物质模型的目标。


## Photometric segregation of dwarf and giant FGK stars using the SVO Filter Profile Service and photometric tools
- **Url**: http://arxiv.org/abs/2406.03310v4
- **Authors**: ['Carlos Rodrigo', 'Patricia Cruz', 'John F. Aguilar', 'Alba Aller', 'Enrique Solano', 'Maria Cruz Galvez-Ortiz', 'Francisco Jimenez-Esteban', 'Pedro Mas-Buitrago', 'Amelia Bayo', 'Miriam Cortes-Contreras', 'Raquel Murillo-Ojeda', 'Silvia Bonoli', 'Javier Cenarro', 'Renato Dupke', 'Carlos Lopez-Sanjuan', 'Antonio Marin-Franch', 'Claudia Mendes de Oliveira', 'Mariano Moles', 'Keith Taylor', 'Jesus Varela', 'Hector Vazquez Ramio']
- **Abstrat**: This paper is focused on the segregation of FGK dwarf and giant stars through narrow-band photometric data using the Spanish Virtual Observatory (SVO) Filter Profile Service and associated photometric tools. We selected spectra from the MILES, STELIB, and ELODIE stellar libraries, and used SVO photometric tools to derive the synthetic photometry in 15 J-PAS narrow filters, which were especially selected to cover spectral features sensitive to gravity changes. Using machine-learning techniques as the Gaussian mixture model and the support vector machine, we defined several criteria based on J-PAS colours to discriminate between dwarf and giant stars. We selected five colour-colour diagrams that presented the most promising separation between both samples. Our results show an overall accuracy in the studied sample of $\sim$0.97 for FGK stars, although a dependence on the luminosity type and the stellar effective temperature was found. We also defined a colour-temperature relation for dwarf stars with effective temperatures between 4\,000 and 7\,000\,K, which allows one to estimate the stellar effective temperature from four J-PAS filters ($J0450$, $J0510$, $J0550$, and $J0620$). Additionally, we extended the study to M-type giant and dwarf stars, achieving a similar accuracy to that for FGK stars.


**Translated Abstract**: 本文聚焦于通过使用西班牙虚拟天文台（SVO）过滤器特征服务和相关光度工具，利用窄带光度数据对FGK矮星和巨星进行分隔。我们从MILES、STELIB和ELODIE恒星库中选择光谱，使用SVO光度工具生成15个J-PAS窄带过滤器的合成光度，这些过滤器特别选择以覆盖对重力变化敏感的光谱特征。通过机器学习技术，如高斯混合模型和支持向量机，我们定义了几个基于J-PAS颜色的标准，以区分矮星与巨星。我们选择了五个颜色-颜色图，通过这些图可以实现这两类样本之间最具前景的分隔。我们的结果显示，FGK星的整体准确性约为0.97，尽管在光度类型和恒星有效温度上存在依赖。我们还为有效温度在4000至7000K之间的矮星定义了颜色-温度关系，该关系允许从四个J-PAS过滤器（J0450、J0510、J0550和J0620）中估算恒星的有效温度。此外，我们还将研究扩展到M型巨星和矮星，达到了与FGK星相似的准确性。

**Summary**:

- (1): 本文探讨了如何通过光度测量分隔FGK矮星和巨星的重要性，以支持银河系结构、化学分布等研究。

- (2): 过去的研究方法主要依赖于传统的光度测量和简单的颜色-颜色图。然而，这些方法可能无法充分区分巨星和矮星，导致样本污染。本文提出的方法结合了SVO光度工具和机器学习技术，提供了更有效的分隔方案。

- (3): 本文的贡献在于提出了一种基于机器学习的光度分隔方法，可有效区分FGK以及M型巨星和矮星，具有高达97%的准确性。

- (4): 研究方法包括从MILES、STELIB和ELODIE恒星库中选择光谱，通过15个特定的J-PAS窄带过滤器生成合成光度，并使用高斯混合模型和支持向量机进行颜色分类。

- (5): 本文的方法在FGK星的分类任务中达到了约97%的准确性，支持其对分离巨星与矮星的目标。


## Supernovae at Distances < 40 Mpc: II. Supernova Rate in the Local Universe
- **Url**: http://arxiv.org/abs/2504.04507v2
- **Authors**: ['Xiaoran Ma', 'Xiaofeng Wang', 'Jun Mo', 'D. Andrew Howell', 'Craig Pellegrino', 'Jujia Zhang', 'Chengyuan Wu', 'Shengyu Yan', 'Dongdong Liu', 'Iair Arcavi', 'Zhihao Chen', 'Joseph Farah', 'Estefania Padilla Gonzalez', 'Fangzhou Guo', 'Daichi Hiramatsu', 'Gaici Li', 'Han Lin', 'Jialian Liu', 'Curtis McCully', 'Megan Newsome', 'Hanna Sai', 'Giacomo Terreran', 'Danfeng Xiang', 'Xinhan Zhang']
- **Abstrat**: Context.This is the second paper of a series aiming to determine the birth rates of supernovae in the local Universe. Aims. In this paper, we aim to estimate the SN rates in the local universe and fit the delay-time distribution of SNe Ia to put constraints on their progenitor scenarios. Methods.We performed a Monte-Carlo simulation to estimate the volumetric rates with the nearby SN sample introduced in Paper I of the series. The rate evolution of core-collapse SNe well traces the evolution of cosmic star formation history; while that of SNe Ia involves the convolution of cosmic star-formation history and a two-component delay-time distribution including a power law and a Gaussian component. Results.The volumetric rates of type Ia, Ibc and II SNe are derived as $0.325\pm0.040^{+0.016}_{-0.010}$, $0.160\pm0.028^{+0.044}_{-0.014}$, and $0.528\pm0.051^{+0.162}_{-0.013}$ (in unit of $10^{-4} yr^{-1} Mpc^{-3} h^3_{70}$), respectively. The rate of CCSNe is consistent with previous estimates. The newly derived local SN Ia rate is larger than existing results given at redshifts 0.01 < z < 0.1, favoring an increased rate from the universe at z ~ 0.1 to the local universe. A two-component model can well fit the rate variation, with the power law component accounting for the rate evolution at larger redshifts and the Gaussian component with a delay time of 12.63$\pm$0.38 Gyr accounting for the local rate evolution. This delayed component with such a longer delay time suggests that the progenitors of these SNe Ia were formed at around 1 Gyr after the birth of the universe, which could only be explained by a double-degenerate progenitor scenario. This is evidenced by the comparison with the PTF sample of SNe Ia at z = 0.073, which reveals that the increase in SN Ia rate at z < 0.01 is primarily due to the SNe Ia of massive E and S0 galaxies with old stellar populations.


**Translated Abstract**: 
背景。本研究是系列论文的第二篇，旨在确定局部宇宙中的超新星（SNe）的出生率。目的。在本文中，我们旨在估计局部宇宙中的SNe率，并拟合Ia型超新星（SNe Ia）的延迟时间分布，以约束其前体情景。方法。我们进行了蒙特卡洛模拟，以利用第一篇论文中引入的附近超新星样本来估计体积率。核心-collapse SNe的速率演化很好地跟踪宇宙星形成历史的演变；而SNe Ia的速率演化则涉及宇宙星形成历史和包含幂律和高斯分量的双组分延迟时间分布的卷积。结果。推导出的Ia型、Ibc型和II型超新星的体积率分别为$0.325\pm0.040^{+0.016}_{-0.010}$、$0.160\pm0.028^{+0.044}_{-0.014}$和$0.528\pm0.051^{+0.162}_{-0.013}$(单位为$10^{-4} yr^{-1} Mpc^{-3} h^3_{70}$)。核心-collapse 超新星的速率与先前的估计一致。新推导的SNe Ia局部率大于红移在0.01 < z < 0.1的现有结果，倾向于一个从z ~ 0.1到局部宇宙在z < 0.01的增加率。一个双组分模型很好地拟合了速率变化，其中幂律组分解释了较大红移下的速率演变，而具有12.63$\pm$0.38 Gyr延迟时间的高斯组分解释了局部速率演变。与双重退化前体情景相符的这种延迟组分的建议表明，这些SNe Ia的前体是在宇宙诞生后约1 Gyr形成的。

**Summary**:

- (1): 该文研究了局部宇宙中超新星的出生率，旨在提供超新星（SNe）前体的约束，以及它们与宇宙化学演化之间的关系。

- (2): 过去的方法主要基于针对特定星系的有选择性观察，存在样本偏差。相比之下，本文采用了蒙特卡洛模拟方法，分析了更全面的超新星样本，以提高了结果的可靠性并减少了观测偏差。

- (3): 本文的贡献在于推导了局部宇宙中Ia型超新星和其它类型超新星的体积率，并提出了一个适用于超新星速率变化的新模型，揭示了它们的前体形成时间。

- (4): 本文的方法论基于蒙特卡洛模拟，结合之前的超新星样本来估计不同类型超新星的体积率，并拟合了包含双组分的延迟时间分布。

- (5): 研究中达到了明显高于过去估计的Supernova Ia率，且提出的性能与目标相符，支持了关于前体的假说和局部星系中超新星爆发率的进一步研究。


## The Impact of Molecular Hydrogen Cooling on the Galaxy Formation Threshold
- **Url**: http://arxiv.org/abs/2503.04885v2
- **Authors**: ['Ethan O. Nadler']
- **Abstrat**: We study the impact of molecular (${\rm H_2}$) and atomic (HI) hydrogen cooling on the galaxy formation threshold. We calculate the fraction of dark matter (DM) halos that exceeds a critical mass required for star formation, $M_{\mathrm{crit}}(z)$, as a function of their peak mass. By convolving analytic halo mass accretion histories (MAHs) with models for $M_{\mathrm{crit}}(z)$, we predict that halos with peak virial masses below $\sim 10^8~M_{\mathrm{\odot}}$ can form stars before reionization through ${\rm H_2}$ cooling. These halos remain dark when only HI cooling and reionization are modeled. However, less than $\approx 10\%$ of halos with peak masses below $\sim 10^{7}~M_{\mathrm{\odot}}$ ever exceed $M_{\mathrm{crit}}(z)$, even when ${\rm H_2}$ cooling is included; this threshold is primarily set by relative streaming motion between DM and baryons imprinted at recombination. We obtain similar results using subhalo MAHs from an extremely high-resolution cosmological DM--only zoom-in simulation of a Milky Way (MW) analog (particle mass $6.3\times 10^3~M_{\mathrm{\odot}}$). Based on the abundance of MW satellites, these results imply that at least some known ultra-faint dwarf galaxies formed through ${\rm H_2}$ cooling. This work sharpens predictions for the galaxy formation threshold and demonstrates how its essential features emerge from the underlying distribution of halo growth histories.


**Translated Abstract**:  
我们研究了分子（${\rm H_2}$）和原子（HI）氢冷却对星系形成阈值的影响。我们计算了超过星形成所需的临界质量$M_{\mathrm{crit}}(z)$的暗物质（DM）晕的比例，作为其峰值质量的函数。通过将分析性的晕质量积累历史（MAHs）与$M_{\mathrm{crit}}(z)$模型卷积，我们预测峰值维里质量低于$\sim 10^8~M_{\mathrm{\odot}}$的晕可以通过${\rm H_2}$冷却在再电离之前形成恒星。当仅建模HI冷却和再电离时，这些晕依然保持暗物质状态。然而，当包括${\rm H_2}$冷却时，峰值质量低于$\sim 10^{7}~M_{\mathrm{\odot}}$的晕中只有少于$\approx 10\%$能够超过$M_{\mathrm{crit}}(z)$；这一阈值主要由重组合时DM与重子之间的相对流动运动设定。我们使用来自极高分辨率的宇宙学DM-仅放大模拟的亚晕MAHs得出了类似的结果。基于银河系（MW）卫星的丰度，这些结果暗示至少一些已知的超微弱矮星系是通过${\rm H_2}$冷却形成的。这项工作清晰地预测了星系形成阈值，并展示了其基本特征如何从晕增长历史的基础分布中产生。

**Summary**:

- (1): 本文研究的背景是星系形成的阈值，探讨何时以及如何形成第一批星系，以及这些星系如何驱动宇宙再电离，特别是暗物质（DM）晕是否存在而没有星系。

- (2): 过去的方法主要依赖于宇宙学水动力学模拟，但这些模拟常常难以捕捉到低质量晕的形成机制。现有方法通常忽视了分子氢（${\rm H_2}$）的冷却效应。该研究提出的办法结合了${\rm H_2}$冷却与氢（HI）冷却，对低质量晕的星形成能够提供更全面的预测。

- (3): 本文的贡献在于确定了低质量晕通过${\rm H_2}$冷却形成恒星的能力，并提出了基于其质量积累历史的新模型，强调了重子和冷暗物质的相对运动对星形成阈值的重要性。

- (4): 本文的方法学主要包括计算未知的暗物质晕数目，结合分析性的晕质量积累历史（MAHs）与${\rm H_2}$冷却的影响，通过两个不同的模型预测$M_{\mathrm{crit}}(z)$。

- (5): 本文的方法在对银河系（MW）卫星的丰度评估中取得了积极成果，表明在特定条件下（如低质量嗫喳）星系确实可以通过${\rm H_2}$冷却形成，从而支持了对星系形成阈值的目标预测。


## Sleeping Giants Arise: Monitoring the Return of Three Changing-Look Quasars to Their High States
- **Url**: http://arxiv.org/abs/2504.06065v1
- **Authors**: ['Laura Duffy', 'Michael Eracleous', 'John J. Ruan', 'Qian Yang', 'Jessie C. Runnoe']
- **Abstrat**: Changing-look quasars challenge many models of the quasar central engine. Their extreme variability in both the continuum and broad emission-line fluxes on timescales on the order of years is difficult to explain. To investigate the cause of the observed transitions, we present new contemporaneous optical and X-ray observations of three faded changing-look quasars as they return to the high state. Two of these three faded changing-look quasars remained in a quiescent state for more than ten years before returning to a new high state. We find that before, during, and after transition, the spectral energy distributions of all three follow predictions for quasars based on X-ray binary outbursts, suggesting that the mechanism for the change is likely a changing accretion rate causing changes in the accretion flow structure. We also find that, in two of the three cases, the transition between the initial high and low state and the transition between the low and new high state took nearly identical amounts of time, on the order of hundreds of days. This transition timescale is useful for testing theoretical models that attempt to explain the short time scale for the state transition.


**Translated Abstract**: 

变化显著的类星体挑战了许多关于类星体中心引擎的模型。它们在几年的时间尺度上表现出极大的变化，包括连续光和宽发射线通量的变化，难以解释。为了研究观察到的转变原因，我们展示了三种褪色的变化显著的类星体的新近同时光学和X射线观测，因为它们返回到高状态。这三种褪色的变化显著的类星体中有两种在返回到新的高状态之前，处于宁静状态超过十年。我们发现，在转变前、转变中和转变后，三者的光谱能量分布均遵循基于X射线双星爆发的类星体预测，表明变化机制很可能是由于改变的吸积率引起的吸积流结构变化。我们还发现，在三种情况下，有两种的初始高状态与低状态之间的转变以及低状态与新高状态之间的转变所需的时间几乎相同，约为几百天。这个转变时间尺度对测试理论模型非常有用，这些模型试图解释状态转变的短时间尺度。

**Summary**:

- (1): 本文的研究背景是变化显著的类星体（CLQs）在光谱中的极端变化，提供了研究吸积流变化的独特机会。

- (2): 过去的方法主要通过跟踪光谱变化来识别类星体的状态变换，但这些方法面临转变时间短以及重复变化的挑战。本文提出的方式是结合光学和X射线观测，利用三种褪色的CLQs的同时观测数据，这种方法能更全面地理解吸积率变化机制，并对以往方法的不足提供了有效的补充。

- (3): 本文的贡献在于展示了三种变化显著的类星体在返回高状态过程中的光谱能量分布遵循X射线双星模型的预测，强调了吸积率变化在此过程中的重要性。

- (4): 本研究的方法论是进行对三种变化显著的类星体的新近同时光学和X射线观测，从而揭示它们在转变过程中的光谱能量分布特征。

- (5): 本文的方法在对三种类星体的状态转变及其时间尺度的研究中取得了重要发现，表现出对不同状态间转变所需时间的相似性，支持了研究目标并对相关理论模型的验证提供了重要数据。


## Distance to M87 as the Mode of the Modulus Distribution
- **Url**: http://arxiv.org/abs/2504.06034v1
- **Authors**: ['Mariusz Tarnopolski']
- **Abstrat**: de Grijs and Bono (ApJS 2020, 246, 3) compiled a list of distances to M87 from the literature published in the last 100 years. They reported the arithmetic mean of the three most stable tracers (Cepheids, tip of the red giant branch, and surface brightness fluctuations). The arithmetic mean is one of the measures of central tendency of a distribution; others are the median and mode. The three do not align for asymmetric distributions, which is the case for the distance moduli $\mu_0$ to M87. I construct a kernel density distribution of the set of $\mu_0$ and estimate the recommended distance to M87 as its mode, obtaining $\mu_0 = \left(31.06~\pm~0.001\,\textrm{(statistical)}\,^{+0.04}_{-0.06}\,\textrm{(systematic)}\right)$~mag, corresponding to \linebreak $D=16.29^{+0.30}_{-0.45}$~Mpc, which yields uncertainties smaller than those associated with the mean and median.


**Translated Abstract**: de Grijs和Bono（ApJS 2020, 246, 3）编制了过去100年文献中关于M87距离的列表。他们报告了三种最稳定的测量工具（Cepheids、红巨星分支的亮度极限和表面亮度波动）的算术平均值。算术平均数是分布中心趋势的度量之一；其他度量包括中位数和众数。在距离模数μ0的非对称分布中，这三者并不一致。我构建了μ0集合的核密度分布，并将M87的推荐距离估计为其众数，得到μ0 = (31.06 ± 0.001（统计）+0.04−0.06（系统）)mag，对应于D=16.29+0.30−0.45 Mpc，这使得不确定性低于与均值和中位数相关的不确定性。

**Summary**:

- (1): 本文的研究背景是基于de Grijs和Bono对M87的距离测量的归纳，涉及超过200个距 M87 的模数（μ0）数据的汇总。

- (2): 过去的方法主要是通过算术平均值、接近的隔离变量（如Cepheids、SBF和TRGB）进行距离测量，而存在的问题是算术平均数在处理非对称分布时不准确。本文提出通过核密度估计获取众数，这能够消除由于不对称性而产生的误差。

- (3): 本文的贡献在于通过众数方法提供了一种更准确的M87距离估计，从而改善了对M87距离的不确定性。

- (4): 研究方法是构建核密度分布并将M87的距离估计为其众数，该方法在统计分析中考虑了不同测量的不确定性。

- (5): 本文的方法在距离计算任务中达到了μ0 = (31.06 ± 0.001（统计）+0.04−0.06（系统）)mag，并且相应的距离D为16.29+0.30−0.45 Mpc，表现出较小的不确定性，支持了其目标的实现。


## NQG III -- Two-Centre Problems, Whirlpool Galaxy and Toy Neutron Stars
- **Url**: http://arxiv.org/abs/2504.06030v1
- **Authors**: ['Richard Durran', 'Aubrey Truman']
- **Abstrat**: In the hunt for WIMPish dark matter and testing our new theory, we extend the results obtained for the Kepler problem in NQG I and NQG II to the Euler two-centre problem and to other classical Hamiltonian systems with planar periodic orbits. In the first case our results lead to quantum elliptical spirals converging to elliptical orbits where stars and other celestial bodies can form as the corresponding WIMP/molecular clouds condense. The examples inevitably involve elliptic integrals as was the case in our earlier work on equatorial orbits of toy neutron stars (see Ref. [27]). Hence this is the example on which we focus in this work on quantisation. The main part of our analysis which leans heavily on Hamilton-Jacobi theory is applicable to any KLMN integrable planar periodic orbits for Hamiltonian systems. The most useful results on Weierstrass elliptic functions needed in these two works we have summarised with complete proofs in the appendix. This has been one of the most enjoyable parts of this research understanding in more detail the genius of Weierstrass and Jacobi. However we have to say that the beautiful simplicity of the Euler two-centre results herein transcend even this as far as we are concerned. At the end of the paper we see how the Burgers-Zeldovich fluid model relates to our set-up through Nelson's stochastic mechanics.


**Translated Abstract**: 

在寻找WIMP型暗物质和测试我们新理论的过程中，我们将NQG I和NQG II中获得的关于开普勒问题的结果扩展到欧拉两中心问题以及其他具有平面周期轨道的经典哈密顿系统。在第一种情况下，我们的结果引导出量子椭圆螺旋，收敛到椭圆轨道，星体及其他天体可以在相应的WIMP/分子云凝聚时形成。由于这些例子不可避免地涉及椭圆积分，因此这是我们在量子化工作中重点关注的示例。我们的分析主要依赖于哈密尔顿-雅可比理论，适用于任何KLMN可积平面周期轨道的哈密顿系统。我们在附录中总结了这两个工作的Weierstrass椭圆函数的最有用结果并提供完整证明。这一研究过程，尤其是深入理解Weierstrass和Jacobi的智慧，使我们感到十分愉快。然而，我们必须说，本文中所述的欧拉两中心结果的美丽简洁性超越了这一点。在论文最后，我们展示了Burgers-Zeldovich流体模型如何通过Nelson的随机力学与我们的设定相关联。

**Summary**:

- (1): 这篇文章的研究背景是针对WIMP型暗物质的寻找以及通过新的理论扩展对经典哈密顿系统的理解。

- (2): 过去的方法如开普勒问题的波函数渐近分析，说明了行星和星系的形成，但未充分探讨其他天文问题。文章提出的新方法采用哈密尔顿-雅可比理论分析欧拉两中心问题，解决了传统方法对其他轨道形态的忽视，具有充分的理论动机。

- (3): 本文贡献在于通过研究欧拉两中心问题，提出了量子化新方法，提供了对星系形成及其演化的新见解，尤其是对WIMP型暗物质的解释。

- (4): 研究方法主要是利用哈密尔顿-雅可比理论和Weierstrass椭圆函数，分析与量子状态有关的力学系统.

- (5): 本文的方法针对欧拉两中心轨道进行了分析，表明星系如Whirlpool Galaxy的形成可能与暗物质有新的关联。这些结果为进一步研究提供了基础，表现出对目标的良好支持。


## A deep search for Complex Organic Molecules toward the protoplanetary disk of V883 Ori
- **Url**: http://arxiv.org/abs/2504.06005v1
- **Authors**: ['Abubakar M. A. Fadul', 'Kamber R. Schwarz', "Merel L. R. van 't Hoff", 'Jane Huang', 'Jennifer B. Bergner', 'Tushar Suhasaria', 'Jenny K. Calahan']
- **Abstrat**: Complex Organic Molecules (COMs) in the form of prebiotic molecules are potentially building blocks of life. Using Atacama Large Millimeter/submillimeter Array (ALMA) Band 7 observations in spectral scanning mode, we carried out a deep search for COMs within the disk of V883 Ori, covering frequency ranges of $\sim$ 348 - 366 GHz. V883 Ori is an FUor object currently undergoing an accretion burst, which increases its luminosity and consequently increases the temperature of the surrounding protoplanetary disk, facilitating the detection of COMs in the gas phase. We identified 26 molecules, including 14 COMs and 12 other molecules, with first detection in this source of the molecules: CH3OD, H2C17O, and H213CO. We searched for multiple nitrogen-bearing COMs, as CH3CN had been the only nitrogen-bearing COM that has been identified so far in this source. We also detected CH3CN, and tentatively detect CH3CH2CN, CH2CHCN, CH3OCN, CH3NCO, and NH2CHO. We compared the abundances relative to CH3OH with those in the handful of objects with previous detections of these species: the Class 0 protostars IRAS 16293-2422 A, IRAS 16293-2422 B and B1-c, the high-mass star-forming region Sagittarius B2 (North), the Solar System comet 67P/Churyumov-Gerasimenko, and the protoplanetary disk of Oph-IRS 48. We report $\sim$ 1 to 3 orders of magnitude higher abundances compared to Class 0 protostars and $\sim$ 1 to 3 orders of magnitude lower abundances compared to the protoplanetary disk, Sagittarius B2 (North), and 67P/C-G. These results indicate that the protoplanetary disk phase could contribute to build up of COMs.


**Translated Abstract**: 

复杂有机分子（COMs）以前生分子的形式可能是生命的组成部分。通过使用阿塔卡马大型毫米/亚毫米阵列（ALMA）第7波段观测，在频率范围约348 - 366 GHz内对V883 Ori的盘面进行了深度搜索。V883 Ori是一个FUor天体，目前正在经历增光，导致其光度增加，进而提高了周围前行星盘的温度，从而有利于在气相中检测COMs。我们识别了26种分子，包括14种COMs和12种其他分子，并首次在该源中检测到分子：CH3OD、H2C17O和H213CO。我们还搜索了多个含氮的COMs，因为迄今为止该源中仅已识别出CH3CN。我们还检测到CH3CN，并初步检测到CH3CH2CN、CH2CHCN、CH3OCN、CH3NCO和NH2CHO。我们将相对丰度与CH3OH在几个较早阶段的对象中进行了比较，包括Class 0原恒星IRAS 16293-2422 A、IRAS 16293-2422 B和B1-c、高质量星形成区Sagittarius B2（North）、太阳系彗星67P/Churyumov-Gerasimenko以及前行星盘Oph-IRS 48。我们报告，与Class 0原恒星相比，丰度高出约1到3个数量级，而与前行星盘、Sagittarius B2（North）和67P/C-G相比，丰度低出约1到3个数量级。这些结果表明，前行星盘阶段可能对COMs的形成有重要贡献。

**Summary**:

- (1): 该文章的研究背景是在星形成区域中，复杂有机分子（COMs）被认为是生命的潜在组成部分，因此了解它们的存在和丰度对于研究生命起源至关重要。

- (2): 过去的方法主要依赖于对前行星盘和原恒星环境的观察，但对于高温条件下COMs的检测存在困难。该研究采用ALMA进行深度观测，针对V883 Ori进行系统的频谱扫描。新方法通过提高温度和光度条件，促进气相中COMs的检测，克服了以往方法的限制，具有良好的动机。

- (3): 该论文的贡献在于首次识别出26种分子（包含14种COMs），包括多种含氮的COMs，并与其他已有天体的丰度进行比较，提供了新的化学演化视角。

- (4): 研究方法论包括利用ALMA对V883 Ori的深度频谱扫描观测，在特定频率范围内识别和分析COMs的存在及其丰度。

- (5): 文章的任务是在V883 Ori中识别COMs，所取得的丰度数据表明，前行星盘阶段的COMs丰度为Class 0原恒星的1到3个数量级高，而与其他天体相比则低，表明该阶段在COMs形成中的重要性，支持作者的研究目标。


## Fluorine abundances in CEMP stars at the lowest metallicity: Hints on the nature of the first stars
- **Url**: http://arxiv.org/abs/2504.05999v1
- **Authors**: ['Aldo Mura-Guzmán', 'David Yong', 'Chiaki Kobayashi', 'Nozomu Tominaga', 'Madeleine McKenzie', 'Ricardo Salinas', 'regory Mace', 'Hwihyun Kim', 'Daniel B. Zucker']
- **Abstrat**: In the last decade, the available measurements of fluorine abundance have increased significantly, providing additional information on the chemical evolution of our Galaxy and details on complex stellar nucleosynthesis processes. However, the observational challenges to obtain stellar F abundances favor samples with higher metallicities, resulting in a scarcity of measurements at low-metallicity ([Fe/H] $<-2.0$). We present F abundances and upper limits in 7 carbon enhanced metal-poor (CEMP) stars observed with the Immersion Grating Infrared Spectrometer (IGRINS), at the Gemini-South telescope. These new observations delivered high-resolution, high signal-to-noise ratio, infrared spectra allowing us to probe significantly deeper into the metal-poor regime and the cosmic origin of F. This work presents the results of our observations, including two 2-sigma detections and five upper limits in a variety of CEMP stars. Arguably the most important result is for CS 29498-0043, a CEMP-no star at [Fe/H] = $-3.87$ with a F detection of [F/Fe] = $+2.0\pm 0.4$, the lowest metallicity star (more than a factor of 10 lower in metallicity than the next detection) with observed F abundance to date. This measurement allowed us to differentiate between two zero metallicity Population III (Pop III) progenitors: one involving He-burning with primary N in Wolf-Rayet stars, and the other suggesting H-burning during hypernova explosions. Our measured value is in better agreement with the latter scenario. This detection represents a pilot, and pioneering study demonstrating the power of F to explore the nature and properties of the first chemical enrichment from Pop III stars.


**Translated Abstract**: 

在过去的十年中，氟的丰度测量显著增加，为我们银河系的化学演化和复杂的恒星核合成过程提供了更多信息。然而，观测氟丰度的挑战更倾向于高金属量样本，导致低金属量（[Fe/H] <-2.0）测量极为稀缺。我们展示了在七颗碳增强金属贫乏星（CEMP）中氟丰度和上限的测量结果，这些星体通过在Gemini-South望远镜上使用浸没光栅红外光谱仪（IGRINS）进行观测。这些新观测提供了高分辨率、高信噪比的红外光谱，使我们能够更深入地探测金属贫乏区域以及氟的宇宙起源。这项工作展示了我们的观测结果，包括两个2σ的检测和五个多种CEMP星的上限数据。最重要的结果是对CS 29498-0043这一CEMP-no星而言，其[Fe/H] = -3.87下检测到[ F/Fe] = +2.0±0.4，这使其成为迄今观测到的最低金属量星，并且其氟丰度比下一个检测星低超过10倍。此测量使我们能够区分两种零金属量的Population III (Pop III) 前体：一种是涉及氦燃烧及Wolf-Rayet星中的N的主要生成，另一种是暗超新星爆炸中氢燃烧。我们测得的值与后者场景更为一致。这一检测代表了一个开创性的初步研究，展示了氟在探索Pop III星的首批化学富集本质和特性方面的潜力。

**Summary**:

- (1): 文章研究的背景是氟的丰度在银河系化学演化和恒星核合成过程中的重要性及其在低金属量星体中的稀缺测量。

- (2): 过去的方法主要依赖于高金属量样本的观测，面临的主要问题是低金属量样本的缺乏。论文中提出的方法则通过使用IGRINS对低金属量的CEMP星进行观测，显著提高了对于氟丰度的测量深度，从而克服了低金属量观测的限制。

- (3): 本文的贡献在于首次检测到CS 29498-0043这一低金属量星的氟丰度，提供了对Pop III星的前体特征的新见解。

- (4): 研究方法通过使用IGRINS进行高分辨率红外光谱观测，收集了七颗CEMP星的氟丰度和上限数据。

- (5): 论文达成的任务是提供CEMP星的氟丰度测量，尤其是在超低金属量的情况下，表现出较高的准确性和信噪比，支持了研究初衷，即深入了解早期宇宙的化学富集过程。


## Subaru High-$z$ Exploration of Low-Luminosity Quasars (SHELLQs). XXIII. The powering mechanisms of the Ly$α$ haloes around high-$z$ quasars probed by slit spectroscopy
- **Url**: http://arxiv.org/abs/2504.05984v1
- **Authors**: ['Hiroki Hoshi', 'Rikako Ishimoto', 'Nobunari Kashikawa', 'Yoshiki Matsuoka', 'Wanqiu He', 'Junya Arita', 'Kazushi Iwasawa', 'Toshihiro Kawaguchi', 'Satoshi Kikuta', 'Rieko Momose', 'Rhythm Shimakawa', 'Shunta Shimizu', 'Ayumi Takahashi', 'Yoshihiro Takeda', 'Yoshiki Toba', 'Takehiro Yoshioka', 'Chien-Hsiu Lee', 'Yuri Nishimura']
- **Abstrat**: We present the analysis of Ly$\alpha$ haloes around faint quasars at $z\sim4$ and $z\sim6$. We use 20 and 162 quasars at $z\sim4$ and $z\sim6$, taken by slit spectroscopy, and detect Ly$\alpha$ haloes around 12 and 26 of these quasars, respectively. The average absolute magnitudes of the detected quasars are $\langle M_{1450} \rangle = -23.84$ mag at $z\sim4$ and $\langle M_{1450} \rangle = -23.68$ mag at $z\sim6$, which are comparable at $z\sim4$ and 3 mag fainter at $z\sim6$ than those of previous studies. The median surface brightness profiles are found to be consistent with an exponential curve, showing a hint of flattening within a radius of 5 kpc. The Ly$\alpha$ haloes around these faint quasars are systematically fainter than those around bright quasars in the previous studies. We confirm the previous results that the Ly$\alpha$ halo luminosity depends on both the ionizing and Ly$\alpha$ peak luminosities of quasars at $z\sim4$, and also find that a similar correlation holds even at $z\sim6$. While the observed Ly$\alpha$ halo luminosity is overall attributed to recombination emission from the optically thin gas clouds in the CGM, its luminosity dependences can be consistently explained by the partial contributions of recombination radiation from the optically thick clouds, which is thought to originate from the CGM centre, and the scattered Ly$\alpha$ photons, which is resonantly trapped at the CGM centre and escaping outside of the haloes.


**Translated Abstract**:  
我们展示了对处于$z\sim4$和$z\sim6$的微弱类星体周围Ly$\alpha$光晕的分析。我们使用了在光谱仪下拍摄的20个和162个$z\sim4$和$z\sim6$的类星体，分别检测到12个和26个类星体周围的Ly$\alpha$光晕。检测到的类星体的平均绝对光度为$\langle M_{1450} \rangle = -23.84$ mag（$z\sim4$）和$\langle M_{1450} \rangle = -23.68$ mag（$z\sim6$），在$z\sim4$时相当，而在$z\sim6$时比之前研究的更暗3个光度单位。我们发现的中位表面亮度分布与指数曲线一致，在半径5 kpc内显示出平坦的迹象。与之前的研究相比，这些微弱类星体周围的Ly$\alpha$光晕普遍较暗。我们确认了过去的结果，即在$z\sim4$时，Ly$\alpha$光晕的亮度依赖于类星体的电离和Ly$\alpha$峰值亮度，并且我们发现，在$z\sim6$时也存在类似的相关性。虽然观察到的Ly$\alpha$光晕亮度最终归因于来自CGM中光学薄气体云的复合发射，其亮度依赖性可以通过光学厚云的复合辐射部分贡献进行一致解释，这种辐射被认为源自CGM中心，而散射的Ly$\alpha$光子则在CGM中心被共振捕获并逃逸出光晕外部。

**Summary**:

- (1): 本文研究表明在$z>6$的时期，超大质量黑洞(SMBHs)已形成，挑战了理论模型对早期宇宙中黑洞快速增长的解释。

- (2): 过去的方法主要使用积分场单位（IFU）在大望远镜上进行的调查，存在样本量不足和对微弱类星体光晕的检测能力差的问题。本文通过使用狭缝光谱法，大规模分析$z\sim4$和$z\sim6$的微弱类星体周围的Ly$\alpha$光晕，能够检测到更多的光晕，解决了样本量和检测能力不足的问题。

- (3): 本文的贡献在于确认了$z\sim4$和$z\sim6$的Ly$\alpha$光晕亮度与类星体的电离和Ly$\alpha$峰值亮度之间的关系，且发现光晕亮度普遍较暗，扩展了该领域的研究。

- (4): 本文采用的研究方法为狭缝光谱法，分析了20个和162个类星体在$z\sim4$和$z\sim6$的Ly$\alpha$光晕，测量了中位表面亮度分布。

- (5): 本文在使用的任务上成功检测了$z\sim4$和$z\sim6$的类星体周围的Ly$\alpha$光晕，性能表现出Ly$\alpha$光晕的亮度依赖性，能够支持其研究目标。


## REMIX SPH -- improving mixing in smoothed particle hydrodynamics simulations using a generalised, material-independent approach
- **Url**: http://arxiv.org/abs/2407.18587v2
- **Authors**: ['Thomas D. Sandnes', 'Vincent R. Eke', 'Jacob A. Kegerreis', 'Richard J. Massey', 'Sergio Ruiz-Bonilla', 'Matthieu Schaller', 'Luis F. A. Teodoro']
- **Abstrat**: We present REMIX, a smoothed particle hydrodynamics (SPH) scheme designed to alleviate effects that typically suppress mixing and instability growth at density discontinuities in SPH simulations. We approach this problem by directly targeting sources of kernel smoothing error and discretisation error, resulting in a generalised, material-independent formulation that improves the treatment both of discontinuities within a single material, for example in an ideal gas, and of interfaces between dissimilar materials. This approach also leads to improvements in capturing wider hydrodynamic behaviour unrelated to mixing. We demonstrate marked improvements in three-dimensional test scenarios, focusing on cases with particles of equal mass across the simulation. This choice is particularly relevant for use cases in astrophysics and engineering -- specifically those in which particles are free to evolve over a large range of density scales -- where bespoke choices of unequal particle masses in the initial conditions cannot easily be used to address emergent and evolving density discontinuities. We achieve these improvements while maintaining sharp discontinuities; without introducing additional equation of state dependence in, for example, particle volume elements; and without contrived or targeted corrections. Our methods build upon a fully compressible and thermodynamically consistent core-SPH construction, retaining Galilean invariance as well as conservation of mass, momentum, and energy. REMIX is integrated in the open-source, state-of-the-art SWIFT code and is designed with computational efficiency also in mind, meaning that its improved hydrodynamic treatment can be used for high-resolution simulations without prohibitive cost to run-speed.


**Translated Abstract**: 

我们提出了REMIX，这是一个设计用于减轻在光滑粒子流体动力学（SPH）模拟中通常抑制混合和不稳定性增长的密度不连续性影响的方案。我们通过直接针对内核平滑误差和离散化误差的来源，形成了一个广义的、与材料无关的公式，从而改善了对单一材料内部的不连续性（例如理想气体）以及不同材料之间界面的处理。该方法还改善了捕获与混合无关的更广泛的流体动力学行为。我们在三维测试场景中展示了显著的改进，重点关注模拟中粒子质量相等的情况。这种选择对于那些粒子在大范围密度尺度上自由演化的天体物理和工程应用特别相关，因为在初始条件下无法轻易采用不等粒子质量来应对新出现和演变中的密度不连续性。我们在保持清晰不连续性的同时实现了这些改进，没有引入额外的状态方程依赖性，也没有采用人为或有针对性的修正。我们的方法建立在完全可压缩和热力学一致的核心-SPH构造之上，保留了伽利略不变性以及质量、动量和能量的守恒。REMIX已集成于开源的最先进的SWIFT代码中，并考虑到计算效率，使得改进的流体动力学处理可以用于高分辨率模拟，而不会对运行速度造成过大负担。

**Summary**:

- (1): 本文的研究背景为光滑粒子流体动力学（SPH）在天体物理和工程中的广泛应用，尤其是在处理流体的复杂行为时的不足之处，如混合和不稳定性在密度不连续性处的抑制现象。

- (2): 过去的方法包括提高核函数的阶数和使用改进的梯度估计方法来减少离散化误差，但这些方法在处理多材料接口时面临挑战。已有方法常常依赖于理想气体状态方程，无法有效改善不同材料之间的密度不连续性。本文提出的REMIX方法适用于单一材料和不同材料的界面，消除了状态方程依赖性，受到了良好的激励。

- (3): 论文的贡献在于提出了一种新颖的REMIX SPH方案，该方案可以有效改善流体混合和不稳定性增长的处理，同时保持密度不连续性和计算效率。

- (4): 本文的研究方法是在完全可压缩且热力学一致的核心-SPH结构上构建，通过直接解决核平滑误差和离散化误差，实现了广义、材料无关的公式。

- (5): 在三维测试场景中，提出的方法表现出显著的性能提升，证明其在高分辨率模拟中的应用能够达到既定目标，且在运行速度上也保持了高效。


## Pushing JWST to the extremes: search and scrutiny of bright galaxy candidates at z$\simeq$15-30
- **Url**: http://arxiv.org/abs/2504.05893v1
- **Authors**: ['M. Castellano', 'A. Fontana', 'E. Merlin', 'P. Santini', 'L. Napolitano', 'N. Menci', 'A. Calabrò', 'D. Paris', 'L. Pentericci', 'J. Zavala', 'M. Dickinson', 'S. L. Finkelstein', 'T. Treu', 'R. O. Amorin', 'P. Arrabal Haro', 'P. Bergamini', 'L. Bisigello', 'E. Daddi', 'P. Dayal', 'A. Dekel', 'A. Ferrara', 'F. Fortuni', 'G. Gandolfi', 'M. Giavalisco', 'C. Grillo', 'S. T. Guida', 'N. P. Hathi', 'B. W. Holwerda', 'A. M. Koekemoer', 'V. Kokorev', 'Z. Li', 'M. Llerena', 'R. A. Lucas', 'S. Mascia', 'B. Metha', 'T. Morishita', 'T. Nanayakkara', 'F. Pacucci', 'P. G. Pérez-González', 'G. Roberts-Borsani', 'G. Rodighiero', 'P. Rosati', 'V. Salazar', 'R. Schneider', 'R. S. Somerville', 'A. Taylor', 'M. Trenti', 'A. Trinca', 'X. Wang', 'P. J. Watson', 'L. Yang', 'L. Y. A. Yung']
- **Abstrat**: We designed customized Lyman-break color selection techniques to identify galaxy candidates in the redshift ranges $15 \leq z \leq 20$ and $20 \leq z \leq 28$. The selection was performed on the ASTRODEEP-JWST multi-band catalogs of the CEERS, Abell-2744, JADES, NGDEEP, and PRIMER survey fields, covering a total area of $\sim0.2$ sq. deg. We identify nine candidates at $15 \leq z \leq 20$, while no objects are found based on the $z\gtrsim20$ color selection criteria. Despite exhibiting a $>$1.5 mag break, all the objects display multimodal redshift probability distributions across different SED-fitting codes and methodologies. The alternative solutions correspond to poorly understood populations of low-mass quiescent or dusty galaxies at z$\sim$3-7. This conclusion is supported by the analysis of a NIRSpec spectrum recently acquired by the CAPERS program for one interloper object, which is confirmed to be a dusty ($E(B-V)=0.8$ mag) starburst galaxy at $z=6.56$. We measured the UV luminosity function under different assumptions on the contamination level within our sample. We find that if even a fraction of the candidates is indeed at $z\gtrsim15$, the resulting UV LF points to a very mild evolution compared to estimates at $z<15$, implying a significant tension with existing theoretical models. In particular, confirming our bright ($M_{\text{UV}}<-21$) candidates would require substantial revisions to the theoretical framework. In turn, if all these candidates will be confirmed to be interlopers, we conclude that future surveys may need ten times wider areas to select $M_{\text{UV}}\lesssim-20$ galaxies at $z>15$. Observations in the F150W and F200W filters at depths comparable to those in the NIRCam LW bands are also required to mitigate contamination from rare red objects at z$\lesssim$8.


**Translated Abstract**: 

我们设计了定制的 Lyman-break 颜色选择技术，以识别红移范围 15 ≤ z ≤ 20 和 20 ≤ z ≤ 28 的星系候选者。选择是在 ASTRODEEP-JWST 多波段目录上进行的，涵盖了 CEERS、Abell-2744、JADES、NGDEEP 和 PRIMER 调查区，总面积约为 0.2 平方度。我们识别出九个在 15 ≤ z ≤ 20 的候选者，而根据 z ≳ 20 的颜色选择标准没有发现对象。尽管所有对象显示出 >1.5 mag 的断裂，但在不同的 SED 拟合代码和方法中，它们都展示了多模态的红移概率分布。替代解对应于z∼3-7 的低质量安静或多尘星系，这是较难理解的。通过 CAPERS 项目最近获取的 NIRSpec 光谱分析进一步支持了这一结论，确认一个干扰对象为 z=6.56 的多尘（E(B-V)=0.8 mag）星爆星系。我们在不同的污染水平假设下测量了紫外光（UV）亮度函数。如果即使部分候选者确实在 z ≳ 15，结果的 UV LF 指出与 z < 15 的估计相比，演化非常温和，暗示与现有理论模型存在显著张力。确认我们的明亮（MUV < -21）候选者将需要对理论框架进行重大修订。相反，如果所有这些候选者都被确认是干扰者，我们得出结论，未来的调查可能需要十倍更广的区域，以选择 z > 15 的 MUV ≲ -20 星系。此外，F150W 和 F200W 过滤器下的观测深度也需要与 NIRCam LW 波段相当，以减少来自 z ≲ 8 稀有红色对象的污染。

**Summary**:

- (1): 该文章研究JWST探测的红移（z）高达30的星系，以测试初期星系形成的理论模型，并解决JWST在z≈10-15的UV亮度函数（LF）演化温和的问题。

- (2): 过去的方法主要依赖于标准的颜色选择技术，难以筛选出红移z>15的星系，且污染物增多导致真实性源的选择变得困难。该文提出的定制Lyman-break选择技术能更有效地识别高红移星系候选者，旨在应对污染与检测困难的问题，具备充分的动机。

- (3): 该论文的贡献在于识别出九个在15≤z≤20的星系候选者，并指出这些候选者如果为真实，可能对现有理论模型造成显著影响。

- (4): 研究方法是基于ASTRODEEP-JWST多波段目录，结合定制的Lyman-break颜色选择技术，以识别不同红移范围的星系候选者。

- (5): 本文的方法在选择高红移星系候选者的任务上取得了积极成果，尽管在z≳20的选择中未能找到候选者。这些结果如果得到确认，能有效支持作者对理论模型的调整目标。


## The Ultraviolet Spectra of 2003fg-like Type Ia Supernovae
- **Url**: http://arxiv.org/abs/2504.05869v1
- **Authors**: ['Snehasish Bhattacharjee', 'Yen-Chen Pan', 'Hao-Yu Miao', 'Charles D. Kilpatrick', 'Willem B. Hoogendam', 'Katie Auchettl', 'Aaron Do']
- **Abstrat**: 2003fg-like Type Ia supernovae (03fg-like SNe Ia) are a rare subtype of SNe Ia, photometrically characterized by broader optical light curves and bluer ultraviolet (UV) colors compared to normal SNe Ia. In this work, we study four 03fg-like SNe Ia using Swift UltraViolet and Optical Telescope (UVOT) grism observations to understand their unique UV properties and progenitor scenario(s). We report 03fg-like SNe Ia to have similar UV features and elemental compositions as normal SNe Ia, but with higher UV flux relative to optical. Previous studies have suggested that the UV flux levels of normal SNe Ia could be influenced by their progenitor properties, such as metallicity, with metal-poor progenitors producing higher UV flux levels. While 03fg-like SNe were previously reported to occur in low-mass and metal-poor host environments, our analysis indicates that their UV excess cannot be explained by their host-galaxy parameters. Instead, we demonstrate that the addition of a hot blackbody component, likely arising from the interaction with the circumstellar material (CSM), to the normal SN Ia spectrum, can reproduce their distinctive UV excess. This supports the hypothesis that 03fg-like SNe Ia could explode in a CSM-rich environment.


**Translated Abstract**: 

2003fg型Ia超新星（03fg-like SNe Ia）是Ia型超新星的一种稀有亚型，其光度特征表现为比正常Ia型超新星更宽的光曲线和更蓝的紫外（UV）颜色。在这项工作中，我们用Swift紫外光和光学望远镜（UVOT）光谱观测研究了四个03fg型Ia超新星，以理解它们独特的UV特性和前身情况。我们报告03fg型Ia超新星与正常Ia型超新星具有相似的UV特征和元素组成，但相对于光学而言，UV通量更高。以前的研究表明，正常Ia型超新星的UV通量水平可能受其前身特性影响，例如金属丰度，金属贫乏的前身倾向于产生更高的UV通量。尽管03fg型超新星先前被报道发生在低质量和金属贫乏的宿主环境中，但我们的分析表明，它们的UV过剩无法通过宿主星系参数解释。相反，我们证明向正常Ia型超新星光谱中增加一个热黑体成分，可能来源于与星周物质（CSM）的相互作用，可以再现其独特的UV过剩。这支持了03fg型Ia超新星可能在富含CSM的环境中爆炸的假设。

**Summary**:

- (1): 本文的研究背景是2003fg型Ia超新星（03fg-like SNe Ia）作为Ia型超新星的一种稀有亚型，其光度曲线和UV颜色特征有显著不同，且能影响到对宇宙膨胀速率的测定。

- (2): 过去的方法主要是通过观测超新星的光学特征来分析其属性，但无法充分解释03fg型Ia超新星的UV特性。本文提出的基于UVOT光谱的分析方法与以往不同，能更好地揭示其UV过剩的原因，因而在研究03fg型Ia超新星的独特性方面具有良好的动机。

- (3): 本文的主要贡献在于揭示了03fg型Ia超新星的UV特征与正常Ia型超新星的相似性及其不同之处，提供了与星周物质（CSM）相互作用相关的新解释，进一步支持了该亚型超新星在CSM丰富环境中爆炸的假设。

- (4): 本文提出的研究方法是使用Swift UVOT对四个03fg型Ia超新星进行光谱观测，并分析其UV成分与特点，以研究其爆炸物理和前身情况。

- (5): 本文在理解03fg型Ia超新星的UV性质及其与宿主环境的关系方面取得了积极的结果，这些结果支持了作者的目标，即提供更全面的对03fg型Ia超新星的了解。


## Analyzing type Ia supernovae near-infrared light curves with Principal Component Analysis
- **Url**: http://arxiv.org/abs/2504.05856v1
- **Authors**: ['T. E. Müller-Bravo', 'L. Galbany', 'M. D. Stritzinger', 'C. Ashall', 'E. Baron', 'C. R. Burns', 'P. Höflich', 'N. Morrell', 'M. Phillips', 'N. B. Suntzeff', 'S. A. Uddin']
- **Abstrat**: Type Ia supernovae (SNeIa), the thermonuclear explosions of C/O white dwarf stars in binary systems, are phenomena that remain poorly understood. The complexity of their progenitor systems, explosion physics and intrinsic diversity poses not only challenges for their understanding as astrophysical objects, but also for their standardization and use as cosmological probes. Near-infrared (NIR) observations offer a promising avenue for studying the physics of SNeIa and for reducing systematic uncertainties in distance estimations, as they exhibit lower dust extinction and smaller dispersion in peak luminosity than optical bands. Here, Principal Component Analysis (PCA) is applied to a sample of SNeIa with well-sampled NIR (YJH-band) light curves to identify the dominant components of their variability and constrain physical underlying properties. The theoretical models of Kasen2006 are used for the physical interpretation of the PCA components, where we found the 56Ni mass to describe the dominant variability. Other factors, such as mixing and metallicity, were found to contribute significantly as well. However, some differences are found between the components of the NIR bands which may be attributed to differences in the explosion aspects they each trace. Additionally, the PCA components are compared to various light-curve parameters, identifying strong correlations between some components and peak brightness in both the NIR and optical bands, particularly in the Y band. When applying PCA to NIR color curves, we found interesting correlations with the host-galaxy mass, where SNeIa with redder NIR colors are predominantly found in less massive galaxies. We also investigate the potential for improved standardization in the Y band by incorporating PCA coefficients as correction parameters, leading to a reduction in the scatter of the intrinsic luminosity of SNeIa.


**Translated Abstract**: 

Ia 型超新星（SNe Ia）是碳氧（C/O）白矮星在双星系统中的热核爆炸，这种现象仍然很复杂且尚未完全理解。由于它们的前体系统、爆炸物理和内在多样性的复杂性，给我们对其作为天体对象的理解以及将其标准化及用于宇宙学探测带来了挑战。近红外（NIR）观测为研究 SNe Ia 的物理学以及减少距离估计中的系统不确定性提供了有希望的途径，因为与光学波段相比，它们表现出更低的尘埃消光和更小的峰值光度分散。在本研究中，我们对具有良好采样 NIR (YJH 波段) 光曲线的 SNe Ia 样本应用主成分分析（PCA），以识别其变异性的主要成分并约束物理基础属性。我们使用 Kasen (2006) 的理论模型来解释 PCA 组件，发现 56Ni 质量描述了主要的变异性。混合和金属丰度等其他因素也显著影响。然而，NIR 波段之间的某些差异可能归因于它们各自追踪的爆炸特征的差异。此外，我们将 PCA 组件与各种光曲线参数进行比较，发现某些组件与 NIR 和光学波段特别是在 Y 波段的峰值亮度之间存在强相关性。当对 NIR 色曲线应用 PCA 时，我们发现与宿主星系质量相关的有趣关联，其中较红的 NIR 颜色的 SNe Ia 主要出现在较小质量的星系中。我们还通过将 PCA 系数作为校正参数，研究了在 Y 波段中提高标准化的潜力，从而减少了 SNe Ia 内在光度的散布。随着新 NIR 观测结果的出现，我们的发现可以得到进一步验证，最终可以细化我们对 SNe Ia 物理学的理解并增强它们作为宇宙距离指标的可靠性。

**Summary**:

- (1): 本文的研究背景为 Ia 型超新星（SNe Ia）是碳氧白矮星在双星系统中产生的热核爆炸，其物理机制和爆炸特性仍未完全理解。

- (2): 过去的研究方法主要使用光学观察，但存在因尘埃消光和峰值光度分散大导致的系统不确定性。该论文提出通过主成分分析（PCA）处理近红外（NIR）数据，从而克服了传统方法的局限。PCA 提供了对 SNe Ia 变异性的深入认识，并揭示了物理属性的关系。

- (3): 本文的贡献在于通过 PCA 分析 NIR 光曲线，识别了 SNe Ia 变异性的主导因素（如 56Ni 质量）以及与宿主星系质量之间的关联，为理解 SNe Ia 的物理学提供了新视角。

- (4): 本文提出的研究方法为应用主成分分析（PCA）于 SNe Ia 的 NIR (YJH) 光曲线，识别主导变异成分并探讨物理属性的相关性。

- (5): 本研究针对 SNe Ia 的变异性进行分析，发现了一系列重要的物理相关性，表明通过 NIR 数据分析可以支持 SNe Ia 作为宇宙学距离指标的有效性。


## Exploring Hard X-ray Properties of $γ$-ray Emitting Narrow Line Seyfert-I Galaxies through NuSTAR Observations
- **Url**: http://arxiv.org/abs/2504.04492v2
- **Authors**: ['Suvas Chandra Chaudhary', 'Raj Prince']
- **Abstrat**: With the launch of the Fermi-LAT observatory in 2008, more new gamma-ray objects were discovered, mostly dominated by blazars. In addition, some of the narrow line Seyfert 1 (NLSy1) galaxies were observed in gamma-ray but in less number, making them different from other NLSy1 galaxies. We studied the six gamma-ray-detected NLSy1 galaxies using the hard X-ray observations from NuSTAR and optical g- & r-band from ZTF. The X-ray spectra corresponding to all objects are well-fitted with a power-law spectral model, and a strong "brighter-when-redder" trend is seen, which is the properties mostly seen in Blazars. The X-ray light curves were produced for all the available observations, and the F$_{var}$ is estimated for all the observations. In 1H 0323+342, we found that F$_{var}$ lies between 9-22%, suggesting significant variability in the same source. Similarly, for PKS 2004-447, we found F$_{var}$ lies between 10-21%. We see a strong X-ray and gamma-ray spectral index correlation among these objects, suggesting that X-rays and gamma-rays are produced through a similar process. Comparing the X-ray spectral index with other class objects, we see that NLSy1 galaxies are similar to LBL and IBL types. We see a negative trend of X-ray flux with the gamma-ray luminosity in these objects, suggesting an anti-correlation between X-ray and gamma-ray luminosity. A similar trend is seen between the X-ray flux, total jet power, and disk luminosity. The X-ray spectral index also shows a negative trend with total jet power and disk luminosity. The optical variability amplitude lies between 0.90 to 2.32, and the fractional variability varies from 13-40%. The color-magnitude plot shows mostly the brighter-when-redder trend, suggesting $\gamma$-NLSy1 are much closer to FSRQs than BL Lacs. Our results, overall, summarize how the various parameters in gamma-ray-detected NLSy1 are connected.


**Translated Abstract**: 

随着2008年Fermi-LAT天文台的发射，发现了更多新的伽马射线天体，主要以耀变体为主。此外，一些窄线 Seyfert 1（NLSy1）星系也被观测到伽马射线，但其数量较少，且其特性与其他NLSy1星系不同。我们使用NuSTAR的硬X射线观测和ZTF的光学g和r波段对六个伽马射线探测到的NLSy1星系进行了研究。所有对象的X射线光谱均很好地拟合了一个幂律光谱模型，并且观察到强烈的“红色更亮”趋势，这是耀变体特有的性质。为所有可用观测生成了X射线光变曲线，并为所有观测估算了F$_{var}$。在1H 0323+342中，F$_{var}$介于9%至22%之间，表明同一源具有显著的变异性。类似地，对于PKS 2004-447，F$_{var}$介于10%至21%。我们观察到这些对象之间存在强烈的X射线和伽马射线谱指数相关性，这表明X射线和伽马射线是通过相似的过程产生的。将X射线谱指数与其他类对象进行比较时，NLSy1星系与LBL和IBL类型相似。对象中的X射线通量与伽马射线光度之间存在明显的负相关趋势，表明X射线和伽马射线光度之间的反相关关系。X射线光谱指数与总喷流功率和盘光度也显示负相关趋势。光学变异幅度在0.90到2.32之间，分数变异率变化在13%到40%之间。颜色-亮度图表明大部分为红色更亮趋势，显示伽马NLSy1与FSRQ相比更接近而不是BL Lacs。我们的结果总结了伽马射线探测到的NLSy1中各参数的联系。

**Summary**:

- (1): 本文研究背景是窄线 Seyfert 1（NLSy1）星系的伽马射线探测相对较少，主要旨在探讨这些特殊类别的活跃星系中心的高能性质。

- (2): 过去的方法主要依赖于光学和软X射线观测，缺乏对硬X射线的深入研究。现有方法未能揭示 X 射线和伽马射线之间的相互关系。本文提出的方法通过使用NuSTAR进行硬X射线观测，能够更全面地分析这些NLSy1星系的性质，明确揭示了它们之间的关联。

- (3): 本文贡献在于通过硬X射线和光学数据的结合，首次系统性地研究了伽马射线检测到的NLSy1星系的光谱和变异性特征，并建立了它们与已知激变体的联系。

- (4): 论文采用的方法包括使用NuSTAR获取硬X射线数据，并结合ZTF的光学数据，通过光谱分析和光变分析确定各对象的变异性、光谱指数和光度关系。

- (5): 本文的方法主要任务是分析六个伽马射线检测到的NLSy1星系的硬X射线特性，所取得的结果显示X射线和伽马射线之间存在明显的相关性，支持了研究目标，即探讨其与激变体的相似性。


## Accurate Decomposition of Galaxies with Spiral Arms: Dust Properties and Distribution
- **Url**: http://arxiv.org/abs/2504.05839v1
- **Authors**: ['A. A. Marchuk', 'I. V. Chugunov', 'F. Galliano', 'A. V. Mosenkov', 'P. V. Strekalova', 'V. S. Kostiuk', 'G. A. Gontcharov', 'V. B. Ilin', 'S. S. Savchenko', 'A. A. Smirnov', 'D. M. Poliakov']
- **Abstrat**: We analyze three nearby spiral galaxies - NGC 1097, NGC 1566, and NGC 3627 -using images from the DustPedia database in seven infrared bands (3.6, 8, 24, 70, 100, 160, and 250 micron). For each image, we perform photometric decomposition and construct a multi-component model, including a detailed representation of the spiral arms. Our results show that the light distribution is well described by an exponential disk and a Sersic bulge when non-axisymmetric components are properly taken into account. We test the predictions of the stationary density wave theory using the derived models in bands, tracing both old stars and recent star formation. Our findings suggest that the spiral arms in all three galaxies are unlikely to originate from stationary density waves. Additionally, we perform spectral energy distribution (SED) modeling using the hierarchical Bayesian code HerBIE, fitting individual components to derive dust properties. We find that spiral arms contain a significant (>10%) fraction of cold dust, with an average temperature of approximately 18-20 K. The estimated fraction of polycyclic aromatic hydrocarbons (PAHs) declines significantly toward the galactic center but remains similar between the arm and interarm regions.


**Translated Abstract**: 

我们分析了三个位于附近的螺旋星系——NGC 1097、NGC 1566 和 NGC 3627——利用来自 DustPedia 数据库的七个红外波段的图像（3.6、8、24、70、100、160 和 250 微米）。针对每幅图像，我们执行了光度分解，并构建了一个多组件模型，包括对螺旋臂的详细表示。我们的结果表明，在适当考虑非轴对称成分时，光分布可以很好地被指数盘和 Sérsic 球体描述。我们使用派生模型测试了静态密度波理论的预测，追踪旧恒星和近期恒星形成。我们的发现表明这三种星系的螺旋臂不太可能源自静态密度波。此外，我们利用层次贝叶斯代码 HerBIE 进行光谱能量分布（SED）建模，拟合各个组件以推导尘埃特性。我们发现螺旋臂包含显著（>10%）的冷尘埃，平均温度大约为 18-20 K。多环芳香烃（PAHs）的估计比例在星系中心显著下降，但在臂区和间臂区之间保持相似。

**Summary**:

- (1): 本文研究背景是尘埃在星系演化中的重要性，尽管其质量占星系总质量的不到 1%。尘埃在调节恒星形成和化学反应中起着关键作用。

- (2): 过去的方法通常通过光度分解使用标准参数模型，然而，螺旋臂的建模往往不准确。例如，存在明显的尘埃分布模型误差和在辐射传输中对螺旋臂的简化处理。本文提出的多组件模型充分考虑了螺旋臂的非轴对称性，能够更准确地描述尘埃和恒星的分布。

- (3): 本文的贡献在于提出了一种新的光度分解方法，能够详细建模螺旋臂的结构，改善了对尘埃属性的理解，并发现了螺旋臂与静态密度波理论的偏离。

- (4): 本文提出的方法通过使用来自 DustPedia 数据库的红外图像，进行光度分解并构建多组件模型，利用层次贝叶斯代码 HerBIE 进行光谱能量分布建模。

- (5): 本文在建模螺旋臂尘埃特性方面取得显著成果，发现螺旋臂中存在显著冷尘埃和确定的温度范围，支持了对尘埃在星系演化中角色的深入理解。


## Ultraviolet Photometry and Reddening Estimation of 105 Galactic Open Clusters
- **Url**: http://arxiv.org/abs/2504.04930v2
- **Authors**: ['Tahereh Ramezani', 'Ernst Paunzen', 'Artem Gorodilov', 'Olga Ines Pintado']
- **Abstrat**: This paper focuses on observing unstudied Galactic open clusters in the Ultraviolet (UV) wavelength range and analyzing their photometric data. The Gaia Data Release 3 (DR3) enables us to precisely study known Galactic open clusters. We conducted observations using the 1.54-meter Danish Telescope (DK1.54) in Chile and the 2.15-meter telescope at the Complejo Astronomico El Leoncito (CASLEO) in Argentina, employing UV filters. Furthermore, we have collected available photometric and astrometric data for our observed clusters. We aim to estimate the reddening of Galactic open clusters using UV photometry. We applied isochrone fitting to determine the reddening of the clusters using well-known members. As a final result, we present the reddening values of 105 Galactic open clusters in the UV, as determined by our photometry.


**Translated Abstract**: 

本文关注于在紫外（UV）波段观察未研究的银河开放星团并分析其光谱数据。利用“Gaia”数据发布3（DR3）的数据，我们能够精确研究已知的银河开放星团。我们使用在智利的1.54米丹麦望远镜（DK1.54）和阿根廷的2.15米“Complejo Astronómico El Leoncito”（CASLEO）望远镜进行观测，并采用紫外过滤器。此外，我们收集了观察星团的可用光度和天体测量数据。我们的目标是利用紫外光度测定银河开放星团的衰减。我们应用等时线拟合来确定星团的衰减，并使用已知成员。最终，我们提供了根据我们的光度测定得出的105个银河开放星团的紫外线衰减值。

**Summary**:

- (1): 本文的研究背景是星团（特别是开放星团）为理解恒星形成、演化和动力学提供了重要实验室，因为它们的恒星具有共同的起源、距离和年龄。

- (2): 过去主要使用的研究方法包括对已知星团的观察，但近年来缺乏紫外观察。现存的研究通常不足以全面了解星团的衰减特性。本文提出的方法通过利用“Gaia”数据发布3（DR3）和紫外观测，相比传统方法可更精确地获取星团的光度和衰减估计。

- (3): 本文的贡献在于它提供了105个银河开放星团的紫外衰减值，这对理解星团的结构和演化具有重要意义。

- (4): 本文的研究方法涉及对105个南半球开放星团的观测，利用1.54米和2.15米望远镜进行紫外光度观测，并通过等时线拟合分析衰减。

- (5): 本文在衰减估计任务上取得了较为精确的结果，成功提供了105个星团的衰减值，这些性能支持了其研究目标。


## Asymmetric accretion through a streamer onto the pre-stellar core H-MM1
- **Url**: http://arxiv.org/abs/2503.21370v2
- **Authors**: ['Spandan Choudhury', 'Jongsoo Kim', 'Paola Caselli', 'Chang Won Lee', 'Jaime E. Pineda']
- **Abstrat**: CONTEXT: Dense cores are thought to be isolated from the surrounding cloud. However, observations of streamers and subsonic material outside core boundaries challenges this idea. AIMS: In this study, we aim to probe the extended subsonic region observed around the pre-stellar core H-MM1 in L1688 using multi-component kinematical analysis of very high-sensitivity NH3 data. METHODS: We used observations of NH3 (1,1) and (2,2) using GBT. We then fitted up to two components towards the core and its surrounding molecular cloud. RESULTS: We detect an extended region of subsonic turbulence in addition to the ambient cloud, which show supersonic turbulence. This extended subsonic region is approximately 12 times the size of and more than two times as massive as the previously detected subsonic material. The subsonic region is further split into two well-separated, velocity-coherent components, one of which is kinematically and spatially connected to the dense core. The two subsonic components are red- and blue-shifted with respected to the cloud component. We also detect a flow of material onto the dense core from the extended subsonic region via a streamer of length ~0.15 pc (~30000 au). CONCLUSIONS: We find that the extended subsonic component kinematically associated with the dense core contains 27% more mass than the core. This material could be further accreted by the core. The other subsonic component contains a mass similar to that of the core mass, and could be tracing material in the early stage of core formation. The H-MM1 streamer is kinematically similar to the ones observed towards protostellar systems, but is the first instance of such an accretion feature onto a core in its pre-stellar phase. This accretion of chemically fresh material by the pre-stellar core challenges our current understanding of a core evolving with a mass unchanged since the time of its formation.


**Translated Abstract**: 
背景：根据密集核心的理论，密集核心被认为与周围的分子云是隔离的。然而，围绕预星核心H-MM1的流体流动的观测挑战了这一观点。本研究的目的是利用多组分动力学分析高灵敏度的NH3数据来探测L1688中H-MM1周围延伸的亚声区。方法：我们使用了G度量的NH3（1,1）和（2,2）观测数据，并为核心及其周围的分子云拟合了多达两个组分。结果：我们发现除了环境云之外，还有一个扩展的亚声湍流区。这个区域的大小大约是以前检测到的亚声材料的12倍，质量也超过其2倍。这个亚声区进一步被分为两个分离的、速度一致的组分，其中一个与密集核心在运动和空间上相连。我们还检测到通过一条长度约为0.15 pc（约30000 au）的流向密集核心流动的物质。结论：我们发现，与密集核心运动学相关的扩展亚声组分具有27%的质量比核心还多。这部分物质可以进一步被核心吸积。另一个亚声组分展现出与核心质量相当的质量，可能标记在核心形成早期阶段的物质。H-MM1流与观测到的原星系统的流动运动学相似，但这是第一次观察到在预星阶段向核心的这种吸积特征。这种对预星核心的新鲜化学物质的吸积挑战了我们对核心在形成后质量不变的演化理解。

**Summary**:

- (1): 本文研究背景是密集核心在分子云中被认为是隔离的传统观念受到挑战，流体观测显示来自核心外部向核心的物质流动。

- (2): 过去的方法主要采用NH3观测数据比较，而现有研究缺乏空间分辨率，无法明确分子云外围极细亚声速物质的运动学特征。本文提出在高灵敏度下实施多组分动力学分析，以解决空间分辨率低的问题。

- (3): 本文的贡献在于首次观察到在预星相阶段通过流体向密集核心的吸积现象，并发现核心及其周围的亚声速材料的显著质量。

- (4): 研究方法包括高灵敏度的NH3（1,1）和（2,2）观测，并对数据进行多组分动力学分析，以识别和量化与H-MM1核心相连的各个运动学组分。

- (5): 本研究在H-MM1核心周围的亚声速物质流动及其物质质量方面取得了成功，表明核心周围的物质流动对核心质量的增加起到了支持作用，符合其预期目标。


## On the evidence of a dark matter density spike around the primary black hole in OJ 287
- **Url**: http://arxiv.org/abs/2504.05715v1
- **Authors**: ['Debabrata Deb', 'Achamveedu Gopakumar', 'Mauri J. Valtonen']
- **Abstrat**: The central engine of blazar OJ~287 is arguably the most notable supermassive black hole (SMBH) binary candidate that emits nano-Hertz (nHz) gravitational waves. This inference is mainly due to our ability to predict and successfully monitor certain quasi-periodic doubly peaked high brightness flares with a period of $\sim$12 years from this blazer. The use of post-Newtonian accurate SMBH binary orbital description that includes the effects of higher order GW emission turned out to be a crucial ingredient for accurately predicting the epochs of such Bremsstrahlung flares in our SMBH binary central engine description for OJ~287. It was very recently argued that one should include the effects of dynamical friction, induced by certain dark matter density spikes around the primary SMBH, to explain the {\it observed} decay of SMBH binary orbit in OJ~287. Invoking binary pulsar timing-based arguments, measurements, and OJ~287's orbital description, we show that observationally relevant SMBH binary orbital dynamics in OJ~287 are insensitive to dark matter-induced dynamical friction effects. This implies that we could only provide an upper bound on the spike index parameter rather than obtaining an observationally derived value, as argued by \cite{Chan2024}.


**Translated Abstract**: 

OJ~287的中心引擎很可能是最著名的超大质量黑洞(SMBH)双星候选体，也是发出纳赫兹(nHz)引力波的源头。这个推论主要基于我们成功预测并监测到一些具有约12年周期的准周期双峰高亮度闪光的能力。采用包含高阶引力波发射效应的后牛顿精确SMBH双星轨道描述，成为了准确预测此类闪光爆发时期的一个关键因素。最近有人提出应考虑由某些暗物质密度尖峰引起的动力摩擦效应，以解释OJ~287中SMBH双星轨道的实际衰减。通过引用基于双脉冲星定时的论证和测量，以及OJ~287的轨道描述，我们展示了OJ~287中与观测相关的SMBH双星轨道动力学对暗物质引起的动力摩擦效应不敏感。这意味着我们只能对尖峰指数参数提供上限，而无法获得观察性推导值，如 Chan & Lee (2024) 所论述的。

**Summary**:

- (1): 文章的研究背景是OJ~287被视为最著名的超大质量黑洞(SMBH)双星候选体，并可能是发出nHz引力波的源头，基于其准周期性闪光的观测所得。

- (2): 过去的方法侧重于考虑动力摩擦效应以解释SMBH双星的轨道衰减，但这可能导致不准确的临界结果。提出的方法主要通过双脉冲星定时，并考虑OJ~287的轨道描述，表明其轨道动力学对暗物质的影响不敏感，从而避免了旧方法中的误导。

- (3): 论文的贡献在于证明OJ~287的SMBH双星轨道动态对暗物质造成的动力摩擦效应不敏感，并确立了仅能对暗物质密度尖峰指数参数提供上限的理论框架。

- (4): 本文研究的方法论涉及运用双脉冲星定时的论证和观测数据，以评估OJ~287中的SMBH双星轨道动力学，并将其与暗物质的影响进行对比分析。

- (5): 论文的任务是研究OJ~287中SMBH双星的轨道动态表现，研究结果表明所提出的方法能够确保对暗物质摩擦效应的解析，并支持其研究目标的达成。


# galaxies
## Constraining the [CII] luminosity function from the power spectrum of line intensity maps at redshift 3.6
- **Url**: http://arxiv.org/abs/2504.06266v1
- **Authors**: ['Elena Marcuzzo', 'Cristiano Porciani', 'Emilio Romano-Díaz', 'Prachi Khatri']
- **Abstrat**: Forthcoming measurements of the line-intensity-mapping power spectrum (PS) are expected to set precious constraints on several quantities of astrophysical and cosmological interest. Our study targets the [CII] luminosity function (LF) at high redshift, which is still highly uncertain, in particular at the faint end. As an example of future opportunities, we present forecasts for the Deep Spectroscopic Survey (DSS) that will be conducted with the Fred Young Submillimeter Telescope at $z \simeq 3.6$ and also make predictions for eventual $10\times$ wider and/or $\sqrt{10}\times$ more sensitive surveys. The halo-occupation properties of [CII] emitters in the MARIGOLD simulations provide us with the motivation to abundance match two versions of the ALPINE LF against the halo mass function. We employ the resulting luminosity-mass relation within the halo model to predict the expected PS signal and its uncertainty. Finally, we use Bayesian inference to analyse mock PS data and forecast what constraints could be achieved on the first two moments of the LF and on Schechter fits. Depending on the actual LF, the DSS will measure the clustering and shot-noise amplitudes of the PS with a signal-to-noise ratio of $\sim 3$ or higher. However, degeneracies with the bias parameter and redshift-space distortions make it unfeasible to extract the first moment of the LF. Even the widest and most sensitive survey we consider can only constrain it with a $50\%$ uncertainty. By jointly fitting the PS and the LF, we directly constrain Schechter-function parameters. We find that the normalisation and the cutoff luminosity are precisely and accurately measured while the faint-end slope remains highly uncertain (unless the true value approaches $-2$). Overall, increasing the survey sensitivity at fixed sky coverage yields greater improvements than covering a larger area at fixed sensitivity.


**Translated Abstract**: 

即将进行的线强度映射功率谱（PS）测量预计将对多个天体物理和宇宙学重要量设定宝贵限制。本研究目标是高红移处[CII]光度函数（LF），尤其是在弱端仍然高度不确定。我们以即将在红移z ≃ 3.6进行的深光谱调查（DSS）为例，并预测未来可能更宽10倍和/或更敏感√10倍的调查。MARIGOLD模拟中的[CII]发射体的晕占有特性为我们提供了动机，将ALPINE LF的两个版本与晕质量函数进行丰度匹配。我们利用得到的光度-质量关系在晕模型中预测预期的PS信号及其不确定性。最后，我们使用贝叶斯推断分析模拟PS数据，并预测对LF的前两个时刻和Schechter拟合可以实现的限制。根据实际的LF，DSS将以约3或更高的信噪比测量PS的聚类和噪声幅度。然而，偏置参数和红移空间扭曲的退化性使得提取LF的第一时刻变得不可行。即使考虑到我们认为的最宽和最敏感的调查，也只能以50%的不确定性对其进行限制。通过联合拟合PS和LF，我们直接限制Schechter函数参数。我们发现，规范化和截止光度被精确和准确地测量，而弱端斜率仍然高度不确定（除非真实值接近-2）。总体而言，固定天空覆盖下提高调查的灵敏度比在固定灵敏度下覆盖更大区域产生更大的改进。

**Summary**:

- (1): 本文的研究背景是即将进行的线强度映射功率谱（PS）测量，将为天体物理和宇宙学的重要量提供限制。

- (2): 过去的方法主要依赖于传统的光度函数（LF）测量，但在高红移、特别是弱端时尤为不确定。本研究采用MARIGOLD模拟中的晕占有属性进行丰度匹配，利用此方法从根本上提供了对光度函数的更好约束。

- (3): 本文的贡献在于基于即将进行的DSS调查，提出了一种新方法来约束高红移[CII]光度函数的参数，特别是对Schechter函数参数进行了直接限制。

- (4): 研究方法包括利用MARIGOLD模拟进行晕占有模型和光度-质量关系的建立，结合贝叶斯推断分析模拟的功率谱数据，从而预测和约束光度函数的参数。

- (5): 所提出的方法在获得大约3的信噪比的情况下，对聚类和噪声幅度进行了测量。该性能可以支持研究目标的实现，但在获取LF的第一时刻方面仍存在50%的不确定性。


## A systematic method to identify runaways from star clusters produced from single-binary interactions: A case study of M67
- **Url**: http://arxiv.org/abs/2504.06252v1
- **Authors**: ['A. Herrera-Urquieta', 'N. Leigh', 'J. Pinto', 'G. Díaz-Cerda', 'S. M. Grondin', 'J. J. Webb', 'R. Mathieu', 'T. Ryu', 'A. Geller', 'M. Kounkel', 'S. Toonen', 'M. Vilaxa-Campos']
- **Abstrat**: One hypothesis for runaway stars (RSs) is that they are ejected from star clusters with high velocities relative to the cluster center-of-mass motion. There are two competing mechanisms for their production: supernova-based ejections in binaries, where one companion explodes, leaves no remnant, and launches the other companion at the instantaneous orbital velocity, and the disintegration of triples (or higher-order multiples), which produces a recoiled runaway binary (RB) and an RS. We search for RS candidates using data from the Gaia DR3 survey with a focus on triple disintegration since in this case the product is always a binary and a single star that should be moving in opposite directions. We created a systematic methodology to look for candidate RS-RB runaway pairs produced from the disintegration of bound three-body systems formed from single-binary interactions based on momentum conservation and causality. The method we use is general and can be applied to any cluster with a 5D kinematic data set. We used our criteria to search for these pairs in a 150 pc circular field of view surrounding the open cluster M67, which we used as a benchmark cluster to test the robustness of our method. Our results reveal only one RS-RB pair that is consistent with all of our selection criteria out of an initial sample of $10^8$ pairs.


**Translated Abstract**: 

有一种关于逃逸恒星（RSs）假设是它们以相对于星团质心运动的高速度被从星团中弹出。它们产生的机制有两种竞争的假说：超新星基础的弹射机制，在这种情况下一个伴星爆炸，留下的伴星以瞬时轨道速度被发射；以及三重系统的解体（或更高阶的复合系统），产生一个反冲的逃逸双星（RB）和一个RS。我们使用Gaia DR3 Survey的数据搜索RS候选对象，重点关注三重解体，因为在这种情况下，产品总是一个双星和一颗应朝相反方向运动的单星。我们创建了一个系统的方法，通过动量守恒和因果关系来寻找由单一-双星相互作用产生的受束缚的三体系统解体所产生的候选RS-RB逃逸对。我们采用的方法是通用的，适用于任何具有5D动力学数据集的星团。我们根据这些标准在围绕开放星团M67的150 pc圆形视野中搜索这些对，M67被用作测试我们方法稳健性的基准星团。我们的结果显示，在初始样本的$10^8$对中，仅有一对RS-RB对符合我们所有的选择标准。

**Summary**:

- (1): 本文的研究背景是逃逸恒星（RSs）的产生机制，特别是与单一-双星相互作用相关的三重解体。

- (2): 过去的方法主要依赖于数值模拟和动态模型，面临的主要问题是无法系统地识别所有可能的逃逸对。本文提出的方法通过动量守恒和因果关系，系统性地确定逃逸对，解决了先前方法存在的局限性，非常有动机。

- (3): 本文的贡献在于提供了一种系统的方法来识别逃逸恒星和逃逸双星之间的关系，扩展了对逃逸恒星形成机制的理解。

- (4): 本文提议的研究方法基于对三体系统解体过程的动量守恒原则，通过分析Gaia DR3数据来寻找RS-RB逃逸对，适用于任何具有5D动力学数据集的星团。

- (5): 在围绕M67的150 pc视野中，本文成功识别出仅有一对符合标准的RS-RB逃逸对，相较于初始的$10^8$对数据，性能表现出一定的有效性，支持了研究目标。


## The Resolved Structure of a Low Metallicity Photodissociation Region
- **Url**: http://arxiv.org/abs/2504.06247v1
- **Authors**: ['Ilyse Y. Clark', 'Karin Sandstrom', 'Mark Wolfire', 'Alberto D. Bolatto', 'Jeremy Chastenet', 'Daniel A. Dale', 'Brandt A. L. Gaches', 'Simon C. O. Glover', 'Javier R. Goicoechea', 'Karl D. Gordon', 'Brent Groves', 'Lindsey Hands', 'Ralf Klessen', 'Ilse De Looze', 'J. D. T. Smith', 'Dries Van De Putte', 'Stefanie K. Walch']
- **Abstrat**: Photodissociation Regions (PDRs) are key to understanding the feedback processes that shape interstellar matter in galaxies. One important type of PDR is the interface between HII regions and molecular clouds, where far-ultraviolet (FUV) radiation from massive stars heats gas and dissociates molecules. Photochemical models predict that the C/CO transition occurs deeper in the PDR compared to the H/H2 transition in low-metallicity environments, increasing the extent of CO-dark H2 gas. This prediction has been difficult to test outside the Milky Way due to the lack of high spatial resolution observations tracing H2 and CO. This study examines a low-metallicity PDR in the N13 region of the Small Magellanic Cloud (SMC) where we spatially resolve the ionization front, the H2 dissociation front, and the C/CO transition using 12CO J=2-1, 3-2 and [CI] (1-0) observations from the Atacama Large Millimeter/sub-mm Array (ALMA) and near-infrared spectroscopy of H2 vibrational lines from the James Webb Space Telescope (JWST). Our analysis shows that the separation between the H/H2 and C/CO boundaries is approximately 0.043 +-0.013(stat.) +- 0.0036(syst.) pc (equivalent to 0."146 +- 0."042 (stat.) +-0."012 (syst.) at the SMC's distance of 62 kpc), defining the spatial extent of the CO-dark H2 region. Compared to our plane-parallel PDR models, we find that a constant pressure model matches the observed structure better than a constant density one. Overall, we find that the PDR model does well at predicting the extent of the CO-dark H2 layer in N13. This study represents the first resolved benchmark for low metallicity PDRs.


**Translated Abstract**: 

光解离区（PDRs）是理解塑造星系中星际物质反馈过程的关键。PDR的一种重要类型是 H II 区和分子云之间的界面，在这里，来自大质量恒星的远紫外线（FUV）辐射加热气体并解离分子。光化学模型预测，在低金属丰度环境中，C/CO 转变发生在 PDR 的更深处，从而增加了 CO 暗 H2 气体的范围。这一预测因缺乏追踪 H2 和 CO 的高空间分辨率观测而难以在银河系外进行验证。本研究考察了小麦哲伦云（SMC）N13 区域的低金属丰度 PDR，在此我们通过阿塔卡马大型毫米亚毫米阵列（ALMA）的 12CO J=2-1、3-2 和 [CI] (1-0) 观测，以及詹姆斯·韦布空间望远镜（JWST）的 H2 振动线近红外光谱，空间解析了电离前沿、H2 解离前沿和 C/CO 转变。我们的分析表明 H/H2 和 C/CO 边界之间的分离约为 0.043 ± 0.013（统计）± 0.0036（系统）pc（相当于在 SMC 距离 62 kpc 时的 0.′′146 ± 0.′′042（统计）± 0.′′012（系统）），定义了 CO 暗 H2 区的空间范围。与我们的平行 PDR 模型相比，我们发现常压模型比常密度模型更好地匹配观测到的结构。总体而言，我们发现PDR模型在预测 N13 中 CO 暗 H2 层的范围方面表现良好。本研究代表了低金属丰度 PDR 的第一个解析基准。

**Summary**:

- (1): 本文研究的背景是光解离区（PDRs），其在理解星际物质反馈过程中的关键作用，特别关注 H II 区与分子云之间的界面。

- (2): 过去的方法主要依赖于光化学模型，但由于缺乏高空间分辨率的观测数据来追踪 H2 和 CO，这使得验证模型的预测变得困难。本文通过使用 ALMA 和 JWST 的高分辨率观测，提出了一种新的方法，能够更清晰地解析 PDR 的结构。

- (3): 论文的贡献在于首次分辨出低金属丰度 PDR N13 区的电离前沿、H2 解离前沿和 C/CO 转变，为理解低金属丰度环境下的 PDR 提供了重要的解析基准。

- (4): 论文采用的研究方法包括使用 ALMA 进行 CO 和 CI 的毫米波观测，同时结合 JWST 的近红外光谱技术，以实现对 PDR 结构的空间解析。

- (5): 本文在小麦哲伦云 N13 区的 CO 暗 H2 层的空间范围上取得了成果，性能良好，支持了其目标，即验证低金属丰度环境中 PDR 的光化学模型。


## SOFIA/upGREAT imaging spectroscopy of the [C II] 158 um fine structure line toward the Sgr A region in the Galactic center
- **Url**: http://arxiv.org/abs/2504.06228v1
- **Authors**: ['A. I. Harris', 'R. Güsten', 'M. A. Requena-Torres', 'D. Riquelme', 'M. R. Morris', 'G. J. Stacey', 'J. Stutzki', 'Y. Okada', 'E. Chambers', 'M. Mertens', 'C. Fischer']
- **Abstrat**: We present SOFIA/upGREAT velocity-resolved spectral imaging and analysis of the 158 um [C II] spectral line toward the central 80 by 43\,pc region of the Central Molecular Zone of the Galaxy. The field we imaged with 14" (0.6 pc) spatial and 1 km/s spectral resolution contains the Circum-Nuclear Disk (CND) around the central black hole Sgr A*, the neighboring thermal Arched Filaments, the nonthermal filaments of the Radio Arc, and the three luminous central star clusters. [C II] traces emission from the CND's inner edge to material orbiting at a distance of approximately 6 pc. Its velocity field reveals no sign of inflowing material nor interaction with winds from the Sgr A East supernova remnant. Wide-field imaging of the Sgr A region shows multiple circular segments, including the thermal Arched Filaments, that are centered on a region that includes the Quintuplet cluster. We examine the possibility that the Arched Filaments and other large-scale arcs trace transient excitation events from supernova blast waves. Along the Arched Filaments, comparisons among far-IR fine structure lines show changes in ionization state over small scales and that high-excitation lines are systematically shifted in position from the other lines. These also point to transient fast winds that shocked on the surface of the Arches cloud to produce additional local UV radiation to excite the Arched Filaments on a cloud surface illuminated by UV from hot stars.


**Translated Abstract**: 

我们展示了SOFIA/upGREAT对银河中心中央分子区（Central Molecular Zone）内158 μm [C II] 谱线的速度分辨率光谱成像和分析。我们成像的区域为80×43 pc，图像分辨率为14″（0.6 pc），谱分辨率为1 km/s，其中包含了围绕中央黑洞 Sgr A* 的环核盘（Circum-Nuclear Disk, CND）、邻近的热弧形细丝（Arched Filaments）、无线电弧（Radio Arc）的非热细丝，以及三个位于中心的星团。 [C II] 追踪了从 CND 内缘到大约6 pc距离的物质的发射。 其速度场没有显示出物质流入的迹象，也没有与Sgr A East超新星遗迹的风相互作用。 Sgr A区域的广域成像显示出多个圆形片段，包括热弧形细丝，它们集中在包括五重星团（Quintuplet cluster）的区域。我们研究了弧形细丝和其他大型弧是否指示超新星冲击波的瞬态激发事件。在弧形细丝上，我们比较远红外细结构线在小尺度上的电离状态变化，高激发线的位置系统性地偏移于其他线的位置。这也指向瞬态快速风暴，在弧细丝云表面产生附加的局部紫外线辐射，以激发被热星紫外线照亮的弧形细丝。

**Summary**:

- (1): 本文研究银河中心的结构、物理条件、运动学和动态特征，以获取螺旋星系核的全面视角。 

- (2): 过去的研究主要使用红外和更长波长的光谱观测，受限于可见光和紫外线受到银河平面中分子云的阻挡，且未能充分揭示银河中心的动态和各种结构。本文提出的方法通过SOFIA/upGREAT成像实现高空间和谱分辨率，解决了过去研究中观察角度不清晰的问题，动机充分。

- (3): 本文贡献在于展示了SOFIA/upGREAT对[C II]发射的新分析，揭示了围绕中心黑洞 Sgr A* 的环核盘和热弧形细丝之间的相互作用及其速度场。

- (4): 本文采用SOFIA/upGREAT光谱成像方法，使用14″（0.6 pc）空间分辨率和1 km/s谱分辨率对[C II]进行观测和分析。

- (5): 本文研究在捕捉银河中心的CII发射和速度场上取得了高分辨率表现，该表现能够支持研究目标，揭示银河中心的复杂动态特征。


## Optimal Follow-Up of Gravitational-Wave Events with the UltraViolet EXplorer (UVEX)
- **Url**: http://arxiv.org/abs/2502.17560v2
- **Authors**: ['Leo P. Singer', 'Alexander W. Criswell', 'Sydney C. Leggio', 'R. Weizmann Kiendrebeogo', 'Michael W. Coughlin', 'Hannah P. Earnshaw', 'Suvi Gezari', 'Brian W. Grefenstette', 'Fiona A. Harrison', 'Mansi M. Kasliwal', 'Brett M. Morris', 'Erik Tollerud', 'S. Bradley Cenko']
- **Abstrat**: The UltraViolet EXplorer (UVEX) is a wide-field ultraviolet space telescope selected as a NASA Medium-Class Explorer (MIDEX) mission for launch in 2030. UVEX will undertake deep, cadenced surveys of the entire sky to probe low mass galaxies and explore the ultraviolet (UV) time-domain sky, and it will carry the first rapidly deployable UV spectroscopic capability for a broad range of science applications. One of UVEX's prime objectives is to follow up gravitational wave (GW) binary neutron star mergers as targets of opportunity (ToOs), rapidly scanning across their localization regions to search for their kilonova (KN) counterparts. Early-time multiband ultraviolet light curves of KNe are key to explaining the interplay between jet and ejecta in binary neutron star mergers. Owing to high Galactic extinction in the ultraviolet and the variation of GW distance estimates over the sky, the sensitivity to kilonovae can vary significantly across the GW localization and even across the footprint of a single image given UVEX's large field of view. Good ToO observing strategies to trade off between area and depth are neither simple nor obvious. We present an optimal strategy for GW follow-up with UVEX in which exposure time is adjusted dynamically for each field individually to maximize the overall probability of detection. We model the scheduling problem using the expressive and powerful mathematical framework of mixed integer linear programming (MILP), and employ a state-of-the-art MILP solver to automatically generate observing plan timelines that achieve high probabilities of kilonova detection. We have implemented this strategy in an open-source astronomical scheduling software package called the Multi-Mission Multi-Messenger Observation Planning Toolkit (M4OPT), on GitHub at https://github.com/m4opt/m4opt.


**Translated Abstract**: 

《紫外线探测器（UltraViolet EXplorer，UVEX）》是一款广域紫外线空间望远镜，已被选为NASA的中型探测器（Medium-Class Explorer，MIDEX）任务，计划在2030年发射。UVEX将进行深度、定期的全天空调查，探测低质量星系并探索紫外线（UV）时间域天空，并将携带第一种快速可部署的UV光谱能力，适用于广泛的科学应用。UVEX的主要目标之一是跟进引力波（GW）双中子星并合事件，作为机会目标（Targets of Opportunity，ToOs），迅速扫描其定位区域，寻找其千新星（Kilonova，KN）伴星。早期多波段紫外光曲线对于解释双中子星并合中喷流与抛射物之间的相互作用至关重要。由于在紫外线中的高银河面灭光和GW距离估计在天空中变化的影响，千新星的灵敏度在GW定位区域以及单幅图像的覆盖范围内可能显著变化。在面积与深度之间权衡的良好ToO观测策略并不简单。我们提出了一种针对GW后续观测的优化策略，其中曝光时间根据每个单独区域动态调整，以最大化整体探测概率。我们使用混合整数线性规划（Mixed Integer Linear Programming，MILP）的数学框架对调度问题进行建模，并利用最先进的MILP求解器自动生成实现高千新星探测概率的观测计划时间表。我们将该策略实施在一个名为Multi-Mission Multi-Messenger Observation Planning Toolkit（M4OPT）的开源天文调度软件包中，网址为https://github.com/m4opt/m4opt。

**Summary**:

- (1): 该研究背景为探测引力波双中子星并合事件及其对应的千新星，特别是在早期紫外线发射的研究中存在显著缺口。

- (2): 过去的方法通常依赖于固定曝光时间与常规观测策略，导致灵敏度及探测概率不均。相比之下，提出的方法允许根据实际情况动态调整曝光时间，从而优化每个区域的探测概率，解决了传统方法中的灵敏度与深度权衡问题，具有良好的动机。

- (3): 论文的贡献在于设计并实现了一种通过动态调整曝光时间的策略，以提高千新星的检测率，并结合了先进的数学调度方法。

- (4): 本文提出的研究方法使用混合整数线性规划（MILP）对调度问题进行建模，结合最先进的求解器生成有效的观测计划。

- (5): 该方法主要任务为优化GW事件的跟踪观测计划，已实现高千新星探测概率，支持其在紫外线时间域研究目标上的实现。


## Impact of MvdW Equation of State and Neutrino Mass on r and s Process Heavy Element Nucleosynthesis in Spiral, Elliptical and Dwarf Galactic Environments and Kilonovae Events
- **Url**: http://arxiv.org/abs/2504.06191v1
- **Authors**: ['Keith Andrew', 'Eric Steinfelds', 'Kristopher Andrew']
- **Abstrat**: We present an analysis of heavy element production with massive neutrinos in galaxies of varying types (spiral, elliptical, and dwarf) and kilonovae events by incorporating a Multicomponent van der Waals (MvdW) equation of state (EoS) for the opacity functions. This EoS is applied to derive opacities and calculate the yields of isotopes formed in r-process and s-process nucleosynthesis, with and without the influence of neutrino masses or oscillations. We look at both the lanthanide and actinide sequences using the MvdW parameters that involve the interaction strength and excluded volume effects. Our results reflect the characteristic differences found in r and s processes in the synthesis and long-term evolution of isotopes from the U, Th, and Sr chain across galactic environments. The inclusion of neutrino masses enhances the neutron-to-proton ratio, favoring heavier r-process isotopes and altering the overall galactic yields by cross section suppression. These findings offer insights into the interplay of nuclear physics and astrophysical environments, highlighting the sensitivity of nucleosynthetic pathways to EoS modifications and neutrino physics. We compare these results to metallicity profiles of similar models: the Galactic Leaky Box, the Galactic Inflow, and the Galactic Closed Box models and to the kilonova event GW170781.


**Translated Abstract**: 

我们通过采用多组分范德瓦尔斯（MvdW）状态方程（EoS）分析了在不同类型星系（螺旋星系、椭圆星系和矮星系）及快速光变事件中伴随重元素产生的质量中微子对 r 过程和 s 过程核合成的影响。该 EoS 用于推导不透明度并计算在 r 过程和 s 过程核合成中形成的同位素产额，研究中考虑了中微子质量和振荡的影响。我们使用 MvdW 参数进行的研究侧重于镧系和锕系元素的序列，反映了不同类型星系在 U、Th 和 Sr 链的同位素合成及其长期演化中的特征差异。中微子质量的引入增强了中子与质子的比率，利于较重的 r 过程同位素形成，并通过交叉截面抑制改变了整体星系产量。这些发现为核物理与天体物理环境之间的相互作用提供了洞察，突显了核合成通路对 EoS 修改和中微子物理的敏感性。我们将这些结果与经典模型（如银河泄漏模型、银河流入模型和银河封闭模型）的金属丰度谱以及快速光变事件 GW170817 进行了比较。

**Summary**:

- (1): 本文探讨了中微子质量对不同类型星系（螺旋、椭圆和矮星系）和快速光变事件中重元素生成的影响，主要针对核合成过程中 r 过程和 s 过程的差异。

- (2): 过去的方法侧重于使用经典的核合成模型，但未考虑中微子质量和相互作用对同位素生成的影响。本文提出的 MvdW EoS 显著增强了对这些影响的理解，从而解决了核合成路径敏感性问题，具有良好的理论动机。

- (3): 本文的贡献在于揭示了中微子质量如何通过影响中子与质子的比率，改变 r 过程同位素的生成，从而影响重元素的观测产量。

- (4): 本文的方法论包括使用 MvdW 方程推导不透明度，并计算在 r 过程和 s 过程中核合成的同位素产量，分析过程中考虑了中微子的质量和振荡。

- (5): 论文的方法达到的任务是评估不同星系环境下重元素的产量，通过与已有模型对比，支持理论预测的金属丰度谱。这一性能足以验证其目标的合理性。


## Primordial Features in light of the Effective Field Theory of Large Scale Structure
- **Url**: http://arxiv.org/abs/2504.06183v1
- **Authors**: ['Rodrigo Calderon', 'Theo Simon', 'Arman Shafieloo', 'Dhiraj Kumar Hazra']
- **Abstrat**: While the simplest inflationary models predict a power-law form of the primordial power spectrum (PPS), various UV complete scenarios predict features on top of the standard power law that leave characteristic imprints in the late-time distribution of matter, encoded in the galaxy power spectrum. In this work, we assess the validity of the Effective Field Theory of Large Scale Structure (EFTofLSS) and the IR-resummation scheme of PyBird in the context of primordial (oscillatory) features. We find an excellent agreement at the level of the matter power spectrum between N-body simulations and the one-loop EFT predictions, for models commonly studied in the literature. We then apply the EFTofLSS to the galaxy power spectrum measurements from BOSS LRG and eBOSS QSO to constrain specific global and local features in the PPS. We demonstrate that while such features can improve the fit to cosmic microwave background (CMB) data, they may result in a poorer fit to clustering measurements at low redshift. The resulting constraints on the amplitude of the primordial oscillations are competitive with those obtained from CMB data, despite the well-known damping of oscillations due to non-linear structure formation processes. For the first time in this context, we jointly analyze the galaxy power spectrum (monopole and quadrupole) in combination with Planck CMB data to derive strong constraints on the amplitude of primordial features. This work highlights the EFTofLSS as a powerful tool for testing early universe scenarios on scales that complement CMB observations.


**Translated Abstract**: 
虽然最简单的膨胀模型预测原始功率谱（PPS）呈幂律形式，但各种 UV 完整场景预测出在标准幂律之上存在特征，这些特征在物质的晚期分布中留下特征印痕，记录在银河系功率谱中。在本研究中，我们评估有效大尺度结构理论（EFTofLSS）和PyBird的IR重整化方案在原始（振荡）特征背景下的有效性。我们发现，对于文献中常研究的模型，N体模拟与一循环EFT预测在物质功率谱水平上的一致性非常好。随后，我们利用EFTofLSS对BOSS LRG和eBOSS QSO的银河系功率谱测量进行应用，以约束PPS中的特定全局和局部特征。我们证明，虽然这些特征可以改善对宇宙微波背景（CMB）数据的拟合，但它们可能导致对低红移聚类测量的拟合更差。尽管由于非线性结构形成过程的阻尼现象，我们对原始振荡幅度的约束与CMB数据获得的结果具有竞争力。这一工作首次在这种背景下联合分析了银河系功率谱（单极和四极）与Planck CMB数据，以得出对原始特征幅度的强约束。这项工作强调了EFTofLSS作为一个强有力的工具，用于在与CMB观测互补的尺度上测试早期宇宙场景。

**Summary**:

- (1): 本文的研究背景是，尽管简单的膨胀模型预测原始功率谱呈现幂律形态，但各种UV完整的模型场景预测存在特征，这些特征在晚期物质分布中产生显著的影响，尤其是在银河系功率谱中。

- (2): 过去的方法主要依赖于线性扰动理论来约束原始特征，但在小尺度上，这种方法未能捕捉非线性效应，导致振荡特征的预测不准确。本文提出的EFTofLSS方法能够处理非线性效应，从而提高了振荡特征的约束效果，并与N体模拟结果保持一致，显示出该方法的有效性和合理性。

- (3): 本文的贡献在于首次联合分析银河系功率谱与CMB数据，并使用EFTofLSS方法有效约束原始特征的幅度，展示了这一理论框架在早期宇宙物理学研究中的强大应用潜力。

- (4): 本文的研究方法是利用有效大尺度结构理论（EFTofLSS），结合N体模拟和IR重整化方案，对BOSS和eBOSS的银河系功率谱进行分析，以推导出对原始振荡的幅度约束。

- (5): 本文的方法在推导银河系功率谱与CMB数据的结合上取得了强约束，展示了在处理宇宙初始条件时的优越性，并为进一步的观测项目（如DESI、LSST和Euclid）提供了有力的支持。


## On Soft Clustering For Correlation Estimators: Model Uncertainty, Differentiability, and Surrogates
- **Url**: http://arxiv.org/abs/2504.06174v1
- **Authors**: ['Edward Berman', 'Sneh Pandya', 'Jacqueline McCleary', 'Marko Shuntov', 'Caitlin Casey', 'Nicole Drakos', 'Andreas Faisst', 'Steven Gillman', 'Ghassem Gozaliasl', 'Natalie Hogg', 'Jeyhan Kartaltepe', 'Anton Koekemoer', 'Wilfried Mercier', 'Diana Scognamiglio', 'COSMOS-Web', ':', 'The JWST Cosmic Origins Survey']
- **Abstrat**: Properly estimating correlations between objects at different spatial scales necessitates $\mathcal{O}(n^2)$ distance calculations. For this reason, most widely adopted packages for estimating correlations use clustering algorithms to approximate local trends. However, methods for quantifying the error introduced by this clustering have been understudied. In response, we present an algorithm for estimating correlations that is probabilistic in the way that it clusters objects, enabling us to quantify the uncertainty caused by clustering simply through model inference. These soft clustering assignments enable correlation estimators that are theoretically differentiable with respect to their input catalogs. Thus, we also build a theoretical framework for differentiable correlation functions and describe their utility in comparison to existing surrogate models. Notably, we find that repeated normalization and distance function calls slow gradient calculations and that sparse Jacobians destabilize precision, pointing towards either approximate or surrogate methods as a necessary solution to exact gradients from correlation functions. To that end, we close with a discussion of surrogate models as proxies for correlation functions. We provide an example that demonstrates the efficacy of surrogate models to enable gradient-based optimization of astrophysical model parameters, successfully minimizing a correlation function output. Our numerical experiments cover science cases across cosmology, from point spread function (PSF) modeling efforts to gravitational simulations to galaxy intrinsic alignment (IA).


**Translated Abstract**: 正确估计不同空间尺度间物体的相关性需要进行 $\mathcal{O}(n^2)$ 距离计算。因此，大多数广泛采用的相关性估计软件包使用聚类算法来近似局部趋势。然而，量化这种聚类所引入误差的方法仍未受到足够研究。为此，我们提出了一种基于概率的算法，用于估计相关性，通过模型推断量化由于聚类造成的无确定性。这种软聚类分配使得相关性估计器在理论上对其输入目录是可微的。此外，我们构建了一个关于可微相关函数的理论框架，描述其相对于现有替代模型的效用。值得注意的是，我们发现重复的规范化和距离函数调用降低了梯度计算的速度，而稀疏雅可比矩阵则破坏了精度，这表明近似或替代方法对于从相关性函数获得精确梯度是必要的。为此，我们在最后讨论了替代模型作为相关性函数的代理。我们提供了一个示例，展示了替代模型在天体物理模型参数的基于梯度的优化中的有效性，成功最小化相关函数的输出。我们的数值实验涵盖了多种宇宙学科学案例，从点扩散函数（PSF）建模到引力模拟以及星系内在排列（IA）。

**Summary**:

- (1): 本文研究了在不同空间尺度上，如何更有效地估计对象之间的相关性，揭示了现有方法在处理相关性计算时的计算复杂性。

- (2): 传统方法通常使用聚类算法来简化计算，但对聚类引入误差的量化研究不足。新方法通过概率论重新构建对象与聚类中心的关联，量化聚类的不确定性，解决了传统方法中聚类误差被认为微不足道的假设。

- (3): 本文的贡献在于提出了一种软聚类算法，使相关估计器理论上具备可微性，并讨论了可微相关函数与现有模型的优劣。

- (4): 论文提出的研究方法包括使用概率性聚类来测量相关性，并建立理论框架，使得通过梯度优化模型参数成为可能。

- (5): 在多个宇宙学任务中，如PSF建模和引力模拟等，方法表现出良好的效能，通过数值实验验证了模型的有效性，为其研究目标提供了支持。


## Investigating Embedded Structures and Gas Kinematics in the IRDC Hosting Bubble N59-North
- **Url**: http://arxiv.org/abs/2504.06170v1
- **Authors**: ['A. K. Maity', 'L. K. Dewangan', 'O. R. Jadhav', 'Saurabh Sharma', 'Ram Kesh Yadav', 'Y. Fukui', 'H. Sano', 'T. Inoue']
- **Abstrat**: We present a multi-wavelength study of an extended area hosting the bubble N59-North to explore the physical processes driving massive star formation (MSF). The Spitzer 8 $\mu$m image reveals an elongated/filamentary infrared-dark cloud (length $\sim$28 pc) associated with N59-North, which contains several protostars and seven ATLASGAL dust clumps at the same distance. The existence of this filament is confirmed through $^{13}$CO and NH$_3$ molecular line data in a velocity range of [95, 106] km s$^{-1}$. All dust clumps satisfy Kauffmann & Pillai's condition for MSF. Using Spitzer 8 $\mu$m image, a new embedded hub-filament system candidate (C-HFS) is investigated toward the ATLASGAL clump, located near the filament's central region. MeerKAT 1.3 GHz continuum emission, detected for the first time toward C-HFS, reveals an ultracompact HII region driven by a B2-type star, suggesting an early stage of HFS with minimal feedback from the young massive star. The comparison of the position-velocity (PV) and position-position-velocity (PPV) diagrams with existing theoretical models suggests that rotation, central collapse, and end-dominated collapse are not responsible for the observed gas motion in the filament. The PPV diagram indicates the expansion of N59-North by revealing blue- and red-shifted gas velocities at the edge of the bubble. Based on comparisons with magnetohydrodynamic simulations, this study suggests that cloud-cloud collision (CCC) led to the formation of the filament, likely giving it a conical structure with gas converging toward its central region, where C-HFS is located. Overall, the study supports multi-scale filamentary mass accretion for MSF, likely triggered by CCC.


**Translated Abstract**: 

我们展示了对位置 N59-North 的气泡周围一个扩展区域的多波长研究，以探讨驱动大质量星形成 (MSF) 的物理过程。Spitzer 8 μm 图像显示出一个与 N59-North 相关的细长/丝状红外暗云（长度约 28 pc），该云中包含多个原恒星和七个在相同距离的 ATLASGAL 尘埃聚集体。通过 $^{13}$CO 和 NH$_3$ 分子线数据确认了这一丝状结构的存在，速度范围为 [95, 106] km s$^{-1}$。所有尘埃聚集体都符合 Kauffmann & Pillai 的 MSF 条件。使用 Spitzer 8 μm 图像，我们调查了位于丝状体中央区域附近的 ATLASGAL 聚集体的新嵌入式中心-丝状体系统候选者 (C-HFS)。首次通过 MeerKAT 1.3 GHz 连续波辐射探测到 C-HFS，揭示了由 B2 型恒星驱动的超紧凑 HII 区，暗示了此 HFS 处于早期阶段，年轻的大质量星反馈较小。位置-速度 (PV) 和位置-位置-速度 (PPV) 图的比较显示，旋转、中心塌缩和末端主导塌缩并不负责丝状体中观察到的气体运动。PPV 图显示 N59-North 的扩展，揭示了气泡边缘的蓝移和红移气体速度。基于与磁流体动力学模拟的比较，本研究表明云-云碰撞 (CCC) 导致了丝状体的形成，可能使其具有圆锥结构，气体向中央区域汇聚，C-HFS 位于其中。总体而言，该研究支持多尺度丝状质量吸积的 MSF，可能是由 CCC 触发的。

**Summary**:

- (1): 本文研究了大质量星形成 (MSF) 的驱动物理过程，关注的是与气泡 N59-North 相关的扩展区域，特别是其内的细长丝状红外暗云。

- (2): 过去的研究主要使用单一波长或偷看到的数据，未能全面探讨结构的形成及其对大质量星形成的影响。与现有方法不同，本文提出的多波长研究结合了多个数据集，能够更全面地分析环境和星形成过程，有效解决了以往研究的局限性。

- (3): 本文的贡献在于揭示了与 N59-North 区域相关的丝状云的存在及其物理环境，识别了新的嵌入式中心-丝状体系统候选者，并提供了关于大质量星形成过程中云-云碰撞的重要证据。

- (4): 本研究的方法论包括多波长数据采集和分析，利用 Spitzer 和 MeerKAT 的数据对气体运动和结构进行了 kinematic 分析，并与磁流体动力学模型进行了比较。

- (5): 本文在 N59-North 区域的星形成过程中观察到了新的结构及其气体运动，表明存在云-云碰撞。这一结果支持其研究目标，即理清大质量星形成初期的环境条件及其动力学机制。


## The low multipoles in the Pantheon+SH0ES data
- **Url**: http://arxiv.org/abs/2403.17741v2
- **Authors**: ['Francesco Sorrenti', 'Ruth Durrer', 'Martin Kunz']
- **Abstrat**: In previous work we have shown that the dipole in the low redshift supernovae of the Pantheon+SH0ES data does not agree with the one inferred from the velocity of the solar system as obtained from CMB data. We interpreted this as the presence of significant bulk velocities. In this paper we study the monopole, dipole and quadrupole in the Pantheon+SH0ES data. We find that in addition to the dipole also both, the monopole and the quadrupole are detected with high significance. They are of similar amplitudes as the bulk flow. While the monopole is only significant at very low redshift, the quadrupole even increases with redshift.


**Translated Abstract**: 

在之前的工作中，我们已经表明，Pantheon+SH0ES数据中低红shift超新星的偶极与从CMB数据推断的太阳系速度不一致。我们将此解释为存在显著的整体速度。在本文中，我们研究了Pantheon+SH0ES数据中的单极、偶极和四极。我们发现除了偶极外，单极和四极也以高显著性被检测到。它们与整体流动的幅度相似。虽然单极仅在非常低红shift时显著，四极甚至随着红shift的增加而增加。

**Summary**:

- (1): 本文的研究背景是标准宇宙学假设宇宙物质和辐射的统计均匀和各向同性分布，但近年来的观测结果表明与这一假设存在偏差。

- (2): 过去的方法主要基于CMB数据推断太阳系速度，分析结果往往得出与超新星数据不一致的偶极值，且对整体运动的理解较为简化。本文提出的研究方法通过研究更多的多极，比如单极和四极，提供了对整体速度的更全面分析，从而缓解了现有方法中对偶极分析的局限性，并对结果的物理解释有更充分的动机。

- (3): 论文的贡献在于首次高显著性地检测到Pantheon+SH0ES数据中的单极和四极，验证了它们的存在以及与整体流动的相似幅度。

- (4): 本文采用的研究方法包括分析Pantheon+SH0ES数据中的单极、偶极和四极，同时考虑红shift的影响，并进行了多种检验和系统误差检查。

- (5): 本文方法在识别Pantheon+SH0ES数据中的多极性方面取得了显著成果，证明了检测到的单极和四极与整体流动相当，可以支持提出的宇宙学目标。


## Constraints on dark energy and modified gravity from the BOSS Full-Shape and DESI BAO data
- **Url**: http://arxiv.org/abs/2409.08971v2
- **Authors**: ['Petter Taule', 'Marco Marinucci', 'Giorgia Biselli', 'Massimo Pietroni', 'Filippo Vernizzi']
- **Abstrat**: We constrain dark energy and modified gravity within the effective field theory of dark energy framework using the full-shape BOSS galaxy power spectrum, combined with Planck cosmic microwave background (CMB) data and recent baryon acoustic oscillations (BAO) measurements from DESI. Specifically, we focus on a varying braiding parameter $\alpha_{\rm B}$, a running of the ``effective'' Planck mass $\alpha_{\rm M}$, and a constant dark energy equation of state $w$. The analysis is performed with two of these parameters at a time, including all the other standard cosmological parameters and marginalizing over bias and nuisance parameters. The full-shape galaxy power spectrum is modeled using the effective field theory of large-scale structure up to 1-loop order in perturbation theory. We find that the CMB data is most sensitive to $\alpha_{\rm B}$, and that adding large-scale structure information only slightly changes the parameter constraints. However, the large-scale structure data significantly improve the bounds on $\alpha_{\rm M}$ and $w$ by a factor of two. This improvement is driven by background information contained in the BAO, which breaks the degeneracy with $H_0$ in the CMB. We confirm this by comparing the BOSS full-shape information with BOSS BAO, finding no significant differences. This is likely to change with future high-precision full-shape data from Euclid and DESI however, to which the pipeline developed here is immediately applicable.


**Translated Abstract**: 

我们在有效的暗能量场论框架下，使用全形 BOSS 星系功率谱，结合 Planck 宇宙微波背景（CMB）数据和 DESI 最近的重子声波振荡（BAO）测量，来限制暗能量和修正引力。我们专注于变化的编织参数 $\alpha_{\rm B}$、“有效”普朗克质量的变化 $\alpha_{\rm M}$ 和常数暗能量状态方程 $w$。分析是以两个这些参数为基础进行的，同时包括所有其他标准宇宙学参数，并对偏差和杂散参数进行边际化。全形星系功率谱使用有效场论的规模结构模型，达到一环节的微扰理论。我们发现 CMB 数据对 $\alpha_{\rm B}$ 的敏感度最高，而添加大尺度结构信息仅略微改变参数约束。然而，大尺度结构数据显著改善了对 $\alpha_{\rm M}$ 和 $w$ 的限制，提高了两倍。这种改进是由 BAO 的背景信息推动的，它打破了 CMB 中与 $H_0$ 的简并性。我们通过对比 BOSS 全形信息与 BOSS BAO，发现没有显著差异。然而，随着未来来自 Euclid 和 DESI 的高精度全形数据的出现，这种情况可能会改变，而这里开发的管道是立即适用的。

**Summary**:

- (1): 本文的研究背景是测试广义相对论（GR）在宇宙尺度上的有效性以及揭示暗能量（DE）的本质。

- (2): 过去的方法主要使用宇宙微波背景（CMB）、BAO、fσ8 等数据进行分析。然而，这些方法在对新异的暗能量模型进行约束时存在理论先验不够充分的问题。本文提出的方法基于有效的暗能量场论（EFTofDE），通过适应性场论模型描述 DE 和修正引力，从而避免不必要的理论假设。

- (3): 本文的贡献在于利用全形 BOSS 星系功率谱和 DESI 的 BAO 数据，提供了对暗能量及修正引力模型的更严格约束，并展示了这些约束相较于仅依赖 CMB 的方法有显著改善。

- (4): 本文的研究方法包括使用1环节的微扰理论模型，通过有效场论（EFTofLSS）对全形星系功率谱进行建模，结合 CMB 和 BAO 数据进行参数约束分析。

- (5): 本文在对 $\alpha_{\rm M}$ 和 $w$ 以及暗能量状态方程的约束任务上，实现了在数据分析中参数约束的显著提高。获得的约束结果可以支持其目标，即有效限制不同暗能量和修正引力模型的参数。


## Dimming Starlight with Dark Compact Objects
- **Url**: http://arxiv.org/abs/2409.08322v2
- **Authors**: ['Joseph Bramante', 'Melissa D. Diamond', 'J. Leo Kim']
- **Abstrat**: We demonstrate a new technique to search for dark compact objects. When dark matter comprising a dark compact object interacts with photons, the compact object can disperse light traveling though it. As these objects pass between Earth and a distant star, they act as "lampshades" that dim the star. We examine how dimming effects from clumps of dark matter in the Galaxy could be searched for in microlensing surveys, which measure the brightness of stars as a function of time. Using the EROS-2 and OGLE surveys, we show that a dimming analysis of existing data can be used to constrain dark sectors, and could be used to discover dark matter in compact objects.


**Translated Abstract**: 
我们展示了一种搜索暗紧凑物体的新方法。当由暗物质构成的暗紧凑物体与光子相互作用时，该紧凑物体可以散射穿过它的光。在这些物体从地球经过并导航到遥远星星时，它们充当“灯罩”，使星星变暗。我们考察了银河中暗物质团块的变暗效应如何在微透镜观测中被寻找，这些观测测量星星亮度随时间的变化。利用EROS-2和OGLE观测，我们表明，对现有数据的变暗分析可用于限制暗物质区域，并可能用于发现紧凑物体中的暗物质。

**Summary**:

- (1): 本文的研究背景是探索暗物质的成因及其存在方式，特别关注原生黑洞（PBHs）和大质量紧凑晕物体（MACHOs），以及它们作为暗物质候选者的潜力。

- (2): 以往的方法主要集中在寻找重的紧凑物体，通常使用微透镜观测来寻找星光的放大效应，但这些方法对较轻或扩展的物体敏感性不足。提议的方法借助微透镜调查中的变暗效应，可使研究者能够探测这些本来被忽视的物体，并通过捕捉光的散射来解决以往对轻暗物体观察的限制。这个方法在理论上是有充分动机的。

- (3): 本文的贡献在于提出了一种新的分析方法，能够通过分析星光的变暗来约束暗物质粒子的性质，拓宽了对暗紧凑物体的探测范围。

- (4): 本文所提出的研究方法是，通过微透镜观测来分析暗物质团块如何通过散射光子来减弱来自遥远星星的光亮，建立了一种可以对现有微透镜数据进行细致分析的框架。

- (5): 该方法应用于对EROS-2和OGLE微透镜观测的数据进行分析，成功地限制了暗物质粒子的质量和光子散射横截面的关系。该方法的性能提高了对暗物质的理解，有助于实现对紧凑暗物体的发现。


## Photometric segregation of dwarf and giant FGK stars using the SVO Filter Profile Service and photometric tools
- **Url**: http://arxiv.org/abs/2406.03310v4
- **Authors**: ['Carlos Rodrigo', 'Patricia Cruz', 'John F. Aguilar', 'Alba Aller', 'Enrique Solano', 'Maria Cruz Galvez-Ortiz', 'Francisco Jimenez-Esteban', 'Pedro Mas-Buitrago', 'Amelia Bayo', 'Miriam Cortes-Contreras', 'Raquel Murillo-Ojeda', 'Silvia Bonoli', 'Javier Cenarro', 'Renato Dupke', 'Carlos Lopez-Sanjuan', 'Antonio Marin-Franch', 'Claudia Mendes de Oliveira', 'Mariano Moles', 'Keith Taylor', 'Jesus Varela', 'Hector Vazquez Ramio']
- **Abstrat**: This paper is focused on the segregation of FGK dwarf and giant stars through narrow-band photometric data using the Spanish Virtual Observatory (SVO) Filter Profile Service and associated photometric tools. We selected spectra from the MILES, STELIB, and ELODIE stellar libraries, and used SVO photometric tools to derive the synthetic photometry in 15 J-PAS narrow filters, which were especially selected to cover spectral features sensitive to gravity changes. Using machine-learning techniques as the Gaussian mixture model and the support vector machine, we defined several criteria based on J-PAS colours to discriminate between dwarf and giant stars. We selected five colour-colour diagrams that presented the most promising separation between both samples. Our results show an overall accuracy in the studied sample of $\sim$0.97 for FGK stars, although a dependence on the luminosity type and the stellar effective temperature was found. We also defined a colour-temperature relation for dwarf stars with effective temperatures between 4\,000 and 7\,000\,K, which allows one to estimate the stellar effective temperature from four J-PAS filters ($J0450$, $J0510$, $J0550$, and $J0620$). Additionally, we extended the study to M-type giant and dwarf stars, achieving a similar accuracy to that for FGK stars.


**Translated Abstract**: 

本论文的重点是通过窄带光度数据对FGK矮星和巨星进行分离，使用西班牙虚拟天文台（SVO）过滤器配置文件服务及相关光度工具。我们选择了来自MILES、STELIB和ELODIE恒星库的光谱，并使用SVO光度工具在15个J-PAS窄波段过滤器中推导出合成光度，这些过滤器特别选择以覆盖对重力变化敏感的光谱特征。利用机器学习技术如高斯混合模型和支持向量机，我们根据J-PAS颜色定义了多个标准，以区分矮星和巨星。我们选择了五个表现出最佳样本分离的颜色-颜色图。我们的结果显示，FGK星的整体准确率约为0.97，尽管发现了与光度类型和恒星有效温度的依赖关系。我们还为有效温度在4000至7000 K之间的矮星定义了颜色-温度关系，可通过四个J-PAS过滤器（J0450、J0510、J0550和J0620）估计恒星的有效温度。此外，我们将研究扩展到M型巨星和矮星，取得了与FGK星相似的准确率。

**Summary**:

- (1): 本文研究的背景是为了在大规模多波段观测中，从光度数据中有效分离FGK矮星和巨星，以改善银河结构、动力学等研究的质量。

- (2): 过去的方法主要依赖于传统的光度测量和统计技术，面临混合样本问题，这可能导致星类分辨率低。本文采用机器学习技术（如高斯混合模型和支持向量机），通过J-PAS颜色的标准来提升识别能力，克服了过去方法的局限性，从而在实现光度测量的一致性和准确性方面更具优势。

- (3): 本文的贡献在于定义了基于颜色的信息标准来有效区分FGK星的矮星和巨星，并扩展到M型星，提供了高精确度的分类方法。

- (4): 本文研究方法包括选择来自多个恒星库的光谱数据，利用SVO光度工具获取合成光度，与机器学习算法结合，构建颜色-颜色图来进行星体分类。

- (5): 本文在FGK星分类任务中实现了约0.97的整体准确率，证明提出的方法能够有效支持识别目标，为后续研究提供了可靠的样本基础。


## Supernovae at Distances < 40 Mpc: II. Supernova Rate in the Local Universe
- **Url**: http://arxiv.org/abs/2504.04507v2
- **Authors**: ['Xiaoran Ma', 'Xiaofeng Wang', 'Jun Mo', 'D. Andrew Howell', 'Craig Pellegrino', 'Jujia Zhang', 'Chengyuan Wu', 'Shengyu Yan', 'Dongdong Liu', 'Iair Arcavi', 'Zhihao Chen', 'Joseph Farah', 'Estefania Padilla Gonzalez', 'Fangzhou Guo', 'Daichi Hiramatsu', 'Gaici Li', 'Han Lin', 'Jialian Liu', 'Curtis McCully', 'Megan Newsome', 'Hanna Sai', 'Giacomo Terreran', 'Danfeng Xiang', 'Xinhan Zhang']
- **Abstrat**: Context.This is the second paper of a series aiming to determine the birth rates of supernovae in the local Universe. Aims. In this paper, we aim to estimate the SN rates in the local universe and fit the delay-time distribution of SNe Ia to put constraints on their progenitor scenarios. Methods.We performed a Monte-Carlo simulation to estimate the volumetric rates with the nearby SN sample introduced in Paper I of the series. The rate evolution of core-collapse SNe well traces the evolution of cosmic star formation history; while that of SNe Ia involves the convolution of cosmic star-formation history and a two-component delay-time distribution including a power law and a Gaussian component. Results.The volumetric rates of type Ia, Ibc and II SNe are derived as $0.325\pm0.040^{+0.016}_{-0.010}$, $0.160\pm0.028^{+0.044}_{-0.014}$, and $0.528\pm0.051^{+0.162}_{-0.013}$ (in unit of $10^{-4} yr^{-1} Mpc^{-3} h^3_{70}$), respectively. The rate of CCSNe is consistent with previous estimates. The newly derived local SN Ia rate is larger than existing results given at redshifts 0.01 < z < 0.1, favoring an increased rate from the universe at z ~ 0.1 to the local universe. A two-component model can well fit the rate variation, with the power law component accounting for the rate evolution at larger redshifts and the Gaussian component with a delay time of 12.63$\pm$0.38 Gyr accounting for the local rate evolution. This delayed component with such a longer delay time suggests that the progenitors of these SNe Ia were formed at around 1 Gyr after the birth of the universe, which could only be explained by a double-degenerate progenitor scenario. This is evidenced by the comparison with the PTF sample of SNe Ia at z = 0.073, which reveals that the increase in SN Ia rate at z < 0.01 is primarily due to the SNe Ia of massive E and S0 galaxies with old stellar populations.


**Translated Abstract**: 

本论文为一系列研究的第二篇文章，旨在确定局部宇宙中超新星（SNe）的出生率。我们的目标是估计局部宇宙中的超新星率，并拟合Ia型超新星的延迟时间分布，以对其前身情景施加约束。我们通过蒙特卡罗模拟估计了基于第一篇文章中引入的附近超新星样本的体积率。核心坍塌超新星的率演变很好地追踪了宇宙星形成历史的演变，而Ia型超新星的率则涉及到宇宙星形成历史和包含幂律及高斯分量的双成分延迟时间分布的卷积。结果表明，Ia型、Ibc及II型超新星的体积率分别为 $0.325\pm0.040^{+0.016}_{-0.010}$、$0.160\pm0.028^{+0.044}_{-0.014}$ 和 $0.528\pm0.051^{+0.162}_{-0.013}$（单位为 $10^{-4} yr^{-1} Mpc^{-3} h^3_{70}$）。核心坍塌超新星的速率与之前的估算一致。新推导的局部Ia型超新星率大于给定红移0.01 < z < 0.1的现有结果，支持从红移z ~ 0.1到当地宇宙的率增加。一个双成分模型可以很好地拟合率变化，幂律成分负责较高红移的率演变，高斯成分（延迟时间为12.63±0.38 Gyr）则负责局部率演变。这个延迟成分表明这些Ia型超新星的前身在宇宙诞生后约1 Gyr形成，只能通过双重退化前身场景来解释。这一结论通过与红移为0.073的PTF样本的比较得到证实，显示出z < 0.01的Ia型超新星率增加主要源自于具有老年恒星群体的巨型椭圆星系和透镜状星系。基于上述结果，我们估计银河系的超新星率为每世纪3.08±1.29次。

**Summary**:

- (1): 本文研究局部宇宙中超新星的出生率，对超新星的前身情景提供约束。

- (2): 过去的研究主要采用控制时间法进行超新星率测量，但可能存在观测偏见。本文提出的蒙特卡罗模拟方法能更准确地估计超新星的体积率，解决了以往方法中光度选择偏倚的问题。

- (3): 本文的贡献在于通过新的体积率估计，更新了不同类型超新星的出生率，并提供了支持双重退化前身场景的证据。

- (4): 本文采用了蒙特卡罗模拟的方法，结合了先前文献的数据，以推导局部宇宙中超新星的体积率。

- (5): 本文在超新星的出生率任务上取得了新的结果，尤其是局部Ia型超新星率的提高，支持了模型目标的实现。


## The Impact of Molecular Hydrogen Cooling on the Galaxy Formation Threshold
- **Url**: http://arxiv.org/abs/2503.04885v2
- **Authors**: ['Ethan O. Nadler']
- **Abstrat**: We study the impact of molecular (${\rm H_2}$) and atomic (HI) hydrogen cooling on the galaxy formation threshold. We calculate the fraction of dark matter (DM) halos that exceeds a critical mass required for star formation, $M_{\mathrm{crit}}(z)$, as a function of their peak mass. By convolving analytic halo mass accretion histories (MAHs) with models for $M_{\mathrm{crit}}(z)$, we predict that halos with peak virial masses below $\sim 10^8~M_{\mathrm{\odot}}$ can form stars before reionization through ${\rm H_2}$ cooling. These halos remain dark when only HI cooling and reionization are modeled. However, less than $\approx 10\%$ of halos with peak masses below $\sim 10^{7}~M_{\mathrm{\odot}}$ ever exceed $M_{\mathrm{crit}}(z)$, even when ${\rm H_2}$ cooling is included; this threshold is primarily set by relative streaming motion between DM and baryons imprinted at recombination. We obtain similar results using subhalo MAHs from an extremely high-resolution cosmological DM--only zoom-in simulation of a Milky Way (MW) analog (particle mass $6.3\times 10^3~M_{\mathrm{\odot}}$). Based on the abundance of MW satellites, these results imply that at least some known ultra-faint dwarf galaxies formed through ${\rm H_2}$ cooling. This work sharpens predictions for the galaxy formation threshold and demonstrates how its essential features emerge from the underlying distribution of halo growth histories.


**Translated Abstract**: 

我们研究了分子（${\rm H_2}$）和原子（HI）氢冷却对星系形成阈值的影响。我们计算了超出所需星形成临界质量$M_{\mathrm{crit}}(z)$的暗物质（DM）晕的比例，作为其峰值质量的函数。通过将解析的晕质量累积历史（MAHs）与$M_{\mathrm{crit}}(z)$模型卷积，我们预测峰值蓝移质量低于$\sim 10^8~M_{\mathrm{\odot}}$的晕能够通过${\rm H_2}$冷却在再电离之前形成恒星。当仅建模HI冷却和再电离时，这些晕保持黑暗。然而，即使考虑${\rm H_2}$冷却，峰值质量低于$\sim 10^{7}~M_{\mathrm{\odot}}$的晕中也不到$\approx 10\%$的晕会超过$M_{\mathrm{crit}}(z)$；这一阈值主要是由再组合时暗物质和重子之间的相对流动运动设定的。我们使用来自非常高分辨率的宇宙学DM-仅缩放模拟的亚晕的MAHs获得类似结果。基于MW卫星的丰度，这些结果暗示至少一些已知的超微弱矮星系是通过${\rm H_2}$冷却形成的。该工作提高了对星系形成阈值的预测，并展示了其基本特征如何从晕生长历史的基础分布中浮现。

**Summary**:

- (1): 本文研究了分子氢（${\rm H_2}$）与原子氢（HI）冷却对星系形成阈值的影响，这是理解宇宙中早期星系形成及其演化的关键议题。

- (2): 过去的方法主要依赖于宇宙学水动力模拟和半解析模型，从而建立关于$M_{\mathrm{crit}}(z)$的预测。已有研究未充分考虑${\rm H_2}$冷却的影响，导致对低质量晕的星形成能力预测不足。本文的方法结合了H2和HI冷却，提供了更全面的模型，解决了先前方法忽视${\rm H_2}$冷却的问题，具有明确的动机。

- (3): 本文的贡献在于明确了低质量暗物质晕通过${\rm H_2}$冷却形成恒星的潜力，并推测出一些已知的超微弱矮星系可能存在于此过程之下。这一发现加深了对星系形成阈值的理解。

- (4): 本文提出的研究方法使用了晕质量累积历史（MAHs）与星形成临界质量$M_{\mathrm{crit}}(z)$模型的卷积，通过分析不同的氢冷却模式来预测星系形成的可能性。

- (5): 方法实现了对低质量晕在再电离前的星形成能力的详细分析，得出的结果表明少于10%的峰值质量低于$\sim 10^{7}~M_{\mathrm{\odot}}$的晕能够达到$M_{\mathrm{crit}}(z)$，验证了其目标。


## Sleeping Giants Arise: Monitoring the Return of Three Changing-Look Quasars to Their High States
- **Url**: http://arxiv.org/abs/2504.06065v1
- **Authors**: ['Laura Duffy', 'Michael Eracleous', 'John J. Ruan', 'Qian Yang', 'Jessie C. Runnoe']
- **Abstrat**: Changing-look quasars challenge many models of the quasar central engine. Their extreme variability in both the continuum and broad emission-line fluxes on timescales on the order of years is difficult to explain. To investigate the cause of the observed transitions, we present new contemporaneous optical and X-ray observations of three faded changing-look quasars as they return to the high state. Two of these three faded changing-look quasars remained in a quiescent state for more than ten years before returning to a new high state. We find that before, during, and after transition, the spectral energy distributions of all three follow predictions for quasars based on X-ray binary outbursts, suggesting that the mechanism for the change is likely a changing accretion rate causing changes in the accretion flow structure. We also find that, in two of the three cases, the transition between the initial high and low state and the transition between the low and new high state took nearly identical amounts of time, on the order of hundreds of days. This transition timescale is useful for testing theoretical models that attempt to explain the short time scale for the state transition.


**Translated Abstract**: 

改变状态的类星体挑战了很多关于类星体中心引擎的模型。它们在类似于年的时间尺度上，在连续光谱和宽发射线通量上的极端变化难以解释。为了调查观察到的转变原因，我们呈现了三颗褪色的改变状态类星体的新近同时进行的光学和X射线观测，它们正在返回高状态。其中两颗在超过十年的时间里保持静息状态才归回新的高状态。我们发现在转变之前、期间和之后，这三者的谱能量分布均符合基于X射线双星爆发的类星体预测，暗示变化机制可能是改变的吸积率导致吸积流结构的变化。我们还发现，在三者中的两者的初始高状态和低状态之间的转变，以及低状态和新高状态之间的转变，所需的时间几乎相同，约为数百天。这个转变时间尺度对测试试图解释状态转变短时间尺度的理论模型是有用的。

**Summary**:

- (1): 本文的研究背景是改变状态的类星体的极端可变性，这种可变性在连续光谱和宽发射线通量上（通常在数年内发生），挑战现有的类星体中心引擎模型。

- (2): 过去的研究主要依赖于光谱跟踪和时间域调查，存在难以解释的短时间尺度转变现象。本文通过同时进行的光学和X射线观察，提出了基于改变吸积率的机制，解决了现有方法对类星体状态变化机制缺乏清晰解释的问题，这一方法具有良好的动机。

- (3): 本文的贡献在于为三颗褪色的改变状态类星体的状态变化提供了新的光学和X射线观测数据，并通过其谱能量分布确认了基于X射线双星的预测，与已有模型提供了有效的对比。

- (4): 本文提出的研究方法包括对三颗褪色改变状态类星体进行同时的光学和X射线观测，分析每个状态转变期间的谱能量分布。

- (5): 本文的方法在情境中实现了对三颗改变状态类星体的状态变化的详细分析，提供的新观测数据和模型验证支持其目标，即理解类星体状态变化的机制。


## Distance to M87 as the Mode of the Modulus Distribution
- **Url**: http://arxiv.org/abs/2504.06034v1
- **Authors**: ['Mariusz Tarnopolski']
- **Abstrat**: de Grijs and Bono (ApJS 2020, 246, 3) compiled a list of distances to M87 from the literature published in the last 100 years. They reported the arithmetic mean of the three most stable tracers (Cepheids, tip of the red giant branch, and surface brightness fluctuations). The arithmetic mean is one of the measures of central tendency of a distribution; others are the median and mode. The three do not align for asymmetric distributions, which is the case for the distance moduli $\mu_0$ to M87. I construct a kernel density distribution of the set of $\mu_0$ and estimate the recommended distance to M87 as its mode, obtaining $\mu_0 = \left(31.06~\pm~0.001\,\textrm{(statistical)}\,^{+0.04}_{-0.06}\,\textrm{(systematic)}\right)$~mag, corresponding to \linebreak $D=16.29^{+0.30}_{-0.45}$~Mpc, which yields uncertainties smaller than those associated with the mean and median.


**Translated Abstract**: 

de Grijs 和 Bono（ApJS 2020, 246, 3）汇编了过去 100 年文献中关于 M87 距离的列表。他们报告了三种最稳定探测器（造父变星、红巨星分支末端及表面亮度波动）的算术平均值。算术平均是分布的一种集中趋势量度，而中位数和众数则是其他量度。对于 M87 的距离模数 μ_0 的非对称分布，这三者并不一致。我构建了 μ_0 的核密度分布，并估计 M87 的推荐距离为众数，得到 μ_0 = (31.06 ± 0.001 (统计) ^{+0.04}_{-0.06} (系统)) mag，对应于 D = 16.29^{+0.30}_{-0.45} Mpc，所得到的不确定性小于与平均值和中位数相关联的不确定性。

**Summary**:

- (1): 本文的研究背景是 M87 的距离测量，综合了过去 100 年文献中的数据，尤其关注最稳定的距离测量方法。

- (2): 过去使用的测量方法主要包括算术平均，但由于 M87 距离模数的非对称分布，这种方法存在一致性问题。相比之下，本文提出的方法是基于众数的距离估计，利用核密度分布来得到更可靠的距离值，从而有效解决了算术平均所带来的不准确性。

- (3): 本文的贡献在于通过众数估计 M87 的距离，提供了更加精确的距离值和不确定性分析，改进了传统的距离测量方法。

- (4): 本文提出的研究方法是构建 μ_0 的核密度分布，然后从中提取众数作为 M87 的推荐距离。

- (5): 文中在测量 M87 距离任务上达到了 μ_0 = (31.06 ± 0.001) mag 和 D = 16.29^{+0.30}_{-0.45} Mpc 的性能表现，这一结果比传统方法提供了更小的不确定性，能够更好地支持其研究目标。


## NQG III -- Two-Centre Problems, Whirlpool Galaxy and Toy Neutron Stars
- **Url**: http://arxiv.org/abs/2504.06030v1
- **Authors**: ['Richard Durran', 'Aubrey Truman']
- **Abstrat**: In the hunt for WIMPish dark matter and testing our new theory, we extend the results obtained for the Kepler problem in NQG I and NQG II to the Euler two-centre problem and to other classical Hamiltonian systems with planar periodic orbits. In the first case our results lead to quantum elliptical spirals converging to elliptical orbits where stars and other celestial bodies can form as the corresponding WIMP/molecular clouds condense. The examples inevitably involve elliptic integrals as was the case in our earlier work on equatorial orbits of toy neutron stars (see Ref. [27]). Hence this is the example on which we focus in this work on quantisation. The main part of our analysis which leans heavily on Hamilton-Jacobi theory is applicable to any KLMN integrable planar periodic orbits for Hamiltonian systems. The most useful results on Weierstrass elliptic functions needed in these two works we have summarised with complete proofs in the appendix. This has been one of the most enjoyable parts of this research understanding in more detail the genius of Weierstrass and Jacobi. However we have to say that the beautiful simplicity of the Euler two-centre results herein transcend even this as far as we are concerned. At the end of the paper we see how the Burgers-Zeldovich fluid model relates to our set-up through Nelson's stochastic mechanics.


**Translated Abstract**: 

在寻找WIMP型暗物质以及验证我们新理论的过程中，我们将NQG I和NQG II中获得的结果扩展到Euler二中心问题以及其他具有平面周期轨道的经典哈密顿系统。在第一个案例中，我们的结果导致量子椭圆螺旋收敛到椭圆轨道，在这些轨道上，随着相应的WIMP/分子云的凝聚，星体和其他天体可以形成。这些例子不可避免地涉及到椭圆积分，正如我们在玩具中子星的赤道轨道中的早期工作一样（参见文献[27]）。因此，这就是我们在这项量子化工作中关注的例子。我们的分析主要依赖于哈密顿-雅可比理论，适用于任何KLMN可积平面周期轨道的哈密顿系统。我们在附录中总结了这两项工作所需的Weierstrass椭圆函数的最有用结果，并提供了完整的证明。理解Weierstrass和Jacobi的天才是我们研究中最愉快的部分之一。然而，我们必须说，本文中Euler二中心结果的优美简洁超越了这一点。在论文的最后，我们看到Burgers-Zeldovich流体模型如何通过Nelson的随机力学与我们的设置相关联。

**Summary**:

- (1): 该文章研究背景围绕寻找WIMP型暗物质以及验证新的理论。

- (2): 过去的方法主要集中在Kepler问题上，利用量子波函数的渐近分析解释行星及星系的演化。而该方法的局限在于对Euler二中心问题的处理不足。提出的方法通过量子化Euler二中心问题，解决了这一不足，并提供新的解决方案。

- (3): 本文的贡献在于将对哈密顿系统的分析扩展到包含平面周期轨道的新领域，特别是在暗物质研究中具有潜在的应用。

- (4): 论文采用的研究方法依赖于哈密顿-雅可比理论，对KLMN可积平面周期轨道进行分析，结合Weierstrass椭圆函数。

- (5): 该方法针对流体动力学模型以及天体物理问题进行量子描述，性能表现出成功的解决方案，支持了深入理解宇宙中暗物质分布的目标。


## A deep search for Complex Organic Molecules toward the protoplanetary disk of V883 Ori
- **Url**: http://arxiv.org/abs/2504.06005v1
- **Authors**: ['Abubakar M. A. Fadul', 'Kamber R. Schwarz', "Merel L. R. van 't Hoff", 'Jane Huang', 'Jennifer B. Bergner', 'Tushar Suhasaria', 'Jenny K. Calahan']
- **Abstrat**: Complex Organic Molecules (COMs) in the form of prebiotic molecules are potentially building blocks of life. Using Atacama Large Millimeter/submillimeter Array (ALMA) Band 7 observations in spectral scanning mode, we carried out a deep search for COMs within the disk of V883 Ori, covering frequency ranges of $\sim$ 348 - 366 GHz. V883 Ori is an FUor object currently undergoing an accretion burst, which increases its luminosity and consequently increases the temperature of the surrounding protoplanetary disk, facilitating the detection of COMs in the gas phase. We identified 26 molecules, including 14 COMs and 12 other molecules, with first detection in this source of the molecules: CH3OD, H2C17O, and H213CO. We searched for multiple nitrogen-bearing COMs, as CH3CN had been the only nitrogen-bearing COM that has been identified so far in this source. We also detected CH3CN, and tentatively detect CH3CH2CN, CH2CHCN, CH3OCN, CH3NCO, and NH2CHO. We compared the abundances relative to CH3OH with those in the handful of objects with previous detections of these species: the Class 0 protostars IRAS 16293-2422 A, IRAS 16293-2422 B and B1-c, the high-mass star-forming region Sagittarius B2 (North), the Solar System comet 67P/Churyumov-Gerasimenko, and the protoplanetary disk of Oph-IRS 48. We report $\sim$ 1 to 3 orders of magnitude higher abundances compared to Class 0 protostars and $\sim$ 1 to 3 orders of magnitude lower abundances compared to the protoplanetary disk, Sagittarius B2 (North), and 67P/C-G. These results indicate that the protoplanetary disk phase could contribute to build up of COMs.


**Translated Abstract**: 

复杂有机分子（COMs）以前生物分子的形式可能是生命的构建基石。我们使用阿塔卡马大型毫米/亚毫米阵列（ALMA）第7波段观测，在频率范围约为348 - 366 GHz内对V883 Ori的盘面进行了深度搜索，识别了26种分子，包括14种COMs和12种其他分子，并首次在此源中检测到分子：CH3OD、H2C17O和H213CO。我们还检测到CH3CN，并初步检测到CH3CH2CN、CH2CHCN、CH3OCN、CH3NCO和NH2CHO。与之前在少数对象中检测到的这些物质的丰度进行了比较，结果显示与Class 0原恒星的丰度相差约1到3个数量级，与高质量星形成区Sagittarius B2（北）和67P/Churyumov-Gerasimenko等的丰度相比，约1到3个数量级较低。这些结果表明，原行星盘阶段可能有助于COMs的积累。

**Summary**:

- (1): 本文的研究背景是复杂有机分子（COMs）在生命的建立中可能起到关键作用，研究它们在恒星形成区的化学演化与星系物体形成之间的联系。

- (2): 过去的方法主要利用ALMA及类似设施进行COMs的检测，但主要集中在高质量原恒星等较早阶段，往往未能准确探测到较晚阶段的COMs。本文采用深度搜索和谱扫描模式来应对这些问题，因而能在盘面温度升高的情况下进行更深入的分子检测。

- (3): 本文的贡献在于首次在V883 Ori的盘面中发现了26种分子及14种COMs，扩展了对氮包含COMs的认识，进一步揭示了这类分子在原行星形成过程中的潜在作用。

- (4): 本文采用了ALMA Band 7观测的数据，结合对V883 Ori的光度捡起和拟合技术，对盘面内气体相中的COMs进行深度探测。

- (5): 本文在探测到的COMs方面取得了显著成果，发现的丰度相对于其他已经检测的天体表明V883 Ori的原行星盘阶段能够促进COMs的形成，为针对COMs的构建块研究提供了支持。


## Fluorine abundances in CEMP stars at the lowest metallicity: Hints on the nature of the first stars
- **Url**: http://arxiv.org/abs/2504.05999v1
- **Authors**: ['Aldo Mura-Guzmán', 'David Yong', 'Chiaki Kobayashi', 'Nozomu Tominaga', 'Madeleine McKenzie', 'Ricardo Salinas', 'regory Mace', 'Hwihyun Kim', 'Daniel B. Zucker']
- **Abstrat**: In the last decade, the available measurements of fluorine abundance have increased significantly, providing additional information on the chemical evolution of our Galaxy and details on complex stellar nucleosynthesis processes. However, the observational challenges to obtain stellar F abundances favor samples with higher metallicities, resulting in a scarcity of measurements at low-metallicity ([Fe/H] $<-2.0$). We present F abundances and upper limits in 7 carbon enhanced metal-poor (CEMP) stars observed with the Immersion Grating Infrared Spectrometer (IGRINS), at the Gemini-South telescope. These new observations delivered high-resolution, high signal-to-noise ratio, infrared spectra allowing us to probe significantly deeper into the metal-poor regime and the cosmic origin of F. This work presents the results of our observations, including two 2-sigma detections and five upper limits in a variety of CEMP stars. Arguably the most important result is for CS 29498-0043, a CEMP-no star at [Fe/H] = $-3.87$ with a F detection of [F/Fe] = $+2.0\pm 0.4$, the lowest metallicity star (more than a factor of 10 lower in metallicity than the next detection) with observed F abundance to date. This measurement allowed us to differentiate between two zero metallicity Population III (Pop III) progenitors: one involving He-burning with primary N in Wolf-Rayet stars, and the other suggesting H-burning during hypernova explosions. Our measured value is in better agreement with the latter scenario. This detection represents a pilot, and pioneering study demonstrating the power of F to explore the nature and properties of the first chemical enrichment from Pop III stars.


**Translated Abstract**: 在过去十年中，氟丰度的测量显著增加，提供了银河化学演化和复杂恒星核合成过程的额外信息。然而，获取恒星F丰度的观测挑战使得高金属丰度样本更容易获得，导致低金属丰度（[Fe/H] < -2.0）的测量稀缺。我们使用Gemini-South望远镜的浸没光栅红外光谱仪（IGRINS）观察了7颗碳增强金属贫困（CEMP）恒星的F丰度及其上限。这些新观察提供了高分辨率、高信噪比的红外光谱，使我们能够深入探测金属贫乏区和F的宇宙起源。我们的观测结果包括两个2-σ的检测结果和五个上限，其中最重要的结果是对于CS 29498-0043（一颗[Fe/H] = -3.87的CEMP-no星）的F检测，其[F/Fe] = +2.0 ± 0.4，这颗星的金属丰度为当前最底的F丰度观测。该测量使我们能够区分两种零金属丰度的Population III（Pop III）前体：一种涉及Wolf-Rayet星的He燃烧和N的主要生成，另一种则暗示在超新星爆炸中的H燃烧。我们的测量值与后者的情景更为一致。这一检测代表了一项开创性研究，展示了F在探讨Pop III星首次化学富集性质和特性的能力。

**Summary**:

- (1): 本文的研究背景是探讨氟的丰度如何对银河化学演化和早期宇宙恒星的核合成过程提供信息，尤其是在低金属丰度恒星中的稀缺测量情况。

- (2): 过去的方法主要针对高金属丰度样本，以获取氟丰度，但由于观测挑战，低金属丰度样本（[Fe/H] < -2.0）测量稀缺。本文提出的方法使用了高分辨率和高信噪比的红外光谱，能够深入探测金属贫乏区，从而解决了传统方法在获得低金属丰度数据方面的局限性。该方法具有良好的动机，因为它能够填补当前研究的空白。

- (3): 本文的贡献在于提供了7颗CEMP星的氟丰度测量以及上限，尤其是为金属丰度最低的CEMP-no星CS 29498-0043提供了新的氟检测结果，促进了对早期宇宙中Pop III星化学富集的理解。

- (4): 本文所提的研究方法是使用IGRINS对7颗CEMP恒星进行观测，以获取其氟丰度和上限，借此探讨低金属丰度区域的元素丰度分布。

- (5): 该方法在CS 29498-0043中达到了[F/Fe] = +2.0 ± 0.4的氟检测，这在金属丰度最低恒星中具有显著性，支持了对Pop III星核合成过程的目标理解。


## Subaru High-$z$ Exploration of Low-Luminosity Quasars (SHELLQs). XXIII. The powering mechanisms of the Ly$α$ haloes around high-$z$ quasars probed by slit spectroscopy
- **Url**: http://arxiv.org/abs/2504.05984v1
- **Authors**: ['Hiroki Hoshi', 'Rikako Ishimoto', 'Nobunari Kashikawa', 'Yoshiki Matsuoka', 'Wanqiu He', 'Junya Arita', 'Kazushi Iwasawa', 'Toshihiro Kawaguchi', 'Satoshi Kikuta', 'Rieko Momose', 'Rhythm Shimakawa', 'Shunta Shimizu', 'Ayumi Takahashi', 'Yoshihiro Takeda', 'Yoshiki Toba', 'Takehiro Yoshioka', 'Chien-Hsiu Lee', 'Yuri Nishimura']
- **Abstrat**: We present the analysis of Ly$\alpha$ haloes around faint quasars at $z\sim4$ and $z\sim6$. We use 20 and 162 quasars at $z\sim4$ and $z\sim6$, taken by slit spectroscopy, and detect Ly$\alpha$ haloes around 12 and 26 of these quasars, respectively. The average absolute magnitudes of the detected quasars are $\langle M_{1450} \rangle = -23.84$ mag at $z\sim4$ and $\langle M_{1450} \rangle = -23.68$ mag at $z\sim6$, which are comparable at $z\sim4$ and 3 mag fainter at $z\sim6$ than those of previous studies. The median surface brightness profiles are found to be consistent with an exponential curve, showing a hint of flattening within a radius of 5 kpc. The Ly$\alpha$ haloes around these faint quasars are systematically fainter than those around bright quasars in the previous studies. We confirm the previous results that the Ly$\alpha$ halo luminosity depends on both the ionizing and Ly$\alpha$ peak luminosities of quasars at $z\sim4$, and also find that a similar correlation holds even at $z\sim6$. While the observed Ly$\alpha$ halo luminosity is overall attributed to recombination emission from the optically thin gas clouds in the CGM, its luminosity dependences can be consistently explained by the partial contributions of recombination radiation from the optically thick clouds, which is thought to originate from the CGM centre, and the scattered Ly$\alpha$ photons, which is resonantly trapped at the CGM centre and escaping outside of the haloes.


**Translated Abstract**: 

我们分析了约在𝑧 ∼ 4和𝑧 ∼ 6的微弱类星体周围的Ly𝛼晕。我们使用在𝑧 ∼ 4和𝑧 ∼ 6的20个和162个类星体，通过狭缝光谱法探测到12个和26个类星体周围的Ly𝛼晕。检测到的类星体的平均绝对光度为𝑀1450平均= -23.84 mag（在𝑧∼4）和𝑀1450平均= -23.68 mag（在𝑧∼6），与𝑧∼4时的结果相近，但在𝑧∼6时比之前的研究暗3个光度级。我们发现，介质表面亮度轮廓符合指数曲线，在半径5 kpc内显示出平坦的迹象。与之前的研究相比，这些微弱类星体周围的Ly𝛼晕总体上较暗。我们确认了先前的结果，认为在𝑧∼4时，Ly𝛼晕的光度依赖于类星体的电离光度和Ly𝛼峰值光度，并发现即使在𝑧∼6时也有类似的相关性。尽管观察到的Ly𝛼晕光度总体上归因于来自CGM的光学薄气体云的复合辐射，但其光度依赖性可以通过来自光学厚云的复合辐射的部分贡献，以及共振捕获的Ly𝛼光子逃逸出晕的散射相一致地解释。

**Summary**:

- (1): 本文的研究背景是关于𝑧>6的超大质量黑洞（SMBH）形成的快速性，提出对理论模型的挑战。

- (2): 过去的方法使用集成光谱单元（IFUs）进行Ly𝛼晕的观测，问题在于主要集中于较亮的类星体。本文提出的狭缝光谱法扩展到微弱的类星体，解决了对较少研究的类星体的观察覆盖。

- (3): 该论文贡献于对微弱类星体周围Ly𝛼晕的首次系统分析，同时确认了Ly𝛼晕光度与类星体光度之间的相关性。

- (4): 本文的方法是通过狭缝光谱法探测𝑧 ∼ 4和𝑧 ∼ 6处的类星体周围的Ly𝛼晕，分析其表面亮度和相关性。

- (5): 本文在𝑧∼4和𝑧∼6的任务中成功检测12个和26个Ly𝛼晕，且所观察到的光度支持了它们对光度与类星体电离光度之间关系的目标。


## REMIX SPH -- improving mixing in smoothed particle hydrodynamics simulations using a generalised, material-independent approach
- **Url**: http://arxiv.org/abs/2407.18587v2
- **Authors**: ['Thomas D. Sandnes', 'Vincent R. Eke', 'Jacob A. Kegerreis', 'Richard J. Massey', 'Sergio Ruiz-Bonilla', 'Matthieu Schaller', 'Luis F. A. Teodoro']
- **Abstrat**: We present REMIX, a smoothed particle hydrodynamics (SPH) scheme designed to alleviate effects that typically suppress mixing and instability growth at density discontinuities in SPH simulations. We approach this problem by directly targeting sources of kernel smoothing error and discretisation error, resulting in a generalised, material-independent formulation that improves the treatment both of discontinuities within a single material, for example in an ideal gas, and of interfaces between dissimilar materials. This approach also leads to improvements in capturing wider hydrodynamic behaviour unrelated to mixing. We demonstrate marked improvements in three-dimensional test scenarios, focusing on cases with particles of equal mass across the simulation. This choice is particularly relevant for use cases in astrophysics and engineering -- specifically those in which particles are free to evolve over a large range of density scales -- where bespoke choices of unequal particle masses in the initial conditions cannot easily be used to address emergent and evolving density discontinuities. We achieve these improvements while maintaining sharp discontinuities; without introducing additional equation of state dependence in, for example, particle volume elements; and without contrived or targeted corrections. Our methods build upon a fully compressible and thermodynamically consistent core-SPH construction, retaining Galilean invariance as well as conservation of mass, momentum, and energy. REMIX is integrated in the open-source, state-of-the-art SWIFT code and is designed with computational efficiency also in mind, meaning that its improved hydrodynamic treatment can be used for high-resolution simulations without prohibitive cost to run-speed.


**Translated Abstract**: 

我们提出了REMIX，一个光滑粒子流体动力学（SPH）方案，旨在减轻通常抑制SPH模拟中密度不连续性处混合和不稳定性增长的影响。我们通过直接针对核平滑误差和离散化误差的来源，形成了一种广义的、与材料无关的公式，改善了单一材料内部的不连续性（例如理想气体）和不同材料之间界面的处理。这种方法还改善了捕捉与混合无关的更广泛流体动力学行为。我们在三维测试场景中展示了显著的改进，重点关注在模拟中具有相等质量粒子的案例。该选择对于那些粒子可以在大范围密度尺度上自由演化的天体物理和工程应用尤其相关，在这种情况下，无法轻易使用不等粒子质量的初始条件来解决新出现和演变的密度不连续。我们在保持锐利不连续性的同时取得这些改进；没有引入额外的状态方程依赖性，例如在粒子体积元素中；并且没有复杂或目标导向的校正。我们的方法建立在完全可压缩和热力学一致的核心-SPH构造上，保持了伽利略不变性以及质量、动量和能量的守恒。REMIX已集成在开源的最先进的SWIFT代码中，并且旨在兼顾计算效率，这意味着它改善的流体动力学处理可用于高分辨率模拟，而不会造成过高的运行成本。

**Summary**:

- (1): 本文的研究背景是光滑粒子流体动力学（SPH）在流体行为复杂性研究中的广泛应用，尤其是在天体物理和工程中。

- (2): 过去的方法主要集中在通过提高核函数阶数和改进梯度估计来减少离散化误差，但它们在密度不连续性处存在抑制混合和不稳定性增长的现象。因此，提出的REMIX方案通过直接针对核平滑和离散化误差的来源，形成了一种更为广泛且与材料无关的公式，从而有效地解决了这类问题，具有良好的动机。

- (3): 该论文的贡献在于提出了一种改进的SPH方法REMIX，旨在提高密度不连续性处的混合能力，并在高分辨率对流体行为的捕捉上展示显著改进。

- (4): 本文提出的研究方法论是构建一个与材料无关的光滑粒子流体动力学框架，通过直接处理核平滑误差和离散化误差，改善流体界面和单一材料内部的混合处理。

- (5): 本文在高分辨率的三维模拟中验证了REMIX方法的有效性，展示了其在捕捉复杂流体行为方面的优越性能，这支持了其研究目标的实现。


## Pushing JWST to the extremes: search and scrutiny of bright galaxy candidates at z$\simeq$15-30
- **Url**: http://arxiv.org/abs/2504.05893v1
- **Authors**: ['M. Castellano', 'A. Fontana', 'E. Merlin', 'P. Santini', 'L. Napolitano', 'N. Menci', 'A. Calabrò', 'D. Paris', 'L. Pentericci', 'J. Zavala', 'M. Dickinson', 'S. L. Finkelstein', 'T. Treu', 'R. O. Amorin', 'P. Arrabal Haro', 'P. Bergamini', 'L. Bisigello', 'E. Daddi', 'P. Dayal', 'A. Dekel', 'A. Ferrara', 'F. Fortuni', 'G. Gandolfi', 'M. Giavalisco', 'C. Grillo', 'S. T. Guida', 'N. P. Hathi', 'B. W. Holwerda', 'A. M. Koekemoer', 'V. Kokorev', 'Z. Li', 'M. Llerena', 'R. A. Lucas', 'S. Mascia', 'B. Metha', 'T. Morishita', 'T. Nanayakkara', 'F. Pacucci', 'P. G. Pérez-González', 'G. Roberts-Borsani', 'G. Rodighiero', 'P. Rosati', 'V. Salazar', 'R. Schneider', 'R. S. Somerville', 'A. Taylor', 'M. Trenti', 'A. Trinca', 'X. Wang', 'P. J. Watson', 'L. Yang', 'L. Y. A. Yung']
- **Abstrat**: We designed customized Lyman-break color selection techniques to identify galaxy candidates in the redshift ranges $15 \leq z \leq 20$ and $20 \leq z \leq 28$. The selection was performed on the ASTRODEEP-JWST multi-band catalogs of the CEERS, Abell-2744, JADES, NGDEEP, and PRIMER survey fields, covering a total area of $\sim0.2$ sq. deg. We identify nine candidates at $15 \leq z \leq 20$, while no objects are found based on the $z\gtrsim20$ color selection criteria. Despite exhibiting a $>$1.5 mag break, all the objects display multimodal redshift probability distributions across different SED-fitting codes and methodologies. The alternative solutions correspond to poorly understood populations of low-mass quiescent or dusty galaxies at z$\sim$3-7. This conclusion is supported by the analysis of a NIRSpec spectrum recently acquired by the CAPERS program for one interloper object, which is confirmed to be a dusty ($E(B-V)=0.8$ mag) starburst galaxy at $z=6.56$. We measured the UV luminosity function under different assumptions on the contamination level within our sample. We find that if even a fraction of the candidates is indeed at $z\gtrsim15$, the resulting UV LF points to a very mild evolution compared to estimates at $z<15$, implying a significant tension with existing theoretical models. In particular, confirming our bright ($M_{\text{UV}}<-21$) candidates would require substantial revisions to the theoretical framework. In turn, if all these candidates will be confirmed to be interlopers, we conclude that future surveys may need ten times wider areas to select $M_{\text{UV}}\lesssim-20$ galaxies at $z>15$. Observations in the F150W and F200W filters at depths comparable to those in the NIRCam LW bands are also required to mitigate contamination from rare red objects at z$\lesssim$8.


**Translated Abstract**: 

我们设计了定制的Lyman-break颜色选择技术，以识别红shift范围在15 ≤ z ≤ 20和20 ≤ z ≤ 28的星系候选者。选择是基于ASTRODEEP-JWST多波段目录进行的，覆盖了CEERS、Abell-2744、JADES、NGDEEP和PRIMER调查场的总面积约为0.2平方弧度。我们在15 ≤ z ≤ 20的范围内识别出九个候选者，而在z ≥ 20的颜色选择标准下未发现任何对象。尽管所有对象表现出超过1.5 mag的断裂，但在不同的SED拟合代码和方法中，它们均显示出多峰红shift概率分布。替代解决方案对应于不太理解的低质量休眠或尘埃丰富的星系，z约为3-7。这一结论得到了CAPERS计划最近获得的NIRSpec光谱分析的支持，该分析确认一个干扰对象为z=6.56的尘埃丰富（E(B-V)=0.8 mag）星暴星系。我们在考虑样本中污染水平不同假设的情况下测量了紫外光度函数。如果即使一部分候选者确实位于z≥15，则得到的UV LF与z＜15的估计相比，演化非常温和，这与现有理论模型存在显著张力。特别是，确认我们的亮（M_{\text{UV}}<-21）候选者将需要对理论框架进行重大修订。反之，如果所有这些候选者都被确认是干扰者，我们得出结论，未来的调查可能需要扩大十倍的范围，以选择z>15的M_{\text{UV}}≤-20的星系。此外，在F150W和F200W滤光器中的观测，深度与NIRCam LW波段相当，也是必要的，以减轻来自z≤8的稀有红色对象的污染。

**Summary**:

- (1): 本文的研究背景是JWST已能够探测到z∼10以上的星系，但在z>14.5的范围内，关于星系的约束极为薄弱。

- (2): 过去的方法主要基于光度特征选择星系候选者，这些方法在选择z≥15星系时面临物体变得更暗及样本污染增加的挑战。本研究提出的定制Lyman-break颜色选择技术旨在识别更高红shift的星系候选者，以应对上述问题，这一方法具有良好的动机。

- (3): 本文的贡献在于提出了新的颜色选择技术，识别出九个15 ≤ z ≤ 20的星系候选者，同时提出了对UV光度函数的分析，为理解早期星系形成和演化提供了重要数据。

- (4): 本文研究方法主要包括基于ASTRODEEP-JWST多波段目录的定制颜色选择技术，以及对样本中污染水平的多种假设进行的UV光度函数测量。

- (5): 在识别星系候选者的任务中，本文取得了九个候选者的成果，表明这些方法可能支持其目标，即探索z≥15的星系及评价其对现有理论模型的影响。


## The Ultraviolet Spectra of 2003fg-like Type Ia Supernovae
- **Url**: http://arxiv.org/abs/2504.05869v1
- **Authors**: ['Snehasish Bhattacharjee', 'Yen-Chen Pan', 'Hao-Yu Miao', 'Charles D. Kilpatrick', 'Willem B. Hoogendam', 'Katie Auchettl', 'Aaron Do']
- **Abstrat**: 2003fg-like Type Ia supernovae (03fg-like SNe Ia) are a rare subtype of SNe Ia, photometrically characterized by broader optical light curves and bluer ultraviolet (UV) colors compared to normal SNe Ia. In this work, we study four 03fg-like SNe Ia using Swift UltraViolet and Optical Telescope (UVOT) grism observations to understand their unique UV properties and progenitor scenario(s). We report 03fg-like SNe Ia to have similar UV features and elemental compositions as normal SNe Ia, but with higher UV flux relative to optical. Previous studies have suggested that the UV flux levels of normal SNe Ia could be influenced by their progenitor properties, such as metallicity, with metal-poor progenitors producing higher UV flux levels. While 03fg-like SNe were previously reported to occur in low-mass and metal-poor host environments, our analysis indicates that their UV excess cannot be explained by their host-galaxy parameters. Instead, we demonstrate that the addition of a hot blackbody component, likely arising from the interaction with the circumstellar material (CSM), to the normal SN Ia spectrum, can reproduce their distinctive UV excess. This supports the hypothesis that 03fg-like SNe Ia could explode in a CSM-rich environment.


**Translated Abstract**: 

2003fg类Ia超新星（03fg-like SNe Ia）是一种罕见的Ia超新星亚型，其光谱特征表现在其光变曲线更宽以及相比正常SNe Ia呈现更蓝的紫外（UV）颜色。本文利用Swift紫外和光学望远镜（UVOT）的谱线观测研究了四个03fg类SNe Ia，以了解其独特的紫外特性和前身场景。我们报告称，03fg类SNe Ia的紫外特征和元素成分与正常SNe Ia相似，但相对光学的紫外通量更高。之前的研究表明，正常SNe Ia的紫外通量水平可能受到其前身特性（如金属丰度）的影响，金属贫乏的前身产生更高的紫外通量。虽然03fg类SNe之前被报道发生在低质量和金属贫乏的宿主环境中，但我们的分析表明其紫外过量无法通过宿主星系参数解释。相反，我们证明，向正常的SNe Ia光谱中添加一个热黑体成分，可能源自与星际物质（CSM）的相互作用，可以再现它们的独特紫外过量。这支持了03fg类SNe Ia可能在富含CSM的环境中爆炸的假设。

**Summary**:

- (1): 本文的研究背景是关于2003fg类Ia超新星（03fg-like SNe Ia）的一些独特特征及其在宇宙爆炸中的重要性，强调其紫外光谱在理解超新星物理和前身系统中的价值。

- (2): 过去的研究主要集中在光谱分析和观测，但对于03fg类SNe Ia的紫外特性及其宿主星系的影响存在不足。提出的方法分析了紫外光通量的来源，并将热黑体成分引入光谱模型，以解决现有方法未能解释的紫外过量问题，具有良好的动机基础。

- (3): 文章的贡献在于提供了对四个03fg类SNe Ia的详细紫外观测数据，揭示了其紫外特性和成因，并提出了可能的CSM与超新星相互作用的理论。

- (4): 本文采用了对四个03fg类SNe Ia进行Swift UVOT的观测，并分析其光谱数据，特别关注紫外波段特性与宿主环境参数之间的关系。

- (5): 本文在观察和分析紫外特性方面取得了显著的成果，紫外光通量相对光学明显增强，这支持了03fg类SNe Ia在CSM丰富环境中的爆炸假设，展示了研究的目标得以实现。


## Analyzing type Ia supernovae near-infrared light curves with Principal Component Analysis
- **Url**: http://arxiv.org/abs/2504.05856v1
- **Authors**: ['T. E. Müller-Bravo', 'L. Galbany', 'M. D. Stritzinger', 'C. Ashall', 'E. Baron', 'C. R. Burns', 'P. Höflich', 'N. Morrell', 'M. Phillips', 'N. B. Suntzeff', 'S. A. Uddin']
- **Abstrat**: Type Ia supernovae (SNeIa), the thermonuclear explosions of C/O white dwarf stars in binary systems, are phenomena that remain poorly understood. The complexity of their progenitor systems, explosion physics and intrinsic diversity poses not only challenges for their understanding as astrophysical objects, but also for their standardization and use as cosmological probes. Near-infrared (NIR) observations offer a promising avenue for studying the physics of SNeIa and for reducing systematic uncertainties in distance estimations, as they exhibit lower dust extinction and smaller dispersion in peak luminosity than optical bands. Here, Principal Component Analysis (PCA) is applied to a sample of SNeIa with well-sampled NIR (YJH-band) light curves to identify the dominant components of their variability and constrain physical underlying properties. The theoretical models of Kasen2006 are used for the physical interpretation of the PCA components, where we found the 56Ni mass to describe the dominant variability. Other factors, such as mixing and metallicity, were found to contribute significantly as well. However, some differences are found between the components of the NIR bands which may be attributed to differences in the explosion aspects they each trace. Additionally, the PCA components are compared to various light-curve parameters, identifying strong correlations between some components and peak brightness in both the NIR and optical bands, particularly in the Y band. When applying PCA to NIR color curves, we found interesting correlations with the host-galaxy mass, where SNeIa with redder NIR colors are predominantly found in less massive galaxies. We also investigate the potential for improved standardization in the Y band by incorporating PCA coefficients as correction parameters, leading to a reduction in the scatter of the intrinsic luminosity of SNeIa.


**Translated Abstract**: 

超新星 Ia（SNe Ia）是碳氧白矮星在双星系统中发生的热核爆炸现象，至今仍然理解不深。其前体系统、爆炸物理学及固有多样性的复杂性，不仅对其作为天体物体的理解构成挑战，也对其标准化和作为宇宙学探针的使用带来困难。近红外（NIR）观测为研究 SNe Ia 的物理学和减少距离估计中的系统误差提供了良好的途径，因为与光学波段相比，NIR 显示出较低的尘埃消光和较小的峰值亮度散布。在此，我们将主成分分析（PCA）应用于具有良好采样的 NIR（YJH 波段）光曲线的 SNe Ia 样本，以识别其可变性的主要成分并约束其物理基础特性。我们利用 Kasen 2006 的理论模型进行 PCA 成分的物理解释，发现 56Ni 质量描述了主要的可变性。混合和金属丰度等其他因素也被发现显著影响可变性。然而，NIR 波段的成分之间存在一些差异，可能归因于其各自追踪的爆炸方面的差异。此外，将 PCA 成分与各种光曲线参数进行比较，识别出某些成分与 NIR 和光学波段的峰值亮度之间存在强关联，尤其是在 Y 波段中。当将 PCA 应用到 NIR 色曲线时，我们发现与宿主星系质量存在有趣的相关性，其中 NIR 颜色较红的 SNe Ia 在较小质量的星系中占主导地位。我们还研究通过将 PCA 系数作为校正参数纳入 Y 波段的潜在改进标准化，从而降低 SNe Ia 固有亮度的散布。随着新的 NIR 观测数据的出现，我们的发现可以进一步验证，最终提升我们对 SNe Ia 物理学的理解并增强它们作为宇宙学距离指示器的可靠性。

**Summary**:

- (1): 本文研究超新星 Ia（SNe Ia）的爆炸机制及其固有多样性，强调其在宇宙学中的重要性及研究中遇到的挑战。

- (2): 过去的方法主要集中在光学波段观测，存在系统误差大和对距离估计不准确等问题。本文提出的方法通过主成分分析（PCA）结合近红外（NIR）数据来分析超新星的变异性，解决了系统误差问题，并为物理机制提供了新的见解。

- (3): 本文的贡献在于利用 PCA 识别 SNe Ia NIR 光曲线的主要可变性成分，发现 56Ni 质量是主要可变性因素，并探讨了与宿主星系质量的相关性。

- (4): 研究方法是运用 PCA 对 SNe Ia NIR 光曲线进行分析，识别主要可变性成分，并利用相关理论模型进行物理解释。

- (5): 在分析 SNe Ia 的 NIR 光曲线和颜色曲线任务中，本文取得了与峰值亮度和宿主星系质量之间的强相关性，证明了 NIR 观测在提升超新星标准化精度方面的潜力。


## Exploring Hard X-ray Properties of $γ$-ray Emitting Narrow Line Seyfert-I Galaxies through NuSTAR Observations
- **Url**: http://arxiv.org/abs/2504.04492v2
- **Authors**: ['Suvas Chandra Chaudhary', 'Raj Prince']
- **Abstrat**: With the launch of the Fermi-LAT observatory in 2008, more new gamma-ray objects were discovered, mostly dominated by blazars. In addition, some of the narrow line Seyfert 1 (NLSy1) galaxies were observed in gamma-ray but in less number, making them different from other NLSy1 galaxies. We studied the six gamma-ray-detected NLSy1 galaxies using the hard X-ray observations from NuSTAR and optical g- & r-band from ZTF. The X-ray spectra corresponding to all objects are well-fitted with a power-law spectral model, and a strong "brighter-when-redder" trend is seen, which is the properties mostly seen in Blazars. The X-ray light curves were produced for all the available observations, and the F$_{var}$ is estimated for all the observations. In 1H 0323+342, we found that F$_{var}$ lies between 9-22%, suggesting significant variability in the same source. Similarly, for PKS 2004-447, we found F$_{var}$ lies between 10-21%. We see a strong X-ray and gamma-ray spectral index correlation among these objects, suggesting that X-rays and gamma-rays are produced through a similar process. Comparing the X-ray spectral index with other class objects, we see that NLSy1 galaxies are similar to LBL and IBL types. We see a negative trend of X-ray flux with the gamma-ray luminosity in these objects, suggesting an anti-correlation between X-ray and gamma-ray luminosity. A similar trend is seen between the X-ray flux, total jet power, and disk luminosity. The X-ray spectral index also shows a negative trend with total jet power and disk luminosity. The optical variability amplitude lies between 0.90 to 2.32, and the fractional variability varies from 13-40%. The color-magnitude plot shows mostly the brighter-when-redder trend, suggesting $\gamma$-NLSy1 are much closer to FSRQs than BL Lacs. Our results, overall, summarize how the various parameters in gamma-ray-detected NLSy1 are connected.


**Translated Abstract**: 

随着2008年Fermi-LAT观测站的发射，发现了许多新的伽马射线天体，这些天体主要由耀变星（blazars）主导。此外，一些窄线 Seyfert-I（NLSy1）星系也被观察到具有伽马射线，但数量较少，使它们与其他NLSy1星系不同。我们利用NuSTAR的硬X射线观测和ZTF的光学g-和r波段数据研究了六个伽马射线检测到的NLSy1星系。所有对象的X射线光谱均很好地符合幂律光谱模型，并表现出强烈的“红色时越亮”的趋势，这是耀变星中常见的特性。我们生成了所有可用观测的X射线光曲线，并估算了F$_{var}$。在1H 0323+342中，我们发现F$_{var}$介于9%和22%之间，表明该源具有显著的变星性。类似地，对于PKS 2004-447，我们发现F$_{var}$介于10%和21%之间。我们观察到这些对象之间X射线和伽马射线谱指数的强相关性，表明X射线和伽马射线是通过相似的过程产生的。与其他类对象进行比较时，我们发现NLSy1星系在X射线谱指数上与LBL和IBL类型相似。我们还观察到X射线通量与伽马射线光度之间的负相关趋势，表明X射线和伽马射线光度之间存在反相关关系。X射线通量、总喷流功率和盘光度之间也观察到类似的趋势。X射线谱指数与总喷流功率和盘光度之间也呈负相关趋势。光学变星幅度介于0.90到2.32之间，分数变星率变化从13%到40%。颜色-亮度图显示主要是“红色时越亮”的趋势，表明伽马-NLSy1与FSRQ更接近而非BL Lacs。总体而言，我们的结果总结了伽马射线检测到的NLSy1中不同参数之间的联系。

**Summary**:

- (1): 本文的研究背景是随着Fermi-LAT的发射，发现了伽马射线发射的窄线 Seyfert-I（NLSy1）星系，这是一个小数量的AGNs类。

- (2): 过去主要的方法是使用传统的光谱和时变分析，面临的主要问题是对NLSy1星系中伽马射线与X射线的关系理解不足。本文采用NuSTAR的硬X射线观测，与光学数据相结合，对比分析了伽马-NLSy1与耀变星的相似性，解决了对比分析不足的问题，方法具有清晰的科学动机。

- (3): 本文的贡献在于提供了关于六个伽马-NLSy1星系的综合分析，揭示了X射线与伽马射线光度之间的反相关趋势，并确定这些星系与FSRQ的相似性。

- (4): 本文的研究方法包括选择六个伽马-NLSy1星系，利用NuSTAR进行硬X射线观测，并结合ZTF的光学观测进行样本分析，从而获得相应的光谱和时变特性。

- (5): 研究任务涉及分析伽马-NLSy1的X射线和伽马射线特性，达到的性能包括识别出X射线通量与伽马射线光度之间的负相关性和变星率，证明了这些方法的有效性及实现目标的支持。


## Accurate Decomposition of Galaxies with Spiral Arms: Dust Properties and Distribution
- **Url**: http://arxiv.org/abs/2504.05839v1
- **Authors**: ['A. A. Marchuk', 'I. V. Chugunov', 'F. Galliano', 'A. V. Mosenkov', 'P. V. Strekalova', 'V. S. Kostiuk', 'G. A. Gontcharov', 'V. B. Ilin', 'S. S. Savchenko', 'A. A. Smirnov', 'D. M. Poliakov']
- **Abstrat**: We analyze three nearby spiral galaxies - NGC 1097, NGC 1566, and NGC 3627 -using images from the DustPedia database in seven infrared bands (3.6, 8, 24, 70, 100, 160, and 250 micron). For each image, we perform photometric decomposition and construct a multi-component model, including a detailed representation of the spiral arms. Our results show that the light distribution is well described by an exponential disk and a Sersic bulge when non-axisymmetric components are properly taken into account. We test the predictions of the stationary density wave theory using the derived models in bands, tracing both old stars and recent star formation. Our findings suggest that the spiral arms in all three galaxies are unlikely to originate from stationary density waves. Additionally, we perform spectral energy distribution (SED) modeling using the hierarchical Bayesian code HerBIE, fitting individual components to derive dust properties. We find that spiral arms contain a significant (>10%) fraction of cold dust, with an average temperature of approximately 18-20 K. The estimated fraction of polycyclic aromatic hydrocarbons (PAHs) declines significantly toward the galactic center but remains similar between the arm and interarm regions.


**Translated Abstract**: 

我们分析了三个位于附近的螺旋星系——NGC 1097、NGC 1566 和 NGC 3627，使用来自DustPedia数据库的七个红外波段（3.6、8、24、70、100、160 和 250 微米）的图像。对于每幅图像，我们进行了光度分解并构建了一个多组分模型，包括对螺旋臂的详细表示。我们的结果表明，当适当地考虑到非轴对称分量时，光的分布可以很好地用指数盘和Sérsic球体来描述。我们使用这些模型在多个波段中测试了静态密度波理论的预测，追踪了老星和新近星形成的情况。我们的发现表明，所有三条星系中的螺旋臂不太可能起源于静态密度波。此外，我们使用分层贝叶斯代码HerBIE进行了光谱能量分布（SED）建模，拟合个别组件以推导灰尘属性。我们发现螺旋臂包含显著（>10%）的冷尘埃，其平均温度约为18-20 K。多环芳烃（PAHs）的估计含量沿银河中心显著下降，但在臂区和间臂区域之间保持相似。

**Summary**:

- (1): 本文研究的是星系中的灰尘及其在银河演化中的关键作用，特别是在螺旋星系中的分布和性质。

- (2): 过去的方法主要采用光度分解技术，但未能准确考虑螺旋臂的非轴对称分量，导致灰尘和星光分布模型的不准确。提出的方法通过改进的光度分解模型准确表示螺旋臂，从而解决了旧有模型的不足，并且动机明确。

- (3): 本文的贡献在于引入了一种新的多组分模型，允许更精细地模拟螺旋臂的光分布，并提供了螺旋臂中灰尘特性的详细分析。

- (4): 本文提出的研究方法包括使用DustPedia数据库的红外图像，进行光度分解并应用改进的模型，同时使用HerBIE进行光谱能量分布建模。

- (5): 本文的方法在推导螺旋臂中灰尘的性质及温度上表现出高性能，支持了研究者对灰尘分布和星际介质的深入理解目标。


## Ultraviolet Photometry and Reddening Estimation of 105 Galactic Open Clusters
- **Url**: http://arxiv.org/abs/2504.04930v2
- **Authors**: ['Tahereh Ramezani', 'Ernst Paunzen', 'Artem Gorodilov', 'Olga Ines Pintado']
- **Abstrat**: This paper focuses on observing unstudied Galactic open clusters in the Ultraviolet (UV) wavelength range and analyzing their photometric data. The Gaia Data Release 3 (DR3) enables us to precisely study known Galactic open clusters. We conducted observations using the 1.54-meter Danish Telescope (DK1.54) in Chile and the 2.15-meter telescope at the Complejo Astronomico El Leoncito (CASLEO) in Argentina, employing UV filters. Furthermore, we have collected available photometric and astrometric data for our observed clusters. We aim to estimate the reddening of Galactic open clusters using UV photometry. We applied isochrone fitting to determine the reddening of the clusters using well-known members. As a final result, we present the reddening values of 105 Galactic open clusters in the UV, as determined by our photometry.


**Translated Abstract**: 

本文集中观察未研究的银河系开放星团在紫外线（UV）波段的表现，并分析其光度数据。Gaia 第三版数据发布（DR3）使我们能够精确研究已知的银河系开放星团。我们在智利的 1.54 米丹麦望远镜（DK1.54）和阿根廷的 2.15 米星体观测台（CASLEO）进行了观测，使用了紫外线滤光片。此外，我们收集了我们观察的星团的可用光度和天体测量数据。我们的目标是使用 UV 光度法估计银河系开放星团的红化。我们应用等时线拟合的方法，通过已知成员来确定红化值。最终结果是，我们展示了使用我们光度测量确定的 105 个银河系开放星团的红化值。

**Summary**:

- (1): 文章背景主要在于研究开放星团，这些星团是理解恒星形成、演化和动力学的重要实验室。紫外线观测对研究年轻、热且质量大的恒星至关重要。

- (2): 过去的方法缺乏针对开放星团的紫外线观测，主要研究集中在已知星团上，并且对红化的考虑不足。该论文提出的方法通过紫外线光度法来估计红化值，弥补了过去研究的不足，方法动机明确。

- (3): 本文的贡献在于观察了 105 个未经研究的银河系开放星团并估计了它们的红化值，在紫外线波段对红化的研究上提供了重要数据。

- (4): 研究方法包括使用 1.54 米和 2.15 米的望远镜进行紫外线观测，结合Gaia DR3进行光度和天体测量数据的匹配，通过等时线拟合来确定各星团的红化值。

- (5): 论文通过紫外线光度法准确估计了 105 个星团的红化值，能够支持对银河系开放星团的红化研究目标。


## Asymmetric accretion through a streamer onto the pre-stellar core H-MM1
- **Url**: http://arxiv.org/abs/2503.21370v2
- **Authors**: ['Spandan Choudhury', 'Jongsoo Kim', 'Paola Caselli', 'Chang Won Lee', 'Jaime E. Pineda']
- **Abstrat**: CONTEXT: Dense cores are thought to be isolated from the surrounding cloud. However, observations of streamers and subsonic material outside core boundaries challenges this idea. AIMS: In this study, we aim to probe the extended subsonic region observed around the pre-stellar core H-MM1 in L1688 using multi-component kinematical analysis of very high-sensitivity NH3 data. METHODS: We used observations of NH3 (1,1) and (2,2) using GBT. We then fitted up to two components towards the core and its surrounding molecular cloud. RESULTS: We detect an extended region of subsonic turbulence in addition to the ambient cloud, which show supersonic turbulence. This extended subsonic region is approximately 12 times the size of and more than two times as massive as the previously detected subsonic material. The subsonic region is further split into two well-separated, velocity-coherent components, one of which is kinematically and spatially connected to the dense core. The two subsonic components are red- and blue-shifted with respected to the cloud component. We also detect a flow of material onto the dense core from the extended subsonic region via a streamer of length ~0.15 pc (~30000 au). CONCLUSIONS: We find that the extended subsonic component kinematically associated with the dense core contains 27% more mass than the core. This material could be further accreted by the core. The other subsonic component contains a mass similar to that of the core mass, and could be tracing material in the early stage of core formation. The H-MM1 streamer is kinematically similar to the ones observed towards protostellar systems, but is the first instance of such an accretion feature onto a core in its pre-stellar phase. This accretion of chemically fresh material by the pre-stellar core challenges our current understanding of a core evolving with a mass unchanged since the time of its formation.


**Translated Abstract**: 

背景：密集核心被认为是星际云中的孤立单元，然而周围云的气流观测挑战了这一观点。目的：本研究旨在使用多组分动力学分析、探测Ophiuchus中H-MM1预星核心周围观察到的扩展次音速区域。方法：我们使用GBT的NH3（1,1）和（2,2）观测数据进行了分析，适合了核心及其周围云的两个组件。结果：我们发现存在扩展的次音速湍流区域，面积约为已知次音速物质的12倍，质量超过两倍。次音速区域分为两个速度一致的组件，其中一个与密集核心连接。我们还探测到通过长约0.15 pc的气流将物质引入密集核心。结论：与核心运动相关的扩展次音速组件含有比核心多27%的质量，可能会被核心进一步吸积。另一个次音速组件的质量与核心相似，可能代表核心形成早期的物质。H-MM1的气流与原恒星系统的特征相似，但这是首次观察到此类特征出现在预星阶段。预星核心吸积化学新鲜材料的现象挑战了我们关于核心演化质量不变的传统理解。

**Summary**:

- (1): 该文章的研究背景是密集核心被认为在星际云中是孤立的，但最近的观测显示出流动物质与核心之间的相互作用，挑战了这一传统观点。

- (2): 以往的方法主要依赖于传统的观测技术，无法准确探测核心边界之外的动态行为。本文提出的多组分动力学分析法，提高了对次音速区域的探测和描述能力，能够揭示与密集核心相关联的扩展区域，解决了以往对核心孤立演化模式的局限性。

- (3): 本文的贡献在于首次发现H-MM1预星核心吸积特征，这为理解核心的物质增量和星形成过程提供了新的视角，挑战了核心演化质量不变的传统认知。

- (4): 本文的方法论包括使用高灵敏度的NH3（1,1）和（2,2）转变观测数据，对H-MM1预星核心及其周围的分子云进行多组分动力学分析。

- (5): 本文的方法在探测H-MM1核心及其周围次音速区域的运动和质量分布方面表现良好，支持了对于核心质量不断增加、以及核心物质吸积的研究目标。


## On the evidence of a dark matter density spike around the primary black hole in OJ 287
- **Url**: http://arxiv.org/abs/2504.05715v1
- **Authors**: ['Debabrata Deb', 'Achamveedu Gopakumar', 'Mauri J. Valtonen']
- **Abstrat**: The central engine of blazar OJ~287 is arguably the most notable supermassive black hole (SMBH) binary candidate that emits nano-Hertz (nHz) gravitational waves. This inference is mainly due to our ability to predict and successfully monitor certain quasi-periodic doubly peaked high brightness flares with a period of $\sim$12 years from this blazer. The use of post-Newtonian accurate SMBH binary orbital description that includes the effects of higher order GW emission turned out to be a crucial ingredient for accurately predicting the epochs of such Bremsstrahlung flares in our SMBH binary central engine description for OJ~287. It was very recently argued that one should include the effects of dynamical friction, induced by certain dark matter density spikes around the primary SMBH, to explain the {\it observed} decay of SMBH binary orbit in OJ~287. Invoking binary pulsar timing-based arguments, measurements, and OJ~287's orbital description, we show that observationally relevant SMBH binary orbital dynamics in OJ~287 are insensitive to dark matter-induced dynamical friction effects. This implies that we could only provide an upper bound on the spike index parameter rather than obtaining an observationally derived value, as argued by \cite{Chan2024}.


**Translated Abstract**: 

OJ~287的中心引擎被认为是最显著的超大质量黑洞（SMBH）双星候选者，它发出纳赫兹（nHz）引力波。这一推测主要来自我们成功预测和监测到的约12年的几何周期双峰高亮度耀斑。采用包含较高阶GW辐射效应的后牛顿精确SMBH双星轨道描述，成为准确预测此类Bremsstrahlung耀斑的关键。然而，最近有人提出应纳入围绕主SMBH某些暗物质密度峰值引起的动力摩擦效应，以解释OJ~287中观察到的SMBH双星轨道衰减。通过引入基于双脉冲定时的论据、测量和OJ~287的轨道描述，我们表明OJ~287中观测相关的SMBH双星轨道动力学对暗物质引起的动力摩擦效应不敏感。这意味着我们只能对此尖峰指数参数提供一个上限，而无法得到观察上的推导值。

**Summary**:

- (1): 本文的研究背景是OJ~287的中心引擎作为超大质量黑洞（SMBH）双星候选者，其引发的纳赫兹（nHz）引力波和显著的高亮度耀斑引起了科学家的关注。

- (2): 过去的方法主要依赖于后牛顿的SMBH双星轨道描述，未能有效处理暗物质引起的动力摩擦效应。本文提出的方法通过考虑这些效应，试图解释OJ~287中观察到的轨道衰减问题，但最终发现对轨道动力学影响有限，因此只能提供暗物质密度尖峰的上限。

- (3): 本文的贡献在于通过实证分析验证了OJ~287的SMBH双星轨道动力学对于暗物质引起的动力摩擦效应不敏感，从而为理解该系统的演化提供了新的视角。

- (4): 研究方法主要涉及基于双脉冲定时的数据分析，以及后牛顿轨道动力学模型的构建，以探讨OJ~287中SMBH双星的轨道演化特性。

- (5): 本文的任务是展示OJ~287的SMBH双星轨道衰减特征，结果表明轨道动力学对暗物质影响不敏感，这一性能支持了其对于暗物质密度尖峰参数的研究目标。


# machine learning
## GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization
- **Url**: http://arxiv.org/abs/2504.06265v1
- **Authors**: ['Bojana Ranković', 'Philippe Schwaller']
- **Abstrat**: Large Language Models (LLMs) can encode complex relationships in their latent spaces, yet harnessing them for optimization under uncertainty remains challenging. We address this gap with a novel architecture that reframes LLM finetuning as Gaussian process (GP) marginal likelihood optimization via deep kernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs to preserve the benefits of both - LLMs to provide a rich and flexible input space for Bayesian optimization and - GPs to model this space with predictive uncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction optimization, our method nearly doubles the discovery rate of high-performing reactions compared to static LLM embeddings (from 24% to 43% coverage of the top 5% reactions in just 50 optimization iterations). We also observe a 14% improvement over domain-specific representations without requiring specialized features. Extensive empirical evaluation across 19 benchmarks - ranging from general chemistry to reaction and molecular property optimization -demonstrates our method's robustness, generality, and consistent improvements across: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder), (3) pretraining domains (chemistry-related or general-purpose) and (4) hyperparameter settings (tuned once on a single dataset). Finally, we explain these improvements: joint LLM-GP optimization through marginal likelihood implicitly performs contrastive learning, aligning representations to produce (1) better-structured embedding spaces, (2) improved uncertainty calibration, and (3) more efficient sampling - without requiring any external loss. This work provides both practical advances in sample-efficient optimization and insights into what makes effective Bayesian optimization.


**Translated Abstract**: 

大型语言模型（LLMs）能够在其潜在空间中编码复杂关系，但在不确定性下进行优化仍然具有挑战性。我们通过一种新颖的架构解决了这一差距，将LLM微调重新构建为通过深核方法进行的高斯过程（GP）边际似然优化。我们引入了LLM基础的深核，与GP共同优化，以保持两者的优势——LLMs为贝叶斯优化提供丰富且灵活的输入空间，而GP则通过预测不确定性对该空间进行建模，以实现更高效的采样。应用于Buchwald-Hartwig反应优化，我们的方法在仅50次优化迭代中，几乎将高性能反应的发现率从24%增加到43%。我们还观察到，相比于领域特定的表示，该方法在不需要专业特征的情况下提升了14%。在19个基准上进行了广泛的实证评估，涵盖了从一般化学到反应和分子性质优化的任务，展示了我们方法的稳健性、一般性和在不同任务、LLM架构（编码器、解码器、编码器-解码器）、预训练领域（化学相关或通用）以及超参数设置（在单一数据集上调优）上的一致性改进。最后，我们解释了这些改进：通过边际似然进行的联合LLM-GP优化隐式执行对比学习，使表示对齐，产生（1）更好结构的嵌入空间，（2）改进的不确定性校准，以及（3）更高效的采样——无需任何外部损失。本研究为样本高效优化提供了实际进展，并洞察了有效贝叶斯优化的关键。

**Summary**:

- (1): 本文的研究背景是大型语言模型（LLMs）在文本生成和语言理解等任务中具有出色能力，但在不确定性优化方面仍然存在挑战，尤其在科学发现等高风险领域，需要进行可靠的不确定性量化。

- (2): 以往方法主要是将LLMs作为特征提取器或通过后续的不确定性量化进行顺序微调。然而，这些方法要么未能充分利用LLMs的适应能力，要么将预测性能与不确定性估计解耦，限制了优化效果。本文提出的方法通过深核学习（Deep Kernel Learning）将LLMs与高斯过程（GP）架构无缝集成，利用GP的边际似然作为LLM微调目标，创建反馈循环，有效提升嵌入空间的性能，通过对比学习增强模型性能，从而解决了上述问题。

- (3): 本文的贡献在于引入GOLLuM框架，它是首个将LLM与GP联合训练的深核架构，提供了一个将LLM能力与贝叶斯优化相结合的端到端框架，同时提供了对嵌入空间的更好结构化和不确定性校准的实证见解。

- (4): 本文的研究方法是通过高斯过程边际似然优化来训练LLM和GP的联合模型，建立LLM嵌入与GP核的紧密联系，使得相似的目标函数值在嵌入空间中更为接近，激励对比学习效应强化优化。

- (5): 本文在化学领域任务（如Buchwald-Hartwig反应优化）上应用了该方法，以94%覆盖生成率显著提高高性能反应发现率。经过50次优化迭代发现率从24%提升到43%，表明所提方法在样本高效优化方面达到预期目标。


## Hogwild! Inference: Parallel LLM Generation via Concurrent Attention
- **Url**: http://arxiv.org/abs/2504.06261v1
- **Authors**: ['Gleb Rodionov', 'Roman Garipov', 'Alina Shutova', 'George Yakushev', 'Vage Egiazarian', 'Anton Sinitsin', 'Denis Kuznedelev', 'Dan Alistarh']
- **Abstrat**: Large Language Models (LLMs) have demonstrated the ability to tackle increasingly complex tasks through advanced reasoning, long-form content generation, and tool use. Solving these tasks often involves long inference-time computations. In human problem solving, a common strategy to expedite work is collaboration: by dividing the problem into sub-tasks, exploring different strategies concurrently, etc. Recent research has shown that LLMs can also operate in parallel by implementing explicit cooperation frameworks, such as voting mechanisms or the explicit creation of independent sub-tasks that can be executed in parallel. However, each of these frameworks may not be suitable for all types of tasks, which can hinder their applicability. In this work, we propose a different design approach: we run LLM "workers" in parallel , allowing them to synchronize via a concurrently-updated attention cache and prompt these workers to decide how best to collaborate. Our approach allows the instances to come up with their own collaboration strategy for the problem at hand, all the while "seeing" each other's partial progress in the concurrent cache. We implement this approach via Hogwild! Inference: a parallel LLM inference engine where multiple instances of the same LLM run in parallel with the same attention cache, with "instant" access to each other's generated tokens. Hogwild! inference takes advantage of Rotary Position Embeddings (RoPE) to avoid recomputation while improving parallel hardware utilization. We find that modern reasoning-capable LLMs can perform inference with shared Key-Value cache out of the box, without additional fine-tuning.


**Translated Abstract**: 

大型语言模型（LLMs）已显示出通过高级推理、长格式内容生成和工具使用来处理日益复杂任务的能力。在人类问题解决中，加速工作的常用策略是协作：通过将问题划分为子任务、并行探索不同策略等。最近的研究表明，LLMs可以通过实现明确的合作框架（如投票机制或明确创建可以并行执行的独立子任务）进行并行操作。然而，这些框架可能不适合所有类型的任务，从而限制了其适用性。在本研究中，我们提出了一种不同的设计方法：我们并行运行LLM“工作者”，使其通过一个并发更新的注意力缓存进行同步，并促使这些工作者决定如何最好地合作。我们的方法允许实例根据手头问题的进展自行制定合作策略，同时“查看”彼此在并发缓存中的部分进展。我们通过Hogwild!推理实现这种方法：一个并行LLM推理引擎，其中多个相同LLM的实例并行运行，使用相同的注意力缓存，并“即时”访问彼此生成的标记。Hogwild!推理利用旋转位置嵌入（RoPE）来避免重复计算，同时改善并行硬件的利用率。我们发现现代推理能力的LLMs可以开箱即用地执行带共享键值缓存的推理，而无需额外的微调。

**Summary**:

- (1): 本文的研究背景是大型语言模型（LLMs）在复杂任务中的应用，包括推理、长格式生成和与工具交互，但这些应用常常需要较长的推理时间计算。

- (2): 过去的方法主要采用明确的合作框架，如投票机制和独立子任务的创建，但这些方法在面对不同类型任务时存在局限性。本文提出的Hogwild!推理方法与现有方法的不同在于，允许LLM工作者并行生成，并实时交换进展，从而自主决定合作策略。这种方法有效应对了现有方法的局限性，具有更大的灵活性。

- (3): 本文的贡献在于提出了一种新的并行推理框架（Hogwild!推理），使LLMs能以更高效的方式进行协作，提升了推理速度和质量。

- (4): 本文提出的研究方法是通过并行运行多个LLM实例，使用共享注意力缓存，并通过即时访问彼此的生成标记来促进协作。

- (5): 本文在多个推理任务上测试Hogwild!推理得到的性能结果表明，经过共享键值缓存的推理在推理质量和速度方面优于传统方法，支持实现其研究目标。


## Fractal and Regular Geometry of Deep Neural Networks
- **Url**: http://arxiv.org/abs/2504.06250v1
- **Authors**: ['Simmaco Di Lillo', 'Domenico Marinucci', 'Michele Salvi', 'Stefano Vigogna']
- **Abstrat**: We study the geometric properties of random neural networks by investigating the boundary volumes of their excursion sets for different activation functions, as the depth increases. More specifically, we show that, for activations which are not very regular (e.g., the Heaviside step function), the boundary volumes exhibit fractal behavior, with their Hausdorff dimension monotonically increasing with the depth. On the other hand, for activations which are more regular (e.g., ReLU, logistic and $\tanh$), as the depth increases, the expected boundary volumes can either converge to zero, remain constant or diverge exponentially, depending on a single spectral parameter which can be easily computed. Our theoretical results are confirmed in some numerical experiments based on Monte Carlo simulations.


**Translated Abstract**: 

我们通过研究不同激活函数下深度神经网络的边界体积，探讨随机神经网络的几何特性。具体而言，对于不太规则的激活函数（例如Heaviside阶梯函数），边界体积表现出分形行为，Hausdorff维数随着深度单调增加。另一方面，对于更规则的激活函数（例如ReLU、logistic和tanh），随着深度的增加，期望边界体积可能收敛到零、保持不变或指数发散，这取决于一个可以轻松计算的单一谱参数。我们的理论结果通过一些基于Monte Carlo模拟的数值实验得到了验证。

**Summary**:

- (1): 本文的研究背景是随着深度学习推进，数学家对神经网络的几何特性理解不断深入，特别是其复杂性和不同架构下的表现。

- (2): 过去的方法主要集中于神经网络的近似理论、统计学和优化等方面，可能无法全面捕捉神经网络的几何结构和复杂性。本文提出的方法通过分析激活函数和深度对神经网络的随机游走特性的影响，从新的角度探讨其几何 properties，更好地解决了现有方法在理解神经网络复杂性上的不足。

- (3): 本文的贡献在于通过定义Covariance Regularity Index (CRI)为神经网络分类，并区分了分形类与Kac-Rice类，从而揭示了不同激活函数下网络的几何行为和边界体积的表现。

- (4): 本文的方法论包括分析随机神经网络深度增加时的曲面体积，以及通过数学理论和Monte Carlo模拟验证结果，强调激活函数和深度对几何特性的影响。

- (5): 本文的方法在理解神经网络的几何特性上取得了新的结果，可支持其目标，即分析不同激活函数对网络形态的影响并提供理论支持。


## Stacking Variational Bayesian Monte Carlo
- **Url**: http://arxiv.org/abs/2504.05004v2
- **Authors**: ['Francesco Silvestrin', 'Chengkun Li', 'Luigi Acerbi']
- **Abstrat**: Variational Bayesian Monte Carlo (VBMC) is a sample-efficient method for approximate Bayesian inference with computationally expensive likelihoods. While VBMC's local surrogate approach provides stable approximations, its conservative exploration strategy and limited evaluation budget can cause it to miss regions of complex posteriors. In this work, we introduce Stacking Variational Bayesian Monte Carlo (S-VBMC), a method that constructs global posterior approximations by merging independent VBMC runs through a principled and inexpensive post-processing step. Our approach leverages VBMC's mixture posterior representation and per-component evidence estimates, requiring no additional likelihood evaluations while being naturally parallelizable. We demonstrate S-VBMC's effectiveness on two synthetic problems designed to challenge VBMC's exploration capabilities and two real-world applications from computational neuroscience, showing substantial improvements in posterior approximation quality across all cases.


**Translated Abstract**: 

变分贝叶斯蒙特卡罗（VBMC）是一种用于计算代价高昂的似然函数的近似贝叶斯推断的样本高效方法。尽管VBMC的局部代理方法提供了稳定的近似，但其保守的探索策略和有限的评估预算可能导致其错过复杂后验分布的区域。在这项工作中，我们引入了堆叠变分贝叶斯蒙特卡罗（S-VBMC），这是一种通过合并独立的VBMC运行来构建全局后验近似的方法，采用一种合理且廉价的后处理步骤。我们的方法利用了VBMC的混合后验表示和每个组分的证据估计，不需要额外的似然评估，同时具有天然的并行化能力。我们在两个设计用于挑战VBMC探索能力的合成问题和两个来自计算神经科学的真实应用中展示了S-VBMC的有效性，在所有情况下大幅提升了后验近似质量。

**Summary**:

- (1): 本文的研究背景是贝叶斯推断在处理高开销的似然函数时的近似推断需求，尤其在科学和工程领域中。

- (2): 过去的方法主要采用变分贝叶斯蒙特卡罗（VBMC），存在保守的探索策略和有限的评估预算，容易错过复杂后验空间。与现有方法相比，提出的堆叠变分贝叶斯蒙特卡罗（S-VBMC）通过合并独立VBMC跑的结果，提升了全局后验近似，解决了VBMC的探索能力不足的问题，具有良好的动机。

- (3): 本文的贡献在于提出了一种新的后处理步骤，通过合并VBMC结果实现全局后验近似，使得这一过程高效且无需额外的似然评估。

- (4): 本文提出的研究方法是堆叠变分贝叶斯蒙特卡罗（S-VBMC），它利用VBMC的混合后验表示和组分证据估计，实现了有效的全局后验预测。

- (5): 本文在两个合成问题和两个计算神经科学的真实应用任务中取得了显著的后验近似质量提升，性能表明该方法能够有效支持其目标。


## Electronic Structure Guided Inverse Design Using Generative Models
- **Url**: http://arxiv.org/abs/2504.06249v1
- **Authors**: ['Shuyi Jia', 'Panchapakesan Ganesh', 'Victor Fung']
- **Abstrat**: The electronic structure of a material fundamentally determines its underlying physical, and by extension, its functional properties. Consequently, the ability to identify or generate materials with desired electronic properties would enable the design of tailored functional materials. Traditional approaches relying on human intuition or exhaustive computational screening of known materials remain inefficient and resource-prohibitive for this task. Here, we introduce DOSMatGen, the first instance of a machine learning method which generates crystal structures that match a given desired electronic density of states. DOSMatGen is an E(3)-equivariant joint diffusion framework, and utilizes classifier-free guidance to accurately condition the generated materials on the density of states. Our experiments find this approach can successfully yield materials which are both stable and match closely with the desired density of states. Furthermore, this method is highly flexible and allows for finely controlled generation which can target specific templates or even individual sites within a material. This method enables a more physics-driven approach to designing new materials for applications including catalysts, photovoltaics, and superconductors.


**Translated Abstract**: 

材料的电子结构从根本上决定了其基本物理性质及其功能属性。因此，能够识别或生成具有期望电子属性的材料将使得定制功能材料的设计成为可能。依赖人类直觉或对已知材料进行详尽计算筛选的传统方法效率低下且资源消耗巨大。本文介绍了DOSMatGen，这是一个机器学习方法的首次实例，生成与给定期望电子态密度相匹配的晶体结构。DOSMatGen是一个E(3)-等变联合扩散框架，并利用无分类器引导准确条件化生成材料的态密度。我们的实验发现此方法可以成功生成稳定且与期望态密度紧密匹配的材料。此外，该方法高度灵活，允许精细控制生成，可以针对特定模板或甚至材料中的单个位置进行目标设置。这种方法使得基于物理的方式设计用于催化剂、光伏和超导体等应用的新材料成为可能。

**Summary**:

- (1): 本文的研究背景是开发能够设计具有特定功能特性的材料，以推动在能源储存、电子和医疗等领域的技术进步。

- (2): 过去的方法主要依靠试错和资源密集型的计算筛选，存在效率低和时间成本高的问题。本文提出的DOSMatGen方法通过数据驱动反向生成材料，旨在解决传统方法的效率低下问题，该方法动机充分，利用机器学习生成特定电子属性的材料结构。

- (3): 本文的贡献在于首次提出DOSMatGen，通过生成与给定电子态密度匹配的晶体结构，提供了一种新的材料设计方法，从而实现更为精细的功能材料定制。

- (4): 研究方法采用了E(3)-等变的联合扩散框架，通过无分类器引导对生成材料的态密度进行准确条件化，以优化材料的结构有效性与目标属性的对齐。

- (5): 本文的方法在生成与特定电子态密度匹配的稳定晶体材料任务上取得了成功，性能表现良好，支持其设计功能材料的目标。


## Variational Online Mirror Descent for Robust Learning in Schrödinger Bridge
- **Url**: http://arxiv.org/abs/2504.02618v2
- **Authors**: ['Dong-Sig Han', 'Jaein Kim', 'Hee Bin Yoo', 'Byoung-Tak Zhang']
- **Abstrat**: Sch\"odinger bridge (SB) has evolved into a universal class of probabilistic generative models. In practice, however, estimated learning signals are often uncertain, and the reliability promised by existing methods is often based on speculative optimal-case scenarios. Recent studies regarding the Sinkhorn algorithm through mirror descent (MD) have gained attention, revealing geometric insights into solution acquisition of the SB problems. In this paper, we propose a variational online MD (OMD) framework for the SB problems, which provides further stability to SB solvers. We formally prove convergence and a regret bound for the novel OMD formulation of SB acquisition. As a result, we propose a simulation-free SB algorithm called Variational Mirrored Schr\"odinger Bridge (VMSB) by utilizing the Wasserstein-Fisher-Rao geometry of the Gaussian mixture parameterization for Schr\"odinger potentials. Based on the Wasserstein gradient flow theory, the algorithm offers tractable learning dynamics that precisely approximate each OMD step. In experiments, we validate the performance of the proposed VMSB algorithm across an extensive suite of benchmarks. VMSB consistently outperforms contemporary SB solvers on a range of SB problems, demonstrating the robustness predicted by our theory.


**Translated Abstract**: 

施罗丁格桥（Schrödinger bridge, SB）已经发展成为一种通用的概率生成模型。然而，在实践中，估计的学习信号往往不确定，现有方法所承诺的可靠性往往基于推测的最优场景。最近关于通过镜像下降（Mirror Descent, MD）的Sinkhorn算法研究引起了关注，揭示了SB问题解的方法几何洞察。本文提出了一种针对SB问题的变分在线镜像下降（Variational Online Mirror Descent, OMD）框架，为SB求解器提供了进一步的稳定性。我们正式证明了该新型OMD公式的收敛性和后悔界限。因此，利用施罗丁格势的高斯混合参数化的Wasserstein-Fisher-Rao几何结构，我们提出了一种无仿真的SB算法，称为变分镜像施罗丁格桥（Variational Mirrored Schrödinger Bridge, VMSB）。基于Wasserstein梯度流理论，该算法提供了可处理的学习动态，准确逼近每一步OMD。实验中，我们验证了所提VMSB算法在广泛基准测试中的性能。VMSB在一系列SB问题上始终超越当代SB求解器，展示了理论上预测的鲁棒性。

**Summary**:

- (1): 本文的研究背景是施罗丁格桥（SB）作为一种概率生成模型的应用，但现有学习方法在估计学习信号时面临不确定性，缺乏可靠性。

- (2): 过去的方法如Sinkhorn算法通过镜像下降（MD）改进了SB解决方案，但大多基于最优情况的假设，缺乏在不确定性下的稳健性。本文提出的变分在线镜像下降（OMD）方法，通过提供稳健的理论保证，克服了这些问题，并强调了SB问题的稳定性。

- (3): 本文的贡献在于提出了一种新的变分镜像施罗丁格桥（VMSB）算法，该算法提供了仿真无关的解决方案，并建立了公式的收敛性和后悔界限，提供了对SB方法的新的理论和实践支持。

- (4): 本文采用的研究方法是通过Wasserstein-Fisher-Rao几何与Wasserstein梯度流理论来进行变分在线镜像下降，从而实现SB问题的优化。

- (5): 本文在多种SB基准任务上验证了VMSB算法的性能，并且VMSB在一系列SB问题上均表现优越，符合理论上的鲁棒性预期。


## APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay
- **Url**: http://arxiv.org/abs/2504.03601v2
- **Authors**: ['Akshara Prabhakar', 'Zuxin Liu', 'Ming Zhu', 'Jianguo Zhang', 'Tulika Awalgaonkar', 'Shiyu Wang', 'Zhiwei Liu', 'Haolin Chen', 'Thai Hoang', 'Juan Carlos Niebles', 'Shelby Heinecke', 'Weiran Yao', 'Huan Wang', 'Silvio Savarese', 'Caiming Xiong']
- **Abstrat**: Training effective AI agents for multi-turn interactions requires high-quality data that captures realistic human-agent dynamics, yet such data is scarce and expensive to collect manually. We introduce APIGen-MT, a two-phase framework that generates verifiable and diverse multi-turn agent data. In the first phase, our agentic pipeline produces detailed task blueprints with ground-truth actions, leveraging a committee of LLM reviewers and iterative feedback loops. These blueprints are then transformed into complete interaction trajectories through simulated human-agent interplay. We train a family of models -- the xLAM-2-fc-r series with sizes ranging from 1B to 70B parameters. Our models outperform frontier models such as GPT-4o and Claude 3.5 on $\tau$-bench and BFCL benchmarks, with the smaller models surpassing their larger counterparts, particularly in multi-turn settings, while maintaining superior consistency across multiple trials. Comprehensive experiments demonstrate that our verified blueprint-to-details approach yields high-quality training data, enabling the development of more reliable, efficient, and capable agents. We open-source both the synthetic data collected and the trained xLAM-2-fc-r models to advance research in AI agents. Models are available on HuggingFace at https://huggingface.co/collections/Salesforce/xlam-2-67ef5be12949d8dcdae354c4 and project website is https://apigen-mt.github.io


**Translated Abstract**:

训练有效的人工智能代理进行多轮交互需要高质量的数据，这些数据能够捕捉现实的人机动态，但此类数据稀缺且人工收集成本高。我们引入了APIGen-MT，一个生成可验证且多样的多轮代理数据的两阶段框架。在第一阶段，我们的代理管道利用大型语言模型 (LLM) 审核委员会和迭代反馈循环生成详细的任务蓝图和真实操作。然后，通过模拟的人机互动将这些蓝图转换为完整的互动轨迹。我们训练了一系列模型——xLAM-2-fc-r系列，参数范围从1B到70B。我们的模型在τ-bench和BFCL基准测试中超越了前沿模型，如GPT-4o和Claude 3.5，其中较小的模型在多轮设置中尤其超越了更大的模型，同时在多次试验中保持了优越的一致性。全面实验表明，我们的核实蓝图到细节的方法产生高质量的训练数据，从而促进更可靠、高效和强大的代理的开发。我们开源了收集的合成数据和训练好的xLAM-2-fc-r模型，以推动人工智能代理的研究。

**Summary**:

- (1): 本文的研究背景是多轮交互的人工智能代理对高质量数据的需求，但此类数据稀缺且昂贵。

- (2): 过去的方法主要依赖于人工数据收集，面临数据稀缺和成本高的挑战。提出的方法APIGen-MT通过生成详细的任务蓝图并进行人机互动模拟，与现有方法不同，该方法有效利用了大型语言模型的反馈机制来生成多样化的数据，解决了数据收集的主要问题，具有良好的动机。

- (3): 本文的贡献在于提出了一种创新的两阶段框架APIGen-MT，通过生成可验证的多轮数据，显著提高了AI代理的训练数据质量，并成功开源合成数据和模型。

- (4): 本文提出的研究方法包括通过代理管道生成任务蓝图，利用大型语言模型的审核和反馈，然后将蓝图转换为完整的人机交互轨迹。

- (5): 本文的方法在τ-bench和BFCL基准测试上表现出色，模型尤其在多轮交互场景中超越前沿模型，证明了其有效性，并能够支持提升AI代理的性能目标。


## Decentralized Federated Domain Generalization with Style Sharing: A Formal Modeling and Convergence Analysis
- **Url**: http://arxiv.org/abs/2504.06235v1
- **Authors**: ['Shahryar Zehtabi', 'Dong-Jun Han', 'Seyyedali Hosseinalipour', 'Christopher G. Brinton']
- **Abstrat**: Much of the federated learning (FL) literature focuses on settings where local dataset statistics remain the same between training and testing time. Recent advances in domain generalization (DG) aim to use data from source (training) domains to train a model that generalizes well to data from unseen target (testing) domains. In this paper, we are motivated by two major gaps in existing work on FL and DG: (1) the lack of formal mathematical analysis of DG objectives and training processes; and (2) DG research in FL being limited to the conventional star-topology architecture. Addressing the second gap, we develop $\textit{Decentralized Federated Domain Generalization with Style Sharing}$ ($\texttt{StyleDDG}$), a fully decentralized DG algorithm designed to allow devices in a peer-to-peer network to achieve DG based on sharing style information inferred from their datasets. Additionally, we fill the first gap by providing the first systematic approach to mathematically analyzing style-based DG training optimization. We cast existing centralized DG algorithms within our framework, and employ their formalisms to model $\texttt{StyleDDG}$. Based on this, we obtain analytical conditions under which a sub-linear convergence rate of $\texttt{StyleDDG}$ can be obtained. Through experiments on two popular DG datasets, we demonstrate that $\texttt{StyleDDG}$ can obtain significant improvements in accuracy across target domains with minimal added communication overhead compared to decentralized gradient methods that do not employ style sharing.


**Translated Abstract**: 

大多数联邦学习（FL）的文献集中于训练和测试时本地数据集统计保持不变的设置。近期的领域泛化（DG）进展旨在利用来自源（训练）域的数据来训练能够很好地泛化到看不见的目标（测试）域数据的模型。本文主要受到两点现有FL与DG研究中的重大缺口的启发：(1) 缺乏对DG目标和训练过程的正式数学分析；(2) FL中的DG研究受到传统星型拓扑架构的限制。为解决第二个缺口，我们开发了一种名为“去中心化联邦领域泛化与风格共享”（StyleDDG）的完全去中心化的DG算法，旨在使点对点网络中的设备通过共享从其数据集中推断出的风格信息实现DG。此外，我们通过提供对基于风格的DG训练优化进行系统数学分析的首次尝试，填补了第一点缺口。我们将现有的集中式DG算法纳入我们的框架，并使用其形式化来建模StyleDDG。基于此，我们得到了在何种情况下可以实现StyleDDG的次线性收敛速率的分析条件。通过在两个热门DG数据集上的实验，我们验证了StyleDDG在目标域上可以显著提高准确性，并且与不使用风格共享的去中心化梯度方法相比，增加的通信负载最小。

**Summary**:

- (1): 本文的研究背景是联邦学习（FL）和领域泛化（DG）中存在的统计数据变化问题，尤其是在不能保证训练和测试数据分布一致的情况下。

- (2): 过去的方法主要集中于集中式DG和星型拓扑的FL，存在缺乏正式数学分析和受限于中心服务器的问题。本文提出的StyleDDG算法是去中心化的，通过共享风格信息解决了这些问题，能够在没有中心服务器的情况下实现有效的DG。

- (3): 本文的贡献在于提出了StyleDDG算法，并对基于风格的DG训练优化提供了系统的数学分析，填补了理论分析方面的空白。

- (4): 研究方法论包含将现有集中式DG算法纳入新的框架，并对StyleDDG进行建模，以分析其收敛性和性能。

- (5): 本文的方法在两个流行的DG数据集上进行实验，取得了显著的准确性提升，性能结果支持其在FL环境下实现有效的领域泛化的目标。


## Privacy Attacks on Image AutoRegressive Models
- **Url**: http://arxiv.org/abs/2502.02514v2
- **Authors**: ['Antoni Kowalczuk', 'Jan Dubiński', 'Franziska Boenisch', 'Adam Dziedzic']
- **Abstrat**: Image autoregressive generation has emerged as a powerful new paradigm, with image autoregressive models (IARs) matching state-of-the-art diffusion models (DMs) in image quality (FID: 1.48 vs. 1.58) while allowing for higher generation speed. However, the privacy risks associated with IARs remain unexplored, raising concerns about their responsible deployment. To address this gap, we conduct a comprehensive privacy analysis of IARs, comparing their privacy risks to those of DMs as a reference point. Specifically, we develop a novel membership inference attack (MIA) that achieves a remarkably high success rate in detecting training images, with a True Positive Rate at False Positive Rate = 1% (TPR@FPR=1%) of 86.38%, compared to just 6.38% for DMs using comparable attacks. We leverage our novel MIA to perform dataset inference (DI) for IARs and show that it requires as few as 6 samples to detect dataset membership, compared to 200 samples for DI in DMs. This confirms a higher level of information leakage in IARs. Finally, we are able to extract hundreds of training data points from an IAR (e.g., 698 from VAR-d30). Our results suggest a fundamental privacy-utility trade-off: while IARs excel in image generation quality and speed, they are empirically significantly more vulnerable to privacy attacks compared to DMs that achieve similar performance. This trend suggests that incorporating techniques from DMs into IARs, such as modeling the per-token probability distribution using a diffusion procedure, could help mitigate IARs' vulnerability to privacy attacks. We make our code available at: https://github.com/sprintml/privacy_attacks_against_iars


**Translated Abstract**: 

图像自回归生成已成为一种强大的新范式，图像自回归模型（IARs）在图像质量方面与最先进的扩散模型（DMs）相匹配（FID：1.48与1.58），同时生成速度更快。然而，IARs的隐私风险尚未探索，引发了它们负责部署的担忧。为了解决这一空白，我们对IARs进行了全面的隐私分析，将它们的隐私风险与DMs作为参考点进行比较。具体来说，我们开发了一种新型的成员推断攻击（MIA），在检测训练图像方面获得了非常高的成功率，假阳性率为1%时的真正正率（TPR@FPR=1%）为86.38%，而DMs在类似攻击下仅为6.38%。我们利用我们的新型MIA进行IARs的数据集推断（DI），并表明只需6个样本即可检测到数据集成员资格，而在DMs中检测DI则需要200个样本。这确认了IARs中信息泄露的更高水平。最后，我们能够从一个IAR中提取数百个训练数据点（例如，从VAR-d30中提取698个）。我们的结果表明存在一种基本的隐私-效用权衡：尽管IARs在图像生成质量和速度上表现出色，但与实现相似性能的DMs相比，它们在实证上明显更容易受到隐私攻击。这一趋势表明，将DMs中的技术引入IARs，例如使用扩散程序建模每个令牌的概率分布，可能有助于减轻IARs对隐私攻击的脆弱性。

**Summary**:

- (1): 本文研究的背景是图像自回归生成模型（IARs）在图像质量和生成速度上的快速发展，而其隐私风险尚未被深入探讨，导致对其合理使用的担忧。

- (2): 过去的方法主要集中在扩散模型（DMs）上，但现有的成员推断攻击（MIA）无法有效评估IARs的隐私风险。作者提出的新方法结合了DMs和大型语言模型（LLMs）的MIA，特别是通过分析条件和无条件输入的输出差异来获得更强的推断信号，这有助于解决信息泄露的问题。该方法得到了良好的动机支持。

- (3): 本文的贡献在于开发了一种新的MIA，展示了IARs在隐私泄露方面的脆弱性，并证实IARs在经训练后能够恢复大量敏感数据。

- (4): 本文通过新颖的MIA和数据集推断（DI）方法，综合评估了IARs的隐私风险，尤其是通过减少所需样本的数量来提高检测效率。

- (5): 本文在IARs的成员推断任务上取得了86.38%的TPR@FPR=1%的优秀性能，相比之下，DMs的成功率仅为6.38%。这一性能支持了对IARs隐私风险的有效评估。


## Position: LLM Unlearning Benchmarks are Weak Measures of Progress
- **Url**: http://arxiv.org/abs/2410.02879v2
- **Authors**: ['Pratiksha Thaker', 'Shengyuan Hu', 'Neil Kale', 'Yash Maurya', 'Zhiwei Steven Wu', 'Virginia Smith']
- **Abstrat**: Unlearning methods have the potential to improve the privacy and safety of large language models (LLMs) by removing sensitive or harmful information post hoc. The LLM unlearning research community has increasingly turned toward empirical benchmarks to assess the effectiveness of such methods. In this paper, we find that existing benchmarks provide an overly optimistic and potentially misleading view on the effectiveness of candidate unlearning methods. By introducing simple, benign modifications to a number of popular benchmarks, we expose instances where supposedly unlearned information remains accessible, or where the unlearning process has degraded the model's performance on retained information to a much greater extent than indicated by the original benchmark. We identify that existing benchmarks are particularly vulnerable to modifications that introduce even loose dependencies between the forget and retain information. Further, we show that ambiguity in unlearning targets in existing benchmarks can easily lead to the design of methods that overfit to the given test queries. Based on our findings, we urge the community to be cautious when interpreting benchmark results as reliable measures of progress, and we provide several recommendations to guide future LLM unlearning research.


**Translated Abstract**:  
本论文探讨了数据“忘记”方法在大规模语言模型（LLMs）中的应用，以提升隐私和安全性。我们发现现有的基准评估方法对候选的“忘记”方法的有效性提供了过于乐观且可能误导的视角。通过对多个流行基准进行简单而善意的修改，我们揭示了在一些情况下，声称已被“忘记”的信息仍然可被访问，或者“忘记”过程在保留信息方面的性能下降程度比原基准所指示的更大。我们识别到现有基准特别容易受到修改的影响，这些修改引入了“忘记”和“保留”信息之间的松散依赖。此外，我们证明了现有基准中的“忘记”目标模糊可能会导致设计出过拟合特定测试查询的方法。因此，我们呼吁社区在解读基准结果时保持谨慎，并提供几项建议以指导未来的LLM“忘记”研究。

**Summary**:

- (1): 本文研究的背景是，随着对隐私保护的关注日益增加，尤其是在使用大规模数据训练生成模型的过程中，数据“忘记”方法的研究日益受到重视。

- (2): 过去的方法主要是针对大规模语言模型（LLMs）进行的基准测试，存在的问题是这些基准可能过于乐观且易被修改，导致错误的评估。与现有方法不同，本文提出了通过简单，高度可修改的测试查询来识别这些缺陷，并揭示了现有基准的局限性。

- (3): 本文的贡献在于揭示了当前LLM“忘记”基准测试的不足之处，尤其在信息相关性依赖和过拟合测试查询这两个方面，并提出了社区在解读评估结果时应更为谨慎的建议。

- (4): 本文采用的研究方法包括对多个流行的LLM“忘记”基准进行实验，通过简单修改基准数据，揭示模型表现与过去声称的成功之间的差异。

- (5): 本文未对某一特定任务进行明确的性能评估，主要关注基准提出的局限性及其可能对“忘记”方法有效性评估的影响，因此难以衡量所提方法是否有效支持其目标。


## Encoder-Decoder Gemma: Improving the Quality-Efficiency Trade-Off via Adaptation
- **Url**: http://arxiv.org/abs/2504.06225v1
- **Authors**: ['Biao Zhang', 'Fedor Moiseev', 'Joshua Ainslie', 'Paul Suganthan', 'Min Ma', 'Surya Bhupatiraju', 'Fede Lebron', 'Orhan Firat', 'Armand Joulin', 'Zhe Dong']
- **Abstrat**: While decoder-only large language models (LLMs) have shown impressive results, encoder-decoder models are still widely adopted in real-world applications for their inference efficiency and richer encoder representation. In this paper, we study a novel problem: adapting pretrained decoder-only LLMs to encoder-decoder, with the goal of leveraging the strengths of both approaches to achieve a more favorable quality-efficiency trade-off. We argue that adaptation not only enables inheriting the capability of decoder-only LLMs but also reduces the demand for computation compared to pretraining from scratch. We rigorously explore different pretraining objectives and parameter initialization/optimization techniques. Through extensive experiments based on Gemma 2 (2B and 9B) and a suite of newly pretrained mT5-sized models (up to 1.6B), we demonstrate the effectiveness of adaptation and the advantage of encoder-decoder LLMs. Under similar inference budget, encoder-decoder LLMs achieve comparable (often better) pretraining performance but substantially better finetuning performance than their decoder-only counterpart. For example, Gemma 2B-2B outperforms Gemma 2B by $\sim$7\% after instruction tuning. Encoder-decoder adaptation also allows for flexible combination of different-sized models, where Gemma 9B-2B significantly surpasses Gemma 2B-2B by $>$3\%. The adapted encoder representation also yields better results on SuperGLUE. We will release our checkpoints to facilitate future research.


**Translated Abstract**: 

尽管仅解码的的大型语言模型（LLMs）取得了令人印象深刻的成果，但由于其推理效率和更丰富的编码器表示，编码-解码模型在实际应用中仍被广泛采用。本文研究了一个新问题：将预训练的仅解码LLMs适应为编码-解码模型，旨在利用两种方法的优势，从而实现更有利的质量-效率权衡。我们论证了适应不仅可以继承仅解码LLMs的能力，而且可以减少较从头开始预训练的计算需求。我们严格探讨了不同的预训练目标和参数初始化/优化技术。通过基于Gemma 2（2B和9B）和一系列新预训练的mT5-size模型（最多1.6B）的广泛实验，我们展示了适应的有效性和编码-解码LLMs的优势。在类似的推理预算下，编码-解码LLMs实现了与其仅解码对手相媲美（通常更好）的预训练性能，但在微调性能上却显著更好。例如，Gemma 2B-2B在指令调优后比Gemma 2B提高了约7%。编码-解码适应还允许不同大小模型的灵活组合，其中Gemma 9B-2B显著超过了Gemma 2B-2B超过3%。适应后的编码器表示在SuperGLUE上也取得了更好的结果。我们将发布我们的检查点以促进未来的研究。

**Summary**:

- (1): 本文研究的背景是尽管仅解码的LLMs取得了成功，但编码-解码模型仍因其推理效率和丰富表示而被广泛采用。

- (2): 过去的方法主要是从头开始预训练模型，但这种方法计算资源需求高且时间长。本文提出将仅解码LLMs适应为编码-解码模型，这种方法能更有效地利用已有模型的能力，减少计算需求，且通过适应过程进一步提升模型性能。

- (3): 本文的贡献在于提出了一种新颖的方法将预训练的仅解码模型适应成高效的编码-解码模型，探讨了不同的预训练目标和优化技术，在提高模型性能上取得了积极的成果。

- (4): 本文采用的方法是先以预训练的仅解码模型初始化编码-解码模型的参数，然后通过自我训练来微调所有参数，确保知识有效传递。

- (5): 本文的方法在SuperGLUE任务上表现出色，编码-解码模型在微调性能上显著优于仅解码模型，支持了提升质量和效率的目标。


## GenoTEX: An LLM Agent Benchmark for Automated Gene Expression Data Analysis
- **Url**: http://arxiv.org/abs/2406.15341v3
- **Authors**: ['Haoyang Liu', 'Shuyu Chen', 'Ye Zhang', 'Haohan Wang']
- **Abstrat**: Recent advancements in machine learning have significantly improved the identification of disease-associated genes from gene expression datasets. However, these processes often require extensive expertise and manual effort, limiting their scalability. Large Language Model (LLM)-based agents have shown promise in automating these tasks due to their increasing problem-solving abilities. To support the evaluation and development of such methods, we introduce GenoTEX, a benchmark dataset for the automated analysis of gene expression data. GenoTEX provides analysis code and results for solving a wide range of gene-trait association problems, encompassing dataset selection, preprocessing, and statistical analysis, in a pipeline that follows computational genomics standards. The benchmark includes expert-curated annotations from bioinformaticians to ensure accuracy and reliability. To provide baselines for these tasks, we present GenoAgent, a team of LLM-based agents that adopt a multi-step programming workflow with flexible self-correction, to collaboratively analyze gene expression datasets. Our experiments demonstrate the potential of LLM-based methods in analyzing genomic data, while error analysis highlights the challenges and areas for future improvement. We propose GenoTEX as a promising resource for benchmarking and enhancing automated methods for gene expression data analysis. The benchmark is available at https://github.com/Liu-Hy/GenoTEX.


**Translated Abstract**: 

近期机器学习的发展显著提升了从基因表达数据集中识别病相关基因的能力。然而，这些过程通常需要广泛的专业知识和手动努力，限制了其可扩展性。基于大型语言模型（LLM）的代理已显示出在自动化这些任务方面的潜力。为了支持此类方法的评估和发展，我们提出了GenoTEX，一个用于基因表达数据自动化分析的基准数据集。GenoTEX提供了解决一系列基因与性状关联问题的分析代码和结果，涵盖数据集选择、预处理和统计分析，形成遵循计算基因组学标准的流程。该基准包含了由生物信息学家专家策划的注释，以确保准确性和可靠性。为了提供这些任务的基线，我们提出了GenoAgent，一个由LLM驱动的代理团队，采用多步骤编程工作流程，灵活自我纠错，以协作分析基因表达数据集。我们的实验展示了LLM方法在分析基因组数据方面的潜力，同时错误分析突出了挑战和未来改进的方向。我们提出GenoTEX作为一个有前途的资源，以基准化和增强基因表达数据分析的自动化方法。该基准可在https://github.com/Liu-Hy/GenoTEX获取。

**Summary**:

- (1): 本文的研究背景是基因表达分析在生物医学研究中的重要性，尤其是在理解生物机制和促进临床应用（如疾病标志物识别和个性化医疗）方面。

- (2): 过去的方法通常依赖手动分析，费时费力，且易出错；而且，由于基因表达数据量巨大，传统流程难以扩展。本文提出的GenoTEX基于LLM代理的自动化流程，能够处理复杂的数据分析任务，解决了人工工作量大、效率低的问题，因此具有较强的动机。

- (3): 本文的贡献在于提出了GenoTEX基准数据集，以标准化基因表达数据的分析流程，并定义了数据集选择、数据预处理和统计分析三个关键任务，促进了自动化基因表达数据分析的发展。

- (4): 本文提出的研究方法论包括使用GenoAgent，一个基于LLM的代理团队，来合作执行数据分析，采用多步骤的编程工作流程来执行基因与性状关联问题的分析。

- (5): 本文的任务是基因与性状关联的分析，GenoAgent在分析精度上展示了良好的性能，但与人类专家表现存在显著差距，表明该方法仍需改进以支持作者的研究目标。


## Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling Opt-Outs
- **Url**: http://arxiv.org/abs/2504.06219v1
- **Authors**: ['Dongyang Fan', 'Vinko Sabolčec', 'Matin Ansaripour', 'Ayush Kumar Tarun', 'Martin Jaggi', 'Antoine Bosselut', 'Imanol Schlag']
- **Abstrat**: The increasing adoption of web crawling opt-outs by copyright holders of online content raises critical questions about the impact of data compliance on large language model (LLM) performance. However, little is known about how these restrictions (and the resultant filtering of pretraining datasets) affect the capabilities of models trained using these corpora. In this work, we conceptualize this effect as the $\textit{data compliance gap}$ (DCG), which quantifies the performance difference between models trained on datasets that comply with web crawling opt-outs, and those that do not. We measure the data compliance gap in two settings: pretraining models from scratch and continual pretraining from existing compliant models (simulating a setting where copyrighted data could be integrated later in pretraining). Our experiments with 1.5B models show that, as of January 2025, compliance with web data opt-outs does not degrade general knowledge acquisition (close to 0\% DCG). However, in specialized domains such as biomedical research, excluding major publishers leads to performance declines. These findings suggest that while general-purpose LLMs can be trained to perform equally well using fully open data, performance in specialized domains may benefit from access to high-quality copyrighted sources later in training. Our study provides empirical insights into the long-debated trade-off between data compliance and downstream model performance, informing future discussions on AI training practices and policy decisions.


**Translated Abstract**: 
随着在线内容的版权持有者越来越多地采用网络爬虫选择退出，关于数据合规性对大型语言模型（LLM）性能影响的重要问题浮出水面。然而，关于这些限制（以及随之而来的预训练数据集过滤）如何影响使用这些语料库训练的模型能力的了解仍然有限。在本研究中，我们将这种影响概念化为数据合规性差距（DCG），它量化了在遵循网站爬虫选择退出的情况下训练的模型与不遵循情况下训练的模型之间的性能差异。我们在两个设置中测量数据合规性差距：从头开始预训练模型和从现有合规模型持续预训练（模拟可以在预训练过程中稍后整合受版权保护数据的设置）。我们对1.5B模型的实验显示，截至2025年1月，遵守网络数据选择退出不会降低一般知识的获取（DCG接近0%）。然而，在医学研究等专业领域，排除主要出版商会导致性能下降。这些发现表明，尽管通用LLM可以使用完全开放数据进行同样良好的训练，但在专业领域的性能可能会从后期获取高质量的受版权保护来源中受益。我们的研究为长期辩论的数据合规性与下游模型性能之间的权衡提供了经验性见解，为未来的AI训练实践和政策决策提供了信息。

**Summary**:

- (1): 本文的研究背景是网络内容版权持有者日益采用网络爬虫选择退出机制，提出了数据合规性对大型语言模型性能影响的疑问。

- (2): 过去的方法主要关注版权数据的过滤以避免侵权，但其在评估这些限制对模型性能的影响方面存在不足。本文提出了数据合规性差距（DCG）这一概念，量化了遵循网络爬虫选择退出对模型性能的影响，旨在解决以往方法在效果量化方面的缺陷，这一方法动机明确。

- (3): 本文的贡献在于提出了DCG的概念和测量方法，提供了数据过滤对一般知识获取影响的实证分析，并揭示了在某些专业领域排除主要出版商数据导致的性能下降。

- (4): 本文的方法论包括在两个设置下测量DCG：从头开始预训练模型和从现有合规模型持续预训练，以评估数据合规性对模型性能的具体影响。

- (5): 本文的方法在一般知识获取任务中展示了接近0%的DCG，而在医学领域等特殊领域表现出明显的DCG。尽管一般任务中性能未受损，但在特定领域的性能下降显示了研究目标的重要性。


## Chernoff Information Bottleneck for Covert Quantum Target Sensing
- **Url**: http://arxiv.org/abs/2504.06217v1
- **Authors**: ['Giuseppe Ortolano', 'Ivano Ruo-Berchera', 'Leonardo Banchi']
- **Abstrat**: Target sensing is a fundamental task with many practical applications, e.g.~in LiDaR and radar systems. Quantum strategies with entangled states can achieve better sensing accuracies with the same probe energy, yet it is often simpler to use classical probes with higher energy than to take advantage of the quantum regime. Recently, it has been shown that useful quantum advantage can be achieved in covert situations, where sensing has to be performed while also avoiding detection by an adversary: here increasing energy is not a viable stratagem, as it facilitates the adversary. In this paper we introduce a general framework to assess and quantify quantum advantage in covert situations. This is based on extending the information bottleneck principle, originally developed for communication and machine learning applications, to decision problems via the Chernoff information, with the ultimate goal of quantitatively optimizing the trade-off between covertness and sensing ability. In this context we show how quantum resources, namely entangled photonic probes paired with photon counting, greatly outperform classical coherent transmitters in target detection and ranging, while also maintaining a chosen level of covertness. Our work highlights the great potential of integrating quantum sensing in LiDAR systems to enhance the covert performance.


**Translated Abstract**: 

目标探测是一个基本任务，具有许多实际应用，例如在LiDaR和雷达系统中。具有纠缠态的量子策略可以在相同的探测能量下实现更好的探测精度，但使用更高能量的经典探测器通常更简单，而不是利用量子区域。最近已经证明，在隐秘情况下可以实现有用的量子优势，其中探测必须在避免被对手发现的同时进行：在这种情况下，增加能量并不是一个可行的策略，因为这会使对手更容易发现。本文引入了一种通用框架，以评估和量化隐秘情况下的量子优势。这是基于将信息瓶颈原理扩展到通过Chernoff信息的决策问题，最终目标是定量优化隐秘性和探测能力之间的权衡。在此背景下，我们展示了量子资源，即与光子计数配对的纠缠光子探针，在目标检测和测距方面显著优于经典相干发射器，同时保持所选的隐秘性水平。我们的工作强调了将量子传感集成到LiDAR系统中以增强隐秘性能的巨大潜力。

**Summary**:

- (1): 本文的研究背景是量子传感在LiDaR和雷达系统中的应用，尤其是在隐秘情况下如何提高探测精度而不被对手发现。

- (2): 过去的方法多依赖于低能量的量子探测，但在实际场景中难以取得优势，尤其是在高热背景中。与现有方法相比，提出的方法利用了Chernoff信息的框架，旨在定量优化隐秘性与探测能力之间的权衡，解决了量子优势在实际应用中的局限性，具有很强的动机。

- (3): 本文的贡献在于提出了一种通用框架，量化并优化了隐秘情况下的量子探测能力，并展示了纠缠光子探针在目标检测和测距中的优势。

- (4): 本文提出的研究方法论基于信息瓶颈原理及Chernoff信息，通过数学量化隐秘性和探测能力的平衡。

- (5): 本文的方法在目标检测和测距的任务中取得了显著的性能提升，验证了量子资源在隐秘探测中的有效性，可以支持其目标。


## A score-based particle method for homogeneous Landau equation
- **Url**: http://arxiv.org/abs/2405.05187v2
- **Authors**: ['Yan Huang', 'Li Wang']
- **Abstrat**: We propose a novel score-based particle method for solving the Landau equation in plasmas, that seamlessly integrates learning with structure-preserving particle methods [arXiv:1910.03080]. Building upon the Lagrangian viewpoint of the Landau equation, a central challenge stems from the nonlinear dependence of the velocity field on the density. Our primary innovation lies in recognizing that this nonlinearity is in the form of the score function, which can be approximated dynamically via techniques from score-matching. The resulting method inherits the conservation properties of the deterministic particle method while sidestepping the necessity for kernel density estimation in [arXiv:1910.03080]. This streamlines computation and enhances scalability with dimensionality. Furthermore, we provide a theoretical estimate by demonstrating that the KL divergence between our approximation and the true solution can be effectively controlled by the score-matching loss. Additionally, by adopting the flow map viewpoint, we derive an update formula for exact density computation. Extensive examples have been provided to show the efficiency of the method, including a physically relevant case of Coulomb interaction.


**Translated Abstract**: 

我们提出了一种新型的基于评分的粒子方法，用于求解等离子体中的兰道方程，该方法无缝结合了学习和结构保持的粒子方法。在兰道方程的拉格朗日观点基础上，一个中心挑战是速度场对密度的非线性依赖。我们主要的创新在于认识到这种非线性以评分函数的形式展现，可以通过评分匹配技术动态近似。所得方法继承了确定性粒子方法的守恒属性，同时规避了以前方法中对核密度估计的必要性。这简化了计算，并增强了维度的可扩展性。此外，我们提供了理论估计，证明了我们的近似与真实解之间的KL散度可以通过评分匹配损失有效控制。此外，通过采用流映射视角，我们推导了精确密度计算的更新公式。提供了大量示例以展示该方法的效率，包括一个物理相关的库仑相互作用的案例。

**Summary**:

- (1): 本文的研究背景是兰道方程，这是一种基本的动理学方程，用于建模带电粒子在库仑相互作用下的演变，尤其是在碰撞效应显著的等离子体中。

- (2): 过去的方法主要基于粒子方法和深度学习的结合，存在训练困难及物理保真度缺失的问题。提出的方法通过动态获取评分函数，避免了昂贵的密度估计，从而加快计算速度，具有良好的动机。

- (3): 本文的贡献在于提出了一种新的基于评分的粒子方法，保留了确定性粒子方法的守恒特性，并在提高计算效率方面取得了实质性进展。

- (4): 本文提出的研究方法是通过评分匹配技术动态近似评分函数，并结合流映射视角推导出更新公式，以精确计算密度。

- (5): 本文方法在求解兰道方程的碰撞算子方面表现出显著的效率，且通过多个示例证明了其性能，支持了本文的研究目标。


## From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models
- **Url**: http://arxiv.org/abs/2504.06214v1
- **Authors**: ['Chejian Xu', 'Wei Ping', 'Peng Xu', 'Zihan Liu', 'Boxin Wang', 'Mohammad Shoeybi', 'Bo Li', 'Bryan Catanzaro']
- **Abstrat**: Long-context capabilities are essential for a wide range of applications, including document and video understanding, in-context learning, and inference-time scaling, all of which require models to process and reason over long sequences of text and multimodal data. In this work, we introduce a efficient training recipe for building ultra-long context LLMs from aligned instruct model, pushing the boundaries of context lengths from 128K to 1M, 2M, and 4M tokens. Our approach leverages efficient continued pretraining strategies to extend the context window and employs effective instruction tuning to maintain the instruction-following and reasoning abilities. Our UltraLong-8B, built on Llama3.1-Instruct with our recipe, achieves state-of-the-art performance across a diverse set of long-context benchmarks. Importantly, models trained with our approach maintain competitive performance on standard benchmarks, demonstrating balanced improvements for both long and short context tasks. We further provide an in-depth analysis of key design choices, highlighting the impacts of scaling strategies and data composition. Our findings establish a robust framework for efficiently scaling context lengths while preserving general model capabilities. We release all model weights at: https://ultralong.github.io/.


**Translated Abstract**: 

长上下文能力对于广泛的应用至关重要，包括文档和视频理解、上下文学习以及推理时的扩展，这些应用都需要模型处理和推理极长的文本和多模态数据。在这项工作中，我们引入了一种高效的训练方案，用于从对齐的指令模型构建超长上下文的大型语言模型，将上下文长度的边界从128K推至1M、2M和4M标记。我们的方法利用高效的持续预训练策略来扩展上下文窗口，并采用有效的指令调优来保持指令跟随和推理能力。基于我们的方案构建的UltraLong-8B，在各种长上下文基准上达到了最先进的性能。重要的是，使用我们的方法训练的模型在标准基准上保持了竞争力，展示了对长短上下文任务的平衡改进。我们进一步提供了关键设计选择的深入分析，强调了扩展策略和数据组成的影响。我们的发现建立了一个稳健的框架，以高效扩展上下文长度，同时保持模型的整体能力。我们在：https://ultralong.github.io/ 发布了所有模型权重。

**Summary**:

- (1): 本文关注超长上下文能力的需求，尤其是在文档和视频理解、上下文学习和推理时扩展的应用领域。

- (2): 过去的方法主要集中于在大型语言模型（LLMs）上扩展上下文窗口，但许多努力受到训练数据组合不足和高效扩展方案缺乏的限制。所提方法通过持续预训练和指令调优的结合，解决了模型在处理超长上下文时的能力不足问题，具有良好的动机。

- (3): 本文的贡献在于提出了一种系统的训练方案，能有效扩展上下文长度，达到1M、2M和4M标记，同时保持模型在标准任务上的竞争性能。

- (4): 研究方法包括两个主要阶段：首先，通过高质量的语料库进行持续预训练来扩展上下文窗口，其次，通过指令调优来提升模型的指令跟随和推理能力。

- (5): 本文的方法在多样的长上下文基准上取得了最先进的性能，这一性能支持了其在处理长短上下文任务的目标。


## Federated Automated Feature Engineering
- **Url**: http://arxiv.org/abs/2412.04404v2
- **Authors**: ['Tom Overman', 'Diego Klabjan']
- **Abstrat**: Automated feature engineering (AutoFE) is used to automatically create new features from original features to improve predictive performance without needing significant human intervention and domain expertise. Many algorithms exist for AutoFE, but very few approaches exist for the federated learning (FL) setting where data is gathered across many clients and is not shared between clients or a central server. We introduce AutoFE algorithms for the horizontal, vertical, and hybrid FL settings, which differ in how the data is gathered across clients. To the best of our knowledge, we are the first to develop AutoFE algorithms for the horizontal and hybrid FL cases, and we show that the downstream test scores of our federated AutoFE algorithms is close in performance to the case where data is held centrally and AutoFE is performed centrally.


**Translated Abstract**: 本文主要探讨了自动特征工程（AutoFE），用于自动从原始特征中生成新特征，以提高预测性能，而无需大量人类干预和领域专业知识。尽管现有许多AutoFE算法，但在联邦学习（FL）背景下的相关研究仍然很少。本研究提出了适用于水平、垂直和混合FL设置的AutoFE算法，这些设置在客户端间数据收集的方式上存在差异。根据我们所知，我们是首次针对水平和混合FL情况开发AutoFE算法，实验结果显示我们的联邦AutoFE算法在下游测试得分上的表现与数据集中存放并进行中心化AutoFE的情况相近。

**Summary**:

- (1): 本文的研究背景是自动特征工程（AutoFE）在联邦学习（FL）环境中的应用，关注如何在不共享原始数据的情况下生成有用的新特征。

- (2): 以往的AutoFE方法主要集中在中心化数据环境中，缺乏对FL设置的考虑，其主要问题在于不能直接在多个不共享数据的客户机上进行特征生成。本文提出的对水平和混合FL情况的AutoFE算法克服了这些问题，使用局部模型和模型权重聚合的方法，从而实现特征生成。

- (3): 本文的贡献在于首次针对水平和混合FL设置提出AutoFE算法，并证明其性能接近于传统中心化方法。

- (4): 本文研究方法包括针对三种FL设置（水平、垂直和混合）提出相应的AutoFE算法，应用同态加密和差分隐私技术安全地组合不同客户的特征，同时采用特征选择方案来确定生成的特征。

- (5): 本文中的方法在多个下游任务上进行评估，实验表明其在性能上与中心化的AutoFE方法相近，支持了研究目标的实现。


## NNN: Next-Generation Neural Networks for Marketing Mix Modeling
- **Url**: http://arxiv.org/abs/2504.06212v1
- **Authors**: ['Thomas Mulc', 'Mike Anderson', 'Paul Cubre', 'Huikun Zhang', 'Ivy Liu', 'Saket Kumar']
- **Abstrat**: We present NNN, a Transformer-based neural network approach to Marketing Mix Modeling (MMM) designed to address key limitations of traditional methods. Unlike conventional MMMs which rely on scalar inputs and parametric decay functions, NNN uses rich embeddings to capture both quantitative and qualitative aspects of marketing and organic channels (e.g., search queries, ad creatives). This, combined with its attention mechanism, enables NNN to model complex interactions, capture long-term effects, and potentially improve sales attribution accuracy. We show that L1 regularization permits the use of such expressive models in typical data-constrained settings. Evaluating NNN on simulated and real-world data demonstrates its efficacy, particularly through considerable improvement in predictive power. Beyond attribution, NNN provides valuable, complementary insights through model probing, such as evaluating keyword or creative effectiveness, enhancing model interpretability.


**Translated Abstract**: 

我们提出了一种基于Transformer的神经网络方法NNN，用于市场营销组合建模（MMM），旨在解决传统方法的关键局限性。与依靠标量输入和参数衰减函数的传统MMM不同，NNN使用丰富的嵌入来捕捉营销和有机渠道（例如搜索查询、广告创意）的定量和定性方面。结合其注意机制，NNN能够建模复杂的交互、捕捉长期影响，并可能提高销售归因准确性。我们表明，L1正则化使得在典型数据受限环境中使用这样的表达模型成为可能。在模拟和真实世界数据上评估NNN证明了其有效性，尤其是在预测能力上的显著提升。除了归因，NNN通过模型探测提供了有价值的补充洞察，例如评估关键词或创意的有效性，从而增强了模型的可解释性。

**Summary**:

- (1): 本文的研究背景是在数据驱动的市场营销环境中，准确归因特定活动的销售额是一个重要挑战，尤其是在第三方Cookie逐渐被淘汰和隐私法规变严的情况下。

- (2): 过去的方法主要是传统的市场营销组合模型（MMM），它们依赖于标量输入和参数化衰减函数，存在难以捕捉长期品牌效果、数据稀疏和假设响应曲线时间不变等问题。提出的方法NNN通过使用高维嵌入和Transformer架构来捕捉复杂交互，能更好地处理时间变化的创意效果，解决了这些传统方法的问题。

- (3): 本文的贡献在于提出了一种新的基于深度学习的市场营销组合建模方法NNN，具有更强的表达能力和预测性能，能够应对传统MMM的限制。

- (4): 本文的研究方法包括使用高维嵌入表示营销活动，建模中介信号以及采用Transformer架构来学习跨渠道和时间的复杂非线性交互，同时通过L1正则化来缓解过拟合问题。

- (5): 本文在模拟和真实数据集上评估NNN的性能，表现出显著的预测能力提升，验证了其在销售归因和效果评估方面的有效性，支撑了研究目标。


## Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs
- **Url**: http://arxiv.org/abs/2504.06211v1
- **Authors**: ['Alhad Daftardar', 'Jianqiao Mo', 'Joey Ah-kiow', 'Benedikt Bünz', 'Ramesh Karri', 'Siddharth Garg', 'Brandon Reagen']
- **Abstrat**: Zero-Knowledge Proofs (ZKPs) are rapidly gaining importance in privacy-preserving and verifiable computing. ZKPs enable a proving party to prove the truth of a statement to a verifying party without revealing anything else. ZKPs have applications in blockchain technologies, verifiable machine learning, and electronic voting, but have yet to see widespread adoption due to the computational complexity of the proving process. Recent works have accelerated the key primitives of state-of-the-art ZKP protocols on GPU and ASIC. However, the protocols accelerated thus far face one of two challenges: they either require a trusted setup for each application, or they generate larger proof sizes with higher verification costs, limiting their applicability in scenarios with numerous verifiers or strict verification time constraints. This work presents an accelerator, zkSpeed, for HyperPlonk, a state-of-the-art ZKP protocol that supports both one-time, universal setup and small proof sizes for typical ZKP applications in publicly verifiable, consensus-based systems. We accelerate the entire protocol, including two major primitives: SumCheck and Multi-scalar Multiplications (MSMs). We develop a full-chip architecture using 366.46 mm$^2$ and 2 TB/s of bandwidth to accelerate the entire proof generation process, achieving geometric mean speedups of 801$\times$ over CPU baselines.


**Translated Abstract**: 
零知识证明（ZKP）在隐私保护和可验证计算中日益重要。ZKP使得证明方能够在不透露任何其他信息的情况下，向验证方证明某一陈述的真实性。ZKP在区块链技术、可验证机器学习和电子投票中有应用，但由于证明过程的计算复杂性，尚未得到广泛采用。最近的研究加速了最先进的ZKP协议中关键原语的GPU和ASIC加速。然而，已有的加速协议面临两项挑战：要么为每个应用程序要求可信设置，要么产生更大的证明体积和更高的验证成本，这限制了它们在有多个验证者或严格验证时间限制的场景中的适用性。本研究提出了一个加速器zkSpeed，针对HyperPlonk这一最先进的ZKP协议，它支持一次性、通用设置和典型ZKP应用中的小证明体积。我们加速了整个协议，包括两个主要原语：SumCheck和多标量乘法（MSMs）。我们开发了一个全芯片架构，使用366.46 mm²和2 TB/s的带宽加速整个证明生成过程，达到了相较于CPU基线的801倍的几何平均加速。

**Summary**:

- (1): 本文的研究背景是零知识证明（ZKP）在隐私保护和可验证计算领域的重要性，尤其是在区块链技术和电子投票中的应用。

- (2): 过去的加速方法主要在GPU和ASIC上进行了ZKP协议关键原语的加速，但面临需要每个应用程序可信设置或产生较大证明体积的问题。提出的方法zkSpeed与现有方法不同，它加速HyperPlonk协议，使用一次性通用设置并生成较小的证明体积，解决了既有方法的局限性。同时，该方法在理论基础上有充分动机。

- (3): 本文的贡献在于设计了zkSpeed，一个专为HyperPlonk协议加速的全芯片架构，实现了高达801倍的速度提升，并解决了传统ZKP协议在计算复杂性和证明体积上的问题。

- (4): 本文提出的研究方法是开发了一个全芯片架构，以366.46 mm²面积和2 TB/s的带宽，对整个证明生成过程进行加速，重点加速了SumCheck和多标量乘法（MSMs）两个主要原语。

- (5): 本研究在HyperPlonk协议的证明生成任务上，实现了相较于CPU基线的801倍的加速性能，这种性能提升支持了研究目标，有助于推动ZKP在广泛应用中的采用。


## The Work Capacity of Channels with Memory: Maximum Extractable Work in Percept-Action Loops
- **Url**: http://arxiv.org/abs/2504.06209v1
- **Authors**: ['Lukas J. Fiderer', 'Paul C. Barth', 'Isaac D. Smith', 'Hans J. Briegel']
- **Abstrat**: Predicting future observations plays a central role in machine learning, biology, economics, and many other fields. It lies at the heart of organizational principles such as the variational free energy principle and has even been shown -- based on the second law of thermodynamics -- to be necessary for reaching the fundamental energetic limits of sequential information processing. While the usefulness of the predictive paradigm is undisputed, complex adaptive systems that interact with their environment are more than just predictive machines: they have the power to act upon their environment and cause change. In this work, we develop a framework to analyze the thermodynamics of information processing in percept-action loops -- a model of agent-environment interaction -- allowing us to investigate the thermodynamic implications of actions and percepts on equal footing. To this end, we introduce the concept of work capacity -- the maximum rate at which an agent can expect to extract work from its environment. Our results reveal that neither of two previously established design principles for work-efficient agents -- maximizing predictive power and forgetting past actions -- remains optimal in environments where actions have observable consequences. Instead, a trade-off emerges: work-efficient agents must balance prediction and forgetting, as remembering past actions can reduce the available free energy. This highlights a fundamental departure from the thermodynamics of passive observation, suggesting that prediction and energy efficiency may be at odds in active learning systems.


**Translated Abstract**: 预测未来观察在机器学习、生物学、经济学等多个领域中发挥着核心作用。它是变分自由能原理等组织原则的核心，甚至被证明是达到顺序信息处理基本能量极限所必需的。尽管预测范式的有效性没有争议，但与环境互动的复杂自适应系统不仅仅是预测机器：它们有能力影响其环境并导致变化。在本研究中，我们开发了一个框架来分析感知-行为循环中的信息处理热力学——即探讨代理与环境相互作用的模型——使我们能够同等考察行为和感知的热力学影响。为此，我们引入了工作容量的概念——代理从环境中提取工作的最大速率。我们的结果揭示，在具有可观察后果的环境中，以前建立的两个高效代理设计原则——最大化预测能力和遗忘过去行为——均不再是最优的。相反，一个权衡出现：高效代理必须在预测和遗忘之间取得平衡，因为记住过去的行为可能会减少可用的自由能。这突出显示了从被动观察的热力学中一个根本的不同，暗示在主动学习系统中，预测与能源效率可能存在矛盾。

**Summary**:

- (1): 文章背景是关于预测未来观察在多个领域的重要性，以及其与复杂自适应系统的相互作用。

- (2): 过去的方法侧重于最大化预测能力或遗忘过去行为，存在无法优化代理在有后果的环境中的实际应用问题。提出的方法通过引入“工作容量”概念，解决了这一问题，强调了在行为与感知的热力学影响上取得平衡的必要性。

- (3): 文章的贡献在于提出了一个新的框架，将热力学与感知-行为循环结合，阐明了在行动具可观察后果的环境中，预测能力和遗忘之间转化的权衡。

- (4): 研究方法是通过信息论模型抽象化地分析感知-行为循环中的信息处理，利用非平衡热力学的原理推导出内在的能量处理界限。

- (5): 具体任务及性能未在摘要中明确提及。尽管如此，提出的方法能够揭示和理解预测与能源效率之间的权衡关系，支持其研究目标。


## An experimental survey and Perspective View on Meta-Learning for Automated Algorithms Selection and Parametrization
- **Url**: http://arxiv.org/abs/2504.06207v1
- **Authors**: ['Moncef Garouani']
- **Abstrat**: Considerable progress has been made in the recent literature studies to tackle the Algorithms Selection and Parametrization (ASP) problem, which is diversified in multiple meta-learning setups. Yet there is a lack of surveys and comparative evaluations that critically analyze, summarize and assess the performance of existing methods. In this paper, we provide an overview of the state of the art in this continuously evolving field. The survey sheds light on the motivational reasons for pursuing classifiers selection through meta-learning. In this regard, Automated Machine Learning (AutoML) is usually treated as an ASP problem under the umbrella of the democratization of machine learning. Accordingly, AutoML makes machine learning techniques accessible to domain scientists who are interested in applying advanced analytics but lack the required expertise. It can ease the task of manually selecting ML algorithms and tuning related hyperparameters. We comprehensively discuss the different phases of classifiers selection based on a generic framework that is formed as an outcome of reviewing prior works. Subsequently, we propose a benchmark knowledge base of 4 millions previously learned models and present extensive comparative evaluations of the prominent methods for classifiers selection based on 08 classification algorithms and 400 benchmark datasets. The comparative study quantitatively assesses the performance of algorithms selection methods along while emphasizing the strengths and limitations of existing studies.


**Translated Abstract**: 

近年来，在解决算法选择和参数化（ASP）问题的文献研究中取得了显著进展，但缺乏批判性分析、总结和评估现有方法性能的调查和比较评估。本文提供了这一不断发展的领域的最新状态概述。调查阐明了通过元学习开展分类器选择的动机。在这方面，自动化机器学习（AutoML）通常被视为ASP问题的一部分，使机器学习技术对缺乏必要专业知识的领域科学家易于接触。它可以简化手动选择机器学习算法和调整相关超参数的任务。我们全面讨论了基于回顾先前工作的结果形成的通用框架中分类器选择的不同阶段。随后，我们提出了一个包含400万之前学习模型的基准知识库，并针对8个分类算法和400个基准数据集的分类器选择方法进行了广泛的比较评估。比较研究定量评估了算法选择方法的绩效，同时强调了现有研究的优缺点。

**Summary**:

- (1): 本文研究背景为解决算法选择与参数化（ASP）问题，近年来在相关领域取得进展但存在对现有方法缺乏综合评估的情况。

- (2): 过去的方法是基于元学习的算法选择与参数化，问题在于缺乏批判性分析和比较评估， proposed 方法通过建立包含400万模型的知识库来解决这些问题，动机充分。

- (3): 本文的贡献在于提供了全面的元学习方法的调查与比较评价，为科学家及研究人员选择适当的算法提供支持。

- (4): 本文提出的研究方法论包括建立基于元数据的分类器选择框架和大规模的知识库，系统性评估现有算法。

- (5): 该方法在400个基准数据集上的算法选择任务中取得了显著性能，支持了其优化和自动化的目标。


## Recitation over Reasoning: How Cutting-Edge Language Models Can Fail on Elementary School-Level Reasoning Problems?
- **Url**: http://arxiv.org/abs/2504.00509v2
- **Authors**: ['Kai Yan', 'Yufei Xu', 'Zhengyin Du', 'Xuesong Yao', 'Zheyu Wang', 'Xiaowen Guo', 'Jiecao Chen']
- **Abstrat**: The rapid escalation from elementary school-level to frontier problems of the difficulty for LLM benchmarks in recent years have weaved a miracle for researchers that we are only inches away from surpassing human intelligence. However, is the LLMs' remarkable reasoning ability indeed comes from true intelligence by human standards, or are they simply reciting solutions witnessed during training at an Internet level? To study this problem, we propose RoR-Bench, a novel, multi-modal benchmark for detecting LLM's recitation behavior when asked simple reasoning problems but with conditions subtly shifted, and conduct empirical analysis on our benchmark. Surprisingly, we found existing cutting-edge LLMs unanimously exhibits extremely severe recitation behavior; by changing one phrase in the condition, top models such as OpenAI-o1 and DeepSeek-R1 can suffer $60\%$ performance loss on elementary school-level arithmetic and reasoning problems. Such findings are a wake-up call to the LLM community that compels us to re-evaluate the true intelligence level of cutting-edge LLMs.


**Translated Abstract**: 

近年来，从小学水平到前沿问题的困难程度的快速升级，让研究人员感到我们已经离超越人类智能仅有一步之遥。然而，LLMs（大型语言模型）非凡的推理能力真的是符合人类标准的真正智能，还是仅仅在重复训练过程中接触到的网络水平的解决方案？为了研究这个问题，我们提出了RoR-Bench，这是一个多模态基准，用于检测LLMs在面对简单推理问题时的重述行为，并开展了对该基准的实证分析。令人惊讶的是，我们发现现有的尖端LLMs都表现出极其严重的重述行为；通过改变条件中的一个短语，顶级模型如OpenAI-o1和DeepSeek-R1在小学水平的算术和推理问题上可以遭遇60%的性能损失。这一发现对LLM社区是一个警钟，促使我们重新评估尖端LLMs的真实智能水平。

**Summary**:

- (1): 本文的研究背景是随着LLMs（大型语言模型）的迅猛发展，在推理能力方面是否真正具备人类智能而存在的疑问。

- (2): 过去的研究主要集中于提升LLMs的训练数据和参数规模，但普遍未能解释LLMs的智能本质。提出的方法RoR-Bench，利用轻微条件变化来检测重述行为，与现有方法相比，更加深入探索LLMs的推理能力。

- (3): 本文的贡献在于揭示了当前尖端LLMs在简单推理问题上重述而非真正推理的严重问题，并提出了相应的基准RoR-Bench来探测这种行为。

- (4): 本文所提的方法是RoR-Bench，这是一种新型的多模态基准，通过158对文本问题和57对图像问题来检测LLMs的推理能力，这些问题都包含轻微但关键的条件变化。

- (5): 本文在小学水平的算术和推理问题上进行了测试，结果表明现有LLMs在性能上存在超过60%的损失，这表明其在实现真实推理能力上仍远未达到目标。


## Improving Genetic Programming for Symbolic Regression with Equality Graphs
- **Url**: http://arxiv.org/abs/2501.17848v2
- **Authors**: ['Fabricio Olivetti de Franca', 'Gabriel Kronberger']
- **Abstrat**: The search for symbolic regression models with genetic programming (GP) has a tendency of revisiting expressions in their original or equivalent forms. Repeatedly evaluating equivalent expressions is inefficient, as it does not immediately lead to better solutions. However, evolutionary algorithms require diversity and should allow the accumulation of inactive building blocks that can play an important role at a later point. The equality graph is a data structure capable of compactly storing expressions and their equivalent forms allowing an efficient verification of whether an expression has been visited in any of their stored equivalent forms. We exploit the e-graph to adapt the subtree operators to reduce the chances of revisiting expressions. Our adaptation, called eggp, stores every visited expression in the e-graph, allowing us to filter out from the available selection of subtrees all the combinations that would create already visited expressions. Results show that, for small expressions, this approach improves the performance of a simple GP algorithm to compete with PySR and Operon without increasing computational cost. As a highlight, eggp was capable of reliably delivering short and at the same time accurate models for a selected set of benchmarks from SRBench and a set of real-world datasets.


**Translated Abstract**: 

使用遗传编程（GP）进行符号回归模型的搜索倾向于重复评估原始或等价形式的表达式。重复评估等价表达式效率低下，因为这并不立即导致更好的解决方案。然而，进化算法需要多样性，并应允许累积在以后的阶段可能发挥重要作用的非活动构建块。等价图是一种能够紧凑存储表达式及其等价形式的数据结构，允许有效验证某个表达式是否已在其存储的任何等价形式中被访问。我们利用e-graph来调整子树操作，减少重复访问表达式的可能性。我们提出的名为eggp的方法在e-graph中存储每个访问过的表达式，这使我们能够过滤出所有可能生成已访问表达式的子树组合。结果表明，对于小表达式，这种方法提高了简单GP算法的性能，使其能够与PySR和Operon竞争，而不增加计算成本。值得一提的是，eggp能够可靠地为SRBench上的一组基准和一组现实世界数据集提供简短而准确的模型。

**Summary**:

- (1): 本文研究背景是符号回归（SR）模型的效率问题，尤其是遗传编程（GP）在搜索过程中倾向重复评估已存在的表达式。

- (2): 过去的方法主要依靠GP进行符号回归，但存在频繁评估等价表达式的问题，导致寻找最优解的效率低下。与现有方法不同，本文提出的eggp采用等价图（e-graph）来存储和验证表达式，确保生成未访问的表达式，从而提升效率。这种方法针对上述问题具有良好的动机。

- (3): 本文的贡献在于提出了一种利用e-graph的eggp算法，显著提高了GP算法在符号回归中的表现，使其与当前的先进算法竞争而无需增加计算成本。

- (4): 本文的研究方法在于调整遗传编程的子树操作，使得在生成表达式时优先选择未访问的表达式，从而有效利用e-graph结构。

- (5): 本文在对比基准数据集及现实世界数据集的任务中，eggp在性能上实现了与PySR和Operon相竞争的效果，表明其达到了预期目标。


## Understanding Gradient Orthogonalization for Deep Learning via Non-Euclidean Trust-Region Optimization
- **Url**: http://arxiv.org/abs/2503.12645v2
- **Authors**: ['Dmitry Kovalev']
- **Abstrat**: Optimization with matrix gradient orthogonalization has recently demonstrated impressive results in the training of deep neural networks (Jordan et al., 2024; Liu et al., 2025). In this paper, we provide a theoretical analysis of this approach. In particular, we show that the orthogonalized gradient method can be seen as a first-order trust-region optimization method, where the trust-region is defined in terms of the matrix spectral norm. Motivated by this observation, we develop the stochastic non-Euclidean trust-region gradient method with momentum, which recovers the Muon optimizer (Jordan et al., 2024) as a special case, along with normalized SGD and signSGD with momentum (Cutkosky and Mehta, 2020; Sun et al., 2023). In addition, we prove state-of-the-art convergence results for the proposed algorithm in a range of scenarios, which involve arbitrary non-Euclidean norms, constrained and composite problems, and non-convex, star-convex, first- and second-order smooth functions. Finally, our theoretical findings provide an explanation for several practical observations, including the practical superiority of Muon compared to the Orthogonal-SGDM algorithm of Tuddenham et al. (2022) and the importance of weight decay in the training of large-scale language models.


**Translated Abstract**: 

最近，使用矩阵梯度正交化的优化方法在训练深度神经网络中表现出令人印象深刻的结果（Jordan等人，2024；Liu等人，2025）。本文提供了对这一方法的理论分析。具体而言，我们证明正交梯度方法可以视为一种一阶信任区域优化方法，其中信任区域是通过矩阵谱范数定义的。基于这一观察，我们开发了带动量的随机非欧几里得信任区域梯度方法，恢复了Muon优化器（Jordan等人，2024）作为特例，以及带动量的规范化SGD和signSGD（Cutkosky和Mehta，2020；Sun等人，2023）。此外，我们证明了所提出算法在多种场景下的最先进收敛结果，涉及任意非欧几里得范数、约束和复合问题，以及非凸、星凹、一阶和二阶平滑函数。最后，我们的理论发现解释了几个实际观察结果，包括Muon在与Tuddenham等人（2022）的Orthogonal-SGDM算法比较中的实际优越性，以及权重衰减在大规模语言模型训练中的重要性。

**Summary**:

- (1): 文章研究的背景是深度神经网络训练中优化算法的逐步发展，特别是适应性梯度优化算法的兴起。

- (2): 过去的方法主要包括AdamW优化器，存在的主要问题是未能在某些任务中超越现有的优化性能。所提议的方法通过正交化梯度更新进行改进，能够在训练大型语言模型中表现得更优秀，具有很好的动机基础。

- (3): 本文的贡献在于理论上分析了正交梯度的优化方法，提出了带动量的随机非欧几里得信任区域梯度方法，并证明了其在多种场景下的收敛性结果。

- (4): 本文的方法论包括将正交梯度方法视为一阶信任区域优化法，并发展了相应的随机算法，对非欧几里得范数及多种类型的优化问题进行研究。

- (5): 该方法应用于训练大规模语言模型，并在性能上超越了多项现有算法，表明其能够支持研究目标。


## TxGemma: Efficient and Agentic LLMs for Therapeutics
- **Url**: http://arxiv.org/abs/2504.06196v1
- **Authors**: ['Eric Wang', 'Samuel Schmidgall', 'Paul F. Jaeger', 'Fan Zhang', 'Rory Pilgrim', 'Yossi Matias', 'Joelle Barral', 'David Fleet', 'Shekoofeh Azizi']
- **Abstrat**: Therapeutic development is a costly and high-risk endeavor that is often plagued by high failure rates. To address this, we introduce TxGemma, a suite of efficient, generalist large language models (LLMs) capable of therapeutic property prediction as well as interactive reasoning and explainability. Unlike task-specific models, TxGemma synthesizes information from diverse sources, enabling broad application across the therapeutic development pipeline. The suite includes 2B, 9B, and 27B parameter models, fine-tuned from Gemma-2 on a comprehensive dataset of small molecules, proteins, nucleic acids, diseases, and cell lines. Across 66 therapeutic development tasks, TxGemma achieved superior or comparable performance to the state-of-the-art generalist model on 64 (superior on 45), and against state-of-the-art specialist models on 50 (superior on 26). Fine-tuning TxGemma models on therapeutic downstream tasks, such as clinical trial adverse event prediction, requires less training data than fine-tuning base LLMs, making TxGemma suitable for data-limited applications. Beyond these predictive capabilities, TxGemma features conversational models that bridge the gap between general LLMs and specialized property predictors. These allow scientists to interact in natural language, provide mechanistic reasoning for predictions based on molecular structure, and engage in scientific discussions. Building on this, we further introduce Agentic-Tx, a generalist therapeutic agentic system powered by Gemini 2.5 that reasons, acts, manages diverse workflows, and acquires external domain knowledge. Agentic-Tx surpasses prior leading models on the Humanity's Last Exam benchmark (Chemistry & Biology) with 52.3% relative improvement over o3-mini (high) and 26.7% over o3-mini (high) on GPQA (Chemistry) and excels with improvements of 6.3% (ChemBench-Preference) and 2.4% (ChemBench-Mini) over o3-mini (high).


**Translated Abstract**: 

治疗药物开发是一个昂贵且高风险的过程，失败率往往很高。为了解决这个问题，我们引入了 TxGemma，一个高效的通用大语言模型（LLM）套件，能够进行治疗属性预测以及互动推理和可解释性。与特定任务的模型不同，TxGemma 综合了来自不同来源的信息，使其能够广泛应用于治疗开发管道。该套件包括 2B、9B 和 27B 参数模型，基于针对小分子、蛋白质、核酸、疾病和细胞系的综合数据集对 Gemma-2 进行了微调。在 66 个治疗开发任务中，TxGemma 在 64 个任务上达到了比最先进的通用模型更优或相当的性能（在 45 个任务上更优），并且在 50 个任务上比最先进的特定模型表现更好（在 26 个任务上更优）。在临床试验不良事件预测等下游任务上微调 TxGemma 模型时，所需的训练数据比微调基础 LLMs 少，使 TxGemma 适合于数据有限的应用。除了这些预测能力外，TxGemma 还具有对话模型，弥合了通用 LLMs 和专业属性预测器之间的差距。这些模型允许科学家使用自然语言进行互动，基于分子结构提供机制推理，并参与科学讨论。基于此，我们进一步引入了 Agentic-Tx，一个由 Gemini 2.5 支撑的通用治疗代理系统，能够推理、行动、管理多样的工作流并获取外部领域知识。Agentic-Tx 在 Humanity's Last Exam 基准（化学与生物学）上超过了之前的领先模型，相对改善了 52.3% 和 26.7% 的 o3-mini（高）分数，并在 ChemBench 上分别提高了 6.3%（ChemBench-Preference）和 2.4%（ChemBench-Mini）相对于 o3-mini（高）。

**Summary**:

- (1): 本研究关注于药物开发过程中的高成本和高风险问题，特别是高失败率以及药物特性预测的有效性。

- (2): 过去的方法通常依赖于特定任务的模型，存在信息集成不足和对多样化数据的应用受限的问题。与之不同，TxGemma 通过综合多种数据源的信息提高预测能力，针对特定下游任务的微调所需数据更少，以适应数据有限的应用。

- (3): 本文的贡献在于提出 TxGemma 套件，展现了其在治疗属性预测和互动推理方面的优越性能，并且公开发布，使研究人员能够在多样的数据集上验证和适应模型。

- (4): 研究方法论包括基于 Therapeutics Data Commons (TDC) 的大规模数据集进行细化训练，采用了一种多层次的微调和对话训练策略。

- (5): TxGemma 在 66 个治疗开发任务中表现突出，64 个任务达到优越或可比的性能，尤其在临床试验不良事件预测中，所需数据显著减少，说明其性能能够支持预定目标。


## Accuracy Enhancement in Refractive Index Sensing via Full-Spectrum Machine Learning Modeling
- **Url**: http://arxiv.org/abs/2504.06195v1
- **Authors**: ['Majid Aalizadeh', 'Chinmay Raut', 'Morteza Azmoudeh Afshar', 'Ali Tabartehfarahani', 'Xudong Fan']
- **Abstrat**: We present a full-spectrum machine learning framework for refractive index sensing using simulated absorption spectra from meta-grating structures composed of titanium or silicon nanorods under TE and TM polarizations. Linear regression was applied to 80 principal components extracted from each spectrum, and model performance was assessed using five-fold cross-validation, simulating real-world biosensing scenarios where unknown patient samples are predicted based on standard calibration data. Titanium-based structures, dominated by broadband intensity changes, yielded the lowest mean squared errors and the highest accuracy improvements: up to a 6065-fold reduction compared to the best single-feature model. In contrast, silicon-based structures, governed by narrow resonances, showed more modest gains due to spectral nonlinearity that limits the effectiveness of global linear models. We also show that even the best single-wavelength predictor is identified through data-driven analysis, not visual selection, highlighting the value of automated feature preselection. These findings demonstrate that spectral shape plays a key role in modeling performance and that full-spectrum linear approaches are especially effective for intensity-modulated index sensors.


**Translated Abstract**: 

我们提出了一种全光谱机器学习框架，用于基于由钛或硅纳米杆组成的超构结构的模拟吸收光谱进行折射率传感。在每个光谱中提取80个主成分后应用线性回归，并利用五折交叉验证评估模型性能，模拟在基于标准校准数据预测未知患者样本的现实生物传感情景。以钛为基础的结构以宽带强度变化为主，产生了最低的均方误差和最高的准确率提升：相比于最佳单特征模型，减少了多达6065倍。相比之下，由窄共振主导的硅基结构由于光谱非线性，导致增益较为温和，限制了全局线性模型的有效性。我们还通过数据驱动分析识别出最佳单波长预测器，而非视觉选择，这突显了自动特征预选择的价值。这些发现表明，光谱形状在建模性能中起着关键作用，全光谱线性方法对于强度调制的折射率传感器尤其有效。

**Summary**:

- (1): 本文研究的背景是折射率传感技术的准确性提升，利用全光谱机器学习方法来改善传感器性能。

- (2): 过去的方法主要采用单一特征或狭窄范围的光谱数据，存在模型精度不足和对光谱非线性敏感的问题。所提出的方法通过全光谱线性回归建模，解决了这些局限性，并展示了光谱形状对建模性能的重要性，具有很强的动机性。

- (3): 本文的贡献在于提出了基于全光谱的机器学习框架，并且通过实验结果显示该方法在钛基结构上的高效性和准确性，并取得了显著的性能提升。

- (4): 本文的研究方法论包括利用模拟吸收光谱提取主成分，并通过线性回归模型进行五折交叉验证，模拟实际生物传感情况。

- (5): 本文的方法在折射率传感任务上取得了最小均方误差和最高准确性，表现出相较于单特征模型高达6065倍的性能提升，支持了其研究目标。


## Heuristic Methods are Good Teachers to Distill MLPs for Graph Link Prediction
- **Url**: http://arxiv.org/abs/2504.06193v1
- **Authors**: ['Zongyue Qin', 'Shichang Zhang', 'Mingxuan Ju', 'Tong Zhao', 'Neil Shah', 'Yizhou Sun']
- **Abstrat**: Link prediction is a crucial graph-learning task with applications including citation prediction and product recommendation. Distilling Graph Neural Networks (GNNs) teachers into Multi-Layer Perceptrons (MLPs) students has emerged as an effective approach to achieve strong performance and reducing computational cost by removing graph dependency. However, existing distillation methods only use standard GNNs and overlook alternative teachers such as specialized model for link prediction (GNN4LP) and heuristic methods (e.g., common neighbors). This paper first explores the impact of different teachers in GNN-to-MLP distillation. Surprisingly, we find that stronger teachers do not always produce stronger students: MLPs distilled from GNN4LP can underperform those distilled from simpler GNNs, while weaker heuristic methods can teach MLPs to near-GNN performance with drastically reduced training costs. Building on these insights, we propose Ensemble Heuristic-Distilled MLPs (EHDM), which eliminates graph dependencies while effectively integrating complementary signals via a gating mechanism. Experiments on ten datasets show an average 7.93% improvement over previous GNN-to-MLP approaches with 1.95-3.32 times less training time, indicating EHDM is an efficient and effective link prediction method.


**Translated Abstract**: 

链接预测是一个重要的图学习任务，应用广泛，包括引用预测和产品推荐。将图神经网络（GNNs）教师的知识蒸馏到多层感知器（MLPs）学生中，已成为一种有效的方法，可以通过消除图依赖关系来实现强大的性能和减少计算成本。然而，现有的蒸馏方法仅使用标准GNNs，忽视了诸如专门针对链接预测的模型（GNN4LP）和启发式方法（例如，公共邻居）等其他教师。本文首先探索了不同教师在GNN到MLP蒸馏中的影响。令人惊讶的是，我们发现更强的教师并不总能产生更强的学生：从GNN4LP蒸馏的MLPs可能表现不如从更简单的GNNs蒸馏的MLPs，而更弱的启发式方法可以教会MLPs以大幅度降低训练成本实现接近GNN的性能。基于这些见解，我们提出了融合启发式蒸馏的MLPs（EHDM），该方法在消除图依赖的同时通过门控机制有效整合互补信号。在十个数据集上的实验表明，与之前的GNN到MLP方法相比，平均提升了7.93%的性能，同时训练时间减少了1.95到3.32倍，表明EHDM是一种高效且有效的链接预测方法。

**Summary**:

- (1): 本文研究背景是链接预测这一重要图学习任务，应用包括引用预测和产品推荐等。

- (2): 过去的方法主要集中在使用标准GNNs作为教师进行知识蒸馏，但这些方法忽视了其他潜在的教师模型，如GNN4LP和启发式方法，且在计算开销和性能上存在局限性。本文提议的方法通过探索不同教师影响MLP性能，提出了启发式方法作为有效教师，从而在性能与计算的权衡上取得突破。

- (3): 本文的贡献在于证明了即使是表现较差的启发式方法也可以成为优良的教师，同时提出了有效的EHDM方法，通过门控机制整合多种启发式蒸馏的MLPs。

- (4): 本文的研究方法是基于启发式教师进行MLP蒸馏，同时设计了一种门控机制来融合多个启发式方法的预测结果，以提升性能并消除图依赖。

- (5): 该方法在十个数据集（包括三个百万规模数据集）上进行评估，实现了平均7.93%的性能提升，整体训练时间减少1.95-3.32倍。该性能支持其提升链接预测的目标。


## rEGGression: an Interactive and Agnostic Tool for the Exploration of Symbolic Regression Models
- **Url**: http://arxiv.org/abs/2501.17859v2
- **Authors**: ['Fabricio Olivetti de Franca', 'Gabriel Kronberger']
- **Abstrat**: Regression analysis is used for prediction and to understand the effect of independent variables on dependent variables. Symbolic regression (SR) automates the search for non-linear regression models, delivering a set of hypotheses that balances accuracy with the possibility to understand the phenomena. Many SR implementations return a Pareto front allowing the choice of the best trade-off. However, this hides alternatives that are close to non-domination, limiting these choices. Equality graphs (e-graphs) allow to represent large sets of expressions compactly by efficiently handling duplicated parts occurring in multiple expressions. E-graphs allow to store and query all SR solution candidates visited in one or multiple GP runs efficiently and open the possibility to analyse much larger sets of SR solution candidates. We introduce rEGGression, a tool using e-graphs to enable the exploration of a large set of symbolic expressions which provides querying, filtering, and pattern matching features creating an interactive experience to gain insights about SR models. The main highlight is its focus in the exploration of the building blocks found during the search that can help the experts to find insights about the studied phenomena.This is possible by exploiting the pattern matching capability of the e-graph data structure.


**Translated Abstract**: 

回归分析用于预测和理解自变量对因变量的影响。符号回归（Symbolic Regression，SR）自动化搜索非线性回归模型，提供一系列权衡准确性与可理解性的假设。许多SR实现返回Pareto前沿，但这隐藏了接近非支配的替代方案，限制了选择。等式图（e-graphs）能够有效处理多个表达式中的重复部分，紧凑地表示大量表达式。e-graphs能够高效存储和查询在一个或多个GP运行中访问的所有SR解候选，分析更大的SR解候选集的可能性。我们介绍了rEGGression，一种利用e-graphs的工具，支持对一大组合符号表达式的探索，提供查询、过滤和模式匹配功能，从而创造交互式体验，帮助深入了解SR模型。其主要亮点在于探索搜索过程中发现的构建块，帮助专家理解所研究的现象，通过利用e-graph数据结构的模式匹配能力实现。

**Summary**:

- (1): 本文的研究背景是回归分析在预测和理解现象中的应用，特别是符号回归（SR）用于自动化搜索非线性回归模型的潜力。

- (2): 过去的方法通常返回Pareto前沿，展示准确性与复杂性的权衡，但这限制了可选择的替代方案。提出的方法通过使用等式图（e-graphs）存储和查询耗时的数据，使用户能够探索更大的SR解集，解决了以往方法对解候选的局限性，具有良好的动机。

- (3): 本文的贡献在于研发出rEGGression工具，支持对来自不同来源的符号表达式模型的交互式探索，提供丰富的可选模型库。

- (4): 本文提出的研究方法是rEGGression工具，该工具利用e-graphs进行符号表达式的查询、过滤和模式匹配，能够高效探索SR解集。

- (5): 本文中提出的方法在符号回归任务上展示了有效性，有助于用户监测和分析多种表达式，支持推动复杂模型的可解释性和理解其背后的现象。


## WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and Real-World Wound Care
- **Url**: http://arxiv.org/abs/2504.06185v1
- **Authors**: ['Vanessa Borst', 'Timo Dittus', 'Tassilo Dege', 'Astrid Schmieder', 'Samuel Kounev']
- **Abstrat**: Chronic wounds affect a large population, particularly the elderly and diabetic patients, who often exhibit limited mobility and co-existing health conditions. Automated wound monitoring via mobile image capture can reduce in-person physician visits by enabling remote tracking of wound size. Semantic segmentation is key to this process, yet wound segmentation remains underrepresented in medical imaging research. To address this, we benchmark state-of-the-art deep learning models from general-purpose vision, medical imaging, and top methods from public wound challenges. For fair comparison, we standardize training, data augmentation, and evaluation, conducting cross-validationto minimize partitioning bias. We also assess real-world deployment aspects, including generalization to an out-of-distribution wound dataset, computational efficiency, and interpretability. Additionally, we propose a reference object-based approach to convert AI-generated masks into clinically relevant wound size estimates, and evaluate this, along with mask quality, for the best models based on physician assessments. Overall, the transformer-based TransNeXt showed the highest levels of generalizability. Despite variations in inference times, all models processed at least one image per second on the CPU, which is deemed adequate for the intended application. Interpretability analysis typically revealed prominent activations in wound regions, emphasizing focus on clinically relevant features. Expert evaluation showed high mask approval for all analyzed models, with VWFormer and ConvNeXtS backbone performing the best. Size retrieval accuracy was similar across models, and predictions closely matched expert annotations. Finally, we demonstrate how our AI-driven wound size estimation framework, WoundAmbit, can be integrated into a custom telehealth system. Our code will be made available on GitHub upon publication.


**Translated Abstract**: 

慢性伤口影响了大量人群，特别是老年人和糖尿病患者，他们通常行动不便并伴有其他健康问题。通过移动图像捕获实现自动化伤口监测，可以减少面对面就诊，简化伤口大小的远程跟踪。语义分割是此过程的关键，但伤口分割在医学成像研究中仍然不够重视。为了解决这一问题，我们对来自通用视觉、医学成像的最先进深度学习模型和公共伤口挑战的顶级方法进行了基准测试。为了公平比较，我们标准化了训练、数据增强和评估，并进行交叉验证以最小化分区偏差。还评估了实际部署方面，包括对分布外伤口数据集的泛化能力、计算效率和可解释性。此外，我们提出了一种基于参考对象的方法，将 AI 生成的掩码转换为临床相关的伤口大小估计，并根据医生评估验证这一点以及掩码质量。总体而言，基于变压器的 TransNeXt 显示出最高的泛化能力。尽管推理时间有所不同，所有模型在 CPU 上的处理速度均达到每秒至少处理一幅图像，这被认为是适合的。可解释性分析通常显示在伤口区域的突出激活，强调关注临床相关特征。专家评估显示所有分析模型的掩码批准率均很高，其中 VWFormer 和 ConvNeXtS 主干表现最佳。尺寸检索的准确性在各模型之间相似，预测与专家注释密切匹配。最后，我们展示了我们的 AI 驱动伤口大小估计框架 WoundAmbit 如何能够集成到定制的远程医疗系统中。我们的代码将在发表后在 GitHub 上发布。

**Summary**:

- (1): 本文背景探讨了慢性伤口对老年人和糖尿病患者的影响，强调传统手动测量伤口方法的局限性和不准确性。

- (2): 过去的方法主要是依赖手动测量和传统特征工程的机器学习，存在主观性强、侵入性以及缺乏标准化等问题。所提出的方法通过利用先进的深度学习模型，特别是基于变压器的模型，实现了自动化伤口大小估计，解决了现有方法缺乏自动化和准确性的问题，并且动机明确。

- (3): 本文的贡献在于系统性地基准测试多种先进的深度学习模型，并提出了一个有效的框架 WoundAmbit，能够实现伤口大小的自动估计并具备临床相关性。

- (4): 研究方法包括对12种先进的深度学习架构进行标准化训练、数据增强和评估，使用5折交叉验证，分析计算效率以及可解释性。

- (5): 该方法在伤口大小估计任务中表现出色，所有模型在推理速度上均能达到每秒处理一幅图像，预测结果与专家注释一致，支持其旨在实现远程伤口监测的目标。


## Non-negative Tensor Mixture Learning for Discrete Density Estimation
- **Url**: http://arxiv.org/abs/2405.18220v2
- **Authors**: ['Kazu Ghalamkari', 'Jesper Løve Hinrich', 'Morten Mørup']
- **Abstrat**: We present an expectation-maximization (EM) based unified framework for non-negative tensor decomposition that optimizes the Kullback-Leibler divergence. To avoid iterations in each M-step and learning rate tuning, we establish a general relationship between low-rank decompositions and many-body approximations. Using this connection, we exploit that the closed-form solution of the many-body approximation updates all parameters simultaneously in the M-step. Our framework offers not only a unified methodology for a variety of low-rank structures, including CP, Tucker, and Tensor Train decompositions, but also their mixtures. Notably, the weights of each low-rank tensor in the mixture can be learned from the data, which enables us to leverage the advantage of different low-rank structures without careful selection of the structure in advance. We empirically demonstrate that our framework overall provides superior generalization in terms of discrete density estimation and classification when compared to conventional tensor-based approaches.


**Translated Abstract**: 

我们提出了一种基于期望最大化（EM）的统一框架，用于非负张量分解，优化Kullback-Leibler散度。为了避免每个M步骤中的迭代和学习率的调优，我们建立了低秩分解与多体近似之间的一般关系。利用这一联系，我们利用多体近似的闭式解同时更新M步骤中的所有参数。我们的框架不仅为多种低秩结构（包括CP、Tucker和Tensor Train分解）提供了统一的方法论，还包括它们的混合体。值得注意的是，混合中每个低秩张量的权重可以从数据中学习，从而使我们能够利用不同低秩结构的优势，而无需提前仔细选择结构。我们实证证明，在离散密度估计和分类方面，与传统的基于张量的方法相比，我们的框架总体上提供了更优秀的泛化能力。 

**Summary**:

- (1): 本文研究了在信号处理、计算机视觉和数据挖掘等领域应用的张量低秩分解，尤其关注其在离散密度估计中的应用。

- (2): 过去的方法主要侧重于通过优化Frobenius范数进行张量低秩分解，存在缺乏统一的KL散度优化框架和可扩展性的问题。本文提出的办法通过建立低秩分解与多体近似之间的关系，提供了一个能够同时更新所有参数的闭式解，避免了需要手动调整低秩结构的复杂性，从而有效解决了这些问题。

- (3): 本文的贡献在于提出了一个统一的非负张量分解方法，能够自动学习混合低秩结构的权重，提供了灵活模型处理，并在离散密度估计上表现出优越的性能。

- (4): 本文采用基于期望最大化（EM）算法的框架，将EM算法与多体近似结合，建立了低秩分解与问题的有效解决方法，确保了算法的收敛性及计算复杂度的降低。

- (5): 本文在离散密度估计和分类任务中实现了优越的泛化性能，支持其目标，即提供更高效和灵活的张量分解方法。


# AGN
## Periodic variations of the first and second moments of broad Balmer emission lines from central accretion disks
- **Url**: http://arxiv.org/abs/2504.05531v1
- **Authors**: ['Zhang XueGuang']
- **Abstrat**: Broad emission line regions (BLRs) lying into central accretion disks has been widely accepted to explain the unique double-peaked broad emission lines in Active Galactic Nuclei (double-peaked BLAGNs). Here, accepted the accretion disk origin, periodic variations of central wavelength $\lambda_{0}$ (the first moment) and line width $\sigma$ (the second moment) of double-peaked broad emission lines are theoretically simulated and determined. Furthermore, through theoretically simulated periodicities of $T_{\lambda0}$ and $T_{\sigma}$ for variations of $\lambda_0$ and $\sigma$, periodicity ratio $R_{fs}$ of $T_{\lambda0}$ to $T_{\sigma}$ to be around 2 can be applied to support the spiral arms to be more preferred in BLRs lying into central accretion disks. Then, periodic variations of $\lambda_0$ and $\sigma$ are determined and shown in the known double-peaked BLAGN NGC1097, leading to the parameter $R_{fs}\sim2$, which can be applied as clues to support that the structure of spiral arms in disk-like BLRs in central accretion disk should be the most compelling interpretation to the variability of double-peaked broad H$\alpha$ in NGC1097. The results provide clean criteria to test accretion disk origins of double-peaked broad emission lines in AGN.


**Translated Abstract**: 

广泛的发射线区域（BLRs）位于中心吸积盘内，被广泛接受为解释活跃星系核（AGNs）中特有的双峰宽发射线的原因。本文基于吸积盘的起源，对双峰宽发射线的中心波长λ₀（第一动量）和线宽σ（第二动量）的周期性变化进行了理论模拟和确定。此外，通过对λ₀和σ的变化进行周期性模拟，得到的周期比R_fs约为2，支持在中心吸积盘内的BLRs中螺旋臂结构更为优越。然后，确定了已知双峰BLAGN NGC1097中的λ₀和σ的周期性变化，得到了R_fs∼2的参数，作为支持中心吸积盘中盘状BLRs中螺旋臂结构的最有力解释，以解释NGC1097中双峰宽Hα的变异性。结果提供了清晰的标准以检验双峰宽发射线的吸积盘起源。

**Summary**:

- (1): 本文研究背景为解释活跃星系核（AGNs）中的双峰宽发射线，其起源与中心吸积盘相关。

- (2): 过去的方法主要包括双黑洞模型和吸积盘模型，但双黑洞模型未能解释长时间的变动，并被否定。提出的方法通过证明双峰宽发射线的中心波长和线宽的周期性变化来支持吸积盘模型，克服了前述模型在解释和预测上的不足，因此具有良好的动机。

- (3): 本文的贡献在于通过周期性波长和线宽的理论模拟，提供证据支持中央吸积盘内BLRs中螺旋臂结构的存在，增强对双峰宽发射线起源的理解。

- (4): 研究方法为对双峰宽发射线的中心波长和线宽进行理论模拟，分析其周期性变化，并与已知的BLAGN NGC1097进行对比。

- (5): 该方法在确认了NGC1097中λ₀和σ的周期性变化的任务上取得了成功，获得的周期比R_fs∼2为支持其假设提供了证据，从而达到了研究目标。


# ALMA
## The Resolved Structure of a Low Metallicity Photodissociation Region
- **Url**: http://arxiv.org/abs/2504.06247v1
- **Authors**: ['Ilyse Y. Clark', 'Karin Sandstrom', 'Mark Wolfire', 'Alberto D. Bolatto', 'Jeremy Chastenet', 'Daniel A. Dale', 'Brandt A. L. Gaches', 'Simon C. O. Glover', 'Javier R. Goicoechea', 'Karl D. Gordon', 'Brent Groves', 'Lindsey Hands', 'Ralf Klessen', 'Ilse De Looze', 'J. D. T. Smith', 'Dries Van De Putte', 'Stefanie K. Walch']
- **Abstrat**: Photodissociation Regions (PDRs) are key to understanding the feedback processes that shape interstellar matter in galaxies. One important type of PDR is the interface between HII regions and molecular clouds, where far-ultraviolet (FUV) radiation from massive stars heats gas and dissociates molecules. Photochemical models predict that the C/CO transition occurs deeper in the PDR compared to the H/H2 transition in low-metallicity environments, increasing the extent of CO-dark H2 gas. This prediction has been difficult to test outside the Milky Way due to the lack of high spatial resolution observations tracing H2 and CO. This study examines a low-metallicity PDR in the N13 region of the Small Magellanic Cloud (SMC) where we spatially resolve the ionization front, the H2 dissociation front, and the C/CO transition using 12CO J=2-1, 3-2 and [CI] (1-0) observations from the Atacama Large Millimeter/sub-mm Array (ALMA) and near-infrared spectroscopy of H2 vibrational lines from the James Webb Space Telescope (JWST). Our analysis shows that the separation between the H/H2 and C/CO boundaries is approximately 0.043 +-0.013(stat.) +- 0.0036(syst.) pc (equivalent to 0."146 +- 0."042 (stat.) +-0."012 (syst.) at the SMC's distance of 62 kpc), defining the spatial extent of the CO-dark H2 region. Compared to our plane-parallel PDR models, we find that a constant pressure model matches the observed structure better than a constant density one. Overall, we find that the PDR model does well at predicting the extent of the CO-dark H2 layer in N13. This study represents the first resolved benchmark for low metallicity PDRs.


**Translated Abstract**: 

光解离区（PDRs）对理解银河系中星际物质的反馈过程至关重要。其重要类型是HII区域与分子云之间的界面，在此处，来自大质量恒星的远紫外光（FUV）辐射加热气体并解离分子。光化学模型预测在低金属度环境中，C/CO转变发生在PDR中比H/H2转变更深的位置，从而增加了CO暗H2气体的存在。这一预测在银河系外很难验证，原因在于缺乏能够追踪H2和CO的高空间分辨率观测。本研究考察了小麦哲伦云（Small Magellanic Cloud, SMC）N13区域的低金属度PDR，在此处我们通过12CO J=2-1、3-2和[CI]（1-0）观测以及詹姆斯·韦布太空望远镜（James Webb Space Telescope, JWST）对H2振动线的近红外光谱，空间解析了电离前沿、H2解离前沿和C/CO转变。我们的分析表明，H/H2和C/CO边界之间的分离约为0.043±0.013（统计）±0.0036（系统）pc（相当于SMC距离62 kpc时的0.′′146±0.′′042（统计）±0.′′012（系统）），定义了CO暗H2区域的空间范围。与我们的平行PDR模型相比，我们发现恒压模型更好地匹配观测结构，而非恒密度模型。总体而言，我们发现PDR模型很好地预测了N13中CO暗H2层的范围。这项研究代表了低金属度PDR的首个解析基准。

**Summary**:

- (1): 本文的研究背景是光解离区（PDRs）对星际物质的反馈过程的重要性，尤其是在低金属度环境下HII区域和分子云之间的相互作用。

- (2): 过去的方法主要依赖于平行的PDR模型，这些模型面临空间分辨率不足的问题，难以测试低金属度环境下的预测。本文的新方法使用ALMA和JWST的高空间分辨率观测，成功解析离子边界和分子变化，解决了先前模型的不足，具有良好的动机。

- (3): 本文的贡献在于首次成功地空间解析低金属度PDR的电离前沿、H2解离前沿和C/CO转变，提供了对CO暗H2区域的全新基准。

- (4): 研究方法包括使用Atacama Large Millimeter/sub-mm Array (ALMA)进行12CO和[CI]观测，以及利用James Webb Space Telescope (JWST)进行H2振动线的近红外光谱分析。

- (5): 本文在测量H/H2和C/CO边界分离距离方面取得了0.043 pc的准确值，所实现的性能支持了对低金属度PDR的研究目标，验证了CO暗H2层的预测。


## Observing radio transients with Phased ALMA: Pulses from the Galactic Centre magnetar
- **Url**: http://arxiv.org/abs/2504.06234v1
- **Authors**: ['J. Vera-Casanova', 'M. Cruces', 'K. Liu', 'J. Wongphexhauxsorn', 'C. A. Braga', 'M. Kramer', 'P. Torne', 'P. Limaye', 'M. C. Espinoza-Dupouy', 'L. Rodriguez']
- **Abstrat**: Radio transients, such as pulsars and Fast Radio Bursts (FRBs), are primarily detected at centimetre radio wavelengths, where higher luminosities are found. However, observations of sources in dense environments are heavily affected by propagation effects which may hinder a detection. Millimetre wave observations bypass this complication but require the largest radio telescopes to compensate for the lower flux densities. When used in phased mode, the ALMA radio telescope provides an equivalent dish size of 84m, being the most sensitive instrument at mm/sub mm. With its high time resolution it offers a unique opportunity to study radio transients in an unexplored window. We study the Galactic Centre (GC) magnetar, PSR J1745$-$2900, as a laboratory for magnetars in complex magneto-turbulent environments and to link with FRBs. We showcase the potential of ALMA in phased mode to observe radio transients and to achieve, for some sources, the first ever detections outside the cm wave range. We studied the GC magnetar using ALMA archival data of Sgr A* at Band 3 from the 2017 GMVA campaign. We searched in intensity and classified the pulses based on their circular and linear polarisation properties and arrival phase. We detected eight pulses with energies in the range of 10$^{29}$ erg. We constructed its cumulative energy distribution and we fit a power law, where the event rate scales with energy as $R \propto E^{\gamma}$. The result is an exponent of $\gamma = -2.4 \pm 0.1$. With the $\gamma -$value and the system properties of phased ALMA, we estimate that over 160 known pulsars could be detected by ALMA. For repeating FRBs, observing during their peak activity window could lead to several detections. We expect that ALMA's lower frequency bands with polarisation capabilities, will serve as a pioneer on mm wave searches for pulsars and to study complex environments involving radio transients.


**Translated Abstract**: 
无线电瞬态，例如脉冲星和快速无线电爆发（FRBs），主要在厘米波段下被探测，那里发现了更高的光度。然而，密集环境中源的观测受到传播效应的严重影响，这可能会妨碍探测。毫米波观测可以绕过这个问题，但需要最大的无线电望远镜来补偿较低的通量密度。当作为相位阵列使用时，ALMA无线电望远镜提供了84米的等效盘面大小，使其成为毫米/亚毫米波长下最灵敏的仪器。结合其高时间分辨率，它为在一个未被探索的窗口研究无线电瞬态提供了独特的机会。我们研究了银河中心（GC）磁星PSR J1745 $-$2900，作为在复杂的磁力湍流环境中研究磁星的实验室，并与FRBs建立联系。我们展示了ALMA在相位模式下观察无线电瞬态的潜力，并首次在某些源中实现了毫米波段下的探测。我们利用2017 GMVA活动中的Sgr A*的ALMA存档数据研究GC磁星。我们根据其圆极化和线极化特性及到达相位对脉冲进行强度搜索和分类。我们探测到八个脉冲，能量在10$^{29}$ erg的范围内。我们构建了其累积能量分布并拟合了一个幂律，其中事件率与能量的关系为$R \propto E^{\gamma}$，结果为$\gamma = -2.4 \pm 0.1$。根据$\gamma$值和相位ALMA的系统特性，我们估计大约有160个已知的脉冲星可以被ALMA探测到。对于重复的FRBs，在其活动高峰期观察可能导致几次探测。我们期望ALMA的低频带和极化能力将成为毫米波下脉冲星搜寻的先锋，并研究涉及无线电瞬态的复杂环境。

**Summary**:

- (1): 本文研究的背景是无线电瞬态（如脉冲星和FRBs）在复杂的密集环境中探测的挑战，特别是在银河中心的磁星PSR J1745 $-$2900的观测。

- (2): 过去主要使用厘米波的无线电望远镜进行观测，这些方法受到传播效应（如散射和色散）的严重影响。与之不同，提出使用相位模式的ALMA进行毫米波观测，从而避免了这些问题，并提升了探测灵敏度。

- (3): 本文的贡献在于展示ALMA在毫米波段探测无线电瞬态的潜力，通过对GC磁星的观测实现了首次在非厘米波段的探测，并提供了对脉冲星和重复FRB的潜在探测估算。

- (4): 本文的方法论是利用ALMA的存档数据对PSR J1745 $-$2900进行强度搜索，并分类脉冲的极化特性及到达相位，构建累积能量分布并拟合幂律。

- (5): 这项研究在探测GC磁星的脉冲上取得了成功，检测到了八个脉冲，能量在10$^{29}$ erg范围内，结果支持了它们可以探测到超过160个已知脉冲星的目标。


## A deep search for Complex Organic Molecules toward the protoplanetary disk of V883 Ori
- **Url**: http://arxiv.org/abs/2504.06005v1
- **Authors**: ['Abubakar M. A. Fadul', 'Kamber R. Schwarz', "Merel L. R. van 't Hoff", 'Jane Huang', 'Jennifer B. Bergner', 'Tushar Suhasaria', 'Jenny K. Calahan']
- **Abstrat**: Complex Organic Molecules (COMs) in the form of prebiotic molecules are potentially building blocks of life. Using Atacama Large Millimeter/submillimeter Array (ALMA) Band 7 observations in spectral scanning mode, we carried out a deep search for COMs within the disk of V883 Ori, covering frequency ranges of $\sim$ 348 - 366 GHz. V883 Ori is an FUor object currently undergoing an accretion burst, which increases its luminosity and consequently increases the temperature of the surrounding protoplanetary disk, facilitating the detection of COMs in the gas phase. We identified 26 molecules, including 14 COMs and 12 other molecules, with first detection in this source of the molecules: CH3OD, H2C17O, and H213CO. We searched for multiple nitrogen-bearing COMs, as CH3CN had been the only nitrogen-bearing COM that has been identified so far in this source. We also detected CH3CN, and tentatively detect CH3CH2CN, CH2CHCN, CH3OCN, CH3NCO, and NH2CHO. We compared the abundances relative to CH3OH with those in the handful of objects with previous detections of these species: the Class 0 protostars IRAS 16293-2422 A, IRAS 16293-2422 B and B1-c, the high-mass star-forming region Sagittarius B2 (North), the Solar System comet 67P/Churyumov-Gerasimenko, and the protoplanetary disk of Oph-IRS 48. We report $\sim$ 1 to 3 orders of magnitude higher abundances compared to Class 0 protostars and $\sim$ 1 to 3 orders of magnitude lower abundances compared to the protoplanetary disk, Sagittarius B2 (North), and 67P/C-G. These results indicate that the protoplanetary disk phase could contribute to build up of COMs.


**Translated Abstract**: 

复杂有机分子（COMs）以前生物分子的形式存在，可能是生命的构建块。利用阿塔卡马大型毫米/亚毫米阵列（ALMA）第7波段观测，我们在V883 Ori的盘面内进行了深度搜索，覆盖大约348 - 366 GHz的频率范围。V883 Ori是一个FUor天体，当前正经历电流爆发，导致其亮度增加，从而提高周围原行星盘的温度，促进了气相中COMs的探测。我们识别了26种分子，其中包括14种COMs和12种其他分子，并首次在此源中发现了分子：CH3OD、H2C17O和H213CO。我们还搜索了多种含氮COMs，因为到目前为止，CH3CN是此源中唯一识别的含氮COM。我们还探测到CH3CN，并初步探测CH3CH2CN、CH2CHCN、CH3OCN、CH3NCO和NH2CHO。我们将相对于CH3OH的丰度与在先前检测到这些物质的少数天体，例如Class 0原恒星IRAS 16293-2422 A、IRAS 16293-2422 B和B1-c、高质量恒星形成区域Sagittarius B2（North）、太阳系彗星67P/Churyumov-Gerasimenko以及Oph-IRS 48的原行星盘进行了比较。我们报告相较于Class 0原恒星，丰度高出约1到3个数量级，而与原行星盘、Sagittarius B2（North）和67P/C-G相比，丰度低出约1到3个数量级。这些结果表明，原行星盘阶段可能对COMs的积累有贡献。

**Summary**:

- (1): 本文的研究背景为复杂有机分子（COMs）是潜在的生命构建块，研究其在原行星盘——特别是V883 Ori辐射使其更容易被探测。

- (2): 过去的研究主要依赖于低频或较为粗略的观测方法，在识别多个COMs时存在不足。本文采用ALMA的高分辨率光谱扫描方法，克服了这些不足，具有较强的动机来深入探索特定环境下的COMs。

- (3): 本文的贡献在于首次在V883 Ori之中检测到了26种分子（包括14种COMs），并报告了含氮COMs（如CH3CN等）的新探测，提高了我们对该特定环境下COMs丰度的理解。

- (4): 本文提出的研究方法使用ALMA进行高频率范围的深度光谱扫描，以识别和量化在V883 Ori盘内的COMs。

- (5): 该方法在识别V883 Ori盘内的复杂有机分子方面取得成功，表现为相对于其它已知天体丰度的数据支持其研究目标。


## PASSAGES: The Discovery of a Strongly Lensed Protocluster Core Candidate at Cosmic Noon
- **Url**: http://arxiv.org/abs/2504.05617v1
- **Authors**: ['Nicholas Foo', 'Kevin C. Harrington', 'Brenda Frye', 'Patrick S. Kamieneski', 'Min S. Yun', 'Massimo Pascale', 'Ilsang Yoon', 'Allison Noble', 'Rogier A. Windhorst', 'Seth H. Cohen', 'James D. Lowenthal', 'Melanie Kaasinen', 'Belén Alcalde Pampliega', 'Daizhong Liu', 'Olivia Cooper', 'Carlos Garcia Diaz', 'Anastasio Diaz', 'Jose Diego', 'Nikhil Garuda', 'Eric F. Jiménez-Andrade', 'Reagen Leimbach', 'Amit Vishwas', 'Q. Daniel Wang', 'Dazhi Zhou', 'Adi Zitrin']
- **Abstrat**: Investigating the processes by which galaxies rapidly build up their stellar mass during the peak of their star formation ($z=2$--$3$) is crucial to advancing our understanding of the assembly of large-scale structures. We report the discovery of one of the most gas- and dust-rich protocluster core candidates, PJ0846+15 (J0846), from the Planck All-Sky Survey to Analyze Gravitationally lensed Extreme Starbursts (PASSAGES) sample. The exceedingly high total apparent star formation rate of up to ($\mu$SFR) $\sim 93600\,\mathrm{M}_\odot\,\text{yr}^{-1}$ is a result of a foreground cluster lens magnifying at least 11 dusty star-forming galaxies between $z=2.660$--$2.669$. Atacama Large Millimeter Array (ALMA) observations revealed 18 CO(3--2) emission-line detections, some of which are multiply-imaged systems, lensed by a foreground cluster at $z=0.77$. We present the first multi-wavelength characterization of this field, constructing a lens model that predicts that these 11 systems (magnification factor, $\mu\simeq1.5$--$25$) are contained within a projected physical extent of $280\times150$ kpc, with a velocity dispersion of $\sigma_{v}=246\pm72$ km s$^{-1}$ and a total intrinsic star formation rate of up to (SFR) $\sim10400\,\mathrm{M}_\odot\,\text{yr}^{-1}$. J0846 is one of the most unique, lensed, protocluster core candidates ever reported, and offers a magnified glimpse into the rapid buildup of massive local galaxy clusters.


**Translated Abstract**: 

研究在宇宙午间（红移 $z=2$--$3$）时，星系快速积累恒星质量的过程，对于推进我们对大规模结构组装的理解至关重要。我们报告了从普朗克全天域调查分析重力透镜极端星暴（PASSAGES）样本中发现的一种最富含气体和尘埃的原星团核心候选体 PJ0846+15（J0846）。由于前景星团透镜放大了至少 11 个红移在 $z=2.660$--$2.669$ 之间的尘埃星形成星系，导致其总表观星形成率高达（$\mu$SFR）$\sim 93600\,\mathrm{M}_\odot\,\text{yr}^{-1}$。阿塔卡马大型毫米波阵列（ALMA）观测到 18 处 CO(3--2) 辐射线，部分为多重成像系统，由前景星团（红移 $z=0.77$）透镜放大。我们首次对该领域进行多波段表征，构建了透镜模型，预测这 11 个系统（放大因子 $\mu\simeq1.5$--$25$）位于约 280×150 kpc 的物理范围内，速度色散为 $\sigma_{v}=246\pm72$ km s$^{-1}$，总内在星形成率可达（SFR）$\sim 10400\,\mathrm{M}_\odot\,\text{yr}^{-1}$。J0846 是迄今报告的最独特的重力透镜原星团核心候选体之一，提供了对大型局部星系团快速建立的放大视角。

**Summary**:

- (1): 本文研究了在宇宙午间（红移 $z=2$--$3$）期间星系如何迅速积累恒星质量的过程，旨在提高我们对大规模结构组成的理解。

- (2): 过去的方法主要包括寻找发射Lyman α的星系、Lyman断裂星系、Hα发射源和活跃星系核等，但许多报道的原星团候选体未显示出明显的重力透镜效应。因此，本文的创新在于从普朗克全天域调查中筛选出重力透镜极端星暴（PASSAGES）样本，采用透镜建模技术，有效检测到更多的重力透镜星系，克服了以往方法的局限性。

- (3): 本文的贡献在于发现了一种新的原星团核心候选体 J0846，它展现了极高的星形成率，并提供了放大观察大型星系团形成的机会。

- (4): 本文采用多波段观测和透镜建模法，结合阿塔卡马大型毫米波阵列（ALMA）数据，构建了透镜模型，分析这些重力透镜星系的物理特性。

- (5): 本文方法在研究中实现了 $\sim 93600\,\mathrm{M}_\odot\,\text{yr}^{-1}$ 的表观星形成率，和 $\sim 10400\,\mathrm{M}_\odot\,\text{yr}^{-1}$ 的总内在星形成率，表现出色，支持了对原星团形成过程的目标。


## The Galactic-Centre Arms inferred from ACES (ALMA CMZ Exploration Survey)
- **Url**: http://arxiv.org/abs/2504.03331v2
- **Authors**: ['Y. Sofue', 'Tomo. Oka', 'S. N. Longmore', 'D. Walker', 'A. Ginsburg', 'J. D. Henshaw', 'J. Bally', 'A. T. Barnes', 'C. Battersby', 'L. Colzi', 'P. Ho', 'I. Jimenez-Serra', 'J. M. D. Kruijssen', 'E. Mills', 'M. A. Petkova', 'M. C. Sormani', 'J. Wallace', 'J. Armijos-Abendano', 'K. M. Dutkowska', 'R. Enokiya', 'Y. Fukui', 'P. Garcia', 'A. Guzman', 'C. Henkel', 'P. -Y. Hsieh', 'Y. Hu', 'K. Immer', 'D. Jeff', 'R. S. Klessen', 'K. Kohno', 'M. R. Krumholz', 'D. Lipman', 'S. Martin', 'M. R. Morris', 'F. Nogueras-Lara', 'M. Nonhebel', 'J. Otto', 'J. E. Pineda', 'M. A. Requena-Torres', 'V. M. Rivilla', 'D. Riquelme-Vasquez', 'A. Sanchez-Monge', 'M. G. Santa-Maria', 'H. A. Smith', 'T. S. Tanvir', 'V. Tolls', 'Q. D. Wang']
- **Abstrat**: Analyzing longitude-velocity diagrams (LVDs) in the CS(J=2-1) and H13CN(J=1-0) molecular lines from the internal release data of the ALMA Central-Molecular-Zone Exploration Survey (ACES) and in the 13CO (J=1-0) line from the Nobeyama Galactic-Centre (GC) survey, we identify six GC Arms as prominent straight LV ridges. In addition to the currently known Arms I to IV, we identify a new inner arm, Arm V, and further highlight the circum-nuclear disc (CND) as Arm VI. Integrated intensity maps of the Arms on the sky suggest that most of the Arms compose ring-like structures inclined from the Galactic plane. We determine the radii (curvatures) of the Arms using the velocity-gradient ($dv/dl$) method, assuming that the arms are rotating on circular orbits at a constant velocity of $\sim 150$ km/s. We show that Arms I and II compose the main ring structure of the CMZ with radii $\sim 100$--120 pc; Arm III is a dense arm 42 pc from the GC; Arm IV is a clear and narrow arm 20 pc from the GC; and Arm V is a faint, long arm of 8.2 pc radius. We show that the circum-nuclear disc (CND) composes the sixth arm, Arm VI, of radius $\sim 2.3$ pc associated with bifurcated spiral fins. We also discuss the association of the 20- and 50-km/s clouds with these Arms. The radii of the arms fall on an empirical relation $R\sim 630 (2/5)^N$ for $N=1$ (Arm I) to 6 (VI), suggesting either discrete rings or a logarithmic spiral with pitch angle $\sim 22^\circ$. The vertical full extent of the arm increases with radius and is represented by $z\sim 0.7 (R/1 {\rm pc})^{0.7}$ pc. The tilt angle of the arms from the Galactic plane, or the warping, increases rapidly toward the GC.


**Translated Abstract**: 

通过分析来自ALMA中央分子区探索调查（ACES）的CS(J=2-1)和H13CN(J=1-0)分子线的经纬度-速度图（LVD），以及来自Nobeyama银河中心（GC）调查的13CO (J=1-0)线数据，我们识别出了六条银河中心臂作为显著的直线LV轮廓。除了目前已知的I至IV臂外，我们还识别出一个新的内臂，即V臂，并进一步强调环核盘（CND）作为VI臂。天空上臂的综合强度图表明，大多数臂构成了倾斜于银河平面的环状结构。我们使用速度梯度（$dv/dl$）方法确定了这些臂的半径（曲率），假设臂以约150 km/s的恒定速度沿圆形轨道旋转。我们展示了I和II臂组成CMZ的主要环状结构，半径约为100-120 pc；III臂位于离GC 42 pc处，是一条密集的臂；IV臂是清晰且狭窄的臂，距离GC 20 pc；而V臂是一条模糊的、长达8.2 pc半径的臂。我们还表明环核盘（CND）构成第六臂VI，半径约为2.3 pc，与双叉螺旋翅膀相关。我们还讨论了与这些臂相关的20和50 km/s云的关联。这些臂的半径符合经验关系$R\sim 630 (2/5)^N$，对于$N=1$（I臂）到6（VI臂），暗示离散环或螺旋结构，倾角约为22度。随着半径变化，臂的垂直全高也在增加，表现为$z\sim 0.7 (R/1 {\rm pc})^{0.7}$ pc。臂相对于银河平面的倾斜角或翘曲，向GC迅速增加。

**Summary**:

- (1): 本文的研究背景是揭示银河中央分子区（CMZ）的三维结构，通过分析与银河旋转相关的经纬度-速度图（LVD）。

- (2): 过去的方法依赖于Kinematic分析和已知的LVD结构，存在对内部结构理解不全面的问题。本文提出的分析方法利用ALMA的高分辨率数据，能够精确识别出更多的臂，解决了过去方法对复杂内部结构无法充分解析的局限。

- (3): 本文的贡献在于识别了六条银河中心臂，包括新发现的V臂和VI臂，并量化了这些臂的半径及其与云的关联，丰富了对CMZ结构的理解。

- (4): 本文的研究方法是结合多种分子线数据（如13CO和HCN），通过速度梯度方法分析得出臂的几何和动力学特性，以探讨其三维结构。

- (5): 本文的方法在确定臂的空间分布及其结构方面取得了显著成果，表现出这些臂的均匀性和特征，能够支持探索CMZ的目标和结构模型构建。

